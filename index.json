[{"content":"按优先级整理：\n 实现UserMapper.java中定义的方法与UserMapper.xml中的sql实现间的相互跳转。  目前是无法实现这个效果的，我需要寻找解决方案，并验证这些解决方案，并整理方案的使用方法。\n该需求的产生，是因为我们希望在UserMapper.java代码中看到某个方法对应的SQL，为了达到这个效果，我们在代码中使用了@Select、@Delete、@Update等注解，我个人认为这些注解只只适合SQL比较简单的情况，一旦SQL复杂了，阅读@Select、@Delete、@Update中的SQL将是灾难级别的。\n如果相应的代码写在UserMapper.xml文件中，SQL阅读起来就不会那么难受了。所以我们目前需要的就是一个快速查看定义和兼顾SQL可阅读性的方案。\n实现UserMapper.xml文件的自动排版。目前的话在UserMappr.xml文件中ctrl+arl+l快捷键是无法生效的，我以往的开发流程是：在sql美化工具中美化我的SQL，然后贴到UserMapper.xml文件中，我希望可以直接将sql从navicat等工具贴到userMapper.xml文件中，然后进行格式化。  去掉上图中的黄色提示。我从事开发以来，上面的提示是一直存在的，但是我从来没有下定角色将它们给干点，我计划这次将它们一起给干掉。  ","description":"","id":0,"section":"notes","tags":null,"title":"00.本次实验想达成的目标","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/00.%E6%9C%AC%E6%AC%A1%E5%AE%9E%E9%AA%8C%E6%83%B3%E8%BE%BE%E6%88%90%E7%9A%84%E7%9B%AE%E6%A0%87/"},{"content":"本次实验我准备使用H2数据库，虽然我现在有足够多的脚本快速启动一个MySQL、PG，但是这毕竟会增加我下次启动该项目时的时间成本。H2数据库用于技术验证是非常不错的，可以将代码和数据库集中在一个项目中，很有研究价值，所以我决定使用H2数据库，顺便积累这个数据的使用经验。\n准备工作 引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   进行配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  spring:application:name:mybatisdatasource:schema:classpath:h2/schema.sqldata:classpath:h2/data.sqlusername:sanpassword:driver-class-name:org.h2.Driverurl:jdbc:h2:file:~/testh2:console:enabled:truepath:/h2-consolesettings:web-allow-others:truetrace:truemybatis-plus:mapper-locations:classpath:mapper/*Mapper.xml  开发Entity和Mapper User.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package fun.junjie.mybatis.entity; import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; @Data @Builder @NoArgsConstructor @AllArgsConstructor @TableName(\u0026#34;t_user\u0026#34;) public class User { /** * 主键 */ private String id; /** * 用户名 */ private String name; }   UserMapper.java\n1 2 3 4 5 6 7 8 9 10 11 12  package fun.junjie.mybatis.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import fun.junjie.mybatis.entity.User; import org.springframework.stereotype.Repository; @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { }   准备schema.sql和data.sql schema.sql\n1 2 3 4 5 6 7 8  DROPTABLEt_user;CREATETABLEt_user(idvarchar(100)PRIMARYKEYNOTNULL,namevarchar(100)NOTNULL);  data.sql\n1 2 3  INSERTINTOt_userVALUES(\u0026#39;1000\u0026#39;,\u0026#39;zhansan\u0026#39;)  测试工作 测试MyBatis-Plus集成是否生效 测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package fun.junjie.mybatis.mapper; import fun.junjie.mybatis.entity.User; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class UserMapperTest { @Autowired private UserMapper userMapper; @Test void selectById() { User user = userMapper.selectById(\u0026#34;1000\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } }   断点发现，user正确的获取到值了，说明h2、MyBatis的集成是有效的。\n测试mapper.xml文件能否正常使用 修改UserMapper文件，代码如下：\n1 2 3 4 5 6 7 8  @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { User selectByIdCustom(String userId); }   开发相应的mapper.xml文件，代码如下：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;fun.junjie.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectByIdCustom\u0026#34; resultType=\u0026#34;fun.junjie.mybatis.entity.User\u0026#34;\u0026gt; SELECT * FROM t_user WHERE id = #{userId} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   开发相应的测试方法：\n1 2 3 4 5 6 7  @Test void selectByIdCustom() { User user = userMapper.selectByIdCustom(\u0026#34;1000\u0026#34;); System.out.println(\u0026#34;\u0026#34;); }   断点发现，最后获取的数据是我需要的。\n截止到目前，我已经完成了基础的实验环境搭建，接下将一一实现我的实验目标。\n","description":"","id":1,"section":"notes","tags":null,"title":"01.配置MyBatis-Plus测试环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/01.%E9%85%8D%E7%BD%AEmybatis-plus%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/"},{"content":"Idea安装Free MyBatis Plugin插件即可\n参考资料  idea中生成mapper xml文件，快速从代码跳转到mapper及从mapper返回代码的插件安装  ","description":"","id":2,"section":"notes","tags":null,"title":"02.实现Mapper.java与Mapper.xml中方法的跳转","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/02.%E5%AE%9E%E7%8E%B0mapper.java%E4%B8%8Emapper.xml%E4%B8%AD%E6%96%B9%E6%B3%95%E7%9A%84%E8%B7%B3%E8%BD%AC/"},{"content":" 如图打开数据源视图   如图添加一个H2数据源  直接将application.yml中的url填写到URL处，界面会发生变化，将用户名改为和application.yml文件中的一致（我目前不知道这个用户名有什么用）  最后配置一下SQL Dialect就可以愉快的使用ctrl + art + l快捷键了。  参考资料  IDEA配置Database数据源 IDEA 为 sql 文件配置方言 IntelliJ IDEA 如何配置数据源  ","description":"","id":3,"section":"notes","tags":null,"title":"03.实现mapper.xml文件的格式化及去除黄色警告","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/03.%E5%AE%9E%E7%8E%B0mapper.xml%E6%96%87%E4%BB%B6%E7%9A%84%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8F%8A%E5%8E%BB%E9%99%A4%E9%BB%84%E8%89%B2%E8%AD%A6%E5%91%8A/"},{"content":"AutoConfigurationPackage注解代码如下：\n1 2 3 4  @Import(AutoConfigurationPackages.Registrar.class) public @interface AutoConfigurationPackage {}   这个注解的功能是：\n 利用Register给容器导入一系列组件 将指定的包下的所有组件导入进来（MainApplication所在的包下）  这个注解存在的意义是，一个一个的导入组件，代码量太大了，而且不太优雅。\n@Import(AutoConfigurationImportSelector.class)这行代码做了什么？\n  利用getAutoConfigurationEntry(annotationMetadata)给容器中批量导入一些组件\n  调用List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类\n  利用工厂加载Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; loadSpringFactories(@Nullable ClassLoader classLoader)得到所有的组件\n  从META-INF/spring.factories位置来加载一个文件。\n 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories    ","description":"","id":4,"section":"notes","tags":null,"title":"@AutoConfigurationPackage注解的意义","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/autoconfigurationpackage%E6%B3%A8%E8%A7%A3%E7%9A%84%E6%84%8F%E4%B9%89/"},{"content":"如下代码：\n1 2 3 4 5 6 7 8  @Bean @ConditionalOnBean(MultipartResolver.class) @ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) public MultipartResolver multipartResolver(MultipartResolver resolver) { return resolver; }   这段配置的含义是这样的，如果容器中有dispatcherServlet的bean，容器中有MultipartResolver.class的bean，那么我们将创造一个名为multipartResolver的Bean。具体的操作是从容器中注入的MultipartResolver.class的Bean，返回一个名为multipartResolver的Bean。\n","description":"","id":5,"section":"notes","tags":null,"title":"@Bean配置时一段经典的源码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/bean%E9%85%8D%E7%BD%AE%E6%97%B6%E4%B8%80%E6%AE%B5%E7%BB%8F%E5%85%B8%E7%9A%84%E6%BA%90%E7%A0%81/"},{"content":"我之所以多这个注解感兴趣，是因为最近开到SpringBootApplication这个注解继承的注解就配置了Filter。\n我认为相关的知识我使用的频率非常的低。\nexcludeFilters 代码如下：\n1 2 3 4 5  @ComponentScan(value = \u0026#34;fun.junjie.demo\u0026#34;, excludeFilters = { @Filter(type = FilterType.ANNOTATION, classes = {Controller.class}) })   @ComponentScan的value参数指明了需要扫描的包，excludeFilters指明了扫描的时候排除哪些类。\n@Filter的type指明了类中带有某个注解则不进行注入，classes指明了具体时哪个注解。\nincludeFilters 这个注解说明了扫描的时候，只包含哪些类。\n常用的规则 ANNOTATION：注解\nASSIGNABLE_TYPE：指定的类型\nASPECT：使用aspect的表达式（不理解，也从来没用过）\nREGEX：使用正则的表达式\nCUSTOM：使用自定义规则\n开发自己的TypeFilter 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class MyTypeFilter implements TypeFilter { @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { /* matadataReader：读取到的当前正在扫描的类的信息 metadataReaderFactory：可以获取到其他任何类的信息 */ // 获取当前类注解的信息  metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的信息  metadataReader.getClassMetadata(); // 获取当前类资源（类的路径）  metadataReader.getResource(); return false; } }   其他知识  如果是jdk8，@ComponentScan组件可以在一个类中重复使用多次  在实践中，我发现因为SpringBootApplication中使用了该注解，所以DemoApplication不能再使用该注解了。看样子继承会影响到重复性。\n如果不是jdk8，可以使用@ComponentScans策略来实现相同的效果  1 2 3 4 5 6 7 8  @ComponentScans( value={ @ComponentScan(value=\u0026#34;fun.junjie1\u0026#34;, includeFilters = {}), @ComponentScan(value=\u0026#34;fun.junjie2\u0026#34;, includeFilters = {}) } )   ","description":"","id":6,"section":"notes","tags":null,"title":"@ComponentScan中使用filter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/componentscan%E4%B8%AD%E4%BD%BF%E7%94%A8filter/"},{"content":"SpringBoot中，更多的是使用已经高度开发的一系列条件注解，第一次接触Spring的条件注解，没想到还需要写实现类。\n1 2 3 4 5 6 7 8 9  @Conditional({ WindowCondition.class }) @Bean public XXX xxx(){ return new XXX(); }   Condition的实现类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class WindowCondition implements Condition { @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) { /* conditionContext：判断条件能使用的上下文（环境） annotatedTypeMetadata：注释信息 */ // 获取到ioc使用的beanFactory  ConfigurableListableBeanFactory beanFactory = conditionContext.getBeanFactory(); // 获取类加载器  ClassLoader classLoader = conditionContext.getClassLoader(); // 获取当前环境信息  Environment environment = conditionContext.getEnvironment(); // 获取到bean定义的注册类（我以为会通过这个类注入Bean，看样子是我想多了）  // 支持定义一个Bean  // 支持移除一个bean  BeanDefinitionRegistry registry = conditionContext.getRegistry(); return false; } }   我们也可以手动指定os.name：\n -Dos.name=linux ","description":"","id":7,"section":"notes","tags":null,"title":"@Conditional注解实现条件注入","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/conditional%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5/"},{"content":"我整理这部分资料，仅仅是查漏补缺，补充一些我不太熟悉的知识。\nSpirng的宽松绑定规则 实体中的hostName可以绑定如下配置：\n mail.hostName mail.hostname mail.host_name mail.host-name mail.HOSTNAME 三种方式将一个Bean注入到Spring Context中   使用@Component注解（前提能够被@ComponentScan扫描）\n  通过Java Configuration实现相同的效果（要求PropertiesConfig可以被扫描到）\n  1 2 3 4 5 6 7 8 9  @Configuration class PropertiesConfig() { @Bean public MailModuleProperties mailModuleProperties() { return new MailModuleProperties(); } }   在@EnableConfigurationProperties注解中指定参数（这种方法我用的非常少）  1 2 3 4 5 6 7  @Configuration @EnableConfigurationProperties(MailModuleProperties.class) class PropertiesConfig() { }   至于如何选择这些方法，网上文章的有一些建议，但是我目前不计划采纳这些建议。\nignoreInvalidFields、ignoreUnknownFields配置 这两个属性配置@ConfigurationProperties中，我觉得是有一定价值的，毕竟开发该属性配置信息的人最清楚如果配置文件中的配置值非法或者未知，该如何处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Data @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreInvalidFields=true) public class MailModuleProperties{ private Boolean enabled = Boolean.TRUE; } @Data @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreUnknownFields=false) public class MailModuleProperties{ private Boolean enabled = Boolean.TRUE; }   备注：ignoreUnknownFields未来可能会被删除，存在两个Properties绑定到一个命名空间上，其中一个类知道某个属性，而另一个不知道。（额，好吧）\n支持@Validate 1 2 3 4 5 6 7 8 9  @Data @Validate @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreUnknownFields=false) public class MailModuleProperties{ @NotNull private Boolean enabled; }   Duration与DataSize SpringBoot内置支持从配置参数中解析durations和data size。duration和data size单位如下：\n ns: 纳秒 us：微秒 ms：毫秒 s ：秒 m ：分 h ：时 d ：天 B KB MB GB TB 配置案例如下：\nmyapp.mail.pause-between-mails = 5s myapp.mail.max-attachment-size = 1MB 对应的Java代码如下：\n1 2 3 4 5 6 7 8 9 10  import org.springframework.util.unit.DataSize; import java.time.Duration; @DurationUnit(ChronoUnit.SECONDS) private Duration pauseBetweenMails; @DataSizeUnit(DataUnit.MEGABYES) private DataSize maxAttachmentSize = DataSize.ofMegabytes(2);   Duration和DataSize这些类我几乎没有用过，这也说明我开发的复杂业务逻辑还是太少了，对JAVA了解的还仅仅只是一个皮毛。\n使用Spring Boot Configuration Processor完成自动补全 添加依赖如下：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   需要重新Build一下（对应到Idea中就是重新启动一下），这时我们在编辑application.yml时就会有自动提示了。\nBuild后会生成一份json文件，相关的提示信息就存储在这份json文件中：\n我一直在用这个依赖，但是从来不知道我们的自动提示功能是有这个依赖提供的，而且这个依赖还可以对我们自己开发的配置进行自动提示。\n编辑配置属性为Deprecated 案例代码如下：\n1 2 3 4 5 6  @DeprecatedConfigurationProperty(reason = \u0026#34;No Need Now\u0026#34;, replacement = \u0026#34;none\u0026#34;) public String getDefaultSubjects() { }   比较糟心的是，这个注解只能注册到方法上，为了使用这个注解我们还需要开发一个Getter方法，使用lombok时非常的不爽。\n@ConfigurationProperties注解不支持SpEL表达式 我目前对SpEL表达式的需求还比较少，先持续关注一些这个问题。\n@ConfigurationProperties、@PropertySource @ConfigurationProperties支持和@PropertySource结合，读取指定文件，博客上说只能用于properties文件，但是我记得在我的实验中，貌似也是支持yaml文件的。\n我目前对该技术没有太大的需求，所以暂时不研究。\n@ConfigurationProperties与@Value的对比 @Value与@ConfigurationProperties涉及到的源码 1 2 3 4 5 6 7 8 9  @Value org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor @ConfigurationProperties org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor   这是好东西，深入学习SpringBoot是没有办法避免研究这些的。\n参考资料   @ConfigurationProperties 注解使用姿势，这一篇就够了\n  SpringBoot配置中@ConfigurationProperties和@Value的区别\n  ","description":"","id":8,"section":"notes","tags":null,"title":"@ConfigurationProperties注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/configurationproperties%E6%B3%A8%E8%A7%A3/"},{"content":"@ImportResource多用在项目中存在老旧的Spring项目（我目前基本上没有遇到过这种情况）\n1 2 3  @ImportResource(\u0026#34;classpath:beans.xml\u0026#34;)   我使用这两个注解的次数非常的少。\n","description":"","id":9,"section":"notes","tags":null,"title":"@ImportResource导入一个bean.xml文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/importresource%E5%AF%BC%E5%85%A5%E4%B8%80%E4%B8%AAbean.xml%E6%96%87%E4%BB%B6/"},{"content":"@Import创建出来的组件，组件的名称为其全类名。这个注解可以用在将第三方的Bean注册到Spring Context。这种方式导入相对于Java Config来说更方便。\n1 2 3  @Import({User.class, DBHelper.class})   @Import可以与ImportSelector结合使用。ImportSelector为一个接口，包含一个selectImports方法，该方法返回一个全类名数组，该数组代表的对象将会被注入到容器中。\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class MyImportSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { // importingClassMetadata当前标注@Import注解类的所有注解信息  return new String[]{ \u0026#34;demo.xxx.XXX\u0026#34;, \u0026#34;demo.xxx.YYY\u0026#34;, }; } }   @Import可以与ImportBeanDefinitionRegistrar结合使用，实现ImportBeanDefinitionRegistrar接口，在registerBeanDefinitions方法中直接通过beanDefinitionRegistry完成Bean的注入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry beanDefinitionRegistry) { /* beanDefinitionRegistry：BeanDefinition注册类，把所有需要注入到容器中的bean，调用 beanDefinitionRegistry.registerBeanDefinition收工注册进来 */ if (beanDefinitionRegistry.containsBeanDefinition(\u0026#34;red\u0026#34;)) { beanDefinitionRegistry.registerBeanDefinition(\u0026#34;red\u0026#34;, new RootBeanDefinition(Weight.class)); } } }   ","description":"","id":10,"section":"notes","tags":null,"title":"@Import与ImportSelector与ImportBeanDefinitionRegistar","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/import%E4%B8%8Eimportselector%E4%B8%8Eimportbeandefinitionregistar/"},{"content":"@Profile注解类型于@Conditional，但是它仅针对当前运行的环境，我觉得这个东西在生产开发中使用的频率非常的低，几乎没有使用的空间。\n但是我们目前的项目中有一个场景，可能会用到相关的技术，在我们的项目中，dev环境使用的数据源驱动并非PG数据库的的官方驱动，而是p6spy数据源启动，p6spy是一个非常强大的数据源，它可以拦截jdbc的所有SQL请求（我在实验中，并非所有的sql都可以被拦截）。但是上sit环境和prod环境时，我们需要使用正常的pg数据源。\n从某种角度上讲，此时我们可以需要使用@Profile技术了。但是SpringBoot非常的强大，我们使用了两个application.yml文件，一个application-sit.yml、一个application-dev.yml文件，在每个文件中配置了不同的driverClass，从而就实现了在不同的环境中使用不同的数据源，感觉非常的方便。\n如果该需求使用@Profile实现，我们会在代码中直接定义两个数据源，并直接硬编码给配置好，然后通过@Profile设置在不同的环境中装配不同的数据源。这么说来@Profile适用的场景是：组件的配置无法配置文件化（或者说没有精力去将一个组件的配置配置文件化，我们选择了在代码里通过JavaConfig进行配置）。\n对@Profile的小结 经过上面的分析，我对@Profile的使用场景总结如下：当我们在进行bean的配置时，如果我们没有精力将组件的配置进行配置文件化，或者组件的配置本身也不是很好的支持配置文件化，我们可以考虑使用@Profile技术。\n使用@Profile文件，我们需要公司级别的常量，用来表示各个公司中尝尝使用的各个环境，然后各个项目都需要遵守这个规范，使用已定义的Profile。\n","description":"","id":11,"section":"notes","tags":null,"title":"@Profile注解的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/profile%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"@PropertySource有如下注意事项：\n  @PropertySource目前也是支持yml文件的，我看网上说只支持properties文件，估计是Spring版本比较旧吧。\n  @PropertySource注入的文件，可以在代码中通过环境变量获取到，代码如下：\n  1 2 3 4 5 6  SpringApplication .run(DemoApplication.class, args) .getEnvironment() .getProperty(\u0026#34;tmp\u0026#34;)    PropertySource是可以在一个类上注解多次的，相同功能也可以使用PropertySources实现。\n  PropertySource这个注解想到于在Spring项目的配置文件中做了如下配置（没有打算使用Spring的xml配置方式，记录这个东西仅仅是为了方便学习和理解）：\n  1 2 3  \u0026lt;context:property-placeholder location=\u0026#34;classpath:tmp.properties\u0026#34;\u0026gt;   ","description":"","id":12,"section":"notes","tags":null,"title":"@PropertySouce注解需要注意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/propertysouce%E6%B3%A8%E8%A7%A3%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"Scope可配置的值如下：\n1 2 3 4 5 6 7  ConfigurableBeanFactory#SCOPE_PROTOTYPE：多实例 ConfigurableBeanFactory#SCOPE_SINGLETON：单实例（默认） WebApplicationContext#SCOPE_REQUEST（一个请求创建一个实例） WebApplicationContext#SCOPE_SESSION（一个Session创建一个实例）   当为单实例时，可以通过@Lazy进行懒加载。这些知识很好理解，不整理代码了。\n","description":"","id":13,"section":"notes","tags":null,"title":"@Scope与@Lazy注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/scope%E4%B8%8Elazy%E6%B3%A8%E8%A7%A3/"},{"content":"该问题由同事定位并修复，我在一旁参观了整个过程。我们的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Select(\u0026#34;\u0026lt;script\u0026gt;\u0026#34; + \u0026#34; SELECT * FROM t_user where is_delete = 0\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.account != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND account like #{request.account} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.registStatus != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND regist_status = #{request.registStatus} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.name != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND name like #{request.name} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.status != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND status = #{request.status} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.startTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026gt;= #{request.startTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.endTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026gt;= #{request.endTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; order by gmt_create_time\u0026#34; + \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;) IPage\u0026lt;User\u0026gt; getUserListPage(Page\u0026lt;User\u0026gt; objectPage, SearchExperienceAccountRequest request);   结果项目在启动的是否报了如下的错误：\n 2021-06-16 15:11:52.260 WARN AbstractApplicationContext.java:558- Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountController' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\controller\\AccountController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountServiceImpl' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\service\\impl\\AccountServiceImpl.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'companyMapper' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\mapper\\CompanyMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is org.springframework.core.NestedIOException: Failed to parse mapping resource: 'file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\mapper\\UserMapper.xml]'; nested exception is org.apache.ibatis.builder.BuilderException: Could not find value method on SQL annotation. Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance. Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 523; 元素内容必须由格式正确的字符数据或标记组成。 问题的原因在于我们的代码中使用了\u0026gt;符号，这是一个特殊的字符，写在xml中需要进行转义。\n改正后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Select(\u0026#34;\u0026lt;script\u0026gt;\u0026#34; + \u0026#34; SELECT * FROM t_user where is_delete = 0\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.account != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND account like #{request.account} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.registStatus != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND regist_status = #{request.registStatus} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.name != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND name like #{request.name} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.status != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND status = #{request.status} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.startTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026amp;gt;= #{request.startTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.endTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026amp;lt;= #{request.endTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; order by gmt_create_time\u0026#34; + \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;) IPage\u0026lt;User\u0026gt; getUserListPage(Page\u0026lt;User\u0026gt; objectPage, SearchExperienceAccountRequest request);   这个问题我需要小心，原因是我之前在开发一款帮忙优化排版的脚本，我并没有注意到这个问题，其次我从业到现在，接触xml的次数太少了，踩过的坑也很少，我很容易犯相同的错误。\n不过我对这种编码的方式也存在一些疑惑：\n  这个查询可以通过LambdaQueryWrapper实现么\n  这样的脚本是自己手动一行一行的编写的么，那我想测试该sql脚本的时候又该怎么办\n  我觉得使用这种方案，还是需要一些小工具的，让编写代码和检查代码都比较轻松，否则的话一点SQL出现了问题，我觉得没有谁有积极性去排查其中的问题。\n","description":"","id":14,"section":"notes","tags":null,"title":"@Select中特殊字符导致的错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/select%E4%B8%AD%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E5%AF%BC%E8%87%B4%E7%9A%84%E9%94%99%E8%AF%AF/"},{"content":"@Valid与@Validation的区别：\n  @Validation支持分组功能，@Valid不支持分组功能\n  @Validated用于类型、方法、方法参数，不能用于成员属性上，@Valid用于方法、构造函数、方法参数、成员属性上。因为@Validated不能用于成员属性，故其不支持嵌套验证功能（在开发中已经遇到过这个问题了）\n  参考资料   @Validated和@Valid区别：Spring validation验证框架对入参实体进行嵌套验证必须在相应属性（字段）加上@Valid而不是@Validated\n还有一部分关于嵌套验证的资料，因为我这部分已经比较熟悉了，就不整理了。\n  ","description":"","id":15,"section":"notes","tags":null,"title":"@Valid与@Validation的区别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/valid%E4%B8%8Evalidation%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"content":"先给条指令，用来查看当前系统的发行版本（这条蛮好用的，目前我的系统都能用这个）：\n cat /etc/issue 添加curl  apk add curl 添加telnet  apk add busybox-extras 参考资料  如何查看LINUX发行版的名称及其版本号 Ryanb58/install.md  ","description":"","id":16,"section":"notes","tags":null,"title":"Alpine Linux 3.11安装常用工具包","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/alpine/alpine-linux-3.11%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%8C%85/"},{"content":"我公司和家里的电脑上同时配置了alt + f快捷键，用来快速打开文件在资源浏览器中的位置。在公司的电脑上我可以在任意打开的文件，或者目录树中任意一个条目中执行该快捷键，但是在家里的电脑上我智能在目录条目上执行该快捷键，很是困扰。\n今天小小研究了一下，发现配置快捷键的时候还可以配置一个条件，我家里的电脑上配置了在非编辑窗口，该快捷键生效，所以一直都有问题，删掉该条件即可。\n","description":"","id":17,"section":"notes","tags":null,"title":"alt+f快捷键不好使了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/vscode/alt+f%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%8D%E5%A5%BD%E4%BD%BF%E4%BA%86/"},{"content":"打算下次再使用的时候系统整理一下这些知识，目前的话我总是在需要的时候才查找这些资料，查找后又没有整理，所以下次用的时候还需要查，非常的不方便。\n参考资料  Java Array、List、Set互相转化  ","description":"","id":18,"section":"notes","tags":null,"title":"Array、Set、List互转的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/arraysetlist%E4%BA%92%E8%BD%AC%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":" 官网下载最新版BIOS   https://cn.msi.com/Motherboard/support/B450M-MORTAR.html  格式化U盘为FAT32（很关键，已经踩过坑了），然后解压官网下载的压缩包，将压缩包内的2~3个文件拷贝到U盘的根目录。\n  进入Bios系统，选择M-Flash，然后后面的都是傻瓜式操作\n  参考资料  官方提供的视频资料  ","description":"","id":19,"section":"notes","tags":null,"title":"B450M主板升级BIOS","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E5%8D%87%E7%BA%A7bios/"},{"content":"BIOS系统中选择OverClocking（应该是这个吧，忘记了，是个大项），然后选择CPU配置，然后选择Svmmode，选择开启。\n参考资料  请问amd 2600+微星b450m怎么开虚拟化技术？  ","description":"","id":20,"section":"notes","tags":null,"title":"B450M主板开启AMD-V","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E5%BC%80%E5%90%AFamd-v/"},{"content":"参考资料  微星b450m迫击炮主板接线图解  ","description":"","id":21,"section":"notes","tags":null,"title":"B450M主板线如何插","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E7%BA%BF%E5%A6%82%E4%BD%95%E6%8F%92/"},{"content":"我以为这个是一个比较简单的工作，像Linux中调用一下nohup就好了，但是没想到方案中有很多代码我都不太懂：\n1 2 3 4 5 6 7  @echo off if \u0026#34;%1\u0026#34; == \u0026#34;h\u0026#34; goto begin mshta vbscript:createobject(\u0026#34;wscript.shell\u0026#34;).run(\u0026#34;%~nx0h\u0026#34;,0)(window.close)\u0026amp;\u0026amp;exit :begin java -jar -Dspring.profiles.active=local gateway.jar \u0026gt; log.txt   参考教程  bat脚本实现后台运行cmd命令 批处理文件 bat 后台运行  ","description":"","id":22,"section":"notes","tags":null,"title":"bat脚本后台启动程序","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/bat%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%E5%90%AF%E5%8A%A8%E7%A8%8B%E5%BA%8F/"},{"content":"最近研究基于注解的参数校验时接触了一些新的概念，整理一下。\nBean Validation Bean Validation是一整套关于数据验证的规范，JSR 303–Bean Validation规范。\nBean Validation定义了一系列元数据模型和API。Hibernate Validator是Bean Validation的参考实现，除了JSR 303规范中内置约束，还额外定义一些常用约束实现。\nBean Validation中的约束 常用：\n @Null @NotNull  少用：\n @Min(value) @Max(value) @Size(max, min) @Pattern(value) @Email @Length @Range @NotEmpty  未用：\n @AssertTrue @AssertFalse @Past @Future @Digits (integer, fraction) @DecimalMin(value) @DecimalMax(value)  在代码中校验 如下代码，其中validator可以从SpringBoot Context中获取，我已经验证过了。\n ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); Validator validator = factory.getValidator(); Set\u0026lt;ConstraintViolation\u0026lt;DemoDTO\u0026gt;\u0026gt; violations = validator.validate(dto); Bean Validation、Hibernate Validation、spring-boot-starter-validation关系 Bean Validation是Java中的一项标准，它通过一些注解表达了对实体的限制规则。通过提出了一些API和扩展性的规范，这个规范是没有提供具体实现的，希望能够Constrain once, validate everywhere。现在它已经发展到了2.0，兼容Java8。\nHibernate Validation实现了Bean Validation标准，里面还增加了一些注解，在程序中引入它我们就可以直接使用。\nSpring MVC也支持Bean Validation，它对Hibernate Validation进行了二次封装，添加了自动校验，并将校验信息封装进了特定的BindingResult类中，org.springframework.boot:spring-boot-starter-validation引入这个库，实现对bean的校验功能。\n参考资料   spring boot 参数校验这么做简洁实用\n  SpringBoot自定义请求参数校验\n讲述了Bean Validation与Hibernate Validation之间的关系，包含一些自定义Validator的代码及一些以编程的方式校验的代码。另外这篇文章的参考文档质量非常高，我有时间想去研究一下。\n  ","description":"","id":23,"section":"notes","tags":null,"title":"Bean Validation","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/bean-validation/"},{"content":"BeanPostProcessor是许多注解、Aware实现的最核心的技术，所以研究它的实现原理是非常有价值的，利于后面其他知识的学习。\n","description":"","id":24,"section":"notes","tags":null,"title":"BeanPostProcessor源码分析（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/beanpostprocessor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"为了尽量还原我GitBook的界面风格，我决定使用Hugo Book主题，按照如下代码启动了Hugo，发现整体上还是蛮让人满意的，左侧为目录树，右侧为具体的每个文档内容，而且目录树部分是可以折叠的，所以我决定研究一下hugo和这个主题。\n1 2 3 4 5 6 7 8  hugo new site mydocs; cd mydocs git init git submodule add https://github.com/alex-shpak/hugo-book themes/book cp -R themes/book/exampleSite/content . hugo server --minify --theme book --bind=\u0026#34;0.0.0.0\u0026#34; --baseUrl=\u0026#34;http://192.168.27.121:1313\u0026#34;   我遇到的第一个问题是，我无法控制目录树的显示状态。实验中我让content目录仅包含docs目录，目录树仍然可以呈现出来，这个和我理解的有很大的出入。最后经过观察，我明白了，每个docs目录下都有一个_index.md文件，这个文件决定了目录树的显示（目前的理解）。\n在随后的资料中，我发现我们可以通过content/menu/index.md文件，控制右侧的目录树显示。当然如果相要这份文件生效，还需要在config.toml中进行如下配置：\n [params] BookMenuBundle = '/menu' 这就是我对BookMenuBundle的第一次接触。我原本以为这是一个非常简单的配置，但是我随后发现Bundles似乎是一个很重要的概念，我决定研究一下这个东西。\ngit submodule add https://github.com/zzossig/hugo-theme-zdoc.git themes/zdoc\nhugo server \u0026ndash;minify \u0026ndash;theme zdoc\n","description":"","id":25,"section":"notes","tags":null,"title":"BookMenuBoundle简单配置的实验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/bookmenuboundle%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"上一次实验中，让我最难以忘怀的每次重新搭建Kubernetes集群时都需要漫长的等待，即使我用了国内的仓库，也需要不停的等待。单纯的搭建K8s，使用阿里的仓库，时间是可以接受的。但是因为后面的装Flannel插件和Istio时及一些杂七杂八的东西时，时间真的受不了。使用国内的仓库，遇到最多的问题就是某个镜像的某些层拉取非常快，而其他的层就拉的非常的慢，我完全无法理解这个现象。\n我当时解决该问题的主要方案是，在一台机器上拉取镜像，然后推到我自己的Harbor仓库，然后在其他结点上拉取我Harbor中的镜像，重新打上Tag。这个方案工作量比较大，而且当时我的Harbor也并非处于一个稳定的环境，经常连带虚拟机一起都被我销毁了，所以体验非常的糟糕。\n重建Kubernetes集群，对我来说是一件非常频繁的事情，当集群出现了我意料之外的状况时，相比慢慢的排错，不如直接重建（主要是排错需要的知识储备不够）。所以我这次必须解决重建速度慢的问题。\n我这次准备了两个方案解决速度慢的问题，一个是透明代理，一个是高质量的使用Harbor。实践中透明代理的速度并不理想，只能达到200~600kb，而且使用透明代理时，依旧存在镜像部分层下载速度巨慢的情况（我不确定是不是我电脑或者我的网络环境造成的）。Harbor提供了类似与Nexus的代理仓库的东西，但是目前的版本只支持Docker Hub和镜像源本身也是使用Harbor的两种场景，非常巧合，K8s搭建时，使用的镜像源是gcr.io，无法被代理（貌似说最新的2.2.1增加了对部分镜像源的支持）。\n所以我最终选择的方案是：宿主机挂透明代理，一台虚拟机上拉取所有的镜像，然后push到我的Harbor。使用Kubedam初始化时指定仓库为我自己的Harbor仓库，这个方案有我之前方案的影子，只是细节处有些不同。我计划未来将这个方案脚本化，总之，我的目标还是能够快速的重建K8s、Istio集群。\n搭建Harbor   官网下载离线安装包，解压该离线包。\n  从harbor.yml.tmp复制一份harbor.yml文件，修改hostname、数据存储目录、日志存储目录，注释掉https相关的配置\n  执行./prepare，得到一份docker-compose.yml文件\n  执行./install.sh，完成镜像的加载，容器的启动。\n  遇到的问题：\n我在安装Harbor遇到的问题，绝大多数人应该都不会遇到。因为我考虑让Harbor的数据更安全，我通过Vagrant的同步目录同步到了主机上。在配置harbor.yml文件时，我将数据和日志文件指向了这个同步目录。结果就导致了harbor-db这个容器没有权限操作这个同步目录。\n对这个问题深入研究后发现一些有意思的东西：harbor-db会创建一个progress用户和一个input用户组，来操作数据目录，同时它会把数据目录的所有者修改为progress:input。但是，Vagrant的同步目录是不支持修改用户和用户组的（执行了chown指令后没有任何效果），这最终到时harbor-db容器一直报无权限。\n实际上对这个问题更深入研究，也会发现一些无法解释的问题。我将同步目录的权限全部设置为了777，并将所有者设置为root:root，而非默认的vagrant:vagrant。理论上讲，harbor-db容器的任何用户都可以操作这个目录了呀，但是它依旧会报错。我觉得这个报错可能不是系统报的，而是harbor-db的程序无法找到自己需要的用户和用户组为progress:input的数据目录，而报的错误。\n我最后决定不使用同步目录了，以后对Harbor所在的虚拟机操作谨慎些，定时同步下吧。又或者，未来有时间将Harbor迁移到J4125那台机器上也行。\n搭建Kubernetes 主节点  关闭防火墙  1 2 3 4  systemctl disable firewalld systemctl stop firewalld   关闭selinux  1 2 3 4 5 6 7 8  # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config   关闭交换分区  1 2 3 4 5 6 7  # 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab   修改内核参数  1 2 3 4 5 6 7  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system   重启后检查各台机器的状态   reboot sestatus swapon -s master节点  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubectl kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   初始化K8s（我执行的是如下指令，如果你没有自己的Harbor，建议参考参考资料部分提供的教程）   # 初次执行，需要将如下镜像拉取下来推送到自己的Harbor仓库 kubeadm config images list kubeadm config images pull docker tag k8s.gcr.io/kube-apiserver:v1.21.0 172.16.100.100:80/library/kube-apiserver:v1.21.0 docker tag k8s.gcr.io/kube-controller-manager:v1.21.0 172.16.100.100:80/library/kube-controller-manager:v1.21.0 docker tag k8s.gcr.io/kube-scheduler:v1.21.0 172.16.100.100:80/library/kube-scheduler:v1.21.0 docker tag k8s.gcr.io/kube-proxy:v1.21.0 172.16.100.100:80/library/kube-proxy:v1.21.0 docker tag k8s.gcr.io/pause:3.4.1 172.16.100.100:80/library/pause:3.4.1 docker tag k8s.gcr.io/etcd:3.4.13-0 172.16.100.100:80/library/etcd:3.4.13-0 docker tag k8s.gcr.io/coredns/coredns:v1.8.0 172.16.100.100:80/library/coredns/coredns:v1.8.0 docker push 172.16.100.100:80/library/kube-apiserver:v1.21.0 docker push 172.16.100.100:80/library/kube-controller-manager:v1.21.0 docker push 172.16.100.100:80/library/kube-scheduler:v1.21.0 docker push 172.16.100.100:80/library/kube-proxy:v1.21.0 docker push 172.16.100.100:80/library/pause:3.4.1 docker push 172.16.100.100:80/library/etcd:3.4.13-0 docker push 172.16.100.100:80/library/coredns/coredns:v1.8.0 kubeadm init \\ --image-repository 172.16.100.100:80/library \\ --kubernetes-version v1.21.0 \\ --pod-network-cidr=10.244.0.0/16 \\ --apiserver-advertise-address=172.16.100.101  配置kubectl工具   mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 获取加入集群的指令   kubeadm token create --print-join-command 从节点  安装kubeadm、kubelet  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   执行加入集群的指令（我直接从教程里Copy过来的）   kubeadm join 192.168.99.104:6443 --token ncfrid.7ap0xiseuf97gikl --discovery-token-ca-cert-hash sha256:47783e9851a1a517647f1986225f104e81dbfd8fb256ae55ef6d68ce9334c6a2 安装网络插件  翻墙下载配置文件（我计划将kube-flannel.yml文件中的image改为我本地harbor中的镜像），该操作每台机器都需要执行：   https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml 参考资料   CentOS 搭建 K8S，一次性成功，收藏了！\n核心参考了该教程。\n  Harbor下载地址\n  centos 7.0 查看selinux状态|关闭|开启\n  Linux开启与关闭Swap交换分区以及Putty命令行的基本操作\n  ","description":"","id":26,"section":"notes","tags":null,"title":"CentOS 7搭建Kubernetes","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/centos-7%E6%90%AD%E5%BB%BAkubernetes/"},{"content":"安装VirtualBox和Vagrant VirutalBox和Vagrant安装方式有很多，我比较推荐的是下载rpm包的方式安装。这样的VirtualBox和Vagrant的安装方式能够统一，如果对其他方案感兴趣，可以在我的废弃资料中找找，我之前有尝试过其他的方案。\n 使用如下地址下载资源（可以尝试去官网找下最新的资源）：   https://download.virtualbox.org/virtualbox/6.1.18/VirtualBox-6.1-6.1.18_142142_el8-1.x86_64.rpm https://releases.hashicorp.com/vagrant/2.2.15/vagrant_2.2.15_x86_64.rpm 资源下载好后，拖到服务器中，运行如下指令安装：   dnf -y install VirtualBox-6.1-6.1.18_142142_el8-1.x86_64.rpm dnf -y install vagrant_2.2.15_x86_64.rpm 官网下载Vagrant的CentOS 8的Box（Vagrant Box下载是有技巧的，使用官网提供的简单下载按钮，容易断流），注意要选择平台为VirtualBox。Vagrant的Box可以理解为Vagrant封装的系统镜像。下载完成后拖到服务器中，用如下指令将Box加载到Vagrant中，我下载了CentOS 7和CentOS 8，因为有时候新系统可能会出些奇怪的问题，且资料还不好找，所以就换着来。   # 参考下载地址，下载后将文件名改为centos7、centos8 https://app.vagrantup.com/generic/boxes/centos7/versions/3.2.14/providers/virtualbox.box https://app.vagrantup.com/generic/boxes/centos8/versions/3.2.14/providers/virtualbox.box vagrant box add --name centos7 7a1ba0be-378a-4d19-bc12-fbb8a21a27f0 vagrant box add --name centos8 c7a9dc13-f8f4-43ac-86fd-7155a2ac7a4c vagrant box list  启动一个虚拟机完成VirtualBox和Vagrant测试。这个过程中可能会遇到VirtualBox无法启动的问题，可以参考我另一篇文章。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  mkdir Test cd Test vagrant init tee Vagrant \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;centos7\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = \u0026#39;node\u0026#39; vb.memory = \u0026#34;1024\u0026#34; vb.cpus = 1 end end EOF vagrant up   接下来你会看到如下日志：   Bringing machine 'default' up with 'virtualbox' provider... ==\u0026gt; default: Clearing any previously set forwarded ports... ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running 'pre-boot' VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.2.44 default: VirtualBox Version: 6.1 ==\u0026gt; default: Machine already provisioned. Run `vagrant provision` or use the `--provision` ==\u0026gt; default: flag to force provisioning. Provisioners marked to run always will still run. 使用Vagrant集群脚本 这个脚本是我之前学习一些集群工具时开发的，它的优点是可以轻松改几行代码就启动一个小集群，因为我目前比较清晰的了解我们目前的需求，所以有针对的对这个脚本进行了一些改造。\n","description":"","id":27,"section":"notes","tags":null,"title":"CentOS 8安装VirtualBox和Vagrant，并配置Vagrant","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-8%E5%AE%89%E8%A3%85virtualbox%E5%92%8Cvagrant%E5%B9%B6%E9%85%8D%E7%BD%AEvagrant/"},{"content":"关于代理的问题，现在已经让我非常的头疼了，我计划还是研究一下软路由，尽量让我的工具机流量全部走外网。另外，我可能还需要升级一下我搭梯子的能力，我感觉我现在的梯子没有跑满我的带宽，速度还是有点慢。\ndnf代理设置 打开/etc/dnf/dnf.conf，在[main]后添加：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  proxy=http://192.168.31.154:1080 proxy_username= proxy_password= tee -a /etc/dnf/dnf.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; proxy=http://192.168.31.154:1080 proxy_username= proxy_password= EOF 20200416补充： 我习惯性的写https_proxy = http://192.168.31.154:1080/，结果遭遇了网络管制，我百思不得解，最后终于尝试返现是将proxy写成了http_proxy，但是dnf本身却没有报任何错误。   wget代理设置 wget完整的配置文件位于/etc/wgetrc，不建议改这个文件，可以拷贝一份放在自己的家目录下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  tee -a ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = http://192.168.31.154:1080/ http_proxy = http://192.168.31.154:1080/ ftp_proxy = http://192.168.31.154:1080/ EOF tee -a ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = http://192.168.13.113:1080/ http_proxy = http://192.168.13.113:1080/ ftp_proxy = http://192.168.13.113:1080/ EOF tee ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = http://192.168.13.59:1080/ http_proxy = http://192.168.13.59:1080/ ftp_proxy = http://192.168.13.59:1080/ EOF # 这种写法不允许，需要研究下 tee -a ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = socks://127.0.0.1:1080/ http_proxy = socks://127.0.0.1:1080/ ftp_proxy = socks://127.0.0.1:1080/ EOF   git代理设置  git config --global http.proxy 'http://192.168.31.154:1080' git config --global https.proxy 'http://192.168.31.154:1080' 参考文档  为 dnf 设置代理 为wget命令设置代理  ","description":"","id":28,"section":"notes","tags":null,"title":"CentOS 8常用软件代理设置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-8%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"},{"content":"操作步骤  指令如下   nmcli conn add con-name pppoe-home type pppoe ifname enp2s0 username 13022052202D396 password 123456 nmcli conn up pppoe-home nmcli conn modify pppoe-home con-name pppoe nmcli conn add con-name enp5s0 ifname enp4s0 type ethernet 我以前一直没有注意到，使用拨号上网的时候，竟然会多出来个这么个东西。\n遇到的问题  遇到如下问题：   -- Logs begin at Sat 2021-05-01 03:10:09 EDT, end at Sat 2021-05-01 04:00:09 EDT. -- May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.1813] manager: (enp2s0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/3) May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.1829] device (enp2s0): state change: unmanaged -\u0026gt; unavailable (reason 'managed', sys-iface-state: 'external') May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.9689] device (enp2s0): state change: unavailable -\u0026gt; disconnected (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6788] device (enp2s0): carrier: link connected May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6798] device (enp2s0): Activation: starting connection 'pppoe-home' (d1402583-37ea-4cbd-890d-4061e6e66d1f) May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6800] device (enp2s0): state change: disconnected -\u0026gt; prepare (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6806] device (enp2s0): state change: prepare -\u0026gt; config (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6813] device (enp2s0): state change: config -\u0026gt; ip-config (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;warn\u0026gt; [1619855983.6816] device (enp2s0): PPPoE failed to start: the PPP plugin /usr/lib64/NetworkManager/1.26.0-12.el8_3/libnm-ppp-plugin.so is not installed 解决方法从如下页面下载相应的dpm包，并进行安装。\n http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/ dnf -y install NetworkManager-ppp-1.26.0-12.el8_3.x86_64.rpm 我感觉我解决VirtualBox的问题时，给我自己留下了不少的技术资产，我已经用相关的知识定位解决了好几个问题了。\n复杂的问题 拨号成功后，我可以ping通8.8.8.8，也可以curl到www.baidu.com。目前我的网络拓补如下：\n这个时候发生了一些怪异的事情，我笔记本能ping通192.168.31.217，也能通过telnetl与其22端口建立连接，但是无法通过xshll建立ssh连接。这种现象我是第一次见，我很难在我的知识范围内找到一个合理的解释。\n不过不的不说，我J4125那台机器上是多网卡的，而且现在enp2s0作为了上网卡，在很多单网卡的机器中，流量都会默认从这个网卡出去。我觉得抓包分析，可能会看到这样的现象，但是J4125上的usb网卡，本来就是临时挂载一下，所以我懒得花精力去修复这个问题。\n参考资料   linux配置网络，nmcli配置法及直接修改配置文件法\n里面简单提了下nmcli支持拨号上网。\n  ","description":"","id":29,"section":"notes","tags":null,"title":"CentOS 8拨号上网","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-8%E6%8B%A8%E5%8F%B7%E4%B8%8A%E7%BD%91/"},{"content":"我一直以为CentOS在下载软件是会就近选择软件源，但是我今天更新软件时发现速度很慢，所以干脆一不做二不休，直接将软件源替换为国内的。\n操作步骤  备份/etc/yum.repos.d文件夹（备份是推荐带上年月日，最好再带上操作人）  1 2 3  cp -r /etc/yum.repos.d /etc/yum.repos.bck20210410   执行如下指令，更换配置文件中的属性：  1 2 3 4 5 6  sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\  -e \u0026#39;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g\u0026#39; \\  -i.bak \\  /etc/yum.repos.d/CentOS-*.repo    更新缓存  1 2 3  dnf makecache   最后更新一下系统软件   dnf update 参考资料  CentOS 镜像使用帮助 CentOS 8 设置国内安装源  ","description":"","id":30,"section":"notes","tags":null,"title":"CentOS 8配置软件源","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-8%E9%85%8D%E7%BD%AE%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"content":"vim /etc/yum.conf\nproxy=http://192.168.13.113:1080\n","description":"","id":31,"section":"notes","tags":null,"title":"CentOS yum设置代理","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-yum%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"这个是我目前找到的最优雅的方式了，需要重启后生效（重启后命令提示符前的主机名也会改变）：\n hostnamectl set-hostname kerrydb 参考资料  Centos 7修改hostname浅析  ","description":"","id":32,"section":"notes","tags":null,"title":"CentOS修改主机名称","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0/"},{"content":"这是一个非常简单的指令，但是我总是拼不对，干脆记下来算了。\n systemctl stop firewalld systemctl disable firewalld 20210502后续：\n我今天才知道firewalld和iptables不是同一个东西，虽然他们都是基于Netfilter的内核数据包管理工具。\n因为firewalld默认是拒绝所有进入的流量（除了22号端口），而iptables默认是允许所有的流量的，所以我在进行实验的时候，经常需要关闭firewalld。（其实我还是有点疑惑，我看结构图，firewalld最终也是调回了iptables的命令，可以真正使用iptables -L去查看的时候，又看不到任何的规则）\n在搭建OpenVPN时，很有趣，配置完iptables后，往往会关闭防火墙，我一直好奇，防火墙都被关闭了，那数据包又该如何如何按照规则分配呢，现在这个问题明晰了。\n还有一个有趣的问题：我之前一直搜索的是如何关闭防火墙，所以搜索到了上面的指令，如果我搜索如何关闭iptables的话，可以得到下面的指令：\n service iptables stop 参考资料  Linux CentOS7关闭防火墙 CentOS6关闭开启防火墙 CentOS打开关闭防火墙  ","description":"","id":33,"section":"notes","tags":null,"title":"CentOS关闭防火墙","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99/"},{"content":"操作步骤  常用指令   uanme -a # 查看当前内核版本 cat /etc/redhat-release # 查看当前系统版本 rpm -qa | grep kernel # 查看已安装的内核 yum repolist # 查看yum当前配置了哪些源 安装elrepo仓库，并查看仓库配置信息   rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm cat /etc/yum.repos.d/elrepo.repo 这一步中，我将elrepo仓库全部配置成enable了，按照教程，如果不配置的话需要在yum的搜索、查询、安装指令上加上--enablerepo=elrepo-kernel。额，实际上我执行这些指令的时候也加上了这行配置。\n查看新的内核包，及查看kernel-lt和kernel-ml的信息。   yum search --enablerepo=elrepo-kernel lt # 这条指令没有给到我有用的信息，返回的内容太多了 yum info --enablerepo=elrepo-kernel kernel-lt kernel-ml 删除旧版本的内核开发工具，并安装新版本的内核，及内核开发工具   yum remove kernel-tools kernel-tools-libs kernel-headers kernel-devel yum install --enablerepo=elrepo-kernel -y kernel-ml kernel-ml-headers kernel-ml-devel kernel-ml-tools kernel-ml-tools-libs kernel-devel-ml yum install --enablerepo=elrepo-kernel -y kernel-lt kernel-lt-headers kernel-lt-devel kernel-lt-tools kernel-lt-tools-libs kernel-devel 因为我那个折腾人的螃蟹2.5G网卡的驱动，必须要求内核在5.6以上，所以我选择了ml内核。\n设置grub（这部分我按教程瞎操作的，我对grub、grub2还不太熟悉）   grub2-set-default 0 grub2-mkconfig -o /boot/grub2/grub.cfg reboot 移除旧版内核（如果能指定版本更好，否则可能有清除到一些有用的工具包）   yum remove kernel-core-4.18.0 kernel-devel-4.18.0 kernel-tools-libs-4.18.0 kernel-headers-4.18.0 yum remove kernel-lt kernel-lt-devel kernel-lt-tools-libs kernel-lt-headers yum remove kernel-ml kernel-ml-devel kernel-ml-tools-libs kernel-ml-headers 踩过的坑  kernel-ml输入成kernel-mt，导致搜索不到相关的开发包  参考资料   Welcome to the ELRepo Project\n我在这个网站学习了设置CentOS 8的ElRepo仓库。\n  CentOS7.6更新内核\n在该教程中学习了很多知识，比如：\n 查看当前安装的内核版本指令 elrepo是一个企业级Linux的仓库 lt表示longterm（长时间支持版本），ml表示mainline（主线版本）    Centos 8升级内核版本\n我一开始使用的是这个教程，但是这个教程只给了内核的安装，没有讲到内核工具包，所以我又上其他教程中补充了一些资料。\n  ","description":"","id":34,"section":"notes","tags":null,"title":"CentOS升级内核到5.12","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B05.12/"},{"content":"参考资料  Linux查看网卡是千兆还是万兆网卡 查看网卡是百兆还是千兆  ","description":"","id":35,"section":"notes","tags":null,"title":"CentOS和Window查看网卡是百兆还是千兆","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%92%8Cwindow%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1%E6%98%AF%E7%99%BE%E5%85%86%E8%BF%98%E6%98%AF%E5%8D%83%E5%85%86/"},{"content":"CentOS安装Python实际上有更简单的方法，就是通过yum安装，但是这种方法安装的版本和我win机器的版本不一致，所以我选择了用源码安装。\n操作步骤  安装编译环境  1 2 3 4 5  yum -y groupinstall development yum install -y zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel yum install libffi-devel -y   去官网下载源码，我下载的是GZipped source tarball：   https://www.python.org/downloads/release/python-389/ # 3.8.9版本的 wget https://www.python.org/ftp/python/3.8.9/Python-3.8.9.tgz 解压源码，进行配置，然后编译：   tar xf Python-3.8.9.tgz \u0026amp;\u0026amp; cd Python-3.8.9 ./configure --prefix=/usr/local/python3 make \u0026amp;\u0026amp; make install 添加Python到环境变量中：   cd /etc/profile.d echo 'export PATH=$PATH:/usr/local/python3/bin/' \u0026gt; python3.sh source /etc/profile 其他知识   添加环境变量的时候是单独为该程序在/etc/profile.d目录创建一个文件去修改环境变量，这样是方便以后查找和取消添加的环境变量。我之前是直接去更改/etc/profile文件，博文提到的这种方式更便于管理。\n  某些场景下可能需要重装，比如我在安装后通过pip拉取工具的时候，报了ModuleNotFoundError: No module named '_ctypes'错误（相关笔记整理在Python分类下的其他文章中），我需要按照教程下载一些CentOS包，然后重新编译安装，指令如下：\n   make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 参考资料   CentOS 7安装Python教程\n  CentOS 7安装Python3 笔记\n这是我很久前收藏的一篇博文，我应该没有按照这个方案去做。\n  ","description":"","id":36,"section":"notes","tags":null,"title":"CentOS安装Python 3.x","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/centos%E5%AE%89%E8%A3%85python-3.x/"},{"content":"指令如下，这是我目前找到的最优雅，最快速的方法：\n nmcli connection modify eth0 \\ ipv4.addresses 192.168.27.15/24 \\ ipv4.dns 192.168.27.22 \\ ipv4.method manual \\ ipv4.gateway 192.168.27.22 \\ connection.autoconnect yes nmcli c up eth0 nmcli connection modify eth0 \\ ipv4.addresses 172.20.11.206/24 \\ ipv4.dns 172.20.11.210 \\ ipv4.method manual \\ ipv4.gateway 172.20.11.210 \\ connection.autoconnect yes nmcli c up eth0 参考资料  Centos8 配置静态IP  ","description":"","id":37,"section":"notes","tags":null,"title":"CentOS快速配置多台机器为静态地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8%E4%B8%BA%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80/"},{"content":"事情的起因是这样的，我发现我Vagrant的虚拟机都会有两张网卡，经过分析我发现第一张网卡是用于nat，第二张网卡是用于我设置的host_only。但是我目前只需要使用host_only，我尝试去删除eth0，结果导致了我虚拟机无法访问，这个是很好理解的：VirtualBox使用host_only模式的时候，主机无法与虚拟机通信。\n为了正常进行实验，我决定设置路由，让我的请求走eth1，我执行的代码如下：\n route add -net 192.168.56.0/24 dev eth1 route add -net 192.168.41.0/24 dev eth1 route add -net 192.168.31.0/24 dev eth1 实验结果是怎样的，192.168.56.1、192.168.41.1都可以正常的ping通，192.168.31.1无法正常的ping通。\n我没有进行抓包分析，但是host_only模式真的是霸道啊，我其实已经在3400G上设置了ip转发，我还检查了3400G的路由信息，这样都没办法ping通。我以前一直以为，host_only模式就是一台虚拟机连接上了虚拟出来的网卡，这个虚拟网卡和普通的物理网卡是相似的，是可以进行ip转发的，现在看来不是这样的。\n我目前的方案是vagrant使用了public_network模式，并指定ip地址，这样非常省事，我可以在我的笔记本上直接ping到我的虚拟机。\n","description":"","id":38,"section":"notes","tags":null,"title":"CentOS添加默认路由","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E6%B7%BB%E5%8A%A0%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1/"},{"content":"我使用的是ip link set enp0s3 up，效果非常好。另外ifdown enp0s8指令不好使，文档里也说了，ifdown不支持以enp打头的网卡，这个坑被我踩了。\nnmcli c down enp0s3是我之后要尝试的方式，我比较喜欢nmcli系列的指令。\n参考资料  Linux 中如何启用和禁用网卡？  ","description":"","id":39,"section":"notes","tags":null,"title":"CentOS禁用网卡","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E7%A6%81%E7%94%A8%E7%BD%91%E5%8D%A1/"},{"content":"我现在最后悔的事情就是买软路由的时候选了R8125 2.5G网卡，这个网卡是在是太折腾人了。CentOS、PVE上都需要手动的编译安装驱动，ESXI上表现的总是有问题（ESXI 6.7本身也有很多Bug）。不过在折腾这张网卡的时候，也接触了一些较高级的知识，算因祸得福吧。\n操作步骤  准备相关工具：   dnf group install \u0026quot;Development Tools\u0026quot; 官网下载驱动，拖到机器中执行如下指令，我选择的是   tar -jxvf r8125-9.005.01.tar.bz2 cd r8125-9.005.01 ./autorun.sh 编译完成后（解决完各种问题后），执行如下指令，完成驱动安装和检查：   modprode r8125 lsmod | grep r8125 modinfo r8125 reboot 解决的各种问题 我按照时间顺序记录，建议倒序阅读，因为后面的方案可以解决前面的所有问题！！！\n 第一个问题   [root@MiWiFi-R4CM-srv r8125-9.005.01]# ./autorun.sh Check old driver and unload it. Build the module and install make[2]: *** /lib/modules/4.18.0-240.el8.x86_64/build: No such file or directory. Stop. make[1]: *** [Makefile:171: clean] Error 2 make: *** [Makefile:48: clean] Error 2 果断定位是kernel-devel工具没装，按照解决VirtualBox相关问题时的方法安装后，发现该报错消失。\n第二个问题   /root/r8125-9.005.01/src/r8125_n.c:62:10: fatal error: linux/pci-aspm.h: No such file or directory #include \u0026lt;linux/pci-aspm.h\u0026gt; ^~~~~~~~~~~~~~~~~~ compilation terminated. make[3]: *** [scripts/Makefile.build:316: /root/r8125-9.005.01/src/r8125_n.o] Error 1 make[2]: *** [Makefile:1544: _module_/root/r8125-9.005.01/src] Error 2 make[1]: *** [Makefile:163: modules] Error 2 make: *** [Makefile:41: modules] Error 2 查了一些资料后意识到是内核版本的问题，果断升级（花了很长时间），参考我相关的资料进行内核升级。\n参考资料   给PVE6添加Realtek 8125 2.5G网卡驱动\n学习了modprode指令的使用，其实我现在也不知道是不是这个指令起的作用，但是原教程给的load module指令，不可用，而且几乎查不到相关的资料。\n  CentOS8 手工编译安装 Realtek 8125 2.5G网卡驱动\n我遇到的问题，这篇教程一个都没有提，糟心。我只学到了大概了流程。\n  ","description":"","id":40,"section":"notes","tags":null,"title":"CentOS编译R8125网卡驱动","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E7%BC%96%E8%AF%91r8125%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"content":"我开发的点外卖提醒机器人，在半夜提醒点外卖了，我的定时脚本如下：\n 30,32,35 11 * * 1-6 /root/Software/launch/dist/launch 45,50 17 * * 1-6 /root/Software/launch/dist/launch 我定时任务肯定是没有任何问题的，所以感觉是服务器时间出问题了，所以打算修复一下这个问题：\n # 检查当前时区 timedatectl status | grep 'Time zone' # 输出为： Time zone: America/New_York (EDT, -0400) # 设置硬件时钟调整为本地时钟一致 timedatectl set-local-rtc 1 # 设置时区为上海 timedatectl set-timezone Asia/Shanghai # 查看时间和时区 date \u0026amp; timedatectl status | grep 'Time zone' # 输出为： Tue Jun 29 09:27:36 CST 2021 Time zone: Asia/Shanghai (CST, +0800) 参考资料  CentOS 7同步时间的2种方法  ","description":"","id":41,"section":"notes","tags":null,"title":"CentOS设置时区","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA/"},{"content":"CentOS 8版本  在/etc/sysconfig/network-scripts下，找到你需要配置的网卡配置文件，打开编辑：   TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static #修改：将dhcp修改为stati表示使用静态ip DEFROUTE=yes IPADDR=192.168.128.129 #新增：设置IP地址 NETMASK=255.255.255.0 #新增：设置子网掩码 GATEWAY=192.168.128.1 #新增：设置网关 DNS1=114.114.114.114 #新增：设置dns IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens33 UUID=e4987998-a4ce-4cef-96f5-a3106a97f5bf DEVICE=ens33  IPADDR=192.168.56.101 NETMASK=255.255.255.0 DNS1=114.114.114.114 GATEWAY=192.168.56.100  使用nmcli c reload命令重启网络  CentOS 7版本 同上，修改/etc/sysconfig/network-scripts下的问题，然后执行：\n service network restart； 我没有尝试使用nmcli c reload，以后有机会尝试一下。\n参考教程  centos8 网络配置 centos7设置静态IP地址  ","description":"","id":42,"section":"notes","tags":null,"title":"CentOS设置静态ip（已废弃）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip%E5%B7%B2%E5%BA%9F%E5%BC%83/"},{"content":"这个不整理了，照着教程做，什么问题都没有遇到。\n参考资料  CentOS 8.x 和 RHEL 8.x 更改默认启动项  ","description":"","id":43,"section":"notes","tags":null,"title":"CentOS设置默认启动项","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%90%AF%E5%8A%A8%E9%A1%B9/"},{"content":"我之前管理VPS时也遇到这样的需求了，整理一下：\n pkill -kill -t pts/0 参考资料  linux下踢掉一个用户（心跳包解决ssh断开连接）  ","description":"","id":44,"section":"notes","tags":null,"title":"CentOS踢掉一个用户","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%B8%A2%E6%8E%89%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7/"},{"content":"我目前的这套方案可以说是以Validation的思想实现我需要的需求。\n已存在的校验技术及我的校验注解需求 搞了大半天的成果，虽然不能很优雅的实现我的需求，但是在研究的过程中增加了我对Validation的了解，所以还是记录一下下吧。\n我听说有一种技术（我已经验证过这个技术），可以在@NotBlank的message中定义占位符，如下所示：\n @NotBlank(message = \u0026quot;{notBlank}不为空\u0026quot;) 然后在一个messages.properties的文件中定义：\n notBlank=\u0026quot;XXX\u0026quot; 当参数校验错误的时候生成的消息为：XXX不为空。更进一步的，我们可以在message.properties中这么定义：\n notBlank=\u0026quot;{0} XXX\u0026quot; 理想情况下，{0}将会被替换为@NotBlank标注的字段的名称，我无法成功实验该技术，但是这个技术的的确确是我想要的。我希望通过这个技术定义自己的@NotNull、@NotBlank等注解，这样我们在使用这些注解时只需要加上这些注解，而不需要写上message消息。\n一种不是太满意的实现方案 这里需要特殊说明一下，其实我可以通过如下的技术实现在ExceptionHandler中拼接字段信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13  @ControllerAdvice public class MyExceptionHandler { @ResponseBody @ExceptionHandler(value = {MethodArgumentNotValidException.class, BindException.class}) public Response exceptionHandler(MethodArgumentNotValidException e) { FieldError fieldError = e.getBindingResult().getFieldError(); return new Response(0, fieldError.getField() + \u0026#34;:\u0026#34; + fieldError.getDefaultMessage()); } }   这种方案很简单也很好理解，但是我放弃这个方案了，其原因是ExceptionHandler是全局的，而@NotNull等注解并不一定应用于Request中的参数校验，这种方式可能会暴露程序内部的一些设计；其次，修改ExceptionHandler是框架层的东西，我对其的任何调整都会影响已经在线上运行的项目，我觉得这样风险很大。最后，我觉得这并不是一种优雅的方式。\n我目前的方案 先分析一下如下代码是如何实现notBlank被替换为我们想要的字符串的。message.properties会被加载到内存中，存在一个叫做messageParams的属性中，当框架发现了message中包含大括号，则其会取到大括号的内容，然后得到该内容在messageParams中映射的值（有兴趣自己读源码吧，我是一点一点断点理解这个问题的）。\n1 2 3  @NotBlank(message = \u0026#34;{notBlank}不为空\u0026#34;)   针对我们的代码，正常情况下参数校验完成后的到的message是：{fieldName}：不能为空。因为我们没办法在message.properties中动态的定义fieldName，故messageParams中是找不到fieldName的。\n1 2 3 4  @JNotBlank(message = \u0026#34;{fieldName}：不能为空\u0026#34;) private String tmpString;   我们可以如何处理这个问题呢？如下代码，我们在开发ConstraintValidator时，是可以在isValid方法中获得一个ConstraintValidatorContext的，通过调用该context的addMessageParameters方法，我们就可以将参数加载到messageParams，从而完成映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class JNotBlankValidator implements ConstraintValidator\u0026lt;JNotBlank, String\u0026gt; { @Override public void initialize(JNotBlank constraintAnnotation) { } @Override public boolean isValid(String value, ConstraintValidatorContext context) { ValidationUtils.addMessageParameters(context); return StringUtils.isNotBlank(value); } } public class ValidationUtils { /** * 添加fieldName参数到ConstraintValidatorContext中 * \u0026lt;p\u0026gt; * 该工具可以在ConstraintValidatorContext添加一个额外的fieldName参数，这样你在 * 使用参数校验的注解时，可以在message中使用{@code fieldName} * \u0026lt;p\u0026gt; * 仅当注解基于字段时，该工具有效。 */ public static void addMessageParameters(ConstraintValidatorContext context) { if (context instanceof HibernateConstraintValidatorContext) { try { Field basePathField = context.getClass().getDeclaredField(\u0026#34;basePath\u0026#34;); basePathField.setAccessible(true); Path basePath = (Path) (basePathField.get(context)); ((HibernateConstraintValidatorContext) context).addMessageParameter(\u0026#34;fieldName\u0026#34;, basePath); } catch (NoSuchFieldException | IllegalAccessException e) { e.printStackTrace(); throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } } } }   至于如何获得fieldName的名称，我想到的办法只有反射了，我花费了很长时间，都没有找到可以获取fieldName字段的api，遂走反射这个方案。\n总结 我其实是无话可说的，这个方案是一点一点的探索出来的。不过这些技术的研究确实可以很好的减少我们工作量，我非常满意。另外，我想把这些技术开发成一个starter，然后用在我们的项目中。\n参考资料   Setting Custom Field Name and Code\nSpring Validation custom messages - field name\n印证了我的一些思想，同时提到了Validator的开发，我目前没有相关的技术需求。\n  spikefin-goby/spring-boot-validation-sample\n讲到了message.properties技术的应用，并提供了相关的案例代码。\n  ","description":"","id":45,"section":"notes","tags":null,"title":"ConstraintValidator中调用addMessageParameter方法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/constraintvalidator%E4%B8%AD%E8%B0%83%E7%94%A8addmessageparameter%E6%96%B9%E6%B3%95/"},{"content":"Converter是通用元件，可以将一种类型转换成另一种类型，可以在应用程序中的任意层使用。\nFormatter只能将String转换成另一种Java类型，是专门为 Web 层设计的；在Spring MVC应用程序中，选择Formatter比选择Converter更合适。\n我目前只能获取比较片面的知识，无法知道Converter和Formatter在整个框架中的定位，所以我计划之后有时间再整理这部分。\n","description":"","id":46,"section":"notes","tags":null,"title":"Converter与Formatter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/converter%E4%B8%8Eformatter/"},{"content":"源目录为source，目标目录为target，则如果target不存在，可直接使用如下指令完成复制：\n1 2 3  cp -r source target   如果target目录已经存在，则需要使用（我已经踩过该坑），此时执行cp -r source target，会将source复制到target中：\n1 2 3  cp -r source/* target   参考资料  linux复制指定目录下的全部文件到另一个目录中，linux cp 文件夹  ","description":"","id":47,"section":"notes","tags":null,"title":"cp将一个目录下的文件复制到另一个目录中","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/cp%E6%8C%87%E4%BB%A4/cp%E5%B0%86%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%AD/"},{"content":"操作步骤  运行如下指令：   apt install -y curl ","description":"","id":48,"section":"notes","tags":null,"title":"Curl Not Found","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/curl-not-found/"},{"content":"我用curl帮助我解决不少问题了，我打算整理下我对其的需求及用法：\n  curl -v google.com\n测试google.com是否可以正常访问，google.com域名是否正确解析。\n  curl \u0026ndash;socks5-hostname 127.0.0.1:2000 google.com\n将域名解析的工作交给socks5服务器。\n  很高级的知识，我的curl工具部分options用不了，我也想解决这个问题（暂时没有研究）\n 打造你自己的cURL命令 Problem running CURL with the dns option     ","description":"","id":49,"section":"notes","tags":null,"title":"curl常用指令","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/curl%E6%8C%87%E4%BB%A4/curl%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"指令如下：\n curl -k https://192.168.13.155:8006 curl --insecure https://192.168.13.155:8006 适用场景：https站点是我自己搭建的~~~\n参考资料  CURL 请求时不检测证书  ","description":"","id":50,"section":"notes","tags":null,"title":"curl访问时不检查证书","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/curl%E6%8C%87%E4%BB%A4/curl%E8%AE%BF%E9%97%AE%E6%97%B6%E4%B8%8D%E6%A3%80%E6%9F%A5%E8%AF%81%E4%B9%A6/"},{"content":"截图如下：\n核心需要注意的是，需要在skip上点一下，直到点出版本号。\n参考资料  Windows 下如何在cygwin上安装curl？  ","description":"","id":51,"section":"notes","tags":null,"title":"Cygwin上安装curl","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/cygwin%E4%B8%8A%E5%AE%89%E8%A3%85curl/"},{"content":"授人以鱼不如授人以渔，使用如下操作，可以看到fdisk支持的命令集：\n fdisk m 删除分区 删除分区的指令如下（核心思路就是使用使用d）：\n fdisk d 2 d 分区 参考资料  linux 硬盘分区，分区，删除分区，格式化，挂载，卸载笔记  ","description":"","id":52,"section":"notes","tags":null,"title":"Debian删除和新建分区","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E5%88%A0%E9%99%A4%E5%92%8C%E6%96%B0%E5%BB%BA%E5%88%86%E5%8C%BA/"},{"content":"操作步骤  替换/etc/apt/sources.list文件为如下内容：   # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free 运行apt update  ","description":"","id":53,"section":"notes","tags":null,"title":"Debian更换软件源","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E6%9B%B4%E6%8D%A2%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"content":"操作步骤  执行如下指令：  1 2 3 4  systemctl poweroff systemctl reboot   ","description":"","id":54,"section":"notes","tags":null,"title":"Debian系统关机","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E7%B3%BB%E7%BB%9F%E5%85%B3%E6%9C%BA/"},{"content":"问题描述  使用XShellssh到PVE服务器，账号使用的是junjie，然后使用su root切换root用户，再使用depmod指令，这时候会提示not found。  解决方法  使用如下指令：  1 2 3  /sbin/depmod `uname -r`   参考教程  安装Realtek8168 网卡驱动  ","description":"","id":55,"section":"notes","tags":null,"title":"depmod not found","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/depmod-not-found/"},{"content":"第三方镜像直接Run的话可能就没有办法进入到系统的终端，我用如下指令定义了我要执行的指令，从而覆盖Dockerfile中的CMD指令：\n docker run -it python:3.8.6 bash 我用该技术测试第三方image是否支持安装Git的软件，当我直接走docker run -it或者ducker attach时，仍然会进入python程序，这不是我想要的。\n","description":"","id":56,"section":"notes","tags":null,"title":"docker run指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker-run%E6%8C%87%E4%BB%A4/"},{"content":"使用场景很多，比如我测试Dockerfile文件后删除测试时生成的镜像，或者在做K8s的实验时，批量删除一些用不到的镜像。\n这篇收藏比较久远了，我基本忘记当时的需求和实践了，所以这块只整理一下。\n 【Docker实战】批量删除指定名称的容器镜像  ","description":"","id":57,"section":"notes","tags":null,"title":"Docker批量删除指定名称的容器镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E5%90%8D%E7%A7%B0%E7%9A%84%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F/"},{"content":"最近在研究GitHub Action，攒了几个Dockerfile，并构建了自己的镜像，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12  FROMpython:3.8.6# Copies your code file from your action repository to the filesystem path `/` of the containerCOPY adjust_pictures_in_md_files.py adjust_pictures_in_md_files.pyCOPY entrypoint.sh entrypoint.shRUN chmod +x entrypoint.sh# Code file to execute when the docker container starts up (`entrypoint.sh`)CMD [\u0026#34;/entrypoint.sh\u0026#34;]  运行的指令如下：\n docker build -t tmp:v1 . 我目前用的指令还比较简单，因为我还没有抽出时间系统、深入的学习Docker，先记录一下吧。\n","description":"","id":58,"section":"notes","tags":null,"title":"Docker构建自己的镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E9%95%9C%E5%83%8F/"},{"content":" docker attach 容器ID 参考资料  进入容器  ","description":"","id":59,"section":"notes","tags":null,"title":"Docker进入容器内部","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/docker%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E5%86%85%E9%83%A8/"},{"content":"如下代码：\n对应生成的YApi文档为：\n这其实不是我想要的，因为我们的@RequestAttribute会从Header中获取一个值赋给该字段，而这个Header来源于网关对token的解析。\n参考了官方的文档，似乎没有零侵入的方案，所以我采用了自己实现注解的方案，我开发的方案如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package com.sdstc.authcenter.annotations; import java.lang.annotation.*; /** * 用于EasyYAPI隐藏@RequestAttribute */ @Documented @Retention(RetentionPolicy.SOURCE) @Target(ElementType.PARAMETER) public @interface EasyYAPIIgnoreParam { boolean hide() default true; }   easyyapi的配置如下：\n param.ignore=@com.sdstc.authcenter.annotations.EasyYAPIIgnoreParam#hide 代码中的写法如下：\n1 2 3 4 5 6 7 8 9  @PostMapping(\u0026#34;/createAuthAppRole\u0026#34;) public ResponseVo\u0026lt;String\u0026gt; createAuthAppRole( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @EasyYAPIIgnoreParam @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid CreateAuthAppRoleRequest request) { return ResponseVo.createSuccessByData(authAppRoleService.createAuthAppRole(userId, tenantId, request)); }   目前YApi的表现和期待的一样，我将持续关注这个问题。\n方案优化 当然，这件事到此并没有结束，在我后来的研究中我发现我们的项目时注解了@RequestAttribute(APICons.REQUEST_USER_ID)的参数需要被忽略，所以我完全可以针对这个注解进行EasyYapi的配置，所以我删除了我开发的注解，并进行了如下的配置。\n param.ignore=@org.springframework.web.bind.annotation.RequestAttribute 代码中的写法如下：\n1 2 3 4 5 6 7 8 9  @PostMapping(\u0026#34;/createAuthAppRole\u0026#34;) public ResponseVo\u0026lt;String\u0026gt; createAuthAppRole( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @EasyYAPIIgnoreParam @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid CreateAuthAppRoleRequest request) { return ResponseVo.createSuccessByData(authAppRoleService.createAuthAppRole(userId, tenantId, request)); }   目前的这个方案我还是挺满意的，哈哈。\n参考资料  EasyYapi官方文档：param_ignore java在注解中绑定方法参数的解决方案  ","description":"","id":62,"section":"notes","tags":null,"title":"EasyYApi处理@RequestAttribute注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E5%A4%84%E7%90%86requestattribute%E6%B3%A8%E8%A7%A3/"},{"content":"我用渣英语提交的Issues，官方一天的时间就帮我修复了，非常棒的体验，哈哈。\n另外EasyYApi真的非常非常的好用，大爱。\n","description":"","id":63,"section":"notes","tags":null,"title":"EasyYApi提交的Bug被处理了，非常棒的体验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E6%8F%90%E4%BA%A4%E7%9A%84bug%E8%A2%AB%E5%A4%84%E7%90%86%E4%BA%86%E9%9D%9E%E5%B8%B8%E6%A3%92%E7%9A%84%E4%BD%93%E9%AA%8C/"},{"content":"Postman 我先从Postman整理起，虽然Postman相关的配置是我最后才实践的，但是确实提升了我不少编码幸福度。我比较喜欢使用Postman进行接口的测试，没有原因就是单纯的习惯了。我之前的方案是先用EasyYapi导出成一个文件，再在Postman中导入这个文件，步骤比较多，挺麻烦的。\n新方案为：\n 先生成一个Postman Token，然后配置到Idea中，这样我就可以直接通过EasyYapi将接口导入到我的Postman中了（Postman Token获取地址：https://go.postman.co/integrations/services/pm_pro_api）  配置postman.prerequest为如下内容，这样导出的每个接口在请求时都会自动加上token和Sdtc-Tenant-Id的Header，这样就不需要我手动填写了，非常舒服   pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({key: \u0026quot;token\u0026quot;,value: \u0026quot;{{token}}\u0026quot;}) pm.request.headers.add({key: \u0026quot;Sdtc-Tenant-Id\u0026quot;,value: \u0026quot;12345678910\u0026quot;}) 当然我Postman上还有一个登录用的脚本，可以同时请求dev和sit环境的登录接口，将token设置到环境变量中（具体实现可以在postman分类下寻找相关笔记）。\n这套方案我目前还是有一些不太舒服的地方，EasyYapi每次导出到Postman时都是新建一个分类，而不是与旧的分类进行融合。这会导致我们Postman看上去非常的乱。\n实际上我是比较希望它们进行融合的，因为我希望完成所有的接口开发后，我能拥有一套带数据的Postman接口，用于日后的维护工作（我不喜欢@Mock等注解，会增加维护成本）\n那么我目前是怎么处理这个问题的呢，如下，我手动维护了一份包含数据的测试接口，当我接口发生改变重新推到了Postman后，我手动的删除旧的Collection中的Request，将新的Request拖到我维护的这个Collection中。目前这个方案运行良好。\nYApi markdown.render.server配置 上来的第一问题就是markdown.render.server配置，我发现官网默认提供的地址被DNS污染了（我经过测试得出了这个结论），所以我不得不自行搭建一个yapi-markdown-render，在搭建yapi-markdown-render中我主要遇到的问题是：使用官方的源码，无法启动项目，因为某个依赖出现了错误，我解决这个问题的方法Fork一份源码，然后修改package.json文件，将该依赖的版本适当的改小，然后项目就可以正常的启动了，非常舒服。\n我Fork的源码地址\n我后来又开发了自己的Dockerfile，以在Docker中启动yapi-markdown-render，相关的笔记我放在了Docker分类下的利用Docker快速启动开发环境中（文章标题及目录未来可能调整），我不打算在这儿赘述了。\n具体到Idea项目中，我需要在.easy.api.config文件的配置如下：\n markdown.render.server=http://192.168.13.68:3001/render 很尴尬，因为后来DNS又恢复了，我已经注释掉这行配置了。\nmethod.return.main配置 如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  /** * xxx接口 * * @return 这是返回数据 */ @PostMapping(\u0026#34;/test\u0026#34;) public ResponseVo\u0026lt;String\u0026gt; test() { return ResponseVo.createSuccessByData(\u0026#34;tmp\u0026#34;); }   默认情况下，渲染出来的YApi文档如下：\n我们不知道返回的data类型是什么，含义是什么，当我们在.easy.api.config配置了如下代码后（具体配置要视各自项目情况而定）：\n method.return.main[groovy:it.returnType().isExtend(\u0026quot;com.sdstc.core.vo.ResponseVo\u0026quot;)]=data YApi渲染出来的页面如下：\nparam.ignore配置 1 2 3 4 5 6 7 8  @PostMapping(\u0026#34;/test\u0026#34;) public ResponseVo\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; createPdmProjMemberGroups(@RequestAttribute(APICons.REQUEST_USER_ID) String userId) { return ResponseVo.createSuccessByData(\u0026#34;tmp\u0026#34;); }   默认情况下，YAPI渲染出来时，会多一个userId的参数，这个会让人很迷惑，实际上userId是我们的网关通过解析Token，然后塞到了Header中，我们在UserIntercept中拿到这个值，然后塞到Attributes中，这儿不截图了。\n所以我进行了如下的配置：\n param.ignore=@org.springframework.web.bind.annotation.RequestAttribute postman.prerequest 这个配置是偷懒用的，我在postman分类下一篇笔记已经谈到过其用意，我目前的配置如下：\n postman.prerequest=``` pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({key: \u0026quot;token\u0026quot;,value: \u0026quot;{{token}}\u0026quot;}) pm.request.headers.add({key: \u0026quot;Sdtc-Tenant-Id\u0026quot;,value: \u0026quot;12345678910\u0026quot;}) ``` 备注与备注中分行 目标是这样的：\n代码中这么写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** * 更新项目团队（包含团队成员信息） * \u0026lt;p\u0026gt; * groupInfo中如果包含projectGroupId，则将对该团队进行更新\u0026lt;br\u0026gt; * groupInfo中如果不包含projectGroupId，则创建该团队信息\u0026lt;br\u0026gt; * 对于属于当前项目的projectGroupId，而在编辑时没有传递的，一律删除\u0026lt;br\u0026gt; */ @PostMapping(\u0026#34;/projectGroup/updatePdmProjMemberGroup\u0026#34;) @Transactional public ResponseVo updatePdmProjMemberGroup( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid UpdatePdmProjMemberGroupsRequest request) { pdmProjMemberGroupService.updatePdmProjMemberGroups(userId, tenantId, request); return ResponseVo.createSuccess(); }   json.rule.convert 目标是让Request和Response中的LocalDateTime类型，呈现在YApi上为Integer类型，具体的配置如下：\n json.rule.convert[java.time.LocalDateTime]=java.lang.Integer 默认情况下是String类型，这个不符合我们的项目场景。\n","description":"","id":64,"section":"notes","tags":null,"title":"EasyYApi目前配置总结","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E7%9B%AE%E5%89%8D%E9%85%8D%E7%BD%AE%E6%80%BB%E7%BB%93/"},{"content":"之所以安装ElasticSearch 1.4.1，是因为《ElasticSearch实战》这本书使用的是该版本的ElasticSearch，在启动的过程中，我发现了该版本的ElasticSearch会闪退。\n我目前没有定位该问题，但是我发现如果我配置了JAVA_HOME，然后去启动我最新版的ElasticSearch，也会闪退，我估计大概率是因为JAVA_HOME导致的闪退，但是我现在没有证据。\n20210615后续：\n该问题在Linux上并不会复现。\n","description":"","id":65,"section":"notes","tags":null,"title":"ElasticSearch 1.4.1闪退问题记录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/elasticsearch/elasticsearch-1.4.1%E9%97%AA%E9%80%80%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"content":"合并单元格 之前的版本中，一直是右键，然后选择合并单元格，最近用的版本貌似不支持这种方法了。\n锁定单元格 需求产生于我们开发，需要在代码中模拟单元格的锁定，所以先掌握在Excel中对其的操作。\n我简单描述下操作过程吧：\n 全选，然后右键，选择单元格属性，然后在保护选项卡中选择取消锁定。 选中需要保护的内容，然后右键，选择单元格属性，然后在保护选项卡中选择锁定。 在Excel顶部的审阅中选择保护工作簿  okay，这就实现了锁定单元格\n隐藏单元格   选中需要隐藏的第一列，按ctrl + stift + left键，选中右侧所有的键，对选中区域右键，选择隐藏\n  选中需要隐藏的第一行，按ctrl + stift + down键，选中下侧所有的键，对选中区域右键，选择隐藏\n  选择工作区域，点击右键，选择单元格格式，调整单元格边框（好看）\n  20210426补充：\n额，这是很久前整理的，我好奇能不能先选中我想要的区域，然后再执行反选呢？\n相关资料  怎么只显示EXCEL编辑区域  ","description":"","id":66,"section":"notes","tags":null,"title":"Excel常用操作","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/excel%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"content":"最近又想将项目中的LocalDateTime序列化和反序列化统一起来，所以需要对Fastjson进行全局化配置，Fastjson全局化配置并不是很复杂，如下代码即可完成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器 serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); });   在这段配置中，我为fastjson的序列化配置增加了一项针对LocalDateTime类型的序列化器，该序列化器会将LocalDateTime类型的对象转换成一个时间戳。\n","description":"","id":67,"section":"notes","tags":null,"title":"Fastjson全局配置的一些事情","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%E6%83%85/"},{"content":"没有比较优雅的方案，代码如下：\n1 2 3 4 5 6 7 8 9 10  Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;json数据格式错误\u0026#34;); }   参考资料  FastJSON判断JSON字符串是JSONObject或JSONArray 如何判断一个JSON字符串是普通JSON(JSONObject)还是数组JSON(JSONArray)  ","description":"","id":68,"section":"notes","tags":null,"title":"FastJSON判断json字符串是array还是object","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%88%A4%E6%96%ADjson%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AFarray%E8%BF%98%E6%98%AFobject/"},{"content":"代码如下:\n1 2 3 4 5 6  JSONObject obj = JSONObject.parseObject(jsonStr, Feature.OrderedField); ~~ 整理这个笔记的时候发现了新的知识点。我之前一直再用`JSON.parsetObject()`方法，需要将返回结果再强转为`JSONObject`类型，很繁琐。其实上可以使用`JSONObject.parseObject()`方法。   ","description":"","id":69,"section":"notes","tags":null,"title":"FastJson反序列化时保持字段的顺序","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E4%BF%9D%E6%8C%81%E5%AD%97%E6%AE%B5%E7%9A%84%E9%A1%BA%E5%BA%8F/"},{"content":"布尔类型 FreeMarker中不可以直接在渲染出布尔值，需要使用如下的语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ${flag?c}\u0026lt;#assign foo = true\u0026gt; ${foo?then(\u0026#39;Y\u0026#39;, \u0026#39;N\u0026#39;)}\u0026lt;#assign foo2 = false\u0026gt; ${foo2?then(\u0026#39;Y\u0026#39;, \u0026#39;N\u0026#39;)}\u0026lt;#assign x = 10\u0026gt; \u0026lt;#assign y = 20\u0026gt; ${100 + (x \u0026gt; y)?then(x, y)}  日期类型 FreeMarker中不可以直接输出日期类型，需要使用如下的语法：\n1 2 3  renderData.put(\u0026#34;openingTime\u0026#34;, new Date());   1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;#assign x = openingTime\u0026gt; ${openingTime?time}\u0026lt;#assign openingTimeTime = openingTime?time\u0026gt; ${openingTimeTime}\u0026lt;#-- 将datetime类型转成date和time --\u0026gt; \u0026lt;#assign openingTimeDateTime = openingTime?datetime\u0026gt; ${openingTimeDateTime}${openingTimeDateTime?date}${openingTimeDateTime?time}  如果问号左边是字符串，那么这些内建函数将字符串转换成日期/时间/日期事件（实验中datetime并不好使）：\n1 2 3 4 5  renderData.put(\u0026#34;openingTimeTimeStr\u0026#34;, \u0026#34;19:27:58\u0026#34;); renderData.put(\u0026#34;openingTimeDateStr\u0026#34;, \u0026#34;2021-6-23\u0026#34;); renderData.put(\u0026#34;openingTimeDatetimeStr\u0026#34;, \u0026#34;2021-6-23 19:27:58\u0026#34;);   1 2 3 4 5  ${openingTimeTimeStr?time}${openingTimeDateStr?date}${openingTimeDateTimeStr?datetime}  还可以使用?string：\n1 2 3 4 5 6  renderData.put(\u0026#34;openingTime\u0026#34;, new java.sql.Time(123456789)); renderData.put(\u0026#34;nextDiscountDay\u0026#34;, new java.sql.Date(123456789)); renderData.put(\u0026#34;lastUpdated\u0026#34;, new java.sql.Timestamp(123456789)); renderData.put(\u0026#34;lastUpdated2\u0026#34;, new java.util.Date(123456789));   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  ${openingTime?string.short}${openingTime?string.medium}${openingTime?string.long}${openingTime?string.full}${openingTime?string.xs}${openingTime?string.iso}${nextDiscountDay?string.short}${nextDiscountDay?string.medium}${nextDiscountDay?string.long}${nextDiscountDay?string.full}${nextDiscountDay?string.xs}${nextDiscountDay?string.iso}${lastUpdated?string.short}${lastUpdated?string.medium}${lastUpdated?string.long}${lastUpdated?string.full}${lastUpdated?string.medium_short}\u0026lt;#-- medium date, short time --\u0026gt; ${lastUpdated?string.xs}${lastUpdated?string.iso}\u0026lt;#-- SimpleDateFormat patterns: --\u0026gt; ${lastUpdated?string[\u0026#34;dd.MM.yyyy, HH:mm\u0026#34;]}${lastUpdated?string[\u0026#34;EEEE, MMMM dd, yyyy, hh:mm a \u0026#39;(\u0026#39;zzz\u0026#39;)\u0026#39;\u0026#34;]}${lastUpdated?string[\u0026#34;EEE, MMM d, \u0026#39;\u0026#39;yy\u0026#34;]}${lastUpdated?string.yyyy}\u0026lt;#-- Same as ${lastUpdated?string[\u0026#34;yyyy\u0026#34;]}--\u0026gt; \u0026lt;#-- Advanced ISO 8601-related formats: --\u0026gt; ${lastUpdated?string.iso_m_u}${lastUpdated?string.xs_ms_nz}  ","description":"","id":70,"section":"notes","tags":null,"title":"FreeMarker中的数据类型","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"content":"之前学习Thymeleaf时，对其include和fragment影响深刻，其功能大致描述如下，我们在一个文件中定义多个fragment，然后在另一份文件中通过include指令，应用这份文件中的fragment。\n我非常喜欢这种方式，因为这种方式很适合模板代码的管理，模板代码中有很多时候实现一个功能的代码分散在Controller、Service、Mapper层，如果支持这种fragment，则我们可以将这些fragment写到同一个文件中，然后再不同层的模板代码中引用这些fragment代码，很可惜FreeMarker的include指令并不支持fragment。所以我决定自己实现该功能。\n这个功能我实现了两版，两版都是通过自定义指令实现的。区别是第一版在自定义指令回调中寻找模板内容，而第二版在SpringBoot项目启动时，扫描相关的目录，加载所有的模板内容到缓存中，然后在自定义指令的回调中从缓存中获取模板内容，然后渲染到页面中。\n相关的实现，在我的工具包代码中。\njunjie2018/AutoTools\n","description":"","id":71,"section":"notes","tags":null,"title":"FreeMarker实现Thymeleaf中的include和fragment","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E5%AE%9E%E7%8E%B0thymeleaf%E4%B8%AD%E7%9A%84include%E5%92%8Cfragment/"},{"content":"我在开发模板代码时，我期待我的模板代码足够清晰，所以我指令和指令之间会空较多的行，用于代码排版，如下所示：\n\u0026lt;#list columnInfos as columnInfo\u0026gt; \u0026lt;@noSpaceLine\u0026gt; \u0026lt;#-- 忽略审计字段 --\u0026gt; \u0026lt;#if columnInfo.columnName == \u0026quot;org_id\u0026quot; || columnInfo.columnName == \u0026quot;creator\u0026quot; || columnInfo.columnName == \u0026quot;modifier\u0026quot; || columnInfo.columnName == \u0026quot;gmt_create_time\u0026quot; || columnInfo.columnName == \u0026quot;gmt_modify_time\u0026quot;\u0026gt; \u0026lt;#continue\u0026gt; \u0026lt;/#if\u0026gt; \u0026lt;#if columnInfo.enumInfo??\u0026gt; /** * ${columnInfo.columnComment} * * @see ${properties.enumsPackage}.${columnInfo.enumInfo.enumClass}#value */ \u0026lt;#if columnInfo.columnName == \u0026quot;id\u0026quot;\u0026gt; @NotBlank \u0026lt;/#if\u0026gt; private ${columnInfo.enumInfo.enumValueType} ${columnInfo.beanObject}; \u0026lt;#elseif columnInfo.internalClassInfo??\u0026gt; /** * ${columnInfo.columnComment} */ private JSONObject ${columnInfo.beanObject}; \u0026lt;#else\u0026gt; /** * ${columnInfo.columnComment} */ \u0026lt;#if columnInfo.columnName == \u0026quot;id\u0026quot;\u0026gt; @NotBlank \u0026lt;/#if\u0026gt; private ${columnInfo.fieldType} ${columnInfo.beanObject}; \u0026lt;/#if\u0026gt; \u0026lt;/@noSpaceLine\u0026gt; \u0026lt;/#list\u0026gt; 其实javadoc的注释、注解和代码之间我不希望有的空行。如果不自行开发指令的话，渲染出来的代码会有很大的空隙，非常影响阅读，我阅读过FreeMarker的文档，没有找到任何好用的指令，所以最后决定自行开发。\n相关的代码体现在我的工具包中：\nNoSpaceLineDiretive.java\n思路核心为：在指令中拿取指令体，然后渲染出指令体，处理掉渲染后的内容中的空白行，再调用env.getOut().write()写回处理后的内容。\n参考资料  Freemarker自定义指令和方法\n学会  ","description":"","id":72,"section":"notes","tags":null,"title":"FreeMarker开发NoSpaceLine指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E5%BC%80%E5%8F%91nospaceline%E6%8C%87%E4%BB%A4/"},{"content":"如果现在让我处理这个问题，我会选择使用自定义指令的方式（也不一定，自定义会让模板代码增加很多无关的标签），但是当时的话我自定义指令也并不是很熟悉，所以我选择了自定义Writer，让后将Writer传递给FreeMarker的渲染方法，代码如下：\nTemplateUtilsMax.java\n代码还处理调整期，未来还可能调整代码。\n","description":"","id":73,"section":"notes","tags":null,"title":"FreeMarker渲染后的内容至多一行空行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E6%B8%B2%E6%9F%93%E5%90%8E%E7%9A%84%E5%86%85%E5%AE%B9%E8%87%B3%E5%A4%9A%E4%B8%80%E8%A1%8C%E7%A9%BA%E8%A1%8C/"},{"content":"我目前没有相关的需求，但是看这篇文章通俗易读易实践，就记录一下。\n参考资料  [Freemarker] Freemarker自定义函数  ","description":"","id":74,"section":"notes","tags":null,"title":"FreeMarker自定义函数的开发","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E7%9A%84%E5%BC%80%E5%8F%91/"},{"content":" 打开Git Bash，执行如下指令：   git config --global core.quotepath false 按如下截图操作：  参考资料  git 显示中文和解决中文乱码  ","description":"","id":75,"section":"notes","tags":null,"title":"Git Bash换成中文（待整理）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git-bash%E6%8D%A2%E6%88%90%E4%B8%AD%E6%96%87%E5%BE%85%E6%95%B4%E7%90%86/"},{"content":"该技术在做Docker镜像的时候非常好使。\n git clone git@github.com.user/my-project.git . 参考资料  git clone如何克隆到当前目录  ","description":"","id":76,"section":"notes","tags":null,"title":"Git Clone到当前目录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git-clone%E5%88%B0%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95/"},{"content":"执行如下指令：\n git reset --soft HEAD^ 这个是在push到远程分支前有效的，如果已经push到远程分支了，需要参考我另一篇笔记。\n该撤销会保存文件~~~\n参考教程  git commit之后，想撤销commit  ","description":"","id":77,"section":"notes","tags":null,"title":"git commit后撤销该commit","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git-commit%E5%90%8E%E6%92%A4%E9%94%80%E8%AF%A5commit/"},{"content":"参考我的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  { \u0026#34;plugins\u0026#34;: [ \u0026#34;-search\u0026#34;, \u0026#34;-lunr\u0026#34;, \u0026#34;-sharing\u0026#34;, \u0026#34;-livereload\u0026#34;, \u0026#34;-font-settings\u0026#34;, \u0026#34;lightbox\u0026#34;, \u0026#34;expandable-chapters\u0026#34;, \u0026#34;chapter-fold\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;back-to-top-button\u0026#34;, \u0026#34;code\u0026#34;, \u0026#34;hide-element\u0026#34;, \u0026#34;custom-favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;copyButtons\u0026#34;: true }, \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/junjie2018\u0026#34; }, \u0026#34;hide-element\u0026#34;: { \u0026#34;elements\u0026#34;: [\u0026#34;.gitbook-link\u0026#34;] }, \u0026#34;favicon\u0026#34;:\u0026#34;favicon.ico\u0026#34; } }   然后执行如下指令：\n gitbook install . 配置说明 -search：去除默认的搜索插件\n-sharing：去除默认的分享插件\n-livereload：去除git serve热更新插件\n-font-settings：去除页面上的A按钮插件\nlightbox：单击查看图片\nexpandable-chapters：\nhide-element：隐藏页面一些元素用的，目前和其他插件有一些冲突\ncustom-favicon：修改标题栏的图标（我的图标是在https://favicon.io/生成的，还不错）\n参考资料  GitBook插件整理  ","description":"","id":78,"section":"notes","tags":null,"title":"GitBook安装插件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/gitbook%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6/"},{"content":"试出来的：\n gitbook --version gitbook current ","description":"","id":79,"section":"notes","tags":null,"title":"Gitbook显示版本号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/gitbook%E6%98%BE%E7%A4%BA%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"指令如下：\n1 2 3 4 5  cd ~ mkdir -p Blogs/output gitbook build Blogs Blogs/output   参考资料  输出为静态网站  ","description":"","id":80,"section":"notes","tags":null,"title":"GitBook生成静态html文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/gitbook%E7%94%9F%E6%88%90%E9%9D%99%E6%80%81html%E6%96%87%E4%BB%B6/"},{"content":"在开发GitHub Actions时，我其实挺建议在脚本里写清楚各个步骤执行的指令，及指令执行后的结果的，因为这样更有利于排除错误，举一个简单的例子。\n1 2 3 4 5 6 7 8 9 10 11 12  # 执行的指令 echo \u0026#34;gitbook init\u0026#34; # 执行指令 gitbook init # 执行的结果 ls cat SUMMARY.md cat README.md   我在修复问题时就用到了这种方式，定位问题挺快的。\n","description":"","id":81,"section":"notes","tags":null,"title":"GitHub Actions开发时的一点小心得","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/github-actions%E5%BC%80%E5%8F%91%E6%97%B6%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E5%BF%83%E5%BE%97/"},{"content":"问题描述 向GitHub仓库推送代码时，先后出现了如下错误：\n1 2 3 4  git push -u origin main fatal: unable to access \u0026#39;https://github.com/junjie2018/blogs.git/\u0026#39;: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054   1 2 3 4  git push -u origin main fatal: unable to access \u0026#39;https://github.com/junjie2018/blogs.git/\u0026#39;: Failed to connect to github.com port 443: Timed out   解决方案  为Git客户端端配置代理：  1 2 3 4  git config --local http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39;   问题给的信息是真的难以定位，只是习惯性的去配一下代码。\n","description":"","id":82,"section":"notes","tags":null,"title":"GitHub推送代码失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/github%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E5%A4%B1%E8%B4%A5/"},{"content":"我fork了一个仓库，做了一些自己的修改，然后发起一个Pull Request，希望该仓库的原作者看到我的修改，然后决定是否采用这些修改。这个就是Pull Request的作用。\n我之前从字面意思理解这个，很糗。\n参考资料  GitHub 的 Pull Request 是指什么意思？  ","description":"","id":83,"section":"notes","tags":null,"title":"GitHub的Pull Requst","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/github/github%E7%9A%84pull-requst/"},{"content":"问题描述 考虑到最近GitHub经常无法正常使用，而我在开发博客脚本需要从GitHub上拉取推送代码，所以我打算在代码中使用代理，我的代码如下：\n1 2 3 4 5 6  Repo.clone_from(\u0026#34;https://github.com/junjie2018/blogs.git\u0026#34;, to_path=blogs_path, branch=\u0026#34;main\u0026#34;, config=\u0026#34;https.proxy=socks://localhost:1080\u0026#34;)   这份代码的问题是，只会偶尔一次两次成功，我并不确定是什么原因产生的。我有尝试过将socks换为http、https，情况也是一样的，都是偶尔一两次成功。我是在Windows环境下进行测试的。\n解决方案 这方面的资料太少了，我决定先绕开这个问题，在执行脚本是前，我设置Git客户端的全局代理。\n1 2 3 4  git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39;   ","description":"","id":84,"section":"notes","tags":null,"title":"gitpython模块中代理无法正常使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/gitpython%E6%A8%A1%E5%9D%97%E4%B8%AD%E4%BB%A3%E7%90%86%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E4%BD%BF%E7%94%A8/"},{"content":"我的需求是这样的，同事将代码提交到自己的分支上了，我需要查看他的代码，所以我需要切换到他的分支上，然后查看代码，我使用命令行操作git。\n我之前将这个问题复杂化了，实际上我只需要在当前分支拉取一下代码，就可以拉取到他的分支的信息，然后使用git checkout切换到他的分支上。\n参考资料   git 拉取远程分支到本地\n简单接触了一下git fetch指令\n  git获取远程服务器的指定分支\ngit pull \u0026lt;远程库名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt;：单独拉下某个分支，我使用这个指令的场景还是蛮多的\n这条指令还可以拉取远程分支与当前分支合并。\ngit pull指令相当于先做了git fetch，再做了git merge\n  ","description":"","id":85,"section":"notes","tags":null,"title":"Git切换到远程分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%88%87%E6%8D%A2%E5%88%B0%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"content":"操作步骤  指令如下  1 2 3 4  # 删除xxx.txt的跟踪，并保留在本地 git rm --cached xxx.txt   ","description":"","id":86,"section":"notes","tags":null,"title":"Git取消对文件的追踪","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%8F%96%E6%B6%88%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%BD%E8%B8%AA/"},{"content":"适用场景：在Uat或生产环境等分支不经常变更的场景，为了定位问题，增加了许多无用的代码，并提交到分支上了。待问题解决后，需要删除这些代码，建议适用分支回退功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  git checkout uat \u0026amp;\u0026amp; git pull # 本地和远程备份分支 git branch uat_backup \u0026amp;\u0026amp; git push origin uat_backup git reset --hard the_commit_id # 删除远程分支，并用本地分支重建 git push origin :uat git push origin uat # 删除远程备份分支 git push origin :uat_backup   其实并不建议使用这个方案，这个方案要删除远程分支，可能因为权限等问题无法实现，且可能因为一些意外情况，造成这个分支永远被销毁了。\n参考资料  git 远程分支回滚  ","description":"","id":87,"section":"notes","tags":null,"title":"Git回退远程分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%9B%9E%E9%80%80%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"content":"操作步骤  指令如下   git remote set-url origin https://github.com/junjie2018/out_of_memory.git ","description":"","id":88,"section":"notes","tags":null,"title":"Git客户端修改远程仓库地址","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BF%AE%E6%94%B9%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E5%9C%B0%E5%9D%80/"},{"content":"操作步骤  指令如下  1 2 3  git config --global core.editor vim   使用场景比较窄，但是当你需要的时候，你又必须去设置。\n相关教程  修改git默认的编辑器  ","description":"","id":89,"section":"notes","tags":null,"title":"Git客户端修改默认的编辑器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/"},{"content":"操作步骤  指令如下：  1 2 3 4 5 6 7  git config --global credential.helper store sudo tee ~/.git-credentials \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https://user:password@gitee.com EOF   这个在只能走https协议的场景下非常好使，但是要记得将自己的账号设置成需要邮箱或手机号验证的，因为这种方案很容易泄漏账号信息。\n","description":"","id":90,"section":"notes","tags":null,"title":"Git客户端配置https免密","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AEhttps%E5%85%8D%E5%AF%86/"},{"content":"操作步骤  指令如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # 全局 git config --global http.proxy \u0026#39;http://192.168.13.59:1080\u0026#39; git config --global https.proxy \u0026#39;http://192.168.13.59:1080\u0026#39; git config --global http.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global http.proxy \u0026#39;http://192.168.13.113:1080\u0026#39; git config --global https.proxy \u0026#39;http://192.168.13.113:1080\u0026#39; git config --global --unset http.proxy git config --global --unset https.proxy # 本地 git config --local http.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --local https.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --local http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local --unset http.proxy git config --local --unset https.proxy   ","description":"","id":91,"section":"notes","tags":null,"title":"Git客户端配置代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"我准备换pygit为GitPython，但是我导入git包后找不到用不了git.Repo，我已经在PyCharm的Inspector中去掉了pygit、gitdb，这些可能影响到我的模块，并开了一个新的项目去测试GitPython，发现是正常的。\n我按住ctrl后，点击git模块，在项目定位到了一个名为git的目录，我感觉这个我的情况不符合，所以我删掉了GitPython，又重新引入，然后按住ctrl后，点击git模块，这此进来的一个git.py文件，这个比较符合我的情况。\n可能是之前导入模块的时候，相互影响了吧。\n","description":"","id":92,"section":"notes","tags":null,"title":"git模块的小问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/git%E6%A8%A1%E5%9D%97%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8  # 删除untracker files git clean -f # 连untracked的目录一起删除 git clean -fd   ","description":"","id":93,"section":"notes","tags":null,"title":"Git清除未跟踪的文件和文件夹","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E6%B8%85%E9%99%A4%E6%9C%AA%E8%B7%9F%E8%B8%AA%E7%9A%84%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"代码如下：\n git config --global user.name 小桀 git config --global user.email 812797569@qq.com ","description":"","id":94,"section":"notes","tags":null,"title":"Git设置提交时的用户名和账号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git%E8%AE%BE%E7%BD%AE%E6%8F%90%E4%BA%A4%E6%97%B6%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E8%B4%A6%E5%8F%B7/"},{"content":"今天第一次接触GRpc，之前有做游戏开发时用的ProtoBuf，对这个东西印象很好，GRpc的底层貌似就是ProtoBuf。\n大概说下我做了哪些操作吧：\n  为类加上@GRpcService注解，这个注解是我们自己开发的，我还没有去了解这些注解的细节。\n  启动应用程序，在日志里搜索port，可以看到GRpcService监听的是9090端口\n  下载grpcui，解压后配置一些环境变量，然后打开cmd执行grpcui -help\n  执行如下指令，将打开一个新的Web页面，该页面就是用来测试GRpc的工具。\n   grpcui -plaintext localhost:9090 GRpc服务的代码如何编写？我刚开始在这个方面犯错了，错误表现为在grpcui点击了invoke按钮后，invoke按钮一直是灰色的。后来按照同事提供的方式编写了如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Override public void create(com.sdstc.catalog.paas.dm.api.EnterModel.CreateRequest request, io.grpc.stub.StreamObserver\u0026lt;com.sdstc.catalog.paas.dm.api.EnterModel.CreateResponse\u0026gt; responseObserver) { System.out.println(\u0026#34;This is Create\u0026#34;); printObject(request); responseObserver.onNext(EnterModel.CreateResponse.newBuilder() .setCode(200) .setRelateId(\u0026#34;1111\u0026#34;) .build()); responseObserver.onCompleted(); }   我犯错的原因是，我没有执行responseObserver.onCompleted()。\n我们的GRpc用在什么场景中？我们有一个目录服务，我们公司所有上传的项目最终都会将内容提交到这个项目中。之前我们的方案中，用户提交的内容先提交到各自服务，然后再调用目录服务的接口，将这些数据提交到目录服务中（是这样么，我不确定之前是不是这样实现的）。\n这样做有什么坏处呢？我们服务间通信使用的是Restful风格的接口，Http请求的时候是有可能失败的，我们是需要进行重试处理的。我们虽然有自己的重试服务，重试工作会比较简单，但是我们每个服务依旧需要提供Client去处理重试逻辑，这会增加每个开发人员的工作量。而且重试只是最终保证了我们的数据时正确的，当数据驻留在消息服务器上的时候，可能会给我们的项目Debug时带来一些困扰。\n还有什么问题呢？目录服务是一个中心服务，向其提交数据有两种方式，暴露接口，让中心服务自己拉取；调用中心服务的接口，将数据主动推送过去。很多时候，我们的服务是需要同时支持这两种方式的，这无形中增加了各个服务的开发量。而且由各个服务决定数据的形式，目录服务本身也会进行一些开发，进行适配。\n总之，在我看来，之前的这种方案，隐含了很多的开发任务，和系统运行的不稳定因素。\n我们新方案的思路是怎样的呢？前端直接将数据提交到目录服务，目录服务完成处理后，调各个服务的接口将用户的数据通知到各个服务。然后服务拿到这些数据后，再按照设计进行入库、或更新。有时候目录中心需要全量的服务数据，这个也是通过GRpc的服务实现的。\n我对这套设计的理解就这些了，还在探索中。\n","description":"","id":95,"section":"notes","tags":null,"title":"GRpc与我们的项目","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/grpc/grpc%E4%B8%8E%E6%88%91%E4%BB%AC%E7%9A%84%E9%A1%B9%E7%9B%AE/"},{"content":"因为需要更换为新Service，所以导致项目中新旧同时存在，项目启动的时候没有任何问题，但是我用grpcui去连接的时候，报了如下的错误：\n Failed to compute set of methods to expose: Symbol not found: com.sdstc.catalog.paas.dm.api.DataModel_12CatalogDMAdapterService DataModel_12CatalogDMAdapterService是我开发的新服务，我的解决方法是将旧服务的代码全部注解掉。\n暂时没有精力对这些问题深入研究，先记录下吧。\n","description":"","id":96,"section":"notes","tags":null,"title":"GRpc问题记录：两个版本的服务同时存在","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/grpc/grpc%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E4%B8%A4%E4%B8%AA%E7%89%88%E6%9C%AC%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8/"},{"content":"我用的时候一般直接解压到当前目录：\n gzip xxx.gz -d 解压位置 参考资料  解压.gz和.tar.gz文件  ","description":"","id":97,"section":"notes","tags":null,"title":"gzip解压.gz后缀结尾的文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip%E6%8C%87%E4%BB%A4/gzip%E8%A7%A3%E5%8E%8B.gz%E5%90%8E%E7%BC%80%E7%BB%93%E5%B0%BE%E7%9A%84%E6%96%87%E4%BB%B6/"},{"content":"目前这个方式适用的场景有点窄，只用为Docker Hub和同Harbor仓库进行代理缓存。先观望着吧。\n参考资料  使用harbor代理缓存docker hub  ","description":"","id":98,"section":"notes","tags":null,"title":"Harbor配置代理缓存","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/harbor%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E7%BC%93%E5%AD%98/"},{"content":"简单指令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 展示可配置项 helm show values bitnami/wordpress # 使用指定文件覆盖默认配置 echo \u0026#39;{mariadb.auth.database: user0db, mariadb.auth.username: user0}\u0026#39; \u0026gt; values.yaml helm install -f values.yaml bitnami/wordpress --generate-name # 查看指定release中--set设置的值 helm get values \u0026lt;release-name\u0026gt; # 清除--set中设置的值 helm upgrade --reset-values   两种方式传递配置数据  \u0026ndash;values(或-f)：使用YAML文件覆盖配置。可以指定多次，优先使用最右边的文件。 \u0026ndash;set：通过命令行的方式对指定项进行覆盖。  如果同时使用两种方式，则\u0026ndash;set中的值会被合并到\u0026ndash;values中，但是\u0026ndash;set中的值优先级更高。\n\u0026ndash;set的格式和限制 \u0026ndash;set选项使用0或多个name/value对。最简单的用法类似于：\u0026ndash;set name=value，等价于如下YAML格式：\n1 2 3  name:value  多个值使用逗号分割，因此\u0026ndash;set a=b,c=d的YAML表示是：\n1 2 3 4  a:bc:d  支持更复杂的表达式。例如，\u0026ndash;set outer.inner=value 被转换成了：\n1 2 3 4  outer:inner:value  列表使用花括号（{}）来表示。例如，\u0026ndash;set name={a, b, c} 被转换成了：\n1 2 3 4 5 6  name:- a- b- c  可以使用数组下标的语法来访问列表中的元素。例如 \u0026ndash;set servers[0].port=80 就变成了：\n1 2 3 4  servers:- port:80  多个值也可以通过这种方式来设置。\u0026ndash;set servers[0].port=80,servers[0].host=example 变成了：\n1 2 3 4 5  servers:- port:80host:example  如果需要在 \u0026ndash;set 中使用特殊字符，你可以使用反斜线来进行转义；\u0026ndash;set name=value1,value2 就变成了：\n1 2 3  name:\u0026#34;value1,value2\u0026#34;  类似的，你也可以转义点\u0008序列（英文句号）。这可能会在 chart 使用 toYaml 函数来解析 annotations，labels，和 node selectors 时派上用场。\u0026ndash;set nodeSelector.\u0026ldquo;kubernetes.io/role\u0026rdquo;=master 语法就变成了：\n1 2 3 4  nodeSelector:kubernetes.io/role:master  深层嵌套的数据结构可能会很难用\u0026ndash;set表达。我们希望Chart的设计者们在设计values.yaml文件的格式时，考虑到\u0026ndash;set的使用。\n参考资料  安装前自定义 chart  ","description":"","id":99,"section":"notes","tags":null,"title":"Helm安装Chart前修改配置文件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/helm%E5%AE%89%E8%A3%85chart%E5%89%8D%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"content":" 从Artifact Hub中、repo中搜索chart  1 2 3 4 5 6 7 8  # 从hub中 helm search hub wordpress # 从repo中 helm repo add brigade https://brigadecore.github.io/charts helm search repo brigade   安装chart  1 2 3 4 5 6 7 8 9 10 11 12 13  # release名字和chart名字 helm install happy-panda bitnami/wordpress helm install bitnami/wordpress --generate-name # 多种来源进行安装 helm install foo foo-0.1.1.tgz helm install foo path/to/foo helm install foo https://example.com/charts/foo-1.2.3.tgz # 查看Release状态 helm status happy-panda   安装前自定义chart（简单版）  1 2 3 4 5 6 7 8  # 查看chart中的可配置项 helm show values bitnami/wordpress # 使用yaml格式文件覆盖任意配置 echo \u0026#39;{mariadb.auth.database: user0db, mariadb.auth.username: user0}\u0026#39; \u0026gt; values.yaml helm install -f values.yaml bitnami/wordpress --generate-name   升级release和失败时恢复  1 2 3 4 5 6 7 8 9 10  # 升级chart的新版本或修改release的配置 helm upgrade -f panda.yaml happy-panda bitnami/wordpress # 可以用于失败时回滚 helm rollback happy-panda 1 # 查看一个特定release的修订版本号 helm history [RELEASE]   卸载相关   helm uninstall happy-panda helm list helm uninstall --keep-history helm list --uninstalled helm list --all 仓库管理   helm repo list helm repo add dev https://example.com/dev-charts # 更新仓库 helm repo update # 移除仓库 helm repo remove dev 创建Chart   helm create deis-workflow # 验证格式 helm lint # 打包分发 helm package deis-workflow # 安装chart helm install deis-workflow ./deis-workflow-0.1.0.tgz 参考资料  使用Helm  ","description":"","id":100,"section":"notes","tags":null,"title":"Helm常用指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/helm%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"如下插件配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  { \u0026#34;plugins\u0026#34;: [ \u0026#34;-search\u0026#34;, \u0026#34;-sharing\u0026#34;, \u0026#34;-livereload\u0026#34;, \u0026#34;-font-settings\u0026#34;, \u0026#34;lightbox\u0026#34;, \u0026#34;expandable-chapters\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;back-to-top-button\u0026#34;, \u0026#34;code\u0026#34;, \u0026#34;hide-element\u0026#34;, \u0026#34;custom-favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;copyButtons\u0026#34;: true }, \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/junjie2018\u0026#34; }, \u0026#34;hide-element\u0026#34;: { \u0026#34;elements\u0026#34;: [\u0026#34;.gitbook-link\u0026#34;,\u0026#34;chapter\u0026#34;] }, \u0026#34;favicon\u0026#34;:\u0026#34;favicon.ico\u0026#34; } }   我在使用中发现，如果我不清除search、sharing、livereload插件，则hide-element插件会起到作用。但是一旦清除了它们，则该插件不会起到任何作用。\n是为什么发生这个问题呢？其实如上的配置，其实会导致我页面报错，页面报错，可能会导致我hide-element的方法没有被执行到，从而无法影藏我想隐藏的内容。\n该如何处理这个问题呢？其实search有一个lunr的插件，这个插件应该是search的后端（具体实现不是太了解），如果我们需要删除search插件，则需要同时删除lunr插件，否则就会导致页面报错。\n后续：\n我在定位这个问题时，在hide-elements配置中加了如下的配置：\n结果后来忘记清除了，导致我这个配置用在了各个地方，最终导致我发布笔记左侧没有目录结构，糟心。\n","description":"","id":101,"section":"notes","tags":null,"title":"hide-element插件冲突的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/hide-element%E6%8F%92%E4%BB%B6%E5%86%B2%E7%AA%81%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"这是之前处理问题时用到的资料，整理一份。\n背景是这样的，我们的http可以正常的建立链接，但是https无法正常的建立链接。\n参考资料  SSL Handshake 被莫名其妙地 RST  ","description":"","id":102,"section":"notes","tags":null,"title":"https无法正常链接","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/istio/https%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E9%93%BE%E6%8E%A5/"},{"content":"指令：\n hugo -D 输出的文件默认放在public目录下，可以通过-d/\u0026ndash;destination修改文件生成时存放的位置，或者在配置文件中通过publishdir修改文件生成后存放的位置。\n参考资料  Build static pages  ","description":"","id":103,"section":"notes","tags":null,"title":"Hugo输出静态文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/hugo%E8%BE%93%E5%87%BA%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/"},{"content":"安装主题后，用如下指令运行代码：\n hugo server --minify --theme book --bind=\u0026quot;0.0.0.0\u0026quot; --baseUrl=\u0026quot;http://192.168.27.121:1313\u0026quot; 报错，无法运行。我安装的是非扩展版，去官方下载扩展版即可。\nhugo release\n","description":"","id":104,"section":"notes","tags":null,"title":"Hugo运行时提示：you need the extended version to build SCSSSASS","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/hugo%E8%BF%90%E8%A1%8C%E6%97%B6%E6%8F%90%E7%A4%BAyou-need-the-extended-version-to-build-scsssass/"},{"content":"Hutool v5.6.3\n","description":"","id":105,"section":"notes","tags":null,"title":"Hutool工具的研究（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/hutool%E5%B7%A5%E5%85%B7%E7%9A%84%E7%A0%94%E7%A9%B6%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"这个问题的核心原因在于Idea版本和Maven版本不兼容。这篇文章整理的太晚了，好多细节信息没有记录下来。先这样吧，知道版本不兼容问题可能会带来问题就好。\n参考资料   Maven3.6.3 在IntelliJ IDEA2019新版本中问题，Unable to import maven project: See logs for details\n  #org.jetbrains.idea.maven - com.google.inject.CreationException: Unable to create injector, see the\n  ","description":"","id":106,"section":"notes","tags":null,"title":"Idea与Maven集成的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%8Emaven%E9%9B%86%E6%88%90%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我其实一致没有系统深入的学习Git，但是现在新工作已经对我这方面能力提出了要求，我先从Idea中Git的使用下手，然后陆续学习更高级的Git知识。\n","description":"","id":107,"section":"notes","tags":null,"title":"Idea中Git的使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%ADgit%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"content":"想看一下spring-boot-starter-parent的源码，看看版本裁决时用了哪些变量，但是发现Idea无法调整到这些源码，这就很奇怪了。\n我没有找到解决跳转问题的办法，先记录一下。我pom文件中parent标签内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt;   通过重新定义spring-boot-starter-parent，从而改变所依赖的组件的版本是一个蛮重要的技术（个人认为），所以以后还是要解决这个问题的。我目前选择的绕开这个问题的方法是，在仓库里手动找到这个pom文件，然后再打开这个文件。\nspring-boot-starter-parent项目的父依赖为spring-boot-dependencies，版本裁决时用到的变量都存在了这个项目中。\n关于版本裁决的利用 针对我们自行开发的starter，如果这些starter中引入了其他的组件，我们想对这些组件进行版本管理，我觉得可行的方案是，我们自行开发一个starter-parent，该starter的parent为spring-boot-starter-parent，其中增加了许多企业内部使用的组件的版本。甚至该starter-parent中可以对spring-boot-starter-parent中的一些变量进行覆盖，从而控制它们的版本号。\n我简单开发了一个Demo用于验证我这种思想，项目结构如下，其中demo为父项目，jj-starter-parent为父依赖，jj-demo依赖于jj-starter-parent。\ndemo的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;jj-parent-starter\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;jj-demo\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/project\u0026gt;   jj-starter-parent的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jj-parent-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;/project\u0026gt;   jj-demo的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jj-parent-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;relativePath\u0026gt;../jj-parent-starter/pom.xml\u0026lt;/relativePath\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;jj-demo\u0026lt;/artifactId\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;   实验中，效果和我预计的一样，基本上是实验成功的。\n项目中的starter-parent开发思路 待续。。。\n","description":"","id":108,"section":"notes","tags":null,"title":"Idea中无法跳转到spring-boot-starter-parent源码了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/idea%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B7%B3%E8%BD%AC%E5%88%B0spring-boot-starter-parent%E6%BA%90%E7%A0%81%E4%BA%86/"},{"content":"有时候习惯了VSCode的小图标，在Idea中会不自觉的去找分屏的小图标：\n","description":"","id":109,"section":"notes","tags":null,"title":"Idea中进行分屏显示代码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B1%8F%E6%98%BE%E7%A4%BA%E4%BB%A3%E7%A0%81/"},{"content":"需求是这样的，我需要查看datasource的username被哪个Properties类接受了，只需按住ctrl键，然后按这个配置即可。\n我之前犯的错误是这样的：我按住ctrl键，然后点击datasource，始终无法跳转，很是糟心。\n","description":"","id":110,"section":"notes","tags":null,"title":"Idea从application.yml配置项跳转到配置项对应的Properties类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%BB%8Eapplication.yml%E9%85%8D%E7%BD%AE%E9%A1%B9%E8%B7%B3%E8%BD%AC%E5%88%B0%E9%85%8D%E7%BD%AE%E9%A1%B9%E5%AF%B9%E5%BA%94%E7%9A%84properties%E7%B1%BB/"},{"content":"操作步骤  Setting \u0026gt; Editor \u0026gt; File Encodings 或者直接搜索File Encodings，将三处都修改为UTF-8。  ","description":"","id":111,"section":"notes","tags":null,"title":"IDEA修改编码方式","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%BF%AE%E6%94%B9%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F/"},{"content":"操作如图：\n开发模板代码时，很有必要关闭这个自动格式化。\n参考资料  IntelliJ IDEA粘贴多行代码时，总是自动缩进  ","description":"","id":112,"section":"notes","tags":null,"title":"Idea关闭粘贴代码时的自动缩进","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%85%B3%E9%97%AD%E7%B2%98%E8%B4%B4%E4%BB%A3%E7%A0%81%E6%97%B6%E7%9A%84%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B/"},{"content":"该方法可以一劳永逸的解决问题，我家用电脑上就是使用的这个方案。\n参考资料  IntelliJ IDEA 修改内存大小，使得idea运行更流畅。  ","description":"","id":113,"section":"notes","tags":null,"title":"Idea内存不足的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"如图，我想在目录树中快速定位我当前打开的文件：\n只需要按如下按钮即可：\n我常用这个功能来找到源码，然后复制一份源码，在源码上进行一些微调。因为我比较喜欢通过复制来复用Request、Response等POJO，而不喜欢通过继承等来复用，我觉得通过继承等手段会增加代码阅读时的复杂度。\n","description":"","id":114,"section":"notes","tags":null,"title":"Idea在目录树中查看当前打开文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%9C%A8%E7%9B%AE%E5%BD%95%E6%A0%91%E4%B8%AD%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6/"},{"content":"操作步骤  File \u0026gt; Settings \u0026gt; Editor \u0026gt; CodeStyle  编写代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // @formatter:on  this.sagaDefinition = step() .withCompensation( orderService.reject, CreateOrderSagaState::makeRejectOrderCommand) .step() .invokeParticipant( consumerService.validateOrder, CreateOrderSagaState::makeValidateOrderByConsumerCommand) .onReply( CreateTicketReply.class, CreateOrderSagaState::handleCreateTicketReply) .withCompensation( kitchenService.cancel, CreateOrderSagaState::makeConfirmCreateTicketCommand) .step() .invokeParticipant( kitchenService.create, CreateOrderSagaState::makeCreateTicketCommand) .step() .invokeParticipant( accountingService.authorize, CreateOrderSagaState::makeAuthorizeCommand) .step() .invokeParticipant( kitchenService.confirmCreate, CreateOrderSagaState::makeConfirmCreateTicketCommand) .step() .invokeParticipant( orderService.approve, CreateOrderSagaState::makeApproveOrderCommand) .build(); // @formatter:off    如上代码，默认情况下使用atrl + art + l时，肯定会被格式化，但是启动了部分格式化后，则不会  参考资料   IDEA(AS)代码格式化部分忽略\n  idea 代码部分格式化\n  ","description":"","id":115,"section":"notes","tags":null,"title":"Idea开启部分代码格式化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%BC%80%E5%90%AF%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96/"},{"content":"操作步骤 解决该问题需要检查三处的配置，如下图所示：\n参考教程  Error:java: Compilation failed: internal java compiler error 解决办法  ","description":"","id":116,"section":"notes","tags":null,"title":"Idea报错：Compilation failed：internal java compiler error","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%8A%A5%E9%94%99compilation-failedinternal-java-compiler-error/"},{"content":"操作步骤  按两下Shift 输入需要搜索的类  参考资料  IDEA中快速搜索Jar包里面的内容  ","description":"","id":117,"section":"notes","tags":null,"title":"Idea搜索jar包中的类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E7%B1%BB/"},{"content":"今天在看SpringBoot源码时，在如下代码出进行了断点，结果断点没有生效，代码直接运行到后面了。此处代码我当时只断点了一处，我以为该处代码没有进入，花了一点时间排查，最后才发现是这个问题导致的。\n我不确定这个是不是一个普遍存在的现象，先记录一下。\n","description":"","id":118,"section":"notes","tags":null,"title":"Idea断点时的一个小问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%96%AD%E7%82%B9%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E9%97%AE%E9%A2%98/"},{"content":"偶然间发现的，如图省略部分是可以点击的，点击后就可以查看终端运行的指令：\n","description":"","id":119,"section":"notes","tags":null,"title":"Idea查看启动程序时的终端指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%9F%A5%E7%9C%8B%E5%90%AF%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%97%B6%E7%9A%84%E7%BB%88%E7%AB%AF%E6%8C%87%E4%BB%A4/"},{"content":"记录一下，最近阅读源码的需求非常的多，有了这种技术，切面、动态代理的实现都可以轻松的查阅到，非常的舒服。\n","description":"","id":120,"section":"notes","tags":null,"title":"Idea查看调用栈","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%9F%A5%E7%9C%8B%E8%B0%83%E7%94%A8%E6%A0%88/"},{"content":"操作步骤  打开：Tools -\u0026gt; Generate JavaDoc other command line arguments栏里输入：   -encoding utf-8 -charset utf-8 ","description":"","id":121,"section":"notes","tags":null,"title":"IDEA生成JavaDoc文档时显示：编码GBK的不可映射字符","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E7%94%9F%E6%88%90javadoc%E6%96%87%E6%A1%A3%E6%97%B6%E6%98%BE%E7%A4%BA%E7%BC%96%E7%A0%81gbk%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6/"},{"content":"如图可以进行调整：\n","description":"","id":122,"section":"notes","tags":null,"title":"Idea目录树中隐藏某个文件或文件夹","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E7%9B%AE%E5%BD%95%E6%A0%91%E4%B8%AD%E9%9A%90%E8%97%8F%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"配置如下：\n我感觉配置并没有生效，后来我手动点击了一下下载：\n","description":"","id":123,"section":"notes","tags":null,"title":"Idea自动下载Maven依赖源码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BDmaven%E4%BE%9D%E8%B5%96%E6%BA%90%E7%A0%81/"},{"content":"操作步骤 勾选如下配置：\nFile \u0026gt; Settings \u0026gt; Tools \u0026gt; Server Certificates \u0026gt; Accept non-trusted certificates automatically\n","description":"","id":124,"section":"notes","tags":null,"title":"Idea警告：Untrusted Server's certificate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%AD%A6%E5%91%8Auntrusted-servers-certificate/"},{"content":"配好PG数据源后，可以愉快的在mapper.xml文件中使用文本格式化快捷键了，但是我发现字段显示为红色，且提示该字段不存在。我猜想是PG的scheme导致的这个问题，我们的表不是放在默认的public scheme下，而是放在别的schema下。\n正好我之前解决这个问题的时候发现了currentScheme参数，所以我尝试在URL上配置了这个参数，结果非常满意，红色提示消失了。\n jdbc:postgresql://192.168.19.12:5432/dev?currentScheme=auth ","description":"","id":125,"section":"notes","tags":null,"title":"Idea配置PG数据源时的currentSchema参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E9%85%8D%E7%BD%AEpg%E6%95%B0%E6%8D%AE%E6%BA%90%E6%97%B6%E7%9A%84currentschema%E5%8F%82%E6%95%B0/"},{"content":"操作步骤  配置步骤如下所示，如果需要使用高级功能，可以查阅相关手册  图中绿色区域为编辑器中使用该目标时需要输入的内容  ","description":"","id":126,"section":"notes","tags":null,"title":"Idea配置模板","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E9%85%8D%E7%BD%AE%E6%A8%A1%E6%9D%BF/"},{"content":"问题描述  网络配置后，点击应用配置出现如下提示：   you need ifupdown2 to reload network configuration(500) 解决方案  执行如下指令：   apt-get install ifupdown2 参考教程  PVE修改网络配置报错需要ifupdown2  ","description":"","id":127,"section":"notes","tags":null,"title":"ifupdown2无法加载网络配置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/ifupdown2%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"content":"看资料中无意间看到的，感觉最近挺需要这个的，故记录下来：\n下面两条指令首先将防火墙的当前规则保存，如果因为规则混乱无法上网了可以还原：\n iptables-save \u0026gt; iptables.rules iptables-restore \u0026lt; iptables.rules ","description":"","id":128,"section":"notes","tags":null,"title":"iptables常用操作（未实践）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%BE%85%E5%AE%8C%E6%88%90/iptables%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E6%9C%AA%E5%AE%9E%E8%B7%B5/"},{"content":"这块是以前用的资料整理，我会后会重新在实验机环境安装，到时候会重新整理一份。\n 使用 Istioctl 安装 IstioOperator Options 调试 Envoy 和 Pilot 最佳实践：Service Mesh 基准性能测试 Serverless与Kubernetes该如何选择？ Istio 网关中的 Gateway 和 VirtualService 配置深度解析 Istio 1.0学习笔记(六)：初识Istio Gateway 使用 Istio 进行金丝雀部署 kubeadm 更改NodePort端口范围 Traffic Management Problems 在Istio上创建自定义的ingress-gateway DevOps的持续部署方法大全  Helm相关资料（我还没有开始系统学习这个工具）\n Helm 从入门到实践  ","description":"","id":129,"section":"notes","tags":null,"title":"Istio安装","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/istio/istio%E5%AE%89%E8%A3%85/"},{"content":"防止以后又蹦出这种想法，现在先断了这个念想。怎么理解这个问题了，在C、C++中，我们定义枚举的时候，可以指定枚举项的值，相同的需求在jdk8中是无法实现的。\n参考资料  我可以在Java中为枚举指定序号吗？  ","description":"","id":130,"section":"notes","tags":null,"title":"java不能指定枚举的ordinal值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%8D%E8%83%BD%E6%8C%87%E5%AE%9A%E6%9E%9A%E4%B8%BE%E7%9A%84ordinal%E5%80%BC/"},{"content":"python中有个readLines的api，这个api可以一次性的将整个文件的文本读取到一个字符串中，我理所当然的认为java中也有类似的api，结果找了一圈没有找到相关的资料，最后我用如下的方式实现了相同的效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  File tplFile = tplFilePath.toFile(); try (FileInputStream fis = new FileInputStream(tplFile)) { byte[] tplBytes = new byte[(int) tplFile.length()]; //noinspection ResultOfMethodCallIgnored  fis.read(tplBytes); String tplContent = new String(tplBytes); tplContentsMap.put(tplFile.getName(), StringUtils.strip(tplContent.trim())); loadFragmentContents(tplFile.getName(), tplContent); } catch (IOException e) { e.printStackTrace(); }   这种方式并不是很直观，我以后看看有没有相应的工具包。\n参考资料  java 读取文件——按照行取出（使用BufferedReader和一次将数据保存到内存两种实现方式）  ","description":"","id":131,"section":"notes","tags":null,"title":"Java中将整个文本读取到字符串中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%AD%E5%B0%86%E6%95%B4%E4%B8%AA%E6%96%87%E6%9C%AC%E8%AF%BB%E5%8F%96%E5%88%B0%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD/"},{"content":"案例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  Set\u0026lt;String\u0026gt; set1 = new HashSet\u0026lt;\u0026gt;(); Set\u0026lt;String\u0026gt; set2 = new HashSet\u0026lt;\u0026gt;(); # 交集 set1.retailAll(set2); # 差集 set.removeAll(set2); # 并集 set1.addAll(set2);   在项目中应用的代码一：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  @Override public void updateUserInfoInEnterprise(String tenantId, UpdateUserInfoInEnterpriseRequest request) { // 判断用户是否存在  selectUserById(request.getUserId()); // 判断传递的用户是否已和当前企业建立关联（获取关联表信息）  List\u0026lt;AuthGroupUserRole\u0026gt; authGroupUserRoles = selectAuthGroupUserRoleByTenantIdAndUserId(tenantId, request.getUserId()); // 处理企业内部组织架构更新  boolean organizeUpdateFlag = StringUtils.isNotBlank(request.getOrganizeId()) \u0026amp;\u0026amp; !authGroupUserRoles.get(0).getOrganizeId().equals(request.getOrganizeId()); String organizeIdValue = organizeUpdateFlag ? request.getOrganizeId() : authGroupUserRoles.get(0).getOrganizeId(); // 处理企业内部角色信息更新  Set\u0026lt;String\u0026gt; roleIdsInRequest = new HashSet\u0026lt;\u0026gt;(request.getRoleIds()); Set\u0026lt;String\u0026gt; roleIdsInDb = authGroupUserRoles.stream() .map(AuthGroupUserRole::getRoleId) .collect(Collectors.toSet()); Set\u0026lt;String\u0026gt; toInsert = new HashSet\u0026lt;\u0026gt;(roleIdsInRequest); Set\u0026lt;String\u0026gt; toUpdate = new HashSet\u0026lt;\u0026gt;(roleIdsInRequest); Set\u0026lt;String\u0026gt; toDelete = new HashSet\u0026lt;\u0026gt;(roleIdsInDb); // 请求中包含的roleId，而数据库中不包含的roleId，则为需要插入的roleId  toInsert.removeAll(roleIdsInDb); // 数据库中包含的roleId，而请求中不包含的roleId，则为需要删除的roleId  toDelete.removeAll(roleIdsInRequest); // 请求中和数据库中同时包含的roleId则为需要更新的Id  toUpdate.retainAll(roleIdsInDb); if (toDelete.size() != 0) { deleteBatchIdsLogic(new ArrayList\u0026lt;\u0026gt;(toDelete)); } if (toInsert.size() != 0) { insertAuthGroupUserRole(tenantId, request.getUserId(), organizeIdValue, new ArrayList\u0026lt;\u0026gt;(toInsert)); } if (toUpdate.size() != 0 \u0026amp;\u0026amp; organizeUpdateFlag) { LambdaQueryWrapper\u0026lt;AuthGroupUserRole\u0026gt; queryWrapperForAuthAppRole = new LambdaQueryWrapper\u0026lt;AuthGroupUserRole\u0026gt;() .eq(AuthGroupUserRole::getOrgId, tenantId) .eq(AuthGroupUserRole::getUserId, request.getUserId()) .eq(AuthGroupUserRole::getDelete, IsDelete.NOT_DELETE.getValue()); AuthGroupUserRole authGroupUserRoleUpdate = AuthGroupUserRole.builder() .organizeId(request.getOrganizeId()) .build(); authGroupUserRoleMapper.update(authGroupUserRoleUpdate, queryWrapperForAuthAppRole); } // 通知到网关  informGatewayUserRoleChange(Collections.singletonList(request.getUserId()), tenantId); }   在项目中应用的代码二：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  public void updatePdmProjMemberGroups( String userId, String tenantId, UpdatePdmProjMemberGroupsRequest request) { // todo 检查projectId是否存在  Map\u0026lt;String, PdmProjMemberGroup\u0026gt; projectGroupIdToProjectMemberGroupMap = getProjectGroupIdToProjectMemberGroupMap(request.getProjectId(), tenantId); List\u0026lt;CreatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO\u0026gt; toAdd = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO\u0026gt; toUpdate = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; toDelete = new ArrayList\u0026lt;\u0026gt;(projectGroupIdToProjectMemberGroupMap.keySet()); // 如果传递的请求中包含Id则进行更新， 否则进行添加  for (UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO groupInfo : request.getGroupInfos()) { if (StringUtils.isBlank(groupInfo.getProjectGroupId())) { // 完成参数转换，方便接下来复用已有方法  toAdd.add(BeanUtil.copyProperties(groupInfo, CreatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO.class)); } else { // 查看用户传递的Id是否已经在数据库中存在  if (!projectGroupIdToProjectMemberGroupMap.containsKey(groupInfo.getProjectGroupId())) { throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } toUpdate.add(groupInfo); toDelete.remove(groupInfo.getProjectGroupId()); } } // 新增  if (toAdd.size() != 0) { createPdmProjMemberGroups(userId, tenantId, request.getProjectId(), toAdd); } // 删除  if (toDelete.size() != 0) { // 删除成员信息  deleteProjectMembersByProjectIdAndTenantId( request.getProjectId(), toDelete, tenantId); // 删除分组信息  deleteProjectMemberGroupsByProjectIdAndTenantId( request.getProjectId(), toDelete, tenantId); } // 修改（成员信息直接删除重建，分组信息进行更新）  if (toUpdate.size() != 0) { deleteProjectMembersByProjectIdAndTenantId( request.getProjectId(), toUpdate.stream() .map(UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO::getProjectGroupId) .collect(Collectors.toList()), tenantId); for (UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO groupInfo : toUpdate) { PdmProjMemberGroup pdmProjMemberGroup = projectGroupIdToProjectMemberGroupMap.get(groupInfo.getProjectGroupId()); PdmProjMemberGroup pdmProjMemberGroupUpdate = PdmProjMemberGroup.builder() .id(pdmProjMemberGroup.getId()) .modifier(userId) .gmtModifyTime(LocalDateTime.now()) .name((JSONObject) JSONObject.toJSON(groupInfo.getName())) .build(); pdmProjMemberGroupMapper.updateById(pdmProjMemberGroupUpdate); // 重新插入成员信息  createProjectMembersBatch(userId, tenantId, request.getProjectId(), groupInfo.getProjectGroupId(), groupInfo.getUserIds()); } } }   参考资料  Java ArrayList retainAll() 方法  ","description":"","id":132,"section":"notes","tags":null,"title":"java中的交集、并集、差集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%AD%E7%9A%84%E4%BA%A4%E9%9B%86%E5%B9%B6%E9%9B%86%E5%B7%AE%E9%9B%86/"},{"content":"判断是否是静态方法的代码如下：\n1 2 3 4 5  Method method = 类.getMethod(相关参数); int modifiers = getModifiers(); Modifier.isStatic(modifiers )   调用静态方法的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public static Object invokeConvertMethod(String enumClazzName, Object methodParam) { if (!methodCache.containsKey(enumClazzName)) { throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } try { Method method = methodCache.get(enumClazzName); // todo 临时，因为还没有决定枚举要不要分String和Integer  return method.invoke(null, String.valueOf(methodParam)); } catch (IllegalAccessException | InvocationTargetException e) { e.printStackTrace(); return null; } }   参考资料  Ｊava判断是否是static方法 Java 反射调用静态方法  ","description":"","id":133,"section":"notes","tags":null,"title":"java反射中如何判断是否是静态方法及静态方法调用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E5%8F%8D%E5%B0%84%E4%B8%AD%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E5%8F%8A%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8/"},{"content":"我确实有深拷贝的需求，我之前的方案是实现了一个静态工具类，在工具类中通过FastJson序列化和反序列化实现深拷贝（我主要用在工具类中，性能问题并不在意），但是毕竟不是非常的方便。最近找资料时发现了几款工具，打算测试一下这几款工具。\ncommons-beanutils 依赖引入：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-beanutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-beanutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   测试代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Test { @Getter @Setter @NoArgsConstructor @AllArgsConstructor static class User { private String name; private Address address; } @NoArgsConstructor @AllArgsConstructor static class Address { private String country; private String province; private String city; } public static void main(String[] args) { User user1 = new User(\u0026#34;test\u0026#34;, new Address(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)); User user2 = new User(); BeanUtils.copyProperties(user1, user2); System.out.println(user1); System.out.println(user2); System.out.println(user1.address); System.out.println(user2.address); } }   输出为：\n com.example.demo.test.Test$User@18e8568 com.example.demo.test.Test$User@33e5ccce com.example.demo.test.Test$Address@5a42bbf4 com.example.demo.test.Test$Address@5a42bbf4 实际上只进行了浅拷贝。\norika 依赖引入：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ma.glasnost.orika\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;orika-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   测试代码编写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  public class Test { @Getter @Setter @NoArgsConstructor @AllArgsConstructor static class User { private String name; private Address address; } @NoArgsConstructor @AllArgsConstructor static class Address { private String country; private String province; private String city; } public static void main(String[] args) { User user1 = new User(\u0026#34;test\u0026#34;, new Address(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)); User user2 = new User(); MapperFactory mapperFactory = new DefaultMapperFactory.Builder() .useAutoMapping(true) .mapNulls(true) .build(); MapperFacade mapperFacade = mapperFactory.getMapperFacade(); mapperFacade.map(user1, user2); System.out.println(\u0026#34;mapperFacade.map(user1, user2)\u0026#34;); System.out.println(user1); System.out.println(user2); System.out.println(user1.address); System.out.println(user2.address); System.out.println(\u0026#34;User user3 = mapperFacade.map(user1, User.class)\u0026#34;); User user3 = mapperFacade.map(user1, User.class); System.out.println(user1); System.out.println(user3); System.out.println(user1.address); System.out.println(user3.address); } }   输出为：\n mapperFacade.map(user1, user2) com.example.demo.test.Test$User@6043cd28 com.example.demo.test.Test$User@4d3167f4 com.example.demo.test.Test$Address@76a3e297 com.example.demo.test.Test$Address@ed9d034 User user3 = mapperFacade.map(user1, User.class) com.example.demo.test.Test$User@6043cd28 com.example.demo.test.Test$User@1060b431 com.example.demo.test.Test$Address@76a3e297 com.example.demo.test.Test$Address@612679d6 可以看到是深拷贝。这个工具略微有点麻烦，需要开发成静态工具类，但是看推荐，说是效率极高。\nBeanUtils（Spring版）、BeanUtil（hutool） 这两款都是浅拷贝，这款就不呈现测试代码了。\n测试总结 我觉得orika是有研究价值的，深度拷贝的应用还是蛮多的，我会花时间对这门技术进行系统学习。\n参考资料  java浅拷贝与深拷贝及拷贝工具推荐  ","description":"","id":134,"section":"notes","tags":null,"title":"Java浅拷贝深拷贝工具测试","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E6%B5%85%E6%8B%B7%E8%B4%9D%E6%B7%B1%E6%8B%B7%E8%B4%9D%E5%B7%A5%E5%85%B7%E6%B5%8B%E8%AF%95/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11  Properties properties = new Properties(); properties.load(new FileInputStream(\u0026#34;src\\\\main\\\\resources\\\\tmp3.properties\u0026#34;)); Enumeration enumeration = properties.propertyNames(); while (enumeration.hasMoreElements()) { String key = (String) enumeration.nextElement(); String value = properties.getProperty(key); System.out.println(key); System.out.println(value); }   写法很糟糕，而且中文还乱码了。\n参考资料  了解自动配置原理  ","description":"","id":135,"section":"notes","tags":null,"title":"Java读取properties文件中的内容，并将它们封装到JavaBean中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E8%AF%BB%E5%8F%96properties%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%E5%B9%B6%E5%B0%86%E5%AE%83%E4%BB%AC%E5%B0%81%E8%A3%85%E5%88%B0javabean%E4%B8%AD/"},{"content":"做实验的时候，利用jdbcTemplate开发了一个简单的方法，用于查看当前链接的时区，感觉还不错，就简单整理一下：\n1 2 3 4 5 6 7 8 9 10 11 12  List\u0026lt;String\u0026gt; timezones = jdbcTemplate.query( \u0026#34;show time zone\u0026#34;, new RowMapper\u0026lt;String\u0026gt;() { @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException { return rs.getString(1); } }); System.out.println(timezones);   ","description":"","id":136,"section":"notes","tags":null,"title":"JdbcTemplate查看当前链接的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/jdbctemplate%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E9%93%BE%E6%8E%A5%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"相关技术的应用我会体现在我的工具包代码里。\n参考资料  jdbcTemplate高效率获取表结构，数据库元数据信息  ","description":"","id":137,"section":"notes","tags":null,"title":"JdbcTemplate获取表的元数据","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/jdbctemplate%E8%8E%B7%E5%8F%96%E8%A1%A8%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE/"},{"content":"问题描述  在配置ShardingSphere-Jdbc时，按照官网官网最新配置，遇到了jdbcUrl is required with driverClassName异常  解决步骤  修改配置中的url为jdbc-url，代码如下：  spring: shardingsphere: props: sql: show: true datasource: names: mmp mmp: # jdbc-url: jdbc:mysql://192.168.53.100:3306/mmp_watsons_junjie?useUnicode=true\u0026amp;characterEncoding=UTF8\u0026amp;serverTimezone=CTT jdbc-url: jdbc:mysql://192.168.53.100:3306/mmp_watsons_junjie?useUnicode=true\u0026amp;characterEncoding=UTF8\u0026amp;serverTimezone=CTT type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver username: promotion_app password: promotion_app 20210617后续：\n很尴尬啊，这篇笔记是很久前整理的，我忘记我当时修改什么东西了\n参考资料  jdbcUrl is required with driverClassName  ","description":"","id":138,"section":"notes","tags":null,"title":"jdbcUrl is required with driverClassName","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/shardingsphere-jdbc/jdbcurl-is-required-with-driverclassname/"},{"content":"问题描述  按照教程走完所有流程后，始终得不到项目的日志输出，项目状态一致处于运行中 查看slave pod的describe和log都没有任何提示 查看master pod的log得到如下日志  VM settings: Max. Heap Size (Estimated): 247.50M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM Running from: /usr/share/jenkins/jenkins.war webroot: EnvVars.masterEnvVars.get(\u0026quot;JENKINS_HOME\u0026quot;) 2020-07-24 02:35:59.320+0000 [id=1]\tINFO\torg.eclipse.jetty.util.log.Log#initialized: Logging initialized @671ms to org.eclipse.jetty.util.log.JavaUtilLog 2020-07-24 02:35:59.470+0000 [id=1]\tINFO\twinstone.Logger#logInternal: Beginning extraction from war file 2020-07-24 02:35:59.540+0000 [id=1]\tWARNING\to.e.j.s.handler.ContextHandler#setContextPath: Empty contextPath 2020-07-24 02:35:59.641+0000 [id=1]\tINFO\torg.eclipse.jetty.server.Server#doStart: jetty-9.4.27.v20200227; built: 2020-02-27T18:37:21.340Z; git: a304fd9f351f337e7c0e2a7c28878dd536149c6c; jvm 1.8.0_242-b08 2020-07-24 02:36:00.642+0000 [id=1]\tINFO\to.e.j.w.StandardDescriptorProcessor#visitServlet: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet 2020-07-24 02:36:00.749+0000 [id=1]\tINFO\to.e.j.s.s.DefaultSessionIdManager#doStart: DefaultSessionIdManager workerName=node0 2020-07-24 02:36:00.749+0000 [id=1]\tINFO\to.e.j.s.s.DefaultSessionIdManager#doStart: No SessionScavenger set, using defaults 2020-07-24 02:36:00.757+0000 [id=1]\tINFO\to.e.j.server.session.HouseKeeper#startScavenging: node0 Scavenging every 660000ms 2020-07-24 02:36:01.618+0000 [id=1]\tINFO\thudson.WebAppMain#contextInitialized: Jenkins home directory: /var/jenkins_home found at: EnvVars.masterEnvVars.get(\u0026quot;JENKINS_HOME\u0026quot;) 2020-07-24 02:36:01.890+0000 [id=1]\tINFO\to.e.j.s.handler.ContextHandler#doStart: Started w.@21be3395{Jenkins v2.235.2,/,file:///var/jenkins_home/war/,AVAILABLE}{/var/jenkins_home/war} 2020-07-24 02:36:01.930+0000 [id=1]\tINFO\to.e.j.server.AbstractConnector#doStart: Started ServerConnector@62043840{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} 2020-07-24 02:36:01.931+0000 [id=1]\tINFO\torg.eclipse.jetty.server.Server#doStart: Started @3283ms 2020-07-24 02:36:01.932+0000 [id=20]\tINFO\twinstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled 2020-07-24 02:36:03.435+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Started initialization 2020-07-24 02:36:03.892+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Listed all plugins 2020-07-24 02:36:09.728+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Prepared all plugins 2020-07-24 02:36:09.738+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Started all plugins 2020-07-24 02:36:09.941+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Augmented all extensions 2020-07-24 02:36:11.228+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: System config loaded 2020-07-24 02:36:11.229+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: System config adapted 2020-07-24 02:36:11.229+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Loaded all jobs 2020-07-24 02:36:11.235+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Configuration for all jobs updated 2020-07-24 02:36:11.624+0000 [id=39]\tINFO\thudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Download metadata 2020-07-24 02:36:11.919+0000 [id=39]\tINFO\thudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Download metadata. 202 ms 2020-07-24 02:36:12.815+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@6effd93a: display name [Root WebApplicationContext]; startup date [Fri Jul 24 10:36:12 CST 2020]; root of context hierarchy 2020-07-24 02:36:12.816+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@6effd93a]: org.springframework.beans.factory.support.DefaultListableBeanFactory@62c07203 2020-07-24 02:36:12.827+0000 [id=26]\tINFO\to.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@62c07203: defining beans [authenticationManager]; root of factory hierarchy 2020-07-24 02:36:13.227+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@1a5fd292: display name [Root WebApplicationContext]; startup date [Fri Jul 24 10:36:13 CST 2020]; root of context hierarchy 2020-07-24 02:36:13.227+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@1a5fd292]: org.springframework.beans.factory.support.DefaultListableBeanFactory@449df8fb 2020-07-24 02:36:13.228+0000 [id=26]\tINFO\to.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@449df8fb: defining beans [filter,legacy]; root of factory hierarchy 2020-07-24 02:36:13.445+0000 [id=26]\tINFO\to.c.j.p.k.KubernetesClientProvider$SaveableListenerImpl#onChange: Invalidating Kubernetes client: kubernetes null 2020-07-24 02:36:13.450+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Completed initialization 2020-07-24 02:36:13.552+0000 [id=19]\tINFO\to.c.j.p.k.KubernetesClientProvider$SaveableListenerImpl#onChange: Invalidating Kubernetes client: kubernetes null 2020-07-24 02:36:13.860+0000 [id=19]\tINFO\thudson.WebAppMain$3#run: Jenkins is fully up and running 2020-07-24 02:37:20.320+0000 [id=11]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: Found invalid crumb 8912d904c747a67dab090ad588545030425547e720e49e7a2af899038c6844b3. If you are calling this URL with a script, please use the API Token instead. More information: https://jenkins.io/redirect/crumb-cannot-be-used-for-script 2020-07-24 02:37:20.320+0000 [id=11]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: No valid crumb was included in request for /ajaxBuildQueue by wujunjie. Returning 403. 2020-07-24 02:37:20.373+0000 [id=15]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: Found invalid crumb 8912d904c747a67dab090ad588545030425547e720e49e7a2af899038c6844b3. If you are calling this URL with a script, please use the API Token instead. More information: https://jenkins.io/redirect/crumb-cannot-be-used-for-script 2020-07-24 02:37:20.373+0000 [id=15]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: No valid crumb was included in request for /ajaxExecutors by wujunjie. Returning 403. 2020-07-24 02:38:41.563+0000 [id=24]\tINFO\to.c.j.p.k.KubernetesCloud#provision: Excess workload after pending Kubernetes agents: 1 2020-07-24 02:38:41.565+0000 [id=24]\tINFO\to.c.j.p.k.KubernetesCloud#provision: Template for label joker-jnlp: jenkins-slave 2020-07-24 02:38:43.128+0000 [id=24]\tINFO\to.internal.platform.Platform#log: ALPN callback dropped: HTTP/2 is disabled. Is alpn-boot on the boot class path? 2020-07-24 02:38:51.948+0000 [id=38]\tINFO\thudson.slaves.NodeProvisioner#lambda$update$6: jenkins-slave-wrpbz provisioning successfully completed. We have now 2 computer(s) 2020-07-24 02:38:52.176+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Created Pod: devops/jenkins-slave-wrpbz 2020-07-24 02:38:52.324+0000 [id=71]\tINFO\to.internal.platform.Platform#log: ALPN callback dropped: HTTP/2 is disabled. Is alpn-boot on the boot class path? 2020-07-24 02:38:52.348+0000 [id=71]\tWARNING\ti.f.k.c.d.i.WatchConnectionManager$1#onFailure: Exec Failure: HTTP 403, Status: 403 - events is forbidden: User \u0026quot;system:serviceaccount:devops:jenkins-sa\u0026quot; cannot watch resource \u0026quot;events\u0026quot; in API group \u0026quot;\u0026quot; in the namespace \u0026quot;devops\u0026quot; java.net.ProtocolException: Expected HTTP 101 response but was '403 Forbidden' at okhttp3.internal.ws.RealWebSocket.checkResponse(RealWebSocket.java:229) at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:196) at okhttp3.RealCall$AsyncCall.execute(RealCall.java:203) at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2020-07-24 02:38:52.354+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#eventWatch: Cannot watch events on devops/jenkins-slave-wrpbz Also: java.lang.Throwable: waiting here at io.fabric8.kubernetes.client.utils.Utils.waitUntilReady(Utils.java:144) at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager.waitUntilReady(WatchConnectionManager.java:341) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:755) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:739) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:70) at org.csanchez.jenkins.plugins.kubernetes.KubernetesLauncher.eventWatch(KubernetesLauncher.java:230) at org.csanchez.jenkins.plugins.kubernetes.KubernetesLauncher.launch(KubernetesLauncher.java:138) at hudson.slaves.SlaveComputer.lambda$_connect$0(SlaveComputer.java:296) at jenkins.util.ContextResettingExecutorService$2.call(ContextResettingExecutorService.java:46) at jenkins.security.ImpersonatingExecutorService$2.call(ImpersonatingExecutorService.java:71) at java.util.concurrent.FutureTask.run(FutureTask.java:266) io.fabric8.kubernetes.client.KubernetesClientException: events is forbidden: User \u0026quot;system:serviceaccount:devops:jenkins-sa\u0026quot; cannot watch resource \u0026quot;events\u0026quot; in API group \u0026quot;\u0026quot; in the namespace \u0026quot;devops\u0026quot; at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager$1.onFailure(WatchConnectionManager.java:203) at okhttp3.internal.ws.RealWebSocket.failWebSocket(RealWebSocket.java:571) at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:198) at okhttp3.RealCall$AsyncCall.execute(RealCall.java:203) at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2020-07-24 02:38:54.672+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Pod is running: devops/jenkins-slave-wrpbz 2020-07-24 02:39:25.039+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Waiting for agent to connect (30/100): jenkins-slave-wrpbz 2020-07-24 02:39:55.272+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Waiting for agent to connect (60/100): jenkins-slave-wrpbz 解决步骤  使用如下RABC配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  apiVersion:v1kind:ServiceAccountmetadata:name:jenkins-sanamespace:devops---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:jenkins-crdlabels:name:jenkinssubjects:- kind:ServiceAccountname:jenkins-sanamespace:devopsroleRef:kind:ClusterRolename:cluster-adminapiGroup:rbac.authorization.k8s.io  ","description":"","id":139,"section":"notes","tags":null,"title":"Jenkins定位Kubernetes集群中，简单的echo实验失败","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/jenkins%E5%AE%9A%E4%BD%8Dkubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%AE%80%E5%8D%95%E7%9A%84echo%E5%AE%9E%E9%AA%8C%E5%A4%B1%E8%B4%A5/"},{"content":"问题描述 因为我们客户端在上传数据时没有进行输入检查（服务端也没有检查），导致我们数据库t_material_info表中插入了一些错误数据。t_material_info表的extra_property列的类型json，可能会被插入如下的值：\n1 2 3 4 5 6  { \u0026#34;\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;field\u0026#34;:\u0026#34;key\u0026#34; }   现在的需求是修改t_material_info表的extra_property列，如果该列的json数据包含了key为空字符串的字段，则去掉该字段。\n我开发的SQL如下：\n1 2 3 4 5 6  UPDATEt_material_infoSETextra_property=jsonb(extra_property)-\u0026#39;\u0026#39;WHEREIDIN(SELECTIDFROMt_material_infoWHEREextra_property::json-\u0026gt;\u0026gt;\u0026#39;\u0026#39;=\u0026#39;\u0026#39;)  因为考虑到该SQL需要在生产环境执行，所以做了一些调整（将原来的一条SQL拆成了两条），我们生产环境处理该问题的逻辑是，先查出所有需要修改的数据，然后update语句的where条件中指明需要修改的记录的id，这样可以最大限度防止SQL错误影响到线上的数据。当然我们可以结合一些工具，批量的生成这些update语句。\n","description":"","id":140,"section":"notes","tags":null,"title":"jsonb中如何key为空字符串怎么办","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/jsonb%E4%B8%AD%E5%A6%82%E4%BD%95key%E4%B8%BA%E7%A9%BA%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%80%8E%E4%B9%88%E5%8A%9E/"},{"content":"我开启了一个新的项目，尝试传递如下json，然后用如下对象接受，结果无法正常接受，这个是符合我预期的。\n { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } @Data private static class TestJson { private String testJson; } @PostMapping(\u0026quot;/testJson\u0026quot;) public TestJson testJson(@RequestBody TestJson testJson) { return testJson; } 按照教程，做了如下配置后spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES，我的请求和返回如下：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } 目前的表现和我们项目框架已经不一样了，我们项目框架中，即使不做任何配置，有如下请求和返回：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;code\u0026quot;: 200, \u0026quot;data\u0026quot;: { \u0026quot;testJson\u0026quot;: \u0026quot;testJson\u0026quot; }, \u0026quot;message\u0026quot;: \u0026quot;成功\u0026quot; } 截止目前，我产生了一下需要探索的项：\n 如何看项目做了哪些配置，比如spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES 是不是因为在项目中实验的时候，返回值在第二层，所以导致返回的testJson没有下滑线  解答一 开启SpringBoot Actuator，然后请求localhost:8888/actuator/configprops，返回结果中搜索jackson就可以看到相关的配置：\n从这份配置甚至可以猜到其可以对输入输出分别配置，从而达到我们项目框架的效果，但是看了其配置后发现它根本没有进行这项的配置：\n我觉得我们项目可能更多的是通过代码进行配置。现在就是不清楚通过JavaConfig进行的配置能够通过configprops反应出来么（已经证实：我们项目中使用的并不是jackson，所以看不到相关的配置。）。\n经过向架构师的咨询，了解到我们项目的HttpMessageConvert使用的并不是Jackson，而是Fastjson，配置代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  @Bean public HttpMessageConverters fastJsonHttpMessageConverters() { return new HttpMessageConverters(getFastJsonHttpMessageConverter()); } public HttpMessageConverter\u0026lt;?\u0026gt; getFastJsonHttpMessageConverter() { // 1.定义一个converters转换消息的对象 \tFastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); List\u0026lt;MediaType\u0026gt; supportedMediaTypes = new ArrayList\u0026lt;\u0026gt;(); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.APPLICATION_ATOM_XML); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_OCTET_STREAM); supportedMediaTypes.add(MediaType.APPLICATION_PDF); supportedMediaTypes.add(MediaType.APPLICATION_RSS_XML); supportedMediaTypes.add(MediaType.APPLICATION_XHTML_XML); supportedMediaTypes.add(MediaType.APPLICATION_XML); supportedMediaTypes.add(MediaType.IMAGE_GIF); supportedMediaTypes.add(MediaType.IMAGE_JPEG); supportedMediaTypes.add(MediaType.IMAGE_PNG); supportedMediaTypes.add(MediaType.TEXT_EVENT_STREAM); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_MARKDOWN); supportedMediaTypes.add(MediaType.TEXT_PLAIN); supportedMediaTypes.add(MediaType.TEXT_XML); fastConverter.setSupportedMediaTypes(supportedMediaTypes); // 2.添加fastjson的配置信息，比如: 是否需要格式化返回的json数据 \tFastJsonConfig fastJsonConfig = new FastJsonConfig(); // 修改配置返回内容的过滤 \t// WriteNullListAsEmpty ：List字段如果为null,输出为[],而非null \t// WriteNullStringAsEmpty ： 字符类型字段如果为null,输出为\u0026#34;\u0026#34;,而非null \t// DisableCircularReferenceDetect ：消除对同一对象循环引用的问题，默认为false（如果不配置有可能会进入死循环） \t// WriteNullBooleanAsFalse：Boolean字段如果为null,输出为false,而非null \t// WriteMapNullValue：是否输出值为null的字段,默认为false \t// PrettyFormat：结果是否格式化  fastJsonConfig.setSerializerFeatures(SerializerFeature.DisableCircularReferenceDetect, SerializerFeature.WriteNullStringAsEmpty, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullBooleanAsFalse); // 配置全局long转String \tSerializeConfig serializeConfig = SerializeConfig.globalInstance; serializeConfig.put(Long.class, ToStringSerializer.instance); serializeConfig.put(Long.TYPE, ToStringSerializer.instance); fastJsonConfig.setSerializeConfig(serializeConfig); fastJsonConfig.setDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); // 3.在converter中添加配置信息 \tfastConverter.setFastJsonConfig(fastJsonConfig); // 4.将converter赋值给HttpMessageConverter \t// HttpMessageConverter\u0026lt;?\u0026gt; converter = fastConverter; \t// 5.返回HttpMessageConverters对象 \treturn fastConverter; }   经过实验，我了解到FastJson是默认支持下滑线式的json key转成java中的驼峰，当需要序列化成json时，需要如下代码实现驼峰装下滑线（这段代码我暂时没有优化，等我需要的时候，我会优化下）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Data @AllArgsConstructor private static class TestJson { private String testJson; } public static void main(String[] args) { // 下滑线转驼峰  String jsonInput = \u0026#34;{\\\u0026#34;test_json\\\u0026#34;:\\\u0026#34;testJson\\\u0026#34;}\u0026#34;; TestJson testJson = JSON.parseObject(jsonInput, TestJson.class); // 驼峰转下划线  TestJson testJson2 = new TestJson(\u0026#34;testJson\u0026#34;); SerializeConfig config = new SerializeConfig(); config.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase; String s = JSON.toJSONString(testJson2, config); }   解答二 包装后，请求与返回如下：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;test_json\u0026quot;: { \u0026quot;test_json\u0026quot;: \u0026quot;testJson\u0026quot; } } 其实从这些表现就可以发现spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES配置的工作原理。它大概是请求时建立了test_json和testJson到testJson的映射，而返回的时候，它会将对象的所有字段都转换成下划线式的。\nhttps://blog.csdn.net/java_cxrs/article/details/105850597\nhttps://www.jianshu.com/p/cb02796dfbd2\n参考资料  springboot(15)修改HTTP默认序列化工具 Java Json 数据下划线与驼峰格式进行相互转换 FastJson下划线转驼峰 springboot与web前端的下划线与驼峰的json转换配置   ","description":"","id":141,"section":"notes","tags":null,"title":"Json序列化时驼峰与下滑线的转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/json%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E9%A9%BC%E5%B3%B0%E4%B8%8E%E4%B8%8B%E6%BB%91%E7%BA%BF%E7%9A%84%E8%BD%AC%E6%8D%A2/"},{"content":"问题是这样的，我在写测试类的时候使用了Lombok的RequiredArgsConstructor注解，结果一直有如下报错：\n org.junit.jupiter.api.extension.ParameterResolutionException: No ParameterResolver registered for parameter [org.springframework.web.client.RestTemplate arg0] in constructor [public fun.junjie.auto.tools.tools.YApiTools(org.springframework.web.client.RestTemplate)]. at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameter(ExecutableInvoker.java:200) at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameters(ExecutableInvoker.java:183) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:74) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:333) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:280) at org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:77) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:262) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$2(ClassBasedTestDescriptor.java:256) at java.util.Optional.orElseGet(Optional.java:267) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$3(ClassBasedTestDescriptor.java:255) at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:29) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:108) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:107) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:71) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$1(NodeTestTask.java:107) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:107) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:75) at java.util.ArrayList.forEach(ArrayList.java:1259) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1259) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:69) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) 我其实很久前就解决过这个问题，但是当时没有记录任何笔记，结果今天又遇到了这个问题。这个是因为在Junit5的测试类中，必须使用@Autowire来注入待测试的类，而不能使用Lombok的@RequiredArgsConstructor。\n","description":"","id":142,"section":"notes","tags":null,"title":"junit5不支持构造函数注入","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/junit5%E4%B8%8D%E6%94%AF%E6%8C%81%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E6%B3%A8%E5%85%A5/"},{"content":"前言  怎么说，犯了低级错误，但是在定位解决这个低级错误的时候又学到了很多知识  操作步骤  拉取代码，将Jenkins运行起来：  1 2 3 4 5 6 7 8  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Devops/Jenkins kubectl apply -f PersistentVolumeClaim.yml kubectl apply -f RBAC.yml kubectl apply -f Jenkins.yml    如图位置，进入Cloud配置页  选择添加kubernetes云，并对如下关键数据配置，配置完成后点击测试连接  配置slave信息，完成后点击保存  创建测试项目，完成配置测试：  相关教程   kubernetes中部署Jenkins并简单使用(完全按照这篇文档\n  在 Kubernetes 上动态创建 Jenkins Slave(知识点丰富，给了解决问题的思路)\n  Kubernetes下Jenkins CI的搭建(截图更晚上，补充了第一篇截图没有截到的地方)\n  ","description":"","id":143,"section":"notes","tags":null,"title":"Kubernetes中搭建Jenkins","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%B8%AD%E6%90%AD%E5%BB%BAjenkins/"},{"content":"操作步骤  拉取代码，将Nexus运行起来：  1 2 3 4 5 6 7 8 9 10 11  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Devops/Jenkins kubectl apply -f PersistentVolumeClaim.yml kubectl apply -f Nexus.yml kubectl create configmap setting.xml \\  -- from-file=setting.xml \\  -n devops   相关资料  Kubernetes部署Nexus3  ","description":"","id":144,"section":"notes","tags":null,"title":"Kubernetes中搭建Nexus","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%B8%AD%E6%90%AD%E5%BB%BAnexus/"},{"content":"操作步骤  拉取代码，将Ingress-Nginx运行起来：  1 2 3 4 5 6 7  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Kubernetes/IngressNginx kubectl apply -f mandatory.yml kubectl apply -f service-nodeport.yml   查看pods时会发现镜像拉不下来，可以查看相关的教程，解决这个问题  相关教程   见异思迁：K8s 部署 Nginx Ingress Controller 之 kubernetes/ingress-nginx\n  NGINX Ingress Controller(无法下载插件，未使用该方案，该方案目前最新)\n  ingress-nginx github地址\n  ","description":"","id":145,"section":"notes","tags":null,"title":"Kubernetes使用ingress-nginx","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%BD%BF%E7%94%A8ingress-nginx/"},{"content":"操作步骤   搭建NFS服务器，想考相关教程\n  配置Kubernetes使用NFS持久卷，指令如下：\n  1 2 3 4 5 6 7 8 9 10  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/PersistentVolume2 kubectl apply -f rabc.yml kubectl apply -f deployment.yml kubectl apply -f class.yml kubectl apply -f test-claim.yml kubectl apply -f test-pod.yml   相关教程   利用NFS动态提供Kubernetes后端存储卷\n  K8S 之 使用NFS作为持久卷使用POD\n  ","description":"","id":146,"section":"notes","tags":null,"title":"Kubernetes使用NFS持久卷","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%BD%BF%E7%94%A8nfs%E6%8C%81%E4%B9%85%E5%8D%B7/"},{"content":"处理步骤  查看pods状态，发现pod没有成功创建：  1  kubectl get po   查看deployment状态，发现deployment一直处于NotReady状态，查看其描述，得不到任何讯息  1 2 3 4  kubectl get deploy kubectl describe deploy nfs-client-provisioner   查看ReplicationSet状态，发现出错，查看其描述，找到出错的原因   kubectl get rs kubectl describe rs nfs-client-provisioner-56596b5cc5 ","description":"","id":147,"section":"notes","tags":null,"title":"Kubernetes解决Deployment一直处于NotReady","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3deployment%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Enotready/"},{"content":"问题描述：  日志如下   Name: nfs-client-provisioner-56596b5cc5-kvsff Namespace: default Priority: 0 Node: kubernetes3/172.17.30.103 Start Time: Thu, 23 Jul 2020 04:06:48 +0000 Labels: app=nfs-client-provisioner pod-template-hash=56596b5cc5 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: IPs: \u0026lt;none\u0026gt; Controlled By: ReplicaSet/nfs-client-provisioner-56596b5cc5 Containers: nfs-client-provisioner: Container ID: Image: quay.io/external_storage/nfs-client-provisioner:latest Image ID: Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: PROVISIONER_NAME: fuseim.pri/ifs NFS_SERVER: 192.168.30.174 NFS_PATH: /home/junjie/nfs Mounts: /persistentvolumes from nfs-client-root (rw) /var/run/secrets/kubernetes.io/serviceaccount from nfs-client-provisioner-token-9dv54 (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: nfs-client-root: Type: NFS (an NFS mount that lasts the lifetime of a pod) Server: 192.168.30.174 Path: /home/junjie/nfs ReadOnly: false nfs-client-provisioner-token-9dv54: Type: Secret (a volume populated by a Secret) SecretName: nfs-client-provisioner-token-9dv54 Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedMount 4m28s kubelet, kubernetes3 MountVolume.SetUp failed for volume \u0026quot;nfs-client-root\u0026quot; : mount failed: exit status 32 Mounting command: systemd-run Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root --scope -- mount -t nfs 192.168.30.174:/home/junjie/nfs /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root Output: Running scope as unit: run-r3196c404e0bd48b89adbb143ac8ba079.scope mount: /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.\u0026lt;type\u0026gt; helper program. Normal Scheduled 4m28s default-scheduler Successfully assigned default/nfs-client-provisioner-56596b5cc5-kvsff to kubernetes3 Warning FailedMount 4m28s kubelet, kubernetes3 MountVolume.SetUp failed for volume \u0026quot;nfs-client-root\u0026quot; : mount failed: exit status 32 Mounting command: systemd-run Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root --scope -- mount -t nfs 192.168.30.174:/home/junjie/nfs /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root Output: Running scope as unit: run-rbed921e0b7cd49a99857c958a1f04a1a.scope mount: /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.\u0026lt;type\u0026gt; helper program. 处理步骤  三台虚拟机上运行如下指令  1 2 3  sudo apt install -y nfs-common   相关教程  KUBERNETES挂载NFS报错：MOUNTVOLUME.SETUP FAILED FOR VOLUME “HTTPD-STORAGE” : MOUNT FAILED: EXIT STATUS 32  ","description":"","id":148,"section":"notes","tags":null,"title":"Kubernetes解决NFS挂载报错的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3nfs%E6%8C%82%E8%BD%BD%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题描述  service原为NodePort类型，改为默认类型时，有报错如下：   kubectl apply -f Jenkins.yml The Service \u0026quot;jenkins\u0026quot; is invalid: spec.ports[1].nodePort: Forbidden: may not be used when `type` is 'ClusterIP' 直接删除原Service，重新建一个Service   kubectl delete -f Jenkins.yml kubectl apply -f Jenkins.yml 问题分析  可能时不同yml文件走了merge逻辑  ","description":"","id":149,"section":"notes","tags":null,"title":"Kubernetes解决Service is invalid问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3service-is-invalid%E9%97%AE%E9%A2%98/"},{"content":"问题描述：  日志如下   Name: jenkins-7d6c886b8-nkl4g Namespace: devops Priority: 0 Node: kubernetes3/172.17.30.103 Start Time: Thu, 23 Jul 2020 06:13:34 +0000 Labels: app=jenkins pod-template-hash=7d6c886b8 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: 10.244.2.3 IPs: IP: 10.244.2.3 Controlled By: ReplicaSet/jenkins-7d6c886b8 Containers: jenkins: Container ID: Image: 192.168.30.174:80/test/jenkins:lts Image ID: Ports: 8080/TCP, 50000/TCP Host Ports: 0/TCP, 0/TCP State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Limits: cpu: 1 memory: 1Gi Requests: cpu: 500m memory: 512Mi Liveness: http-get http://:8080/login delay=60s timeout=5s period=10s #success=1 #failure=12 Readiness: http-get http://:8080/login delay=60s timeout=5s period=10s #success=1 #failure=12 Environment: JAVA_OPTS: -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai Mounts: /var/jenkins_home from jenkinshome (rw) /var/run/secrets/kubernetes.io/serviceaccount from jenkins-sa-token-nt57q (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: jenkinshome: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: jenkins-pvc ReadOnly: false jenkins-sa-token-nt57q: Type: Secret (a volume populated by a Secret) SecretName: jenkins-sa-token-nt57q Optional: false QoS Class: Burstable Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 5m38s (x3 over 6m45s) default-scheduler persistentvolumeclaim \u0026quot;jenkins-pvc\u0026quot; not found Warning FailedScheduling 4m54s default-scheduler running \u0026quot;VolumeBinding\u0026quot; filter plugin for pod \u0026quot;jenkins-7d6c886b8-nkl4g\u0026quot;: error getting PVC \u0026quot;devops/jenkins-pvc\u0026quot;: could not find v1.PersistentVolumeClaim \u0026quot;devops/jenkins-pvc\u0026quot; Warning FailedScheduling 4m54s (x2 over 4m54s) default-scheduler running \u0026quot;VolumeBinding\u0026quot; filter plugin for pod \u0026quot;jenkins-7d6c886b8-nkl4g\u0026quot;: pod has unbound immediate PersistentVolumeClaims Normal Scheduled 4m50s default-scheduler Successfully assigned devops/jenkins-7d6c886b8-nkl4g to kubernetes3 Normal Pulling 3m26s (x4 over 4m48s) kubelet, kubernetes3 Pulling image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot; Warning Failed 3m26s (x4 over 4m48s) kubelet, kubernetes3 Failed to pull image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://192.168.30.174:80/v2/: http: server gave HTTP response to HTTPS client Warning Failed 3m26s (x4 over 4m48s) kubelet, kubernetes3 Error: ErrImagePull Normal BackOff 3m12s (x6 over 4m47s) kubelet, kubernetes3 Back-off pulling image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot; Warning Failed 2m59s (x7 over 4m47s) kubelet, kubernetes3 Error: ImagePullBackOff 处理步骤  三台上配置/etc/docker/deamon.json文件，具体配置内容参考相关教程（我已提供相关教程）  ","description":"","id":150,"section":"notes","tags":null,"title":"Kubernetes解决使用Harbor时无法拉取镜像的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8harbor%E6%97%B6%E6%97%A0%E6%B3%95%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"说在前面  真的有点喜极而泣的感觉，花了一下午，终于解决了这个问题，心理很舒服  解决步骤  下载flannel的yml文件，在如下部分增加一条条目，并修改为需要使用的网卡：  卸载原有的flannel插件，并安装更改后的插件：   kubectl delete -f kube-flannel.yml kubectl apply -f kube-flannel.yml 问题分析  我的虚拟机是用两张网卡的，在搭建Kubernetes时，两张网卡可能会影响到我搭建，所以之前的搭建中我会关闭一张网卡 本次实验中，我使用了kubeadm新的参数：apiserver-advertise-address=172.17.30.101。避免了在搭建阶段对我的影响 但是该方案在搭建完成后，安装flannel时出现新的问题，我认为flannel会默认使用我enp0s3网卡，导致我无法进行实验  相关教程  kubernetes\u0026ndash;flannel（kubeadm安装）的不同node上的pod间无法通信 解决k8s无法通过svc访问其他节点pod的问题(同上) Kubernetes主机间curl cluster ip时通时不通(给了一点思路) 解决Kubernetes中Pod无法正常域名解析问题分析与IPVS parseIP Error问题 Kubernetes中coredns无法正常域名解析问题分析(同上)  ","description":"","id":151,"section":"notes","tags":null,"title":"Kubernetes解决运行在不同主机上的Pod无法ping通的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3%E8%BF%90%E8%A1%8C%E5%9C%A8%E4%B8%8D%E5%90%8C%E4%B8%BB%E6%9C%BA%E4%B8%8A%E7%9A%84pod%E6%97%A0%E6%B3%95ping%E9%80%9A%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"MyBatis-Plus中发现的关于泛型的问题 在使用MyBatis-Plus的LambdaQueryWrapper时，发现了一个有趣的小问题，先记录下来：\n嗯，从Java泛型的实现原理上，我应该是有能力解释这个问题的，但是现在不太着急解决它，哈哈。\n","description":"","id":152,"section":"notes","tags":null,"title":"LambdaQueryWrapper泛型写法的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/lambdaquerywrapper%E6%B3%9B%E5%9E%8B%E5%86%99%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"操作如下  优化后的方案，指令如下   ssh-copy-id mmpprd@10.44.2.106 ssh-copy-id mmpprd@10.44.0.177 i29PmmpImK ","description":"","id":153,"section":"notes","tags":null,"title":"Linux 建立SSH免密登录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/ssh/linux-%E5%BB%BA%E7%AB%8Bssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"},{"content":"md5 指令如下：\n md5sum 文件名 参考资料  Linux下对文件进行md5校验命令 Shell 变量 Shell —— 变量的声明和使用   ","description":"","id":154,"section":"notes","tags":null,"title":"Linux常用操作","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"content":"df -h\n","description":"","id":155,"section":"notes","tags":null,"title":"Linux查看硬盘使用情况","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5/"},{"content":"我不想用iptables、和firewall的方案，因为我对这些工具还不够熟悉，我只想一个小小的工具完成我的工作。最后我找到了socat（话说我用的kt connect工具貌似也需要这个工具）。\n指令如下：\n yum install -y socat socat TCP4-LISTEN:12345,reuseaddr,fork TCP4:127.0.0.1:2223 完美收工\n参考资料  Linux端口转发的几种常用方法  ","description":"","id":156,"section":"notes","tags":null,"title":"Linux端口映射","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"content":"我开发了一个外卖提醒的脚本，每次运行的时候，会发送一条消息到我们的钉钉群，提醒我们点外卖，我将它放到了我的实验机上。开发的定时任务脚本如下：\n # 编辑/etc/crontab增加如下内容 vi /etc/crontab # 增加的内容 30,32,35 11 * * 1-6 /root/Software/launch/dist/launch 45,50 17 * * 1-6 /root/Software/launch/dist/launch # 加载任务 crontab /etc/crontab # 查看任务 crontab -l crontab -u root -l 我想要的效果是：周一到周六每天中午11.30、11.32、11.35提醒一次，晚上17.45、17.50提醒一次。\n参考资料  CentOS 7 定时计划任务设置  ","description":"","id":157,"section":"notes","tags":null,"title":"Linux设置定时任务","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E8%AE%BE%E7%BD%AE%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"content":"这份笔记来自对另一份笔记的拆分，这篇笔记偏重于LocalDateTime，为了方便查阅，所以我移动到了另一篇笔记中。\n项目目前对对timestamptz的应用 首先对着我们库执行show timezone得到的结果为GMT。GMT表明了我们数据库服务设计的初心：我们中美服务器的数据库都统一使用一个时区。结合我们的实践，现在我产生了如下几个问题：\n  向表中插入一条当前系统的时间，然后再去查表中的记录，这个时候的时间是什么呢（我期待的是做过转换的GMT时间）\n  当我们的项目链接到数据库时，此时的链接的时区是什么，也是GMT么？\n  我们用于接受timestamptz的LocalDateTime类型，有什么特殊的地方么，在插入和查询结果时。\n  我们的Java服务实例的时区对整个时间戳有什么影响么，要求我们的Java实例必须设置正确的时区吗？\n  到底如何和前端配置，前端的意思是我们可以给一个+00的时间戳，但是我们又使用了LocalDateTime，LocalDateTime在反序列化时貌似自动完成了+08运算。\n  第一个问题 如下实验：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  CREATE TABLE timestamp_demo (ts TIMESTAMP, tstz TIMESTAMPTZ); INSERT INTO timestamp_demo (ts, tstz) VALUES ( \u0026#39;2021-07-19 11:00:00-00\u0026#39;, \u0026#39;2021-07-19 11:00:00-00\u0026#39; ); INSERT INTO timestamp_demo (ts, tstz) VALUES ( now(), now() );   最后查看数据库中的数据：\n我发现当我使用字符串的进行timestamptz类型插入的时候，timestamptz类型的字段没有按照我的现象根据我操作系统当前所在的时区（链接、用户所在的时区），将时间转换成GMT时间。按照MySQL的经验，show timezone或许得到的就是当前链接（即session）的时区，那么这个现象是可以理解的：我在GMT的时区里插入任何数据，都不需要进行转换。\n我现在手动切换当前session时区到PRC，我先执行了一次select语句，我发现timestamp的数据没有任何变化，timestamptz类型的数据按照设计完成了+8运算。\n实验到这儿，我才发现了一些问题，我在插入数据的时候，已经带上了时区~~~，秒后面的+00和-00其实就是时区信息，我一直没有意识到这个问题，不过好在该细节对前面我作出来的分析并没有任何影响，我前面的分析都是正确的。此时我将当前链接的时区设置为PRC，然后用如下代码进行插入实验，最终插入数据库的数据确实完成了PRC时区到GMT时区（即UTC时间）转换，非常的开心。\n1 2 3 4 5 6 7 8  INSERT INTO timestamp_demo (ts, tstz) VALUES ( \u0026#39;2021-07-19 11:00:00\u0026#39;, \u0026#39;2021-07-19 11:00:00\u0026#39; );   发现数据没有像我想象的一样转换成GMT时间。看了上面的资料，我认为可能是因为我用户或者我链接的所在的时区影响了数据库出数据（自动帮我完成了时区的缓存）。\n第二个问题 我用如下代码，查看了当前数据库的链接，发现数据库的链接的时区为：Asia/Shanghai。\n1 2 3 4 5 6 7 8 9 10 11 12  List\u0026lt;String\u0026gt; timezones = jdbcTemplate.query( \u0026#34;show time zone\u0026#34;, new RowMapper\u0026lt;String\u0026gt;() { @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException { return rs.getString(1); } }); System.out.println(timezones);   这个结果是比较出乎我的意料的，因为我们数据库的请求url上并没有配置时区，我现在不知道这个时区数据是从何而来的。最后我查找资料，成功的将SpringBoot实例的时区更换为了GMT，相关笔记我整理在了SpringBoot分类下。\n我仅仅只是处于技术探索的目的进行SpringBoot时区的调整，实践中该技术貌似没有太大的需求。\n第三个问题 在写入的时候，在我们自定义的typeHandler中，LocalDateTime类型的参数被转换成了Timestamp类型的对象。这个然后这个timestamp对象由pg自己的驱动器了进行处理（我想pg自己的驱动器类应该很清楚知道pg数据库支持的类型，所以可以很好的根据数据库中的类型处理这个timestamp对象，我之所以作出这个判断，是因为我在开发库上做实验，而开发库没有开启sql日志）\n在读出数据的时候，在我们自定义的typeHandler中，pg的数据库交给我们一个Timestamp类型的对象，然后我们将这个timestamp对象转换成LocalDateTime对象。整个过程平平无奇，并没有涉及到过于底层的东西（最底层的东西都被PG的驱动器类自己处理了）。\n第四个问题 SpringBoot实例所设置的时区，对时间戳影响很大。我们在程序内部是很少使用时间戳概念的，我们使用的都是Date、Time、DateTime之类的概念（我们不会拿时间戳做运算，但是我们会拿DateTime等做运算）。我之前没有意识到这个问题，其实Date、Time、DateTime之类的概念都蕴含了时区的概念，也就是说，我们只能说某某时区的Date、Time和DateTime，而不能脱离时区谈论这些概念。\n因此，从这些对象转换成时间戳的时候，运算过程一定是带上了时区的。举个例子，一个时间2021-07-19 16:00:00转换成时间戳，如果单纯的计算秒数，我们实际上是假设了这个时间是零时区的。但是我们目前处于+8时区，所以在计算秒数的时候，需要先将这个时间减去8小时，然后再计算秒数。\nSpringBoot实例应该会根据系统当前的时区，来设置整个实例的时区，同时，这个时区会用于与pg数据建立链接（即我们的链接的session和SpringBoot的时区是一致的）。\n第五个问题 综上，产生这个问题的原因在我们项目中在讲LocalDateTime转换成时间戳的时传递了错误的ZoneOffset，我们硬编码了一个+8的值。当项目跑在国内的环境中时，这个问题的印象是比较小的，当我们的项目跑在国外的环境中时，这个问题时灾难的，因为此时的LocalDateTime中记录的时区并不是+8时区，但是强行按照了+8时区进行时间戳转换，所以算出来的数据是错误的。\n此时如下编码，即可解决这个问题：\n1 2 3 4 5 6 7 8  LocalDateTime localDateTime = LocalDateTime.of(2021, 7, 19, 15, 0, 0); ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(localDateTime); localDateTime.toInstant(offset).toEpochMilli();   这段代码中，我们应用当前系统所在的时区来转换LocalDateTime对象，是符合需求的。\n","description":"","id":158,"section":"notes","tags":null,"title":"LocalDateTime与timestamptz","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/localdatetime/localdatetime%E4%B8%8Etimestamptz/"},{"content":"这是我使用在我们项目中的一个方案，我挺喜欢这个方案的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // LocalDateTime到时间戳  ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(localDateTime); return String.valueOf(localDateTime.toInstant(offset).toEpochMilli()); // 时间戳到LocalDateTime  long timestamp = Long.parseLong(text); Instant instant = Instant.ofEpochMilli(timestamp); ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone);   参考资料  java8中时间的各种转换(LocalDateTime)  ","description":"","id":159,"section":"notes","tags":null,"title":"LocalDateTime与时间戳互相转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/localdatetime%E4%B8%8E%E6%97%B6%E9%97%B4%E6%88%B3%E4%BA%92%E7%9B%B8%E8%BD%AC%E6%8D%A2/"},{"content":"最近服务的消费者提出了新的需求，要求我们的时间字段的格式都必须为时间戳，我原本以为是一个简单的问题，结果发现Fastjson在处理LocalDateTime时不是那么简单（我还没有思考过为什么使用LocalDateTime而不是Date等类）。找了一圈，没有很好的方案，所以我开发了如下的代码，我打算在下次遇到该需求的时候再重构代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  // todo 临时方案，以后需要优化  @Data public static class DataPoDTO { private String formId; private String orgId; private Map\u0026lt;String, Object\u0026gt; extraData; protected String id; protected Integer delete = 0; protected LocalDateTime gmtModifyTime; protected LocalDateTime gmtCreateTime; protected String modifier; protected String creator; public Long getGmtModifyTime() { return gmtModifyTime.toEpochSecond(ZoneOffset.of(\u0026#34;+8\u0026#34;)); } public Long getGmtCreateTime() { return gmtCreateTime.toEpochSecond(ZoneOffset.of(\u0026#34;+8\u0026#34;)); } }   我们从数据库中查出来的数据，先COPY到DataPoDTO中，然后再进行序列化。\n相关资料收集 整理一下这些资料，便于以后深入研究：\n  从LocalDateTime序列化探讨全局一致性序列化\n这篇文章提到了序列化工具和反序列化工具全局一致性，但是作者的案例使用的是JackJson。\n  FastJson输出时间类型强转为时间戳\n提到了fastJsonConfig.setSerializeFilters()，对我当前的问题来说，这个解决方案太重了，但是如果是全局一致性的话，可以考虑使用这个方案。\n  Java8 LocalDateTime获取时间戳（毫秒/秒）、LocalDateTime与String互转、Date与LocalDateTime互转\nlocaldatetime实现时间戳(相互转换)\n包含了LocalDateTime时间戳转换的知识。\n  ","description":"","id":160,"section":"notes","tags":null,"title":"LocalDateTime序列化时格式问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/localdatetime/localdatetime%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E6%A0%BC%E5%BC%8F%E9%97%AE%E9%A2%98/"},{"content":"上周把Idea升级到了最新版，结果启动项目时出现了如下错误：\n我最后修复该问题的方案是放弃我自己进行lombok版本管理，让SpringBoot进行版本裁决：\n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   参考资料  You aren‘t using a compiler supported by lombok, so lombok will not work and has been disabled.  ","description":"","id":161,"section":"notes","tags":null,"title":"Lombok与Idea版本不兼容","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/lombok%E4%B8%8Eidea%E7%89%88%E6%9C%AC%E4%B8%8D%E5%85%BC%E5%AE%B9/"},{"content":"scope取值   compile\n 默认为compile，什么都不配置就意味着compile compile表示被依赖项目需要参与当前项目的编译、测试、运行 打包的时候，compile也会被打包进去    test\n 仅参与测试相关的工作，包括测试代码的编译、执行    runtime\n 被依赖项目无需参与项目的编译，但是需要参与后期的测试和运行 与compile相比，仅跳过编译，与compile区别不是很大 案例：JSR xxx等，API Jar是compile的，具体实现是runtime的，编译时只需要知道接口即可 案例：jdbc驱动框架，jdbc相关api是compile，而具体实现可以通过Class.forName获取 备注：可以与optional搭配使用，optional为true，则可以用A实现也可以用B实现    provided\n 打包时可以不用打包进去，别的设施会提供 该依赖理论上可以参与编译、测试、运行等周期 相比于compile，在打包阶段做了exclude动作    system\n 从参与角度来说，与provide相同 依赖项不会被maven仓库抓，而是从本地文件系统拿 一定需要配合systemPath属性使用    scope依赖传递 A -\u0026gt; B -\u0026gt; C。\n知道了B在A项目中的scope，如何知道C在A中的scope呢？\n 如果C是test或者provided，C直接被抱起，A不依赖C 否则A依赖于C，C的scope继承于B的scope  参考资料  Maven依赖中的scope详解spring-boot-starter-tomcat  ","description":"","id":162,"section":"notes","tags":null,"title":"Maven中的Scope","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E4%B8%AD%E7%9A%84scope/"},{"content":"我在deploy auth-center项目的时候，在根项目执行deploy，报如下错误（没有太多的有用的信息）：\n \u0026quot;C:\\Program Files\\Java\\jdk1.8.0_281\\bin\\java.exe\u0026quot; -Dmaven.multiModuleProjectDirectory=D:\\Project\\auth-center \u0026quot;-Dmaven.home=D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\u0026quot; \u0026quot;-Dclassworlds.conf=D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\\bin\\m2.conf\u0026quot; \u0026quot;-javaagent:D:\\Software\\IntelliJ IDEA 2019.1.4\\lib\\idea_rt.jar=55517:D:\\Software\\IntelliJ IDEA 2019.1.4\\bin\u0026quot; -Dfile.encoding=UTF-8 -classpath \u0026quot;D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\\boot\\plexus-classworlds-2.6.0.jar\u0026quot; org.codehaus.classworlds.Launcher -Didea.version2019.1.4 -s D:\\MavenRepository\\settings-guoxiong.xml -Dmaven.repo.local=D:\\MavenRepository\\repository -DskipTests=true deploy -P local [WARNING] [WARNING] Some problems were encountered while building the effective settings [WARNING] 'servers.server.id' must be unique but found duplicate server with id maven-public @ D:\\MavenRepository\\settings-guoxiong.xml [WARNING] [INFO] Scanning for projects... [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-common:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-client:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-server:jar:1.0 [WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-install-plugin is missing. @ line 136, column 21 [WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-deploy-plugin is missing. @ line 152, column 21 [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-login:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build. [WARNING] [WARNING] For this reason, future Maven versions might no longer support building such malformed projects. [WARNING] [INFO] ------------------------------------------------------------------------ [INFO] Reactor Build Order: [INFO] [INFO] authcenter-common [jar] [INFO] authcenter-client [jar] [INFO] authcenter-login [jar] [INFO] authcenter-server [jar] [INFO] authcenter [pom] [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-common \u0026gt;--------------------- [INFO] Building authcenter-common 1.0 [1/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-common --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-common --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-common --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-common --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-common --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-common --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-common --- [INFO] Installing D:\\Project\\auth-center\\authcenter-common\\target\\authcenter-common.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-common\\1.0\\authcenter-common-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-common\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-common\\1.0\\authcenter-common-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-common --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.jar (237 kB at 2.1 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.pom (1.8 kB at 87 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml (302 B at 9.4 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml (302 B at 1.5 kB/s) [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-client \u0026gt;--------------------- [INFO] Building authcenter-client 1.0 [2/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-client --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-client --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-client --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-client --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-client --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-client --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-client --- [INFO] Installing D:\\Project\\auth-center\\authcenter-client\\target\\authcenter-client.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-client\\1.0\\authcenter-client-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-client\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-client\\1.0\\authcenter-client-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-client --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.jar (36 kB at 1.3 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.pom (2.3 kB at 63 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml (302 B at 14 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml (302 B at 1.7 kB/s) [INFO] [INFO] ---------------------\u0026lt; com.sdstc:authcenter-login \u0026gt;--------------------- [INFO] Building authcenter-login 1.0 [3/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-login --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-login --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-login --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-login --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-login --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-login --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-login --- [INFO] Installing D:\\Project\\auth-center\\authcenter-login\\target\\authcenter-login.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-login\\1.0\\authcenter-login-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-login\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-login\\1.0\\authcenter-login-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-login --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.jar (181 kB at 4.2 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.pom (3.5 kB at 55 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml (301 B at 15 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml (301 B at 1.8 kB/s) [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-server \u0026gt;--------------------- [INFO] Building authcenter-server 1.0 [4/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-server --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] Copying 13 resources [INFO] Copying 13 resources [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-server --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-server --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] Copying 19 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-server --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-server --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-server --- [INFO] Building jar: D:\\Project\\auth-center\\authcenter-server\\target\\authcenter.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.2.5.RELEASE:repackage (default) @ authcenter-server --- [INFO] Replacing main artifact with repackaged archive [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-server --- [INFO] Skipping artifact installation [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-server --- [INFO] Skipping artifact deployment [INFO] [INFO] ------------------------\u0026lt; com.sdstc:authcenter \u0026gt;------------------------ [INFO] Building authcenter 1.0 [5/5] [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter --- [INFO] Installing D:\\Project\\auth-center\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter\\1.0\\authcenter-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter --- [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for authcenter 1.0: [INFO] [INFO] authcenter-common .................................. SUCCESS [ 3.053 s] [INFO] authcenter-client .................................. SUCCESS [ 0.516 s] [INFO] authcenter-login ................................... SUCCESS [ 0.817 s] [INFO] authcenter-server .................................. SUCCESS [ 2.236 s] [INFO] authcenter ......................................... FAILURE [ 0.008 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 6.958 s [INFO] Finished at: 2021-05-10T14:14:49+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project authcenter: Deployment failed: repository element was not specified in the POM inside distributionManagement element or in -DaltDeploymentRepository=id::layout::url parameter -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn \u0026lt;goals\u0026gt; -rf :authcenter Process finished with exit code 1 我并没有定位出这个问题，我解决该问题的方案是只Deploy子项目，不要用根项目Deploy。\n","description":"","id":163,"section":"notes","tags":null,"title":"Maven无法从根项目deploy","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E6%97%A0%E6%B3%95%E4%BB%8E%E6%A0%B9%E9%A1%B9%E7%9B%AEdeploy/"},{"content":"1 2 3 4  mvn dependency:tree mvn dependency:tree -Doutput=*.txt   参考资料  如何查看Maven项目中的jar包依赖树情况？  ","description":"","id":164,"section":"notes","tags":null,"title":"Maven查看依赖树","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E6%9F%A5%E7%9C%8B%E4%BE%9D%E8%B5%96%E6%A0%91/"},{"content":"需求产生于一个非常特殊的场景，在做内部应用上云时，我们的流水线始终无法拉取下面的包（我们已经配置了VPN，且阿里云的Maven仓库已经做了全量同步），所以没有办法，只能通过下面的方式将jar包上传到阿里的仓库上（是这样的么，我好想忘记细节了）\n指令如下  mvn deploy:deploy-file \\ -DgroupId=com.oracle \\ -DartifactId=ojdbc7 \\ -Dversion=12.1.0.2 \\ -Dfile=./ojdbc7-12.1.0.2.jar \\ -Durl=http://ci.pc.com.cn/nexus/content/repositories/releases/ \\ -DrepositoryId=releases 20210421后续：\n有意思，我没想到这种需求也能再次遇到，今天在做GRpc相关的功能时，需要用到个grpc-starter.jar的包，这个包在Maven仓库里没有。我先尝试修改上面的指令，改动结果如下，企图简简单单的完成推送任务，但是一直报如下错误：\n1 2 3 4 5 6 7 8 9  mvn deploy:deploy-file \\ \t-DgroupId=com.sdstc.paas \\  -DartifactId=grpc-starter \\  -Dversion=1.0.0-RELEASE \\  -Dfile=./grpc-starter.jar \\  -Durl=http://192.168.20.9:8081/repository/mavenreleases/ \\  -DrepositoryId=maven-releases    [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- Uploading to maven-releases: http://192.168.20.9:8081/repository/mavenreleases/com/sdstc/paas/grpc-starter/1.0.0-RELEASE/grpc-starter-1.0.0-RELEASE.jar Uploading to maven-releases: http://192.168.20.9:8081/repository/mavenreleases/com/sdstc/paas/grpc-starter/1.0.0-RELEASE/grpc-starter-1.0.0-RELEASE.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.748 s [INFO] Finished at: 2021-04-21T16:31:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy-file (default-cli) on project standalone-pom: Failed to deploy artifacts: Could not find artifact com.sdstc.paas:grpc-starter:jar:1.0.0-RELEASE in maven-releases (http://192.168.20.9:8081/repository/mavenreleases/) -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 我登录Nexus后并没有感觉到异常，maven-releases仓库都是存在的。而且maven-releases下有很多com.sdstc的包，我感觉推送到到这块应该是没有问题的（我被包名称上的Release给忽悠了，感觉这个包就应该推到release仓库）。后来我尝试在浏览器访问http://192.168.20.9:8081/repository/mavenreleases/地址，结果发现该地址报404错误。\n我再次检查我的setting文件，在文件中找到了新的仓库地址，并检查了该仓库地址，是正常可以访问的，所以重新配置使用这个仓库，最终成功的完成了推送。成功配置如下：\n mvn deploy:deploy-file \\ -DgroupId=com.sdstc.paas \\ -DartifactId=grpc-starter \\ -Dversion=1.0.0-RELEASE \\ -Dfile=./grpc-starter.jar \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo 在解决这个问题时，我学习到了将包安装在本地的指令，我想我下次可能会优先使用这个指令。我是在Win10上执行的，代码需要写成一行，但是，为了整理笔记时好看，我按Linux的方式重新调整了代码：\n mvn install:install-file \\ -DgroupId=com.sdstc.paas \\ -DartifactId=grpc-starter \\ -Dversion=1.0.0-RELEASE \\ -Dfile=./grpc-starter.jar -Durl=http://192.168.20.9:8081/repository/mavenreleases/ -DrepositoryId=maven-releases \\ -Dpackaging=jar 20210426后续：\n没想到还有相关的需求？？？而且我们运维也是通过这种方式上传的（假的吧）,这次我用如下代码上传，遇到了如下的报错，我的解决方法是将jar包从本地的maven仓库中移出来，放到一个临时的文件夹中，然后再执行这行指令（玄学），然后就成功的推送了。\n mvn deploy:deploy-file \\ -DgroupId=cn.hutool \\ -DartifactId=hutool-all \\ -Dversion=5.6.3 \\ -Dfile=./hutool-all-5.6.3.jar \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo  // 报错上传的日志 D:\\MavenRepository\\repository\\cn\\hutool\\hutool-all\\5.6.3\u0026gt;mvn deploy:deploy-file -DgroupId=cn.hutool -DartifactId=hutool-all -Dversion=5.6.3 -Dfile=./hutool-all-5.6.3.jar -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.264 s [INFO] Finished at: 2021-04-26T10:08:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy-file (default-cli) on project standalone-pom: Cannot deploy artifact from the local repository: D:\\MavenRepository\\repository\\cn\\hutool\\hutool-all\\5.6.3\\hutool-all-5.6.3.jar -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException // 正确上传的日志 C:\\Users\\wujj\\Desktop\\tmp3\u0026gt;mvn deploy:deploy-file -DgroupId=cn.hutool -DartifactId=hutool-all -Dversion=5.6.3 -Dfile=./hutool-all-5.6.3.jar -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.jar (1.9 MB at 4.2 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.pom (393 B at 2.4 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml (299 B at 2.4 kB/s) [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.514 s [INFO] Finished at: 2021-04-26T10:55:08+08:00 [INFO] ------------------------------------------------------------------------ 我很讨厌这种充满玄学的问题，我觉得一个问题不知道其底层的缘由都是在给自己给别人埋坑，所以我计划花时间解决好这个问题，我目前的疑惑有：\n  为什么在本地Maven仓库下不能成功，非要拷贝到一个临时文件夹中执行，是路径太长了么，还是Maven仓库中的一些文件影响了结果（我查看了日志，没有找到任何有用的信息）？\n  我发现我最终推到Nexus仓库后的pom文件和该jar包原本的pom文件不一致，我觉得这是一个隐患（我有办法解决这个问题了）\n  我觉得存在技术，将本地Maven仓库的某个依赖整体推送到Nexus仓库。我在做阿里云的Maven时，阿里云就提供了这个工具，阿里云是将整个maven的本地仓库都推送过去，我觉得Nexus也提供相应的工具。（我还是没有找到这种工具）  问题一 我已经实验过了，不是目录太深、不是目录中带有数字、不是目录与版本号一致造成的问题。\n当在本地仓库的jar包所在目录，新建一个临时目录，把jar包放进去，然后执行指令，也是可以成功的上传的。\n知道问题的答案后，我不知道该用什么语言形容我的心情，只要你当前使用的maven工具的setting.xml文件中的localRepository和你正在上传的jar包不是同一个仓库，就可以成功的上传。我大致猜到了实现逻辑了，它会先通过命令的groupId、artificialId、version加上setting.xml文件中的localRepository，得到一个jar包的地址，然后与你当前希望上传的jar包地址进行对比，如果两者是一样的就会阻止上传。实际上报错中已经说明白了这个问题:Cannot deploy artifact from the local repository。只是我理解错了方向。\n我没有找到解释为什么这样设计的资料。\n问题二 我用如下指令解决了这个问题，但是前提是我还是得把pom文件和jar包拷贝到一个临时文件夹：\n mvn deploy:deploy-file \\ -DgeneratePom=false \\ -DrepositoryId=project-repo \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ \\ -DpomFile=./hutool-all-5.6.3.pom \\ -Dfile=./hutool-all-5.6.3.jar 参考资料   将jar推送到本地maven库和nexus中的方法\n  jar包上传maven私服出错Cannot deploy artifact from the local repository\n  使用Nexus3搭建Maven私服+上传第三方jar包到本地maven仓库\n  Maven私服Nexus3.x环境构建操作记录\n学习到一些Nexus仓库的基础知识，知道了如果存在proxy仓库，使用第三方包时可以通过这个仓库获取。我们的Nexus也确实存在一个proxy，但是我们的本地环境和dev环境的setting.xml文件中都没有配置这个仓库，难受。\n  ","description":"","id":165,"section":"notes","tags":null,"title":"Maven用命令行将jar包上传到Nexus仓库","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B0%86jar%E5%8C%85%E4%B8%8A%E4%BC%A0%E5%88%B0nexus%E4%BB%93%E5%BA%93/"},{"content":"我们的项目有一个比较便利的功能，如图，当我们选择了local后，我们启动SpringBoot项目时，将自动使用application-local.yml配置文件，当我们选择sit后，则会使用application-sit.yml配置文件。\n该功能是如何实现的呢，如图，在我们公司自己的starter-parent上有如下的配置：\n而在我们的bootstrap.properties中有如下配置：\n我认为项目在启动的时候，会将@spring.profiles.active@转换为相应的Maven Profile的值，从而实现使用相应的配置文件。\n对上述分析的验证 我准备了如下配置文件：\n # application.properties spring.profiles.active=@spring.profiles.active@ # applicaiton-local.yml tmp: key: local # applicaiton-sit.yml tmp: key: sit 我准备了如下配置类：\n1 2 3 4 5 6 7 8  @Data @Component @ConfigurationProperties(prefix = \u0026#34;tmp\u0026#34;) public class TmpConfiguration { private String key; }   在测试类中，我们发现当我们选择了不同的Maven Profile后，tmpConfiguration中的key值将会为local或者sit。\n实验基本证实了我的想法。\n还存在的问题 我在实验的过程中又产生了一些新的问题，如下：\n @spring.profiles.active@只能写在application.properties中，不能写在application.yml中，如果写在application.yml中，则会在启动时报如下的错误（已解决，参考同目录下的笔记）：   Caused by: while scanning for the next token found character '@' that cannot start any token. (Do not use @ for indentation) in 'reader', line 3, column 13: active: @spring.profiles.active@ 那么如果我想达到和application.properties相同的配置效果，我又该如何写这个值呢？\n我目前不知道Maven Profile与SpringBoot项目的关系，application.properties中是如何获取我们在Maven Profile中配置的Profile呢？（已解决）  ","description":"","id":166,"section":"notes","tags":null,"title":"Maven的profiles与SpringBoot的application.yml","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/maven%E7%9A%84profiles%E4%B8%8Espringboot%E7%9A%84application.yml/"},{"content":"问题描述 报错如下：\n Caused by: java.lang.IllegalStateException: Method has too many Body parameters: public abstract void com.sdstc.authcenter.client.UserConfigClient.updateUserListConfig(java.lang.String,com.sdstc.authcenter.request.UpdateListConfigRequest) at feign.Util.checkState(Util.java:127) ~[feign-core-10.1.0.jar:?] at feign.Contract$BaseContract.parseAndValidateMetadata(Contract.java:117) ~[feign-core-10.1.0.jar:?] at org.springframework.cloud.openfeign.support.SpringMvcContract.parseAndValidateMetadata(SpringMvcContract.java:188) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at feign.Contract$BaseContract.parseAndValidatateMetadata(Contract.java:66) ~[feign-core-10.1.0.jar:?] at feign.ReflectiveFeign$ParseHandlersByName.apply(ReflectiveFeign.java:154) ~[feign-core-10.1.0.jar:?] at feign.ReflectiveFeign.newInstance(ReflectiveFeign.java:52) ~[feign-core-10.1.0.jar:?] at feign.Feign$Builder.target(Feign.java:251) ~[feign-core-10.1.0.jar:?] at org.springframework.cloud.openfeign.HystrixTargeter.target(HystrixTargeter.java:36) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.cloud.openfeign.FeignClientFactoryBean.getTarget(FeignClientFactoryBean.java:284) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.cloud.openfeign.FeignClientFactoryBean.getObject(FeignClientFactoryBean.java:247) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:171) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1818) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1266) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:260) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1510) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1467) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1250) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] ... 19 more Feign客户端代码：\n // Version 1 @PostMapping(\u0026quot;/updateUserListConfig\u0026quot;) void updateUserListConfig( @RequestAttribute(APICons.REQUEST_USER_ID) @NotEmpty String userId, @RequestBody @Validated UpdateListConfigRequest request); // Version 2 @PostMapping(\u0026quot;/updateUserListConfig\u0026quot;) void updateUserListConfig( String userId, @RequestBody @Validated UpdateListConfigRequest request); 以上两种写法都不可以，会导致Feign消费端报错。\n解决方案 如下写法不会报错：\n1 2 3 4 5 6  @PostMapping(\u0026#34;/updateUserListConfig\u0026#34;) void updateUserListConfig( @RequestParam(\u0026#34;tmp\u0026#34;) String userId, @RequestBody @Validated UpdateListConfigRequest request);   截止目前，已经从技术上解决这个报错的问题了。接下来我谈一谈我在项目中如何修复该问题，及我的思考。\n我们之所以在项目中使用@RequestAttribute是因为通过网关进入到服务内部时，网关会根据Token取得用户的一些信息，并塞到请求里的Header中，然后请求到下一个服务。我们的Controller通过@RequestAttribute获得的属性可以快速进行逻辑处理。理论上，服务会将这个Header信息存储起来，在下一跳请求中，塞上这个Header（具体的技术细节可以参考如何塞traceId）。下一个服务于是就可以同样使用该Header信息，并使用@RequestAttribute注解。\n我们的问题在于，我们将这样的一份Controller复制成了Client，只删除了方法体，而没有删除@RequestAttribute。最后导致了Feign服务端导入失败。从技术上讲，复制的时候删除所有@RequestAttribute参数，这个问题也不会出现了。\n我最后怎么改，我将其全部改为了@RequestParam，因为我得到消息说，我们内部服务之间的请求可能不包含Header信息，而且，我们有些接口可能是从MQ消费者请求的，这些MQ消费者是没有任何Token信息的，它们发出的请求也就没有Header了。\n很糟糕的开发体验哦，一种非常好的框架，结果不能发挥出其强大的作用。如何避免这个问题呢？我觉得区分内部接口和外部接口可能会有点作用（需要在路径、Client命名上进行区分），所有可能被网关直接、间接访问到的接口都是外部接口，外部接口是一定可以使用@RequestAttribute属性的；除此之外的接口都是内部接口，内部接口主要服务于MQ等。\n这可能会带来一些冗余，一份相同功能的接口将会存在两个版本，其区别仅仅是Controller接受参数的方式不同。我这边能给到的建议只是：Controller层只做参数的简单处理，Service层做真正的逻辑，这样Service层的复用性增加，可以稍微减少冗余带来的不爽快的体验。（实际开发中，肯定是假设所有的接口都是外部接口，等到MQ有需求后，再去开发一个内部接口，开发内部接口时，如果有Service有机会复用，这个时候重构下代码就好了）\n这里面可能还存在一个问题：可能有一部分外部接口需要调到内部接口，这种事情应该绝对不可以发生，这个需要从规则层面限制。还有一个问题：可能一个接口会被网关调用的接口间接调用，但是他实际上不应该暴露给网关，我们该处理这个问题（这是一个非常常见的需求），如何处理这个问题？我对这个问题的提出的解决方法是，每个controller中的方法都写完整的路径名（不要使用类上的@RequestMapping来提升一丁点的复用性），通过在路径名最前方上加internel。然后在网关上配置，确保internel不会暴露给外部。 （这个地方应该设计以下关键字，使用internel关键字可能会让人疑惑）\n项目管理方面，服务提供方，大概需要一个服务于外部接口的Feign客户端，加一个服务于内部接口的Feign客户端。\n服务部署时，我们也可以将提供外部接口的服务和提供内部接口的服务分开部署，尽管它们是同一套代码。\n这件事没想到还有后续：在后续对项目的研究中，我发现我们的确是存在两种Controller，一种服务于外部，没有找到相关的Feign Client；一种是服务于内部，其Controller以I打头，会存在相关的Feign Client，服务于内部的的Controller的方法的返回值，没有使用ResponseVo包装，其方法没有使用@RequestAttribute注解标注。这样的设计，可能最终会降低服务于外部的接口的复用性，且最后导致接口管理混乱。\n小结 综上，接口存在以下几种：\n 被网关直接调用的接口 被网关间接调用的接口，其本身也可能被网关直接调用 被网关间接调用的接口，其本身不应该被网关调用 服务于MQ消费者的接口  对上述内容总结如下：\n 从网关进入的请求，请求的接口，及这些接口请求到的内部服务的接口都视为外部接口，其他的接口视为内部接口 网关的一个请求将会形成请求树，这个树上的每个节点都需要是外部接口 外部接口可以使用@RequestAttribute注解，返回值需要用RequestVo包装 服务提供方提供两份Feign客户端代码用于调用服务于外部的接口，一份用于调用服务于内部的接口。 部署服务提供方时需要部署两份，一份为外部接口提供服务，一份为内部接口提供服务  我将会持续关注这部分，收集相关的需求，并完善这部分的文档。\n","description":"","id":167,"section":"notes","tags":null,"title":"Method has too many Body parameters","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/method-has-too-many-body-parameters/"},{"content":"问题描述 PG库中的字段类型为varchar，实体中字段类型为String，PO的简化后结构如下：\n1 2 3 4 5 6 7 8 9 10  @Data @Builder @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_field\u0026#34;, autoResultMap = true) class FieldVo extends BaseVo { private String id; private Integer dataType }   通过MyBatis-Plus的BaseMapper中的selectOne方法查询实体的时候报了如下错误：\n 2021-04-19 11:44:45.580 INFO StartupInfoLogger.java:61- [b3=,TraceId=,SpanId=,ParentSpanId=,Export=,Sampled=,Flags=] [Org=,User=] Started StartDyfProviderTest in 12.897 seconds (JVM running for 14.333) Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@69aeeb5] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7058c450] will not be managed by Spring ==\u0026gt; Preparing: SELECT id,org_id,domain_id,field_code,field_name,lang_code,field_type,data_type,default_value,note,group_id,expression,display_type,fill_note,example,unit,default_json_schema,is_required,is_delete,gmt_modify_time,gmt_create_time,modifier,creator FROM t_dyf_field WHERE is_delete=0 AND (id = ? AND org_id = ?) ==\u0026gt; Parameters: 17393408226095104(String), 100(String) \u0026lt;== Columns: id, org_id, domain_id, field_code, field_name, lang_code, field_type, data_type, default_value, note, group_id, expression, display_type, fill_note, example, unit, default_json_schema, is_required, is_delete, gmt_modify_time, gmt_create_time, modifier, creator \u0026lt;== Row: 17393408226095104, 100, 测试数据72, 测试数据71, 字段名, 测试数据52, 74920, 2659, 测试数据3, 测试数据36, 测试数据52, 测试数据27, 测试数据32, 测试数据18, 测试数据44, 测试数据5, {}, 46501, 0, 2021-04-19 11:00:54.086+08, 2021-04-19 11:00:54.086+08, 100, 100 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@69aeeb5] 2021-04-19 11:44:48.480 ERROR CloudControllerExceptionHandler.java:79- [b3=,TraceId=8ba0bed669734552,SpanId=8ba0bed669734552,ParentSpanId=,Export=true,Sampled=,Flags=] [Org=,User=] 运行时异常 org.springframework.dao.DataIntegrityViolationException: Error attempting to get column 'lang_code' from result set. Cause: org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 ; 不良的类型值 int : 测试数据52; nested exception is org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:88) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.sun.proxy.$Proxy151.selectOne(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectOne(SqlSessionTemplate.java:159) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:90) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.sun.proxy.$Proxy155.selectOne(Unknown Source) ~[?:?] at com.baomidou.mybatisplus.extension.service.impl.ServiceImpl.getOne(ServiceImpl.java:201) ~[mybatis-plus-extension-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.extension.service.IService.getOne(IService.java:229) ~[mybatis-plus-extension-3.4.2.jar:3.4.2] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl.selectField(FieldServiceImpl.java:83) ~[classes/:?] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl$$FastClassBySpringCGLIB$$ed8fc6c7.invoke(\u0026lt;generated\u0026gt;) ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) ~[spring-aop-5.2.12.RELEASE.jar:5.2.12.RELEASE] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl$$EnhancerBySpringCGLIB$$2162c38d.selectField(\u0026lt;generated\u0026gt;) ~[classes/:?] at com.sdstc.dyf.admin.core.controller.DyfController.getField(DyfController.java:53) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.41.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.41.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at brave.servlet.TracingFilter.doFilter(TracingFilter.java:68) ~[brave-instrumentation-servlet-5.12.7.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at com.sdstc.scdp.log.filter.GlobalLogFilter.doFilterInternal(GlobalLogFilter.java:60) ~[scdp-log-1.0.2-20210417.042821-8.jar:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at brave.servlet.TracingFilter.doFilter(TracingFilter.java:87) ~[brave-instrumentation-servlet-5.12.7.jar:?] at org.springframework.cloud.sleuth.instrument.web.LazyTracingFilter.doFilter(TraceWebServletAutoConfiguration.java:139) ~[spring-cloud-sleuth-core-2.2.6.RELEASE.jar:2.2.6.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) ~[spring-boot-actuator-2.3.8.RELEASE.jar:2.3.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_281] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_281] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281] Caused by: org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 at org.postgresql.jdbc.PgResultSet.toInt(PgResultSet.java:3014) ~[postgresql-42.2.18.jar:42.2.18] at org.postgresql.jdbc.PgResultSet.getInt(PgResultSet.java:2188) ~[postgresql-42.2.18.jar:42.2.18] at org.postgresql.jdbc.PgResultSet.getInt(PgResultSet.java:2626) ~[postgresql-42.2.18.jar:42.2.18] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1173) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterAdapter.resultSet_getInt(FilterAdapter.java:1645) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1169) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterAdapter.resultSet_getInt(FilterAdapter.java:1645) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1169) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.proxy.jdbc.ResultSetProxyImpl.getInt(ResultSetProxyImpl.java:492) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.pool.DruidPooledResultSet.getInt(DruidPooledResultSet.java:292) ~[druid-1.2.4.jar:1.2.4] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.apache.ibatis.logging.jdbc.ResultSetLogger.invoke(ResultSetLogger.java:69) ~[mybatis-3.5.6.jar:3.5.6] at com.sun.proxy.$Proxy184.getInt(Unknown Source) ~[?:?] at org.apache.ibatis.type.IntegerTypeHandler.getNullableResult(IntegerTypeHandler.java:37) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.type.IntegerTypeHandler.getNullableResult(IntegerTypeHandler.java:26) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.type.BaseTypeHandler.getResult(BaseTypeHandler.java:85) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createUsingConstructor(DefaultResultSetHandler.java:710) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createByConstructorSignature(DefaultResultSetHandler.java:693) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:657) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:630) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:397) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap(DefaultResultSetHandler.java:354) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:328) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSet(DefaultResultSetHandler.java:301) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSets(DefaultResultSetHandler.java:194) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:65) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) ~[mybatis-3.5.6.jar:3.5.6] at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doQuery(MybatisSimpleExecutor.java:69) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.5.6.jar:3.5.6] at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:165) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:92) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:76) ~[mybatis-3.5.6.jar:3.5.6] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ~[mybatis-spring-2.0.5.jar:2.0.5] ... 75 more 定位问题时发现如下现象（按照发现顺序）：\n 注释FieldVo中所有的字段，selectOne可以正常执行 注释FieldVo中的Integer字段，selectOne可以正常执行 注释FieldVo不继承BaseVO代码，selectOne可以正常执行  现象到这块就已经有点离奇了，后来一个同事发现，注释掉@Builder，其他部分保持不变，该代码也可以正常执行。开始意识到可能是Lombok与PG库驱动存在或者MyBatis-Plus存在某些冲突，果断按照这些关键字查找，寻找到如下资料：\nMybatisPlus 3.X 与lombok @Builder 冲突 解决方案\n我按照该文档修复了该问题，但是这个现象我是无法理解的，查看添加@Builder和不添加@Builder后生成的代码，发现区别仅仅是，当加了@Builder、@NoArgsConstructor、@AllArgsConstructor后会生成公共的无参数构造函数、全参的构造函数、和Builder类；如果只加了@Builder，会生成一个默认访问权限的全参构造函数、和Builder类，信息截止到目前，还是没有办法解释这个现象的。\n我只能暂时记录下这个现象，未来有机会去解决。\n","description":"","id":168,"section":"notes","tags":null,"title":"MyBatis 3.0 与 Lombok中的@Builder","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-3.0-%E4%B8%8E-lombok%E4%B8%AD%E7%9A%84builder/"},{"content":"这个报错非常的迷惑人，让人感觉是自己的sql查出来了多条记录，但是代码中将多条数据塞到了一个对象中，实际上并不是这样的，MyBatis拼出来的SQL最终检查出来的也是一条记录。\n这个问题最终是因为Entity上加了@Builder后，缺少默认构造函数导致的，我已经第二次踩这个坑了。\n参考资料  mybatis-plus java.lang.IndexOutOfBoundsException: Index: 23, Size: 23  ","description":"","id":169,"section":"notes","tags":null,"title":"mybatis-plus java.lang.IndexOutOfBoundsException","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-plus-java.lang.indexoutofboundsexception/"},{"content":"这是我自己开发的工具，从entity到typeHandler、到枚举代码如下：\n1 2 3 4 5 6 7 8  /** * 是否是模型必须 */ @TableField(typeHandler = IsModelRequiredTypeHandler.class) private IsModelRequired modelRequired; private Integer isModelRequired;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public class IsModelRequiredTypeHandler extends AbstractEnumTypeHandler\u0026lt;IsModelRequired\u0026gt; { @Override protected IsModelRequired parseValue(String inputParam) { return IsModelRequired.convert(inputParam); } @Override protected String toValue(IsModelRequired isModelRequired) { return isModelRequired.getValue(); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  /** * 是否是模型必须 */ @AllArgsConstructor(access = AccessLevel.PROTECTED) public enum IsModelRequired { /** * 否 */ NOT_MODEL_REQUIRED(\u0026#34;0\u0026#34;), /** * 是 */ MODEL_REQUIRED(\u0026#34;1\u0026#34;), ; @Getter private String value; public static IsModelRequired convert(String inputValue) { for (IsModelRequired enumItem : IsModelRequired.values()) { if (enumItem.getValue().equals(inputValue)) { return enumItem; } } throw new RuntimeException(\u0026#34;Enum Transfer Wrong.\u0026#34;); } }   参考资料  如何在MyBatis中优雅的使用枚举  ","description":"","id":170,"section":"notes","tags":null,"title":"MyBatis-Plus处理枚举的转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-plus%E5%A4%84%E7%90%86%E6%9E%9A%E4%B8%BE%E7%9A%84%E8%BD%AC%E6%8D%A2/"},{"content":"核心就在于使用select方法，参考代码如下：\n1 2 3 4 5 6  LambdaQueryWrapper\u0026lt;AuthFun\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;AuthFun\u0026gt;() .eq(AuthFun::getTreeCode, TreeCode.SERVICE_PACKAGE.getValue()) .in(AuthFun::getParentId, authFuncParentIds) .select(AuthFun::getId, AuthFun::getOperaList);   使用这个方法精准的限制被搜索到的字段是非常的有意义的，可以避免浪费太多的网络资源、减少对数据库的压力。\n参考资料  使用Mybatis-plus，查询表中某个字段的值，返回List集合_cc920095705的博客-程序员宅基地_mybatisplus查询指定字段  ","description":"","id":171,"section":"notes","tags":null,"title":"MyBatis-Plus拼SQL时不要拼全部的字段","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-plus%E6%8B%BCsql%E6%97%B6%E4%B8%8D%E8%A6%81%E6%8B%BC%E5%85%A8%E9%83%A8%E7%9A%84%E5%AD%97%E6%AE%B5/"},{"content":"这个问题我暂时只能描述一下，因为这个问题发生的时候，我询问了同事，结果这是我们架构中已知的问题，所以很快就解决了，我并没有查找任何资料，也没有做任何分析。\n该问题大致是这样的，我在开发时使用了MyBatis-Plus中从BaseMapper中继承而来的方法selectById（其他方法也有这个问题），该方法在本地运行的时候非常的正常，能够正确的检查出我想要的数据。但是，当把项目部署到dev环境的时候，该方法会报no statement的错误（具体错误细节我忘记了，大概是这个意思）。\n同事告诉我，dev环境的配置文件需要进行如下配置：\n mybatis-plus: global-config: super-mapper-class: com.baomidou.mybatisplus.core.mapper.BaseMapper 就是将BaseMapper指向我们自己实现的一个BaseMapper。我大概知道是怎么回事了，dev环境默认执行的BaseMapper的实现中并没有该方法的实现，所以在运行的时候会报no statement错误。\n","description":"","id":172,"section":"notes","tags":null,"title":"MyBatis-plus指定BaseMapper实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-plus%E6%8C%87%E5%AE%9Abasemapper%E5%AE%9E%E7%8E%B0/"},{"content":"最近的工作又是在跟TypeHandler较劲，同样的错误我已经在两个场景中发现了，这次的场景是我修改了typeHandlerPackage配置，我想测一下我自己的typeHandler是否能实现我想要的效果，结构就出现了这个问题。\n事后我分析，可能两次问题都是同一个原因：我在我自己的TypeHandler中的Mapped中配置了Object.class。\n","description":"","id":173,"section":"notes","tags":null,"title":"MyBatis-Plus生成的SQL中包含双引号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis-plus%E7%94%9F%E6%88%90%E7%9A%84sql%E4%B8%AD%E5%8C%85%E5%90%AB%E5%8F%8C%E5%BC%95%E5%8F%B7/"},{"content":"这个问题是我同事遇到的，这个问题大概是说，当一个字段注解了@TypeHandler后，在使用LambdaQueryWrapper时，你传递的参数不会给TypeHandler中指定的类转换，从而导致数据库报出异常。\n我比较关注这个问题，是因为我最近也在大量的使用TypeHandler，我怕我自己也掉进去了。\n参考资料  在字段上设置typeHandler，使用LambdaQueryWrapper查询时没有生效  ","description":"","id":174,"section":"notes","tags":null,"title":"MyBatisPlus中使用TypeHandler时的一个坑","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatisplus%E4%B8%AD%E4%BD%BF%E7%94%A8typehandler%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/"},{"content":"我目前比较中意的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 查询思路：table.id = fieldId and (table.orgId = orgId or table.orgId = 超管orgId)  LambdaQueryWrapper\u0026lt;FieldPo\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;FieldPo\u0026gt;() .eq(FieldPo::getId, fieldId) .and(queryWrapperInner -\u0026gt; queryWrapperInner .eq(FieldPo::getOrgId, orgId) .or() .eq(FieldPo::getOrgId, SystemAdmin.ORG_ID.getOrgId())); FieldPo fieldPo = fieldDao.selectOne(queryWrapper); if (fieldPo == null) { throw new ApiException( ExceptionCode.FIELD_NOT_FOUND.getCode(), ExceptionCode.FIELD_NOT_FOUND.getMsg()); } return fieldPo;   参考资料  Mybatis Plus中的lambdaQueryWrapper条件构造图介绍  ","description":"","id":175,"section":"notes","tags":null,"title":"MyBatis条件构造器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis%E6%9D%A1%E4%BB%B6%E6%9E%84%E9%80%A0%E5%99%A8/"},{"content":"在application.yml配置中增加如下配置：\n1 2 3 4 5  mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImpl  参考资料  mybatisPlus配置控制台打印sql语句  ","description":"","id":176,"section":"notes","tags":null,"title":"MyBatis配置打印日志信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/mybatis%E9%85%8D%E7%BD%AE%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E4%BF%A1%E6%81%AF/"},{"content":"不知道算不算一个Bug，我通过Navicat Premium 12创建的表，无法在Navicat Premium 12中查看。\n该问题目前仅针对PG数据库。\n参考资料  Navicat Premium 下看不到PostgreSQL下已创建的表（已解决！！）  ","description":"","id":177,"section":"notes","tags":null,"title":"Navicat Premium 12看不到PostgreSQL创建的表","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/navicat/navicat-premium-12%E7%9C%8B%E4%B8%8D%E5%88%B0postgresql%E5%88%9B%E5%BB%BA%E7%9A%84%E8%A1%A8/"},{"content":"今天配置好Actuator后，访问其接口时报如下错误：\n { \u0026quot;code\u0026quot;: 100101, \u0026quot;data\u0026quot;: null, \u0026quot;message\u0026quot;: \u0026quot;params invalidate: No converter for [class org.springframework.boot.actuate.beans.BeansEndpoint$ApplicationBeans] with preset Content-Type 'null'\u0026quot;, \u0026quot;success\u0026quot;: false } 我一步一步知道我们的框架层，发现如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { Iterator\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; iterator = converters.iterator(); while(iterator.hasNext()){ HttpMessageConverter\u0026lt;?\u0026gt; converter = iterator.next(); if(StringUtils.containsIgnoreCase(converter.getClass().getName(),\u0026#34;jackson2\u0026#34;)){ iterator.remove(); } } FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义fastjson配置  FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(FastJsonUtil.serializerFeatures); fastJsonHttpMessageConverter.setFastJsonConfig(config); // 添加支持的MediaTypes;不添加时默认为*/*,也就是默认支持全部  // 但是MappingJackson2HttpMessageConverter里面支持的MediaTypes为application/json  // 参考它的做法, fastjson也只添加application/json的MediaType  List\u0026lt;MediaType\u0026gt; fastMediaTypes = new ArrayList\u0026lt;\u0026gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); // fastMediaTypes.add(MediaType.ALL); 这行代码为我边写  fastJsonHttpMessageConverter.setSupportedMediaTypes(fastMediaTypes); converters.add(fastJsonHttpMessageConverter); }   我发现我们的messageConverters仅支持MediaType.APPLICATION_JSON_UTF8，我尝试将其改为fastMediaTypes.add(MediaType.ALL)，发现接口能正确的返回数据。\n我简单的查看了一下源码，发现实现Actuator接口的实现并不是通过Controller，而是@EndPoint和@ReadOperation注解，我猜想可能在一个切面中会得到@ReadOperation的返回值，然后在HttpMessageConverts中寻找一个可以处理Content-Type为null的转换器进行处理，结果没有找到，结果就报错了。\n针对这个案例，我不打算做框架层面任何修改，因为我们Maven管理方面走的是OverWrite，我修改了底层框架，很大概率会影响到线上的代码，有点担心会带来不好的影响。\n参考资料  springBoot或者springCloud 的集成 Prometheus监控-数据无法解析  ","description":"","id":178,"section":"notes","tags":null,"title":"No convert for xxx with preset Content-Type 'null'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/no-convert-for-xxx-with-preset-content-type-null/"},{"content":"在CentOS上自行编译python3后，安装依赖时出现了如下问题：\n [root@base launch]# pip3 install pyinstaller Collecting pyinstaller Downloading pyinstaller-4.3.tar.gz (3.7 MB) |████████████████████████████████| 3.7 MB 1.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done ERROR: Exception: Traceback (most recent call last): File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\u0026quot;, line 228, in _main status = self.run(options, args) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\u0026quot;, line 182, in wrapper return func(self, options, args) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/commands/install.py\u0026quot;, line 323, in run requirement_set = resolver.resolve( File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 183, in resolve discovered_reqs.extend(self._resolve_one(requirement_set, req)) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 388, in _resolve_one abstract_dist = self._get_abstract_dist_for(req_to_install) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 340, in _get_abstract_dist_for abstract_dist = self.preparer.prepare_linked_requirement(req) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\u0026quot;, line 482, in prepare_linked_requirement abstract_dist = _get_prepared_distribution( File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\u0026quot;, line 91, in _get_prepared_distribution abstract_dist.prepare_distribution_metadata(finder, build_isolation) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py\u0026quot;, line 38, in prepare_distribution_metadata self._setup_isolation(finder) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py\u0026quot;, line 96, in _setup_isolation reqs = backend.get_requires_for_build_wheel() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/wrappers.py\u0026quot;, line 160, in get_requires_for_build_wheel return self._call_hook('get_requires_for_build_wheel', { File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/wrappers.py\u0026quot;, line 265, in _call_hook raise BackendUnavailable(data.get('traceback', '')) pip._vendor.pep517.wrappers.BackendUnavailable: Traceback (most recent call last): File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/_in_process.py\u0026quot;, line 86, in _build_backend obj = import_module(mod_path) File \u0026quot;/usr/local/python3/lib/python3.8/importlib/__init__.py\u0026quot;, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 1014, in _gcd_import File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 991, in _find_and_load File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 961, in _find_and_load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 219, in _call_with_frames_removed File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 1014, in _gcd_import File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 991, in _find_and_load File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 975, in _find_and_load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 671, in _load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap_external\u0026gt;\u0026quot;, line 783, in exec_module File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 219, in _call_with_frames_removed File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/__init__.py\u0026quot;, line 18, in \u0026lt;module\u0026gt; from setuptools.dist import Distribution File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/dist.py\u0026quot;, line 38, in \u0026lt;module\u0026gt; from setuptools import windows_support File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/windows_support.py\u0026quot;, line 2, in \u0026lt;module\u0026gt; import ctypes File \u0026quot;/usr/local/python3/lib/python3.8/ctypes/__init__.py\u0026quot;, line 7, in \u0026lt;module\u0026gt; from _ctypes import Union, Structure, Array ModuleNotFoundError: No module named '_ctypes' WARNING: You are using pip version 20.2.3; however, version 21.1.3 is available. You should consider upgrading via the '/usr/local/python3/bin/python3.8 -m pip install --upgrade pip' command. 我执行了如下指令：\n yum install libffi-devel -y make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 因为环境变量之前在第一次编译安装时我已经配置过了，所以这块不需要进行任何配置。\n参考资料  ModuleNotFoundError: No module named \u0026lsquo;_ctypes\u0026rsquo;的解决方案  ","description":"","id":179,"section":"notes","tags":null,"title":"No module named '_ctypes'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/no-module-named-_ctypes/"},{"content":"这个错误发生的非常让人哭笑不得，现象就是运行测试时如论如何都无法正确的运行，总是显示No tests were found。\n最后检查代码发现，是因为编写了如下的代码：\n我分析我当时是先注入什么对象的，结果因为其他事情给耽搁了，所以就导致写了一半，最后就发生了这个Bug。\n参考资料   JAVA——JUNIT运行错误[No tests were found]\n我解决问题的时候，这篇教程没有帮到我，当时我定位问题后，发现问题正是文章里罗列的排查项，有点意思。\n  ","description":"","id":180,"section":"notes","tags":null,"title":"No tests were found","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/no-tests-were-found/"},{"content":"问题描述  C:\\Users\\wujj\\Desktop\\ElectronProject\u0026gt;npm install electron --save (node:14808) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification. (Use `node --trace-warnings ...` to show where the warning was created) \u0026gt; core-js@3.9.1 postinstall C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\core-js \u0026gt; node -e \u0026quot;try{require('./postinstall')}catch(e){}\u0026quot; \u0026gt; electron@12.0.2 postinstall C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\electron \u0026gt; node install.js (node:27104) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification. (Use `node --trace-warnings ...` to show where the warning was created) RequestError: read ECONNRESET at ClientRequest.\u0026lt;anonymous\u0026gt; (C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\got\\source\\request-as-event-emitter.js:178:14) at Object.onceWrapper (events.js:422:26) at ClientRequest.emit (events.js:327:22) at ClientRequest.origin.emit (C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\@szmarczak\\http-timer\\source\\index.js:37:11) at TLSSocket.socketErrorListener (_http_client.js:469:9) at TLSSocket.emit (events.js:315:20) at emitErrorNT (internal/streams/destroy.js:106:8) at emitErrorCloseNT (internal/streams/destroy.js:74:3) at processTicksAndRejections (internal/process/task_queues.js:80:21) npm WARN bookmarker@1.0.0 No repository field. npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! electron@12.0.2 postinstall: `node install.js` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the electron@12.0.2 postinstall script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\wujj\\AppData\\Roaming\\npm-cache\\_logs\\2021-03-29T10_29_25_848Z-debug.log 试了很多种方法，改源、修改全局tsl，最后只有这个办法成功了，执行指令前，执行如下代码（我在Win 10系统）：\n set NODE_TLS_REJECT_UNAUTHORIZED=0 参考文档  npm install时报unable to verify the first certificate 证书无效的错误  ","description":"","id":181,"section":"notes","tags":null,"title":"Node.js install总是失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/node.js/node.js-install%E6%80%BB%E6%98%AF%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题描述 执行如下指令时，报如下错误：\n npm install -g yo npm WARN registry Unexpected warning for https://registry.npmjs.org/: Miscellaneous Warning UNABLE_TO_VERIFY_LEAF_SIGNATURE: request to https://registry.npmjs.org/yo failed, reason: unable to verify the first certificate npm WARN registry Using stale data from https://registry.npmjs.org/ due to a request error during revalidation. npm ERR! code UNABLE_TO_VERIFY_LEAF_SIGNATURE npm ERR! errno UNABLE_TO_VERIFY_LEAF_SIGNATURE npm ERR! request to https://registry.npmjs.org/generator-code failed, reason: unable to verify the first certificate npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\wujj\\AppData\\Roaming\\npm-cache\\_logs\\2021-03-22T10_23_21_944Z-debug.log 解决方案  执行如下指令，关闭strict-ssl：   npm config set strict-ssl false 执行如下指令，完成安装任务：   npm install -g yo 执行如下指令，开启strict-ssl：   npm config set strict-ssl true 参考教程  npm install 出现UNABLE_TO_VERIFY_LEAF_SIGNATURE的解决办法  ","description":"","id":182,"section":"notes","tags":null,"title":"Node.js中的UNABLE_TO_VERIFY_LEAF_SIGNATURE","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/node.js/node.js%E4%B8%AD%E7%9A%84unable_to_verify_leaf_signature/"},{"content":"我在Debain上使用默认的库安装Node.js，版本过低，报npm冲突了。所以我不得不寻找其他的安装方法。\n我最终使用的指令如下：\n1 2 3 4  curl -sL https://deb.nodesource.com/setup_12.x | bash - sudo apt install nodejs   参考资料  在Debian 10系统上安装Node.js和npm的三种不同方法  ","description":"","id":183,"section":"notes","tags":null,"title":"NodeSource存储库安装Node.js和npm","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/node.js/nodesource%E5%AD%98%E5%82%A8%E5%BA%93%E5%AE%89%E8%A3%85node.js%E5%92%8Cnpm/"},{"content":"指令如下：\n npm config set proxy=http://127.0.0.1:1080 npm config set https-proxy=http://127.0.0.1:1080 npm config set registry=http://registry.npmjs.org npm config set proxy=http://127.0.0.1:1080 npm config set https-proxy=http://192.168.13.113:1080 ","description":"","id":184,"section":"notes","tags":null,"title":"npm设置代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/node.js/npm%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"我觉得我遇到的这个问题属于PyCharm的BUG！！！通过oss2推送图片到阿里云OSS时，因为网络环境的问题，我需要设置代理，我在网上找到了一篇教程，是通过环境变量的方式，我果断的设置环境变量后尝试该方案，结果失败了。我以为是这个方案不适用Win环境，于是我在Linux环境测试，发现该方案可行。\n我本人不信邪，我觉得从原理上讲，应该两个平台的表现是一致的，我有在Win平台寻找解决放案，后来发现了通过os.environ设置all_proxy的方式设置代理，是可行的。我意识到，可能是我设置了环境变量后，PyCharm没有立即获取到这些环境变量，于是，我设置了环境变量后，重启PyCharm，发现程序按照我的想法运行了。\n我明白造成我问题的原因了，就是我设置了环境变量后，在PyCharm中启动程序时，没有读取到最新的环境变量。我觉得这个就是PyCharm的BUG。\n其他讯息 其实这次解决问题，本来没有不会花费这么长时间的，我之前有做python中获取环境变量的实验，那个时候获取的始终是none，我没有想到是Pycharm的问题，而是以为我api调用错误，就搁置了这个问题，结果最后就导致这次解决问题花了很长时间。\n这次的问题，还有一些奇怪的现象。我Win机器上开启了代理，oss2的请求会阻塞很长时间，然后报proxy错误，我不知道这个请求最终请求到哪了，为什么会出现这种现象。我觉得我应该学习一些相关的技术，这样下次遇到类似的问题时，我至少知道我的数据包去到哪了。\n参考资料  需要在没有外网但可以使用代理的服务器上，上传文件到oss，该如何设置代理 Request高级用法 python 使用代理的几种方式 python 获取环境变量  后续 这个问题其实还没有结束，解决了环境变量的问题后，还可能存在成功一次上传，部分成功，部分报SSL错误的情况或者Post成功Get失败。真的是离奇到爆炸。但是这次我开始耐心定位问题，我先通过如下指令，判断我1080端口是否正在监听：\n # 要么用双引号，要么不用，单引号没有任何效果 netstat -aon|findstr 1080 当1080端口没有监听的时候，执行测试代码，发现报如下错误，这个错误是我预先知道的，是符合我们公司的网络环境的：\n (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1125)'))) 配置代码使用本地代理后，再次执行脚本，报如下错误：\n (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) 很明显，这是两种不同类型的SSL错误，我之前一直以为是一种，导致我以为是Request中某些玄学的因素导致无法正常请求。所以，也在尝试用一些玄学的办法解决这个问题~\n目前已经尝试的解决方案：\n Linux配置透明代理（失败） ALL_PROXY走socks5协议（失败） ALL_PROXY设置为其他机器（失败） 在VPS环境测试，免使用代理进行测试（失败） 为Bucket类传递Session参数（失败）  我现在真的觉得这种问题好哔狗，我清掉了OSS里的所有图片，重新运行脚本，这次运行的过程中因为我操作失误忘记清除max_retries=40的设置，结果整个脚本又跑成功了？？？但是这次运行花了很长一段时间，成功运行了脚本后，我又立即运行了一次，结果这次又出现了之前的错误！！！而且我还发现了一些怪异的现象，我如下代码断点，真正断点的时候，resp并没有获取到任何东西（如截图所示），我决定不在继续运行代码，在此等候代码执行，结果过了一会，resp的值又出现了。要命，难道这就是Python的异步？？？\n # Create the Request. req = Request( method=method.upper(), url=url, headers=headers, files=files, data=data or {}, json=json, params=params or {}, auth=auth, cookies=cookies, hooks=hooks, ) prep = self.prepare_request(req) proxies = proxies or {} settings = self.merge_environment_settings( prep.url, proxies, stream, verify, cert ) # Send the request. send_kwargs = { 'timeout': timeout, 'allow_redirects': allow_redirects, } send_kwargs.update(settings) resp = self.send(prep, **send_kwargs) return resp 我想锤人！！！我猜测是不是网络的问题，我的bucket在北京，我的vps在香港，而我在广州，请求需要从我这到香港，然后从香港到北京，这个过程太慢了，最后导致失败。我将bucket重建在深圳，结果脚本非常正确的运行了。真的哔狗啊，这种解决问题的方法已经超出我对事物的理解范围了，为什么post就可以无视请求时长的影响，而get就会受到印象呢？oss2又如何设置这个时长呢？我暂时不打算对这些东西深入研究了，知道有这些问题存在就好了。\n后续20210427 没想到这件事情还有后续！！！我今天要使用脚本的时候准备做一些脚本清理工作，结果发现之前用深圳的bucket做实验的时候和用北京节点的bucket做实验的时候没有控制变量，北京用的是https://oss-cn-beijing.aliyuncs.com，而深圳用的是oss-cn-shenzhen.aliyuncs.com，区别是北京的多了一个https。当我深圳的endpoint也加上https，会报和北京bucket一样的错误（区别在于可能可以多运行一会，遇到该问题的几率小一点）！！！，而当我的北京endpoint去到这个https后，也不会报任何错误，而且速度还很快。\n我这段代码是用的我很久前的代码，我以为是我当时写错了，我后来去网上搜索，发现很多代码都是加上https的，我之前写这段代码时也是参考的官方的文档，我认为大概率是官方文档调整了写法。\n我觉得这是oss2的bug或者是oss2底层使用的库的bug，这个问题最困扰人的一点是加不加https，不是绝对的，加了不一定失败，所以定位这个问题时完全靠观察能力。这个问题深入底层的分析，需要掌握抓包、过滤包、解析https包的技术，我暂时没有掌握这些技术，所以先放弃了。\n还有些东西需要记录下来，当抛出异常的时候，我貌似在鲨鱼上看到RST包了，不知道两者有没有关系。\n个人小结 这次实验让我开始注意到网络环境对实验的影响了，我之前对这些东西无感，我觉得都是毫秒级的差距，应该感觉不出来，但是这次很明显的看到从香港vps上传东西到北京bucket，需要上十分钟，而到深圳，只需要一分钟不到。同时，网络请求的跳数太多，可能会对实验结果代理不可预知的问题。\n其他知识 我发现其实我Shadowsocks客户端一打开，即使我调整为其为禁用，我1080端口也处于监听状态。额，我之前一直以为该端口会关闭，尴尬。\n参考资料   How to get around python requests SSL and proxy error?\n报错的位置和我很像，连代码的行数都很像，但是没有提供给我任何有用的讯息。\n  ","description":"","id":185,"section":"notes","tags":null,"title":"oss2代理设置问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/oss2%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE%E9%97%AE%E9%A2%98/"},{"content":" 依赖配置如下：   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;p6spy\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;p6spy\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; application.yml配置如下   spring: datasource: # driver-class-name: org.postgresql.Driver # 原始的 driver-class-name: com.p6spy.engine.spy.P6SpyDriver # 使用p6spy后的 password: HelloWorld # url: jdbc:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 原始的 url: jdbc:p6spy:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 使用p6spy后的 username: postgres sps.properties配置   module.log=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory # 自定义日志打印 logMessageFormat=fun.junjie.autotools.config.P6spyLogFormat # 使用日志系统记录sql appender=com.p6spy.engine.spy.appender.Slf4JLogger ## 配置记录Log例外 excludecategories=info,debug,result,batc,resultset # 设置使用p6spy driver来做代理 deregisterdrivers=true # 日期格式 dateformat=yyyy-MM-dd HH:mm:ss # 实际驱动 #driverlist=com.mysql.jdbc.Driver #drive=com.p6spy.engine.spy.P6SpyDriver driverlist=com.p6spy.engine.spy.P6SpyDriver # 是否开启慢SQL记录 outagedetection=true # 慢SQL记录标准 秒 outagedetectioninterval=2 P6spyLogFormat开发   package fun.junjie.autotools.config; import com.p6spy.engine.spy.appender.MessageFormattingStrategy; import io.micrometer.core.instrument.util.StringUtils; public class P6spyLogFormat implements MessageFormattingStrategy { @Override public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) { return StringUtils.isNotEmpty(sql) ? new StringBuilder().append(\u0026quot; Execute SQL：\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026quot;).append(sql.replaceAll(\u0026quot;[\\\\s]+\u0026quot;, \u0026quot; \u0026quot;)).append(String.format(\u0026quot; \u0026lt;\u0026lt;\u0026lt;\u0026lt; Execute time: %s ms\u0026quot;, elapsed)).toString() : null; } } 小结 我配置p6spy是为了打印我通过JdbcTemplate获取表元数据时执行的SQL，但是，我发现这个工具根本不好使。我最后采用的方案是自己搭建一个PG数据库，然后开启SQL日志。\n我没有深入研究p6spy，毕竟它目前不满足我的需求。\n参考资料  使用P6Spy监控你的Spring boot数据库操作 springboot 配置 P6spy  ","description":"","id":186,"section":"notes","tags":null,"title":"p6spy的使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/p6spy%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"content":"PanDownlaod我一直当做http下载器使用，使用浏览器默认的下载器，总是可能出现断流的情况，而且浏览器里下载，断流的话需要全部重新下，PanDownload不用。\n设置代理适用的场景是，下载Github里的东西，另外说一下，Github这东西，就连用代理也拯救不了它的速度。\n  进入软件所在目录，打开配置文件PanData/config.ini\n  修改proxy的值，格式为代理IP地址:端口，例如：proxy=192.168.1.1:3128，保存后重启程序\n  参考资料  PanDownlaod设置代理  ","description":"","id":187,"section":"notes","tags":null,"title":"PanDownlaod配置代理","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/pandownlaod%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"用的比较少，但是做实验中这些指令比较重要。\n1 2 3 4 5 6 7 8  # 查看时区 show time zone # 设置时区  set time zone \u0026#39;PRC\u0026#39;; # 相当于+08时区 set time zone \u0026#39;GMT\u0026#39;; # 相当于+00时区   参考资料   postgresql 时区配置，系统主机与数据库时间不一致\n  PostgreSQL时区、时间不一致、差8小时\n  ","description":"","id":188,"section":"notes","tags":null,"title":"PG查看并设置当前session的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/pg%E6%9F%A5%E7%9C%8B%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%BD%93%E5%89%8Dsession%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"问题描述 我在CentOS上通过自己编译的Python的pip工具下载oss2模块时，出现如下报错：\n [root@localhost ~]# pip3 install oss2 Collecting oss2 Using cached oss2-2.14.0.tar.gz (224 kB) ERROR: Command errored out with exit status 1: command: /usr/local/python3/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\u0026quot;'\u0026quot;'/tmp/pip-install-5yv_1h3n/oss2/setup.py'\u0026quot;'\u0026quot;'; __file__='\u0026quot;'\u0026quot;'/tmp/pip-install-5yv_1h3n/oss2/setup.py'\u0026quot;'\u0026quot;';f=getattr(tokenize, '\u0026quot;'\u0026quot;'open'\u0026quot;'\u0026quot;', open)(__file__);code=f.read().replace('\u0026quot;'\u0026quot;'\\r\\n'\u0026quot;'\u0026quot;', '\u0026quot;'\u0026quot;'\\n'\u0026quot;'\u0026quot;');f.close();exec(compile(code, __file__, '\u0026quot;'\u0026quot;'exec'\u0026quot;'\u0026quot;'))' egg_info --egg-base /tmp/pip-pip-egg-info-pi9uat3k cwd: /tmp/pip-install-5yv_1h3n/oss2/ Complete output (11 lines): Traceback (most recent call last): File \u0026quot;\u0026lt;string\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/__init__.py\u0026quot;, line 23, in \u0026lt;module\u0026gt; from setuptools.dist import Distribution File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/dist.py\u0026quot;, line 34, in \u0026lt;module\u0026gt; from setuptools import windows_support File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/windows_support.py\u0026quot;, line 2, in \u0026lt;module\u0026gt; import ctypes File \u0026quot;/usr/local/python3/lib/python3.8/ctypes/__init__.py\u0026quot;, line 7, in \u0026lt;module\u0026gt; from _ctypes import Union, Structure, Array ModuleNotFoundError: No module named '_ctypes' ---------------------------------------- ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available. You should consider upgrading via the '/usr/local/python3/bin/python3.8 -m pip install --upgrade pip' command. 解决方案  执行如下指令：   yum install libffi-devel -y 然后重新编译安装你的Python。\n make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 参考资料  ModuleNotFoundError: No module named \u0026lsquo;_ctypes\u0026rsquo;的解决方案  ","description":"","id":189,"section":"notes","tags":null,"title":"pip3拉oss2包时报错","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip3%E6%8B%89oss2%E5%8C%85%E6%97%B6%E6%8A%A5%E9%94%99/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8 9  mkdir -p ~/.pip sudo tee ~/.pip/pip.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; sudo tee [global] index-url = https://mirrors.aliyun.com/pypi/simple EOF   ","description":"","id":190,"section":"notes","tags":null,"title":"pip3设置国内源","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip3%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E6%BA%90/"},{"content":"用于精细化定位问题，及修复问题：\n pip list pip freeze pip show module_name 参考资料  如何查看python包的版本号?  ","description":"","id":191,"section":"notes","tags":null,"title":"pip查看某个库的版本号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip%E6%9F%A5%E7%9C%8B%E6%9F%90%E4%B8%AA%E5%BA%93%E7%9A%84%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"今天用官方源初始化一个SpringBoot项目时发现parent标签下有一个relativePath标签，简单查询了一下，有如下解释：\n  查找顺序：relativePath元素中的地址 \u0026gt; 本地仓库 \u0026gt; 远程仓库\n  如果relateivePath设置为一个空值，将始终从仓库中获取，不从本地路径获取。\n  目前我主要到relateivePath标签主要应用于parent标签中，通过查资料对给标签有了进一步理解（查看该标签的描述信息）：\n  relativePath用于指定父pom.xml的相对位置\n  父pom.xml默认位置为../pom.xml\n  Maven首先从当前项目的Reactor中寻找父Pom.xml,然后从文件系统中寻找，然后从本地仓库寻找，然后从远程仓库\n  relativePath允许配置一个特定的位置，如果项目是扁平的，或者纵深的（总之没有一个清晰的父Pom）\n  groupId、artifactId、version仍然被需要，而且必须与配置的路径上的pom.xml文件相符合\n  这项特性只加强了项目的本地检查\n  参考资料   maven 工程 pom.xml 中 relativePath 的作用\n  Maven parent.relativePath 说明\n  ","description":"","id":192,"section":"notes","tags":null,"title":"pom.xml文件中的relativePath","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/pom.xml%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84relativepath/"},{"content":"写在application.yml配置文件中的：org.postgresql.Driver\n不记录一下，总是忘记，每次忘记再搜索，很麻烦。\n","description":"","id":193,"section":"notes","tags":null,"title":"postgresql的驱动配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/postgresql%E7%9A%84%E9%A9%B1%E5%8A%A8%E9%85%8D%E7%BD%AE/"},{"content":"使用场景是我配置了日志输出，配置了P6spy，但是依旧有些执行记录无法查看。\n使用的配置文件如下：\n # ----------------------------- # PostgreSQL configuration file # ----------------------------- # # This file consists of lines of the form: # # name = value # # (The \u0026quot;=\u0026quot; is optional.) Whitespace may be used. Comments are introduced with # \u0026quot;#\u0026quot; anywhere on a line. The complete list of parameter names and allowed # values can be found in the PostgreSQL documentation. # # The commented-out settings shown in this file represent the default values. # Re-commenting a setting is NOT sufficient to revert it to the default value; # you need to reload the server. # # This file is read on server startup and when the server receives a SIGHUP # signal. If you edit the file on a running system, you have to SIGHUP the # server for the changes to take effect, run \u0026quot;pg_ctl reload\u0026quot;, or execute # \u0026quot;SELECT pg_reload_conf()\u0026quot;. Some parameters, which are marked below, # require a server shutdown and restart to take effect. # # Any parameter can also be given as a command-line option to the server, e.g., # \u0026quot;postgres -c log_connections=on\u0026quot;. Some parameters can be changed at run time # with the \u0026quot;SET\u0026quot; SQL command. # # Memory units: kB = kilobytes Time units: ms = milliseconds # MB = megabytes s = seconds # GB = gigabytes min = minutes # TB = terabytes h = hours # d = days #------------------------------------------------------------------------------ # FILE LOCATIONS #------------------------------------------------------------------------------ # The default values of these variables are driven from the -D command-line # option or PGDATA environment variable, represented here as ConfigDir. #data_directory = 'ConfigDir'\t# use data in another directory # (change requires restart) #hba_file = 'ConfigDir/pg_hba.conf'\t# host-based authentication file # (change requires restart) #ident_file = 'ConfigDir/pg_ident.conf'\t# ident configuration file # (change requires restart) # If external_pid_file is not explicitly set, no extra PID file is written. #external_pid_file = ''\t# write an extra PID file # (change requires restart) #------------------------------------------------------------------------------ # CONNECTIONS AND AUTHENTICATION #------------------------------------------------------------------------------ # - Connection Settings - listen_addresses = '*' # comma-separated list of addresses; # defaults to 'localhost'; use '*' for all # (change requires restart) #port = 5432\t# (change requires restart) max_connections = 100\t# (change requires restart) #superuser_reserved_connections = 3\t# (change requires restart) #unix_socket_directories = '/var/run/postgresql'\t# comma-separated list of directories # (change requires restart) #unix_socket_group = ''\t# (change requires restart) #unix_socket_permissions = 0777\t# begin with 0 to use octal notation # (change requires restart) #bonjour = off\t# advertise server via Bonjour # (change requires restart) #bonjour_name = ''\t# defaults to the computer name # (change requires restart) # - TCP settings - # see \u0026quot;man tcp\u0026quot; for details #tcp_keepalives_idle = 0\t# TCP_KEEPIDLE, in seconds; # 0 selects the system default #tcp_keepalives_interval = 0\t# TCP_KEEPINTVL, in seconds; # 0 selects the system default #tcp_keepalives_count = 0\t# TCP_KEEPCNT; # 0 selects the system default #tcp_user_timeout = 0\t# TCP_USER_TIMEOUT, in milliseconds; # 0 selects the system default # - Authentication - #authentication_timeout = 1min\t# 1s-600s #password_encryption = md5\t# md5 or scram-sha-256 #db_user_namespace = off # GSSAPI using Kerberos #krb_server_keyfile = 'FILE:${sysconfdir}/krb5.keytab' #krb_caseins_users = off # - SSL - #ssl = off #ssl_ca_file = '' #ssl_cert_file = 'server.crt' #ssl_crl_file = '' #ssl_key_file = 'server.key' #ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL' # allowed SSL ciphers #ssl_prefer_server_ciphers = on #ssl_ecdh_curve = 'prime256v1' #ssl_min_protocol_version = 'TLSv1.2' #ssl_max_protocol_version = '' #ssl_dh_params_file = '' #ssl_passphrase_command = '' #ssl_passphrase_command_supports_reload = off #------------------------------------------------------------------------------ # RESOURCE USAGE (except WAL) #------------------------------------------------------------------------------ # - Memory - shared_buffers = 128MB\t# min 128kB # (change requires restart) #huge_pages = try\t# on, off, or try # (change requires restart) #temp_buffers = 8MB\t# min 800kB #max_prepared_transactions = 0\t# zero disables the feature # (change requires restart) # Caution: it is not advisable to set max_prepared_transactions nonzero unless # you actively intend to use prepared transactions. #work_mem = 4MB\t# min 64kB #hash_mem_multiplier = 1.0\t# 1-1000.0 multiplier on hash table work_mem #maintenance_work_mem = 64MB\t# min 1MB #autovacuum_work_mem = -1\t# min 1MB, or -1 to use maintenance_work_mem #logical_decoding_work_mem = 64MB\t# min 64kB #max_stack_depth = 2MB\t# min 100kB #shared_memory_type = mmap\t# the default is the first option # supported by the operating system: # mmap # sysv # windows # (change requires restart) dynamic_shared_memory_type = posix\t# the default is the first option # supported by the operating system: # posix # sysv # windows # mmap # (change requires restart) # - Disk - #temp_file_limit = -1\t# limits per-process temp file space # in kilobytes, or -1 for no limit # - Kernel Resources - #max_files_per_process = 1000\t# min 64 # (change requires restart) # - Cost-Based Vacuum Delay - #vacuum_cost_delay = 0\t# 0-100 milliseconds (0 disables) #vacuum_cost_page_hit = 1\t# 0-10000 credits #vacuum_cost_page_miss = 10\t# 0-10000 credits #vacuum_cost_page_dirty = 20\t# 0-10000 credits #vacuum_cost_limit = 200\t# 1-10000 credits # - Background Writer - #bgwriter_delay = 200ms\t# 10-10000ms between rounds #bgwriter_lru_maxpages = 100\t# max buffers written/round, 0 disables #bgwriter_lru_multiplier = 2.0\t# 0-10.0 multiplier on buffers scanned/round #bgwriter_flush_after = 512kB\t# measured in pages, 0 disables # - Asynchronous Behavior - #effective_io_concurrency = 1\t# 1-1000; 0 disables prefetching #maintenance_io_concurrency = 10\t# 1-1000; 0 disables prefetching #max_worker_processes = 8\t# (change requires restart) #max_parallel_maintenance_workers = 2\t# taken from max_parallel_workers #max_parallel_workers_per_gather = 2\t# taken from max_parallel_workers #parallel_leader_participation = on #max_parallel_workers = 8\t# maximum number of max_worker_processes that # can be used in parallel operations #old_snapshot_threshold = -1\t# 1min-60d; -1 disables; 0 is immediate # (change requires restart) #backend_flush_after = 0\t# measured in pages, 0 disables #------------------------------------------------------------------------------ # WRITE-AHEAD LOG #------------------------------------------------------------------------------ # - Settings - #wal_level = replica\t# minimal, replica, or logical # (change requires restart) #fsync = on\t# flush data to disk for crash safety # (turning this off can cause # unrecoverable data corruption) #synchronous_commit = on\t# synchronization level; # off, local, remote_write, remote_apply, or on #wal_sync_method = fsync\t# the default is the first option # supported by the operating system: # open_datasync # fdatasync (default on Linux and FreeBSD) # fsync # fsync_writethrough # open_sync #full_page_writes = on\t# recover from partial page writes #wal_compression = off\t# enable compression of full-page writes #wal_log_hints = off\t# also do full page writes of non-critical updates # (change requires restart) #wal_init_zero = on\t# zero-fill new WAL files #wal_recycle = on\t# recycle WAL files #wal_buffers = -1\t# min 32kB, -1 sets based on shared_buffers # (change requires restart) #wal_writer_delay = 200ms\t# 1-10000 milliseconds #wal_writer_flush_after = 1MB\t# measured in pages, 0 disables #wal_skip_threshold = 2MB #commit_delay = 0\t# range 0-100000, in microseconds #commit_siblings = 5\t# range 1-1000 # - Checkpoints - #checkpoint_timeout = 5min\t# range 30s-1d max_wal_size = 1GB min_wal_size = 80MB #checkpoint_completion_target = 0.5\t# checkpoint target duration, 0.0 - 1.0 #checkpoint_flush_after = 256kB\t# measured in pages, 0 disables #checkpoint_warning = 30s\t# 0 disables # - Archiving - #archive_mode = off\t# enables archiving; off, on, or always # (change requires restart) #archive_command = ''\t# command to use to archive a logfile segment # placeholders: %p = path of file to archive # %f = file name only # e.g. 'test ! -f /mnt/server/archivedir/%f \u0026amp;\u0026amp; cp %p /mnt/server/archivedir/%f' #archive_timeout = 0\t# force a logfile segment switch after this # number of seconds; 0 disables # - Archive Recovery - # These are only used in recovery mode. #restore_command = ''\t# command to use to restore an archived logfile segment # placeholders: %p = path of file to restore # %f = file name only # e.g. 'cp /mnt/server/archivedir/%f %p' # (change requires restart) #archive_cleanup_command = ''\t# command to execute at every restartpoint #recovery_end_command = ''\t# command to execute at completion of recovery # - Recovery Target - # Set these only when performing a targeted recovery. #recovery_target = ''\t# 'immediate' to end recovery as soon as a # consistent state is reached # (change requires restart) #recovery_target_name = ''\t# the named restore point to which recovery will proceed # (change requires restart) #recovery_target_time = ''\t# the time stamp up to which recovery will proceed # (change requires restart) #recovery_target_xid = ''\t# the transaction ID up to which recovery will proceed # (change requires restart) #recovery_target_lsn = ''\t# the WAL LSN up to which recovery will proceed # (change requires restart) #recovery_target_inclusive = on # Specifies whether to stop: # just after the specified recovery target (on) # just before the recovery target (off) # (change requires restart) #recovery_target_timeline = 'latest'\t# 'current', 'latest', or timeline ID # (change requires restart) #recovery_target_action = 'pause'\t# 'pause', 'promote', 'shutdown' # (change requires restart) #------------------------------------------------------------------------------ # REPLICATION #------------------------------------------------------------------------------ # - Sending Servers - # Set these on the master and on any standby that will send replication data. #max_wal_senders = 10\t# max number of walsender processes # (change requires restart) #wal_keep_size = 0\t# in megabytes; 0 disables #max_slot_wal_keep_size = -1\t# in megabytes; -1 disables #wal_sender_timeout = 60s\t# in milliseconds; 0 disables #max_replication_slots = 10\t# max number of replication slots # (change requires restart) #track_commit_timestamp = off\t# collect timestamp of transaction commit # (change requires restart) # - Master Server - # These settings are ignored on a standby server. #synchronous_standby_names = ''\t# standby servers that provide sync rep # method to choose sync standbys, number of sync standbys, # and comma-separated list of application_name # from standby(s); '*' = all #vacuum_defer_cleanup_age = 0\t# number of xacts by which cleanup is delayed # - Standby Servers - # These settings are ignored on a master server. #primary_conninfo = ''\t# connection string to sending server #primary_slot_name = ''\t# replication slot on sending server #promote_trigger_file = ''\t# file name whose presence ends recovery #hot_standby = on\t# \u0026quot;off\u0026quot; disallows queries during recovery # (change requires restart) #max_standby_archive_delay = 30s\t# max delay before canceling queries # when reading WAL from archive; # -1 allows indefinite delay #max_standby_streaming_delay = 30s\t# max delay before canceling queries # when reading streaming WAL; # -1 allows indefinite delay #wal_receiver_create_temp_slot = off\t# create temp slot if primary_slot_name # is not set #wal_receiver_status_interval = 10s\t# send replies at least this often # 0 disables #hot_standby_feedback = off\t# send info from standby to prevent # query conflicts #wal_receiver_timeout = 60s\t# time that receiver waits for # communication from master # in milliseconds; 0 disables #wal_retrieve_retry_interval = 5s\t# time to wait before retrying to # retrieve WAL after a failed attempt #recovery_min_apply_delay = 0\t# minimum delay for applying changes during recovery # - Subscribers - # These settings are ignored on a publisher. #max_logical_replication_workers = 4\t# taken from max_worker_processes # (change requires restart) #max_sync_workers_per_subscription = 2\t# taken from max_logical_replication_workers #------------------------------------------------------------------------------ # QUERY TUNING #------------------------------------------------------------------------------ # - Planner Method Configuration - #enable_bitmapscan = on #enable_hashagg = on #enable_hashjoin = on #enable_indexscan = on #enable_indexonlyscan = on #enable_material = on #enable_mergejoin = on #enable_nestloop = on #enable_parallel_append = on #enable_seqscan = on #enable_sort = on #enable_incremental_sort = on #enable_tidscan = on #enable_partitionwise_join = off #enable_partitionwise_aggregate = off #enable_parallel_hash = on #enable_partition_pruning = on # - Planner Cost Constants - #seq_page_cost = 1.0\t# measured on an arbitrary scale #random_page_cost = 4.0\t# same scale as above #cpu_tuple_cost = 0.01\t# same scale as above #cpu_index_tuple_cost = 0.005\t# same scale as above #cpu_operator_cost = 0.0025\t# same scale as above #parallel_tuple_cost = 0.1\t# same scale as above #parallel_setup_cost = 1000.0\t# same scale as above #jit_above_cost = 100000\t# perform JIT compilation if available # and query more expensive than this; # -1 disables #jit_inline_above_cost = 500000\t# inline small functions if query is # more expensive than this; -1 disables #jit_optimize_above_cost = 500000\t# use expensive JIT optimizations if # query is more expensive than this; # -1 disables #min_parallel_table_scan_size = 8MB #min_parallel_index_scan_size = 512kB #effective_cache_size = 4GB # - Genetic Query Optimizer - #geqo = on #geqo_threshold = 12 #geqo_effort = 5\t# range 1-10 #geqo_pool_size = 0\t# selects default based on effort #geqo_generations = 0\t# selects default based on effort #geqo_selection_bias = 2.0\t# range 1.5-2.0 #geqo_seed = 0.0\t# range 0.0-1.0 # - Other Planner Options - #default_statistics_target = 100\t# range 1-10000 #constraint_exclusion = partition\t# on, off, or partition #cursor_tuple_fraction = 0.1\t# range 0.0-1.0 #from_collapse_limit = 8 #join_collapse_limit = 8\t# 1 disables collapsing of explicit # JOIN clauses #force_parallel_mode = off #jit = on\t# allow JIT compilation #plan_cache_mode = auto\t# auto, force_generic_plan or # force_custom_plan #------------------------------------------------------------------------------ # REPORTING AND LOGGING #------------------------------------------------------------------------------ # - Where to Log - #log_destination = 'stderr'\t# Valid values are combinations of # stderr, csvlog, syslog, and eventlog, # depending on platform. csvlog # requires logging_collector to be on. # This is used when logging to stderr: logging_collector = on\t# Enable capturing of stderr and csvlog # into log files. Required to be on for # csvlogs. # (change requires restart) # These are only used if logging_collector is on: log_directory = 'log'\t# directory where log files are written, # can be absolute or relative to PGDATA log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\t# log file name pattern, # can include strftime() escapes log_file_mode = 0600\t# creation mode for log files, # begin with 0 to use octal notation #log_truncate_on_rotation = off\t# If on, an existing log file with the # same name as the new log file will be # truncated rather than appended to. # But such truncation only occurs on # time-driven rotation, not on restarts # or size-driven rotation. Default is # off, meaning append to existing files # in all cases. #log_rotation_age = 1d\t# Automatic rotation of logfiles will # happen after that time. 0 disables. #log_rotation_size = 10MB\t# Automatic rotation of logfiles will # happen after that much log output. # 0 disables. # These are relevant when logging to syslog: #syslog_facility = 'LOCAL0' #syslog_ident = 'postgres' #syslog_sequence_numbers = on #syslog_split_messages = on # This is only relevant when logging to eventlog (win32): # (change requires restart) #event_source = 'PostgreSQL' # - When to Log - #log_min_messages = warning\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # info # notice # warning # error # log # fatal # panic #log_min_error_statement = error\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # info # notice # warning # error # log # fatal # panic (effectively off) #log_min_duration_statement = -1\t# -1 is disabled, 0 logs all statements # and their durations, \u0026gt; 0 logs only # statements running at least this number # of milliseconds #log_min_duration_sample = -1\t# -1 is disabled, 0 logs a sample of statements # and their durations, \u0026gt; 0 logs only a sample of # statements running at least this number # of milliseconds; # sample fraction is determined by log_statement_sample_rate #log_statement_sample_rate = 1.0\t# fraction of logged statements exceeding # log_min_duration_sample to be logged; # 1.0 logs all such statements, 0.0 never logs #log_transaction_sample_rate = 0.0\t# fraction of transactions whose statements # are logged regardless of their duration; 1.0 logs all # statements from all transactions, 0.0 never logs # - What to Log - #debug_print_parse = off #debug_print_rewritten = off #debug_print_plan = off #debug_pretty_print = on #log_checkpoints = off #log_connections = off #log_disconnections = off #log_duration = off #log_error_verbosity = default\t# terse, default, or verbose messages #log_hostname = off #log_line_prefix = '%m [%p] '\t# special values: # %a = application name # %u = user name # %d = database name # %r = remote host and port # %h = remote host # %b = backend type # %p = process ID # %t = timestamp without milliseconds # %m = timestamp with milliseconds # %n = timestamp with milliseconds (as a Unix epoch) # %i = command tag # %e = SQL state # %c = session ID # %l = session line number # %s = session start timestamp # %v = virtual transaction ID # %x = transaction ID (0 if none) # %q = stop here in non-session # processes # %% = '%' # e.g. '\u0026lt;%u%%%d\u0026gt; ' #log_lock_waits = off\t# log lock waits \u0026gt;= deadlock_timeout #log_parameter_max_length = -1\t# when logging statements, limit logged # bind-parameter values to N bytes; # -1 means print in full, 0 disables #log_parameter_max_length_on_error = 0\t# when logging an error, limit logged # bind-parameter values to N bytes; # -1 means print in full, 0 disables log_statement = 'all'\t# none, ddl, mod, all #log_replication_commands = off #log_temp_files = -1\t# log temporary files equal or larger # than the specified size in kilobytes; # -1 disables, 0 logs all temp files log_timezone = 'UTC' #------------------------------------------------------------------------------ # PROCESS TITLE #------------------------------------------------------------------------------ #cluster_name = ''\t# added to process titles if nonempty # (change requires restart) #update_process_title = on #------------------------------------------------------------------------------ # STATISTICS #------------------------------------------------------------------------------ # - Query and Index Statistics Collector - #track_activities = on #track_counts = on #track_io_timing = off #track_functions = none\t# none, pl, all #track_activity_query_size = 1024\t# (change requires restart) #stats_temp_directory = 'pg_stat_tmp' # - Monitoring - #log_parser_stats = off #log_planner_stats = off #log_executor_stats = off #log_statement_stats = off #------------------------------------------------------------------------------ # AUTOVACUUM #------------------------------------------------------------------------------ #autovacuum = on\t# Enable autovacuum subprocess? 'on' # requires track_counts to also be on. #log_autovacuum_min_duration = -1\t# -1 disables, 0 logs all actions and # their durations, \u0026gt; 0 logs only # actions running at least this number # of milliseconds. #autovacuum_max_workers = 3\t# max number of autovacuum subprocesses # (change requires restart) #autovacuum_naptime = 1min\t# time between autovacuum runs #autovacuum_vacuum_threshold = 50\t# min number of row updates before # vacuum #autovacuum_vacuum_insert_threshold = 1000\t# min number of row inserts # before vacuum; -1 disables insert # vacuums #autovacuum_analyze_threshold = 50\t# min number of row updates before # analyze #autovacuum_vacuum_scale_factor = 0.2\t# fraction of table size before vacuum #autovacuum_vacuum_insert_scale_factor = 0.2\t# fraction of inserts over table # size before insert vacuum #autovacuum_analyze_scale_factor = 0.1\t# fraction of table size before analyze #autovacuum_freeze_max_age = 200000000\t# maximum XID age before forced vacuum # (change requires restart) #autovacuum_multixact_freeze_max_age = 400000000\t# maximum multixact age # before forced vacuum # (change requires restart) #autovacuum_vacuum_cost_delay = 2ms\t# default vacuum cost delay for # autovacuum, in milliseconds; # -1 means use vacuum_cost_delay #autovacuum_vacuum_cost_limit = -1\t# default vacuum cost limit for # autovacuum, -1 means use # vacuum_cost_limit #------------------------------------------------------------------------------ # CLIENT CONNECTION DEFAULTS #------------------------------------------------------------------------------ # - Statement Behavior - #client_min_messages = notice\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # log # notice # warning # error #search_path = '\u0026quot;$user\u0026quot;, public'\t# schema names #row_security = on #default_tablespace = ''\t# a tablespace name, '' uses the default #temp_tablespaces = ''\t# a list of tablespace names, '' uses # only default tablespace #default_table_access_method = 'heap' #check_function_bodies = on #default_transaction_isolation = 'read committed' #default_transaction_read_only = off #default_transaction_deferrable = off #session_replication_role = 'origin' #statement_timeout = 0\t# in milliseconds, 0 is disabled #lock_timeout = 0\t# in milliseconds, 0 is disabled #idle_in_transaction_session_timeout = 0\t# in milliseconds, 0 is disabled #vacuum_freeze_min_age = 50000000 #vacuum_freeze_table_age = 150000000 #vacuum_multixact_freeze_min_age = 5000000 #vacuum_multixact_freeze_table_age = 150000000 #vacuum_cleanup_index_scale_factor = 0.1\t# fraction of total number of tuples # before index cleanup, 0 always performs # index cleanup #bytea_output = 'hex'\t# hex, escape #xmlbinary = 'base64' #xmloption = 'content' #gin_fuzzy_search_limit = 0 #gin_pending_list_limit = 4MB # - Locale and Formatting - datestyle = 'iso, mdy' #intervalstyle = 'postgres' timezone = 'UTC' #timezone_abbreviations = 'Default' # Select the set of available time zone # abbreviations. Currently, there are # Default # Australia (historical usage) # India # You can create your own file in # share/timezonesets/. #extra_float_digits = 1\t# min -15, max 3; any value \u0026gt;0 actually # selects precise output mode #client_encoding = sql_ascii\t# actually, defaults to database # encoding # These settings are initialized by initdb, but they can be changed. lc_messages = 'en_US.utf8'\t# locale for system error message # strings lc_monetary = 'en_US.utf8'\t# locale for monetary formatting lc_numeric = 'en_US.utf8'\t# locale for number formatting lc_time = 'en_US.utf8'\t# locale for time formatting # default configuration for text search default_text_search_config = 'pg_catalog.english' # - Shared Library Preloading - #shared_preload_libraries = ''\t# (change requires restart) #local_preload_libraries = '' #session_preload_libraries = '' #jit_provider = 'llvmjit'\t# JIT library to use # - Other Defaults - #dynamic_library_path = '$libdir' #------------------------------------------------------------------------------ # LOCK MANAGEMENT #------------------------------------------------------------------------------ #deadlock_timeout = 1s #max_locks_per_transaction = 64\t# min 10 # (change requires restart) #max_pred_locks_per_transaction = 64\t# min 10 # (change requires restart) #max_pred_locks_per_relation = -2\t# negative values mean # (max_pred_locks_per_transaction # / -max_pred_locks_per_relation) - 1 #max_pred_locks_per_page = 2 # min 0 #------------------------------------------------------------------------------ # VERSION AND PLATFORM COMPATIBILITY #------------------------------------------------------------------------------ # - Previous PostgreSQL Versions - #array_nulls = on #backslash_quote = safe_encoding\t# on, off, or safe_encoding #escape_string_warning = on #lo_compat_privileges = off #operator_precedence_warning = off #quote_all_identifiers = off #standard_conforming_strings = on #synchronize_seqscans = on # - Other Platforms and Clients - #transform_null_equals = off #------------------------------------------------------------------------------ # ERROR HANDLING #------------------------------------------------------------------------------ #exit_on_error = off\t# terminate session on any error? #restart_after_crash = on\t# reinitialize after backend crash? #data_sync_retry = off\t# retry or panic on failure to fsync # data? # (change requires restart) #------------------------------------------------------------------------------ # CONFIG FILE INCLUDES #------------------------------------------------------------------------------ # These options allow settings to be loaded from files other than the # default postgresql.conf. Note that these are directives, not variable # assignments, so they can usefully be given more than once. #include_dir = '...'\t# include files ending in '.conf' from # a directory, e.g., 'conf.d' #include_if_exists = '...'\t# include file only if it exists #include = '...'\t# include file #------------------------------------------------------------------------------ # CUSTOMIZED OPTIONS #------------------------------------------------------------------------------ # Add settings for extensions here 我只改了局部配置，如果需要知道改了哪些项，可以拿安装包中的配置文件的和该配置文件对比，或者参考教程。\n参考教程  postgres 查看历史sql执行记录  ","description":"","id":194,"section":"notes","tags":null,"title":"PostgreSQL配置显示SQL执行记录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/postgresql%E9%85%8D%E7%BD%AE%E6%98%BE%E7%A4%BAsql%E6%89%A7%E8%A1%8C%E8%AE%B0%E5%BD%95/"},{"content":"使用新的环境变量方案，旧的环境变量都需要删除：\n再网上找了一圈没有找到删除的方案，最后自己给试出来了。\n","description":"","id":195,"section":"notes","tags":null,"title":"Postman删除环境变量","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%88%A0%E9%99%A4%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"之所以研究这个技术，主要我通过EasyYapi导出到Postman的频率太高了，每次导出都需要重新填写Header，不是很舒服。我开发了如下脚本：\n pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({ key: \u0026quot;token\u0026quot;, value: \u0026quot;{{token}}\u0026quot; }) pm.request.headers.add({ key: \u0026quot;Sdtc-Tenant-Id\u0026quot;, value: \u0026quot;12345678910\u0026quot; }) 参考资料  Scripting with request data  ","description":"","id":196,"section":"notes","tags":null,"title":"Postman发起请求前自动添加Header","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%8F%91%E8%B5%B7%E8%AF%B7%E6%B1%82%E5%89%8D%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0header/"},{"content":"左右布局用起来非常的不方便，就莫名其妙的变成了左右布局！！！\n参考资料  postman界面变成了左右结构怎么办  ","description":"","id":197,"section":"notes","tags":null,"title":"Postman变成了左右布局","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%8F%98%E6%88%90%E4%BA%86%E5%B7%A6%E5%8F%B3%E5%B8%83%E5%B1%80/"},{"content":"应用场景不用多说吧，只是可惜了，导出来的curl在windows上执行不了。\n这个code按钮还是有很多东西可以研究的，我之后研究下：\n参考资料  Postman 导出 curl命令 到命令行运行 Mac OS  ","description":"","id":198,"section":"notes","tags":null,"title":"Postman导出curl指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%AF%BC%E5%87%BAcurl%E6%8C%87%E4%BB%A4/"},{"content":"我机器出现这个问题的原因是因为我的内存不足，公司为我分配的开发主机内存位16G，但是真正能够使用的是有60%，一旦到了60%就无法正常分配内存了，具体表现为：\n Chrome总是报内存分配错误，且会出现黑屏 Idea无法正常启动服务，也会报内存错误，即使为其设置了近20G的堆大小 Postman打开后总是灰屏  ","description":"","id":199,"section":"notes","tags":null,"title":"Postman总是灰屏","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E6%80%BB%E6%98%AF%E7%81%B0%E5%B1%8F/"},{"content":"场景是这样的，我们local和dev共用一套token，之前的脚本中我将通过如下方法设置到了当前环境中，所以当我切换环境的时候我不得不重新运行一次登录脚本。\n1 2 3  postman.setEnvironmentVariable(\u0026#39;token\u0026#39;, token)   因为我需要高频率的在local和dev环境间切换，所以我希望我的登录脚本能够将获取的token信息保存在全局变量中，然后在当前环境中通过一个变量中引用全局变量，从而实现一次登录应用不同的环境。\n我登录脚本代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  var token var login_address const loginRequestDev = { url: \u0026#39;http://dev.4dshoetech.local/backend/authcenter/login/login\u0026#39;, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;junjie001@qq.com\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;Hello123\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } const loginRequestSit = { url: \u0026#39;http://sit.4dshoetech.local/backend/authcenter/login/login\u0026#39;, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;502\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;123456\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } pm.sendRequest(loginRequestDev,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token pm.globals.set(\u0026#34;dev_token\u0026#34;, token); console.log(response.data.token); } }); pm.sendRequest(loginRequestSit,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token pm.globals.set(\u0026#34;sit_token\u0026#34;, token); console.log(response.data.token); } });   我global和local、dev、sit配置如下：\n在使用token时，只需要如下配置，就可以实现只运行一次登录脚本，不同环境中使用：\n参考资料  Postman配置全局变量与环境变量详细教程 postman 设置全局变量  ","description":"","id":200,"section":"notes","tags":null,"title":"Postman用脚本设置全局变量","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E7%94%A8%E8%84%9A%E6%9C%AC%E8%AE%BE%E7%BD%AE%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/"},{"content":"我把这路径记一记，因为我感觉我随时要去整它，Postman好几个版本在我公司电脑上老是出问题，糟心。\nC:\\Users\\wujj\\AppData\\Local\\Postman\n","description":"","id":201,"section":"notes","tags":null,"title":"Postman的安装路径","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/"},{"content":"问题描述  完成了一个postman的脚本（可以在该分类下找到该脚本源码），用于在请求时自动计算签名，使用该脚本时发现绝大多数请求的签名校验成功，部分签名校验失败 将这个请求的data部分替换掉，则签名校验成功（我们签名验证部分是需要将data计算在内的）  解决流程  postman打印所所有用于签名的字段，用java中的方法进行md5计算，计算结果与postman计算结果一致 网关断点调试，发现计算出来的签名与postman计算出来的请求不一致 截取网关请求，截取postman请求，截取计算签名时用的data的请求，发现data与postman处不一致  原因分析  postman脚本中拿data计算签名时，用到了JSON.parse(request.data)，JSON.parse()反序列化时存在精度丢失的问题 而我们的请求中，memberId的字段太长了，且是数字类型，就刚好撞到这个问题上  解决方案  将memberId字段换成String，或者截断一点（我采用的方案） 不使用JSON.parse()，使用JsonPath直接拿数据（Postman貌似不支持引入JsonPath模块） 不使用JSON.parse()，使用正则表达式提取data部分（不是很想搞，太麻烦了，哈哈）  ","description":"","id":202,"section":"notes","tags":null,"title":"Postman解决使用签名脚本，部分接口签名校验失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8%E7%AD%BE%E5%90%8D%E8%84%9A%E6%9C%AC%E9%83%A8%E5%88%86%E6%8E%A5%E5%8F%A3%E7%AD%BE%E5%90%8D%E6%A0%A1%E9%AA%8C%E5%A4%B1%E8%B4%A5/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  var token const loginRequest = { url: login_url, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;junjie001@qq.com\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;Hello123\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } pm.sendRequest(loginRequest,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token postman.setEnvironmentVariable(\u0026#39;token\u0026#39;, token) console.log(response.data.token); } });   参考教程  Postman脚本中发送请求 js字符串转换为对象格式 Postman：脚本应用_预请求脚本  ","description":"","id":203,"section":"notes","tags":null,"title":"Postman请求前获取Token","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%AF%B7%E6%B1%82%E5%89%8D%E8%8E%B7%E5%8F%96token/"},{"content":"相关操作  如图，点击Postman的Pre-request Script选项卡:  填写如下代码：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  var CryptoJS = require(\u0026#34;crypto-js\u0026#34;); // select channel_app_id,sign_secret from mmp_brand_channel_app; var channelIdToAppSecret = { \u0026#34;11111111\u0026#34;:\u0026#34;11111111111111111111111111111111\u0026#34;, \u0026#34;300000001\u0026#34;:\u0026#34;300000001300000001300000001300000001\u0026#34;, \u0026#34;300000002\u0026#34;:\u0026#34;300000002300000002300000002300000002\u0026#34;, \u0026#34;300000003\u0026#34;:\u0026#34;300000003300000003300000003300000003\u0026#34;, \u0026#34;300000004\u0026#34;:\u0026#34;300000004300000004300000004300000004\u0026#34; } var body = JSON.parse(request.data) var appId = body.appId var appSecret = channelIdToAppSecret[appId] var timestamp = Date.parse(new Date()) / 1000 var data = JSON.stringify(body.data) var sign = CryptoJS.MD5(appId + appSecret + timestamp + data).toString().toUpperCase() console.log(appId) console.log(appSecret) console.log(timestamp) console.log(sign) console.log(data) postman.setEnvironmentVariable(\u0026#39;timestamp\u0026#39;, timestamp); postman.setEnvironmentVariable(\u0026#39;sign\u0026#39;, sign);   改写请求的body（请求参数和Header也支持双大括号语法）  1 2 3 4 5 6 7 8 9 10  { \u0026#34;brandId\u0026#34;: 100000001, \u0026#34;channelId\u0026#34;: 200000001, \u0026#34;appId\u0026#34;: 300000001, \u0026#34;timestamp\u0026#34;: \u0026#34;{{timestamp}}\u0026#34;, \u0026#34;sign\u0026#34;: \u0026#34;{{sign}}\u0026#34;, \u0026#34;data\u0026#34;:{\u0026#34;cardId\u0026#34;:\u0026#34;1400000002\u0026#34;,\u0026#34;outTradeNo\u0026#34;:\u0026#34;123555\u0026#34;,\u0026#34;appUserId\u0026#34;:\u0026#34;zhenye\u0026#34;} }   相关教程  使用postman生成md5签名 postman 发送MD5加密签名请求  ","description":"","id":204,"section":"notes","tags":null,"title":"Postman请求时自动完成md5计算","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%AF%B7%E6%B1%82%E6%97%B6%E8%87%AA%E5%8A%A8%E5%AE%8C%E6%88%90md5%E8%AE%A1%E7%AE%97/"},{"content":"操作步骤  准备编译工具   apt update \u0026amp;\u0026amp; apt install pve-headers-$(uname -r) build-essential 从如下地址下载驱动源码   https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software 解压并编译   tar xvf r8125-9.004.01.tar cd r8125-9.004.01 make 安装驱动   cd src mkdir -p /lib/modules/5.4.78-2-pve/kernel/drivers/net/ethernet/realtek/ install -m 644 -o root r8125.ko /lib/modules/5.4.78-2-pve/kernel/drivers/net/ethernet/realtek/ /sbin/depmod `uname -r` /sbin/modprobe r8125 检验安装结果并重启   lsmod | grep r8125 modinfo r8125 reboot 个人小结 1.我贴出来的代码，是在我的机器上实际使用的代码（除了驱动版本号与代码中的不符合），教程中提到了装dkms，但是我无法安装该工具，遂放弃。\n参考教程  给PVE6添加Realtek 8125 2.5G网卡驱动  ","description":"","id":205,"section":"notes","tags":null,"title":"Promox VE 6.3装Realtek 8125 2.5G网卡驱动","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/promox-ve-6.3%E8%A3%85realtek-8125-2.5g%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"content":"SpringBoot集成MyBatis-Plus后，启动时报如下错误：\n org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userMapper' defined in file [D:\\Project\\Mybatis\\target\\classes\\fun\\junjie\\mybatis\\mapper\\UserMapper.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1794) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:878) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at fun.junjie.mybatis.MybatisApplication.main(MybatisApplication.java:12) [classes/:na] Caused by: java.lang.IllegalArgumentException: Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required at org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.mybatis.spring.support.SqlSessionDaoSupport.checkDaoConfig(SqlSessionDaoSupport.java:122) ~[mybatis-spring-2.0.6.jar:2.0.6] at org.mybatis.spring.mapper.MapperFactoryBean.checkDaoConfig(MapperFactoryBean.java:73) ~[mybatis-spring-2.0.6.jar:2.0.6] at org.springframework.dao.support.DaoSupport.afterPropertiesSet(DaoSupport.java:44) ~[spring-tx-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1853) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1790) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] ... 16 common frames omitted 经过分析发现，是我依赖引入错误：\n 原来： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 改为： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 参考资料  java.lang.IllegalArgumentException: Property \u0026lsquo;sqlSessionFactory\u0026rsquo; or \u0026lsquo;sqlSessionTemplate\u0026rsquo; are require  ","description":"","id":206,"section":"notes","tags":null,"title":"Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/property-sqlsessionfactory-or-sqlsessiontemplate-are-required/"},{"content":"操作步骤  修改/etc/network/interfaces：   # network interface settings; autogenerated # Please do NOT modify this file directly, unless you know what # you're doing. # # If you want to manage parts of the network configuration manually, # please utilize the 'source' or 'source-directory' directives to do # so. # PVE will preserve these directives, but will NOT read its network # configuration from sourced files, so do not attempt to move any of # the PVE managed interfaces into external files! source /etc/network/interfaces.d/* auto lo iface lo inet loopback iface enx00e04c36028c inet dhcp iface enp2s0 inet manual iface enp3s0 inet manual iface enp4s0 inet manual iface enp5s0 inet manual auto vmbr2 iface vmbr2 inet manual bridge-ports enp2s0 bridge-stp off bridge-fd 0 auto vmbr3 iface vmbr3 inet manual bridge-ports enp3s0 bridge-stp off bridge-fd 0 auto vmbr4 iface vmbr4 inet manual bridge-ports enp4s0 bridge-stp off bridge-fd 0 # 修改的部分在这块，主要修改为该manual为static，增加address、netmask、gateway段 auto vmbr5 iface vmbr5 inet static address 192.168.31.218 netmask 255.255.255.0 gateway 192.168.31.1 bridge-ports enp5s0 bridge-stp off bridge-fd 0 修改/etc/issue（提示文件，随便你改）：   ------------------------------------------------------------------------------ Welcome to the Proxmox Virtual Environment. Please use your web browser to configure this server - connect to: https://192.168.31.218:8006/ ------------------------------------------------------------------------------ 修改etc/hosts：   127.0.0.1\tlocalhost # 改动主要在这块 192.168.31.218\tj4125.home\tj4125 # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters 重启网络   /etc/init.d/networking restart 参考教程  proxmox ve（PVE）修改管理IP地址\n\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD Proxmox Virtual Environment（PVE）完美的更改IP地址\n======= 为 Proxmox 配置私有网络         7c66f5cb0aba592a369c0b995f28f9cd80108540\n       ","description":"","id":207,"section":"notes","tags":null,"title":"Proxmox VE修改管理员IP地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/proxmox-ve%E4%BF%AE%E6%94%B9%E7%AE%A1%E7%90%86%E5%91%98ip%E5%9C%B0%E5%9D%80/"},{"content":"这个问题我在4月份的时候已经注意到了，当时折腾的一段时间后没有结果，最后选择了先安装Debian，然后安装PVE 6.x。\n经过一段时间的考虑，我决定大面积的使用PVE（试验机、工具机、J4215都走这套方案），所以我开始系统学习PVE。但是当我开始使用U盘安装该系统的时候，出现了问题，我始终无法进入到安装界面，一致显示如下错误：\n 我原本将问题定位在我的U盘，或官方提供的镜像。经过在群里询问，了解到其他人没有类似的问题，我同时已经尝试了足够多品牌的U盘了，我不想再购买新的U盘进行实验。\n这个时候，我注意到我下载ISO文件的SHA256值和官方提供的SHA256值并不一样，我重新在中文论坛下载ISO文件后，并计算SHA256值，与官网的一致，该问题修复了。\n没有玄学 这个问题已经超出了我的认知范围，为什么官网下载的ISO文件竟然和它自己提供的SHA256值不一样呢。再发现这个问题后，我使用我的下载器又下载了一次该镜像，计算出来的值和前一次、官网的都不一样。我将问题定位到时官网提供的资源有问题。\n实际上这个答案不能让我信服，我又进行了如下实现：在公司，使用浏览器下载该ISO文件，使用下载器下载该ISO文件，分别计算SHA256值，最后发现浏览器下载的和官网提供的一样，而下载器下载的不一样。我不认为是我的下载器出了问题，我更多的是认为，从官网下载页面Copy的链接是不支持在下载器下载的。\n这个问题到此告一段落了。\n小结 我从解决这个问题收获了什么？\n 关注下载的制品的SHA256值，我以前是无条件信任官网下载的东西的，这次好好的给我上了一课，我至少有3~5天的时间，都浪费在这个问题上（当然，解决这个问题时，我在其他方面也是有一定收获的）。  ","description":"","id":208,"section":"notes","tags":null,"title":"PVE 6.x无法U盘安装","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve-6.x%E6%97%A0%E6%B3%95u%E7%9B%98%E5%AE%89%E8%A3%85/"},{"content":"事情的起因是这样的，我创建Ubuntu虚拟机时没有调整硬盘大小，结果磁盘只有32G，这个孔家大小在编译OpenWrt时完全不够用。按照我以往的做法，我会直接重新一个新的虚拟机，并调整硬盘大小为100G。但是，在接触PVE的过程中，我对Linux的磁盘有些熟悉了，我想尝试这自己将这个磁盘调整为我想要的大小。于是有了这篇文章。\n操作步骤   在PVE上将虚拟机的磁盘大小调整为132G。\n  查看磁盘信息：我在查看磁盘信息的时候，终端显示了一些红色的提示信息，大致就是说部分空间没有用上，下面的一步可以修改该问题：\n   fdisk -l 修复fdisk -l指令中的提示信息。完成该步后，fdisk -l就不会有任何错误提示信息，我也是偶然发现可以用这个修复的。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # 我的输入 root@junjie:~# parted /dev/sda GNU Parted 3.3 Using /dev/sda Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. # 我的输入 (parted) print Warning: Not all of the space available to /dev/sda appears to be used, you can fix the GPT to use all of the space (an extra 209715200 blocks) or continue with the current setting? # 我的输入 Fix/Ignore? fix Model: QEMU QEMU HARDDISK (scsi) Disk /dev/sda: 142GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 1076MB 1074MB ext4 3 1076MB 34.4GB 33.3GB   为分区增加空间，完成该不，通过fdisk -l指令已经可以看到分区的大小发生了变化。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # 我的输入 root@junjie:~# parted /dev/sda GNU Parted 3.3 Using /dev/sda Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. # 我的输入 (parted) print Model: QEMU QEMU HARDDISK (scsi) Disk /dev/sda: 142GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 1076MB 1074MB ext4 3 1076MB 34.4GB 33.3GB # 我的输入 (parted) resizepart 3 100% # 我的输入 (parted) quit Information: You may need to update /etc/fstab.   修改物理卷大小（这一步我没有看出任何变化信息）   pvresize /dev/sda2 修改逻辑卷大小（ubuntu\u0026ndash;vg-ubuntu\u0026ndash;lv文件视各自情况而定，你的文件可能不叫这个名字）   lvresize --extents +100%FREE --resizefs /dev/mapper/ubuntu--vg-ubuntu--lv 这一步带来的变化如图所示：\n最后重启验证下  参考资料  proxmox ve (PVE) 调整虚拟机(VM)的磁盘大小  ","description":"","id":209,"section":"notes","tags":null,"title":"PVE修改Ubuntu虚拟机的硬盘大小","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E4%BF%AE%E6%94%B9ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A1%AC%E7%9B%98%E5%A4%A7%E5%B0%8F/"},{"content":"vgremove pve2\n使用的场景是不小心动了pve的卷组设置。\n该方案需要结合下面的教程使用，否则的话无法删除PVE界面上的pve2\nProxmox 删除local-lvm 操作步骤\n参考资料  Linux LVM-删除卷组逻辑卷物理卷  ","description":"","id":210,"section":"notes","tags":null,"title":"PVE删除lvm卷组","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E5%88%A0%E9%99%A4lvm%E5%8D%B7%E7%BB%84/"},{"content":"我觉得这篇文章给的方法最优雅，我采用的也是这样方案。\n参考资料  Proxmox VE（PVE）如何添加多块硬盘  ","description":"","id":211,"section":"notes","tags":null,"title":"PVE添加一块硬盘作为存储","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E6%B7%BB%E5%8A%A0%E4%B8%80%E5%9D%97%E7%A1%AC%E7%9B%98%E4%BD%9C%E4%B8%BA%E5%AD%98%E5%82%A8/"},{"content":"截图如下：\n第三张图中，需要选到本地的一个exe文件。\n","description":"","id":212,"section":"notes","tags":null,"title":"Pycharm设置sdk","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pycharm%E8%AE%BE%E7%BD%AEsdk/"},{"content":"我之前使用的方式是一行一行的读取文件，然后调用update方法，需要写好多行代码，下面的写法更简洁一些：\n1 2 3 4 5 6 7 8  import hashlib fd=open(\u0026#34;1.jpg\u0026#34;,\u0026#34;r\u0026#34;) fcont=fd.read() fmd5=hashlib.md5(fcont) print fmd5.hexdigest() #get 32 value   ","description":"","id":213,"section":"notes","tags":null,"title":"Python计算md5（更新版）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/python%E8%AE%A1%E7%AE%97md5%E6%9B%B4%E6%96%B0%E7%89%88/"},{"content":"安装Rancher  执行如下指令   docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher:latest 导入集群  首先在Cluster选项卡下选择Add Cluster。因为我已经配置过了，这个按钮不见了。   在第一栏的Register Existing Cluster里选择Other。我看有的教程选择的是GKE，我这个是最新版，选择GKE不行。\n  之后会让你执行三条指令，我是如下处理的：\n   # 换[USER_ACCOUNT]为root kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user root # 不执行 kubectl apply -f https://192.168.13.68/v3/import/x26bbfhcn855gd4h24n59jdcd84l2xvjvv28n2t6fgpt4f77dkrfpf_c-whs58.yaml # 执行（在node1节点上执行的） curl --insecure -sfL https://192.168.13.68/v3/import/x26bbfhcn855gd4h24n59jdcd84l2xvjvv28n2t6fgpt4f77dkrfpf_c-whs58.yaml | kubectl apply -f - 遇到的问题  我执行第二条的时候，报了如下的错误：   Unable to connect to the server: x509: certificate is valid for 127.0.0.1, 172.17.0.2, 172.17.0.4, not 192.168.13.68 我猜想是因为我的集群里证书都是我自己造的，所以有这个问题。\n我执行第三条的时候，也遇到了问题，大意说没有给kubectl传递任何东西。我还是怀疑是证书的问题。所以我选择了在浏览器中下载，推到node1上，然后执行（这个可能是个例，不一定都存在这个问题）。  参考资料  Rancher部署并导入K8S集群  ","description":"","id":214,"section":"notes","tags":null,"title":"Rancher的安装与导入K8S集群","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/rancher%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AF%BC%E5%85%A5k8s%E9%9B%86%E7%BE%A4/"},{"content":"其实这个问题的原因很简单，就是传递给restTemplate.getForObject的类，没有Getter和Setter。\n其实这种问题完全没有必要记录，一旦发现了这个问题后，简单的尝试后就能获得这样的知识。\n但是的但是，快速定位这个问题是需要一些基础设施的，比如我在这次定位的过程中，就是因为我配置了restTemplate打印请求的信息，才能够快速获取一部分信息。\n","description":"","id":215,"section":"notes","tags":null,"title":"restTemplate.getForObject执行后的返回值字段全部为空","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate.getforobject%E6%89%A7%E8%A1%8C%E5%90%8E%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC%E5%AD%97%E6%AE%B5%E5%85%A8%E9%83%A8%E4%B8%BA%E7%A9%BA/"},{"content":"今天在一个没有配置RestTemplate的项目中使用RestTemplate，所以我需要自己配置一下，按照我之前的方式配置好了后，发现报了如下错误：\n org.springframework.web.client.RestClientException: No HttpMessageConverter for com.sdstc.show.controller.external.DynamicFormController$PostDataRequest at org.springframework.web.client.RestTemplate$HttpEntityRequestCallback.doWithRequest(RestTemplate.java:961) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:737) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:674) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.postForObject(RestTemplate.java:418) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at com.sdstc.show.controller.external.DynamicFormController.postData(DynamicFormController.java:49) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:523) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:590) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at com.sdstc.core.configuration.web.RequestBodyFilter.doFilter(RequestBodyFilter.java:39) ~[sdstc-core-1.1.4.jar:?] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_281] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_281] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281] HttpMessageConverter这东西我还是有点熟悉的，我立刻对RestTemplate加了如下配置：\n FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); restTemplate.getMessageConverters().add(fastConverter); 结果又报错说无法找不到MediaType，额，还好我最近看过这部分知识，于是我进行了如下配置：\n FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); List\u0026lt;MediaType\u0026gt; supportedMediaTypes = new ArrayList\u0026lt;\u0026gt;(); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.APPLICATION_ATOM_XML); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_OCTET_STREAM); supportedMediaTypes.add(MediaType.APPLICATION_PDF); supportedMediaTypes.add(MediaType.APPLICATION_RSS_XML); supportedMediaTypes.add(MediaType.APPLICATION_XHTML_XML); supportedMediaTypes.add(MediaType.APPLICATION_XML); supportedMediaTypes.add(MediaType.IMAGE_GIF); supportedMediaTypes.add(MediaType.IMAGE_JPEG); supportedMediaTypes.add(MediaType.IMAGE_PNG); supportedMediaTypes.add(MediaType.TEXT_EVENT_STREAM); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_MARKDOWN); supportedMediaTypes.add(MediaType.TEXT_PLAIN); supportedMediaTypes.add(MediaType.TEXT_XML); fastConverter.setSupportedMediaTypes(supportedMediaTypes); restTemplate.getMessageConverters().add(fastConverter); 我们的框架高度定制化，有很多默认存在的东西，都因为定制的原因已经不叫原来的名字了，所以我们无法使用到这些bean，最后就导致出现了问题。\n","description":"","id":216,"section":"notes","tags":null,"title":"RestTemplate更高级配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate%E6%9B%B4%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"content":"代码如下：\nRestTemplateConfig类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  @Configuration public class RestTemplateConfig { @Bean public RestTemplate restTemplate(ClientHttpRequestFactory httpRequestFactory) { RestTemplate restTemplate = new RestTemplate(httpRequestFactory); // 设置拦截器，答应请求信息，方便Debug  List\u0026lt;ClientHttpRequestInterceptor\u0026gt; interceptors = new ArrayList\u0026lt;\u0026gt;(); interceptors.add(new LoggingClientHttpRequestInterceptor()); restTemplate.setInterceptors(interceptors); //提供对传出/传入流的缓冲,可以让响应body多次读取(如果不配置,拦截器读取了Response流,再响应数据时会返回body=null)  restTemplate.setRequestFactory(new BufferingClientHttpRequestFactory(httpRequestFactory)); return restTemplate; } @Bean public ClientHttpRequestFactory simpleClientHttpRequestFactory() { SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); factory.setConnectTimeout(15000); factory.setReadTimeout(5000); return factory; } }   LoggingClientHttpRequestInterceptor 类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  @Slf4j public class LoggingClientHttpRequestInterceptor implements ClientHttpRequestInterceptor { @Override public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException { traceRequest(request, body); ClientHttpResponse response = execution.execute(request, body); traceResponse(response); return response; } private void traceRequest(HttpRequest request, byte[] body) { log.info(\u0026#34;=========================== request begin ===========================\u0026#34;); log.info(\u0026#34;uri : {}\u0026#34;, request.getURI()); log.info(\u0026#34;method : {}\u0026#34;, request.getMethod()); log.info(\u0026#34;headers : {}\u0026#34;, request.getHeaders()); log.info(\u0026#34;request body : {}\u0026#34;, new String(body, StandardCharsets.UTF_8)); log.info(\u0026#34;============================ request end ============================\u0026#34;); } private void traceResponse(ClientHttpResponse httpResponse) throws IOException { StringBuilder inputStringBuilder = new StringBuilder(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(httpResponse.getBody(), StandardCharsets.UTF_8)); String line = bufferedReader.readLine(); while (line != null) { inputStringBuilder.append(line); inputStringBuilder.append(\u0026#39;\\n\u0026#39;); line = bufferedReader.readLine(); } log.info(\u0026#34;============================ response begin ============================\u0026#34;); log.info(\u0026#34;Status code : {}\u0026#34;, httpResponse.getStatusCode()); log.info(\u0026#34;Status text : {}\u0026#34;, httpResponse.getStatusText()); log.info(\u0026#34;Headers : {}\u0026#34;, httpResponse.getHeaders()); log.info(\u0026#34;Response body: {}\u0026#34;, inputStringBuilder.toString()); log.info(\u0026#34;============================= response end =============================\u0026#34;); } }   这个功能不是手到擒来的（如果你按照上面的配置去搞，就是傻瓜版开启了这个功能），我开启这个功能时遇到了哪些问题？我找到教程前，已经有了自己的一份关于RestTemplate的配置，我不想对我的配置进行太大的改动，所以我只复制了我觉得重要的配置，即没有复制该行：restTemplate.setRequestFactory(new BufferingClientHttpRequestFactory(httpRequestFactory));\n结果就导致了，日志信息明明看到了返回体有相关的信息，但是得到的对象总是为空。我仔细阅读了教程中的代码，发现漏了上面的一行。实际上我对底层的实现还是有点不太理解，目前先记录下来，把这些知识积累起来，这种知识积累多了后，可能就可以学习到更多的知识。\n参考资料  Spring RestTemplate配置拦截器打印请求URL和响应结果 Spring RestTemplate配置拦截器打印请求URL和响应结果  ","description":"","id":217,"section":"notes","tags":null,"title":"RestTemplate配置打印请求的详细信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate%E9%85%8D%E7%BD%AE%E6%89%93%E5%8D%B0%E8%AF%B7%E6%B1%82%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF/"},{"content":"我的需求是这样的，我需要拉下一个仓库，然后删除这个仓库中除.git外的所有文件，然后在这个仓库中放入我的新文件，在提交到远程仓库中。\n我最后使用的代码如下：\n1 2 3  cd GitRepo \u0026amp;\u0026amp; find . | grep -v .git | xargs rm -rf   这个方案要求我必须进入我下载的仓库里执行，我在外部执行的时候，不能很好的工作（我能理解产生这种现象的原因）\n我尝试过rm !(.git)的方案，结果提示我不存在!指令。\n参考资料  Linux rm 删除指定文件外的其他文件 方法汇总  ","description":"","id":218,"section":"notes","tags":null,"title":"rm指令在移除的时候排除一些文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/rm%E6%8C%87%E4%BB%A4%E5%9C%A8%E7%A7%BB%E9%99%A4%E7%9A%84%E6%97%B6%E5%80%99%E6%8E%92%E9%99%A4%E4%B8%80%E4%BA%9B%E6%96%87%E4%BB%B6/"},{"content":"Strust2是基于Filter实现的，而SpringMVC是Servlet的扩展。我很好奇Filter和Servlet究竟有什么区别，查了了该资料，已经能比较清晰的了解Servlet和Filter的区别了。\n我想到了一些问题，我之前的一家公司测试方面做的比较细心，需要做防SQL注入、XSS攻击方面的测试，我们的代码没有注意到这些问题，所以需要开发相应的工具来解决这个问题。由于当时我对Spring底层知识了解的并不是太多，我选择了基于反射开发一个工具类，将Request对象传入到这个工具类中，工具类将会判断字段的类型，当字段的类型为String时，则执行SQL、JS代码清理工作。如果现在让我实现这个功能，我想我会选择使用过滤器实现（我当时查的资料基本都是基于过滤器的）。\n我们目前的项目中有这样的一个功能：我们在返回Response时，针对图片、文件等OSS里存放的资料，打上一个标记，则会有个Filter计算出该资源的url（携带了签名、鉴权等信息），我去寻找源码时，并没有找到相关的源码，我想这个功能应该是通过某种特别的方式实现的吧，我SpringBoot相关的知识还不够，需要继续学习。\n后续：\n在和同时的讨论中，我知道了我们代码中处理OSS字段的类：ResponseBodyAdvice。从命名上看，这个应该是切面技术，而并非过滤器技术，我目前没有系统的学习相关的知识，所以保持观望状态。\n","description":"","id":219,"section":"notes","tags":null,"title":"Servlet和Filter的区别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/servlet%E5%92%8Cfilter%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"content":"ShardingSphere-Jdbc研究告一段落，目前总结的配置文件和增加的类已经基本能够满足我们的业务需求。而且我已经对我使用到的每个技术点都进行了相对充分的测试，确保了我的理解是正确的。我将对ShardingSphere-Jdbc的研究总结如下。\n业务需求 我们的业务上只有分表需求，并没有分库需求，所以主要研究了在分表方面的使用。\n在分表方面，我们的需求为：\n 按照某个字段的模进行分表 按照创建时间进行分表（这个地方需要注意，存在创建表的需求）  研究时编写的代码我已提交到：shardingsphere-jdbc，有兴趣的同学可以自行查看\n发现或解决的问题 截止目前，发现的和解决的问题如下所列，并不是所有的问题都解决了，但是眼下的方案能让我们的以下在一定时间内正常运行：\n 分页问题（使用临时方案解决） 查询时不包括分表键的问题（使用临时方案解决） 绑定表 按时间分表及相关定时任务  分页问题 使用ShardingSphere-Jdbc时，有分页需求时，需要从多个数据源中拿数据，然后再拼接为最终的结果。很直观的，不可能从每个数据节点（数据节点：一个数据库 + 表名定义唯一一个数据节点）执行一次limit，然后将结果拼接再一次，选出目标范围内的数据。ShardingSphere-Jdbc也的确不是这样做的，它做了一些SQL的改写。\nShardingSphere-Jdbc如何改写：举个例子，如果我们要得到第3页的10个数据，原始limit的写法为limit 3, 10。ShardingSphere-Jdbc对其的改写为：limit 0, 33，它从每个数据节点拿到前33个数据，拼接后，再显示按照需求显示第3页的10个数据。\n我们不必担心这个过程中内存会使用量会非常高，按照官方文档的说法，其底层采用了流式处理方案，并不是将各个数字节点的数据缓存到内存后再做分页。\n不过，如果分页偏移量很大，则可能引发新的问题，那就是网络开销，按照ShardingSphere-Jdbc的实现，如果我们有三个数据节点，需求为要第一万页的数据，则其至少需要传输三万乘以每页大小个数据。\nShardingSphere-Jdbc官方文档中简单提到了一个解决方案，分别如下：\n 构建行记录数量与行偏移量  这个方案我并没有查到相关的资料，也不知道如何实践。\n通过某个可排序的字段完成分页  代码演示如下：\n1  SELECT*FROMt_orderWHEREid\u0026gt;100000ANDid\u0026lt;=100010ORDERBYid  其实这个是没有办法在我们生产中实践的，因为我们生产中的id是由雪花算法产生的，并且和行不是一一对应的，所以100010 \u0026gt;= id \u0026gt; 100000在分页层面并没有任何含义。\n我认为我们可以使用一个row字段，来模拟这种解决方案，但又会引入新的问题，那就是在微服务架构中，我们还需要确保row字段全局唯一而且还要递增，这本身就是一个技术难题（我们的项目中，目前没有积累解决这种问题的方案）。这个方案还存在一个问题，那就是应用面窄，一旦增加了排序的需求，row字段就没有任何意义的，又会回归到ShardingSphere默认的解决方法。\n不过我们的项目实际上只采用了分表，没有采用分库，甚至整个微服务都是用同一个库（我们再尽量避免分布式事务方面的问题）。所以通过一些技巧，还是有办法拿到全局唯一的row值。\n我们项目一直不愿意引入新的技术方案，怕增加研发成本，这限制了我们解决问题的思路。这个问题应该可以使用ES解决，但是没有机会进行探索这个方案。\n查询时不包括分表键的问题 我们分表策略为按照某个字段，进行模运算。但是我们实际业务中，不一定按照这个字段进行查询，这就导致了会出现按照非分表键进行查询的问题，按照文档所说，这个查询将会遍历全部的分表。\n该如何解决了，我们采用的方案为：对这些非分表键加索引。这个方案看上去不是很优雅，但是可以在一定程度上环节这个问题。\n还有一种高大上的解决方案，我们可以使用多个键进行分表，且算法需要保证单独使用各个键、使用全部这些键时能够定位到同一张表，关于这个算法如何实现能不能实现，其实我是不知道的。\n或许业务精心设计后，这个问题也是可以避免的，但是在我们的项目中，这样做的成本会非常高。\n绑定表 绑定表是指指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。\n这儿挪用一下官方的案例，一个查询如下：\nSELECT i.* FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 那么按照笛卡尔积，则应该改写SQL为：\nSELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 配置了绑定表关系后，改写所得的SQL为：\nSELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在我们的业务中有相关的需求，所以我们需要使用到绑定表。\n按时间分表及相关定时任务 我们一些记录表，是按照时间分片的，在ShardingSphere-Jdbc中，我们需要自行提供分片算法，思路清晰时，这个算法实现起来比较简单。\n这儿说说我在实现时遇到的一个坑：因为我们的schedule项目需要操作分表，故项目引入了ShardingSphere-JDBC，同时我想在执行建表语句前，检查一下该表是否存在，故我使用了show tables like \u0026lsquo;'，解决发现返回的结果为空。后来经过实验，我发现，原生的数据源的的确确支持show语句，但是ShardingSphere-JDBC配置的数据源是不支持这个语句的。（官方文档也有谈到对各种语句的支持，我没有深入研究）\n最后我的解决方案为，创建一张纯记录表，记录目前定时任务已经创建了哪些表，这样使用select语句就可以知道表是否创建了。\n值得研究的方向  与Liquibase的结合  我是比较感兴趣这个技术点的，但是，我对Liquibase的掌握，目前也仅仅限制与一些简单的Demo。\n为什么我会对这两者的结合感兴趣了，ShardingSphere-Jdbc支持插入语句，我们可以从旧表中读取数据，然后再插入到新表中，完成数据的迁移。而完成这个工作的最好工具就是Liquibase。\n系统的使用这款工具  我们的业务需求真的只使用了这个工具的很小一部分功能，它还提供了很多非常强大的功能。我们对这款工具的使用是存在隐患的，如前文所述，有很多业务场景下的解决方案都不是很优雅，而且，很多生产中可能会遇到的问题，我们都没有进行假设，并准备应对方案（这本来应该是DBA干的，我们开发客串了）。\n参考资料  Apache ShardingSphere apache/shardingsphere  ","description":"","id":220,"section":"notes","tags":null,"title":"ShardingSphere-Jdbc研究日志","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/shardingsphere-jdbc/shardingsphere-jdbc%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"},{"content":"shell定义变量和使用变量  first_name=\u0026quot;Bob\u0026quot; second_name=\u0026quot;bob\u0026quot; your_name=\u0026quot;$first_name $second_name\u0026quot; your_name2='Bob bob' ","description":"","id":221,"section":"notes","tags":null,"title":"shell定义变量和使用变量","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/shell%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E5%92%8C%E4%BD%BF%E7%94%A8%E5%8F%98%E9%87%8F/"},{"content":"我的需求是这样的，我需要序列化一个对象成yaml文档，序列化时要求驼峰转下划线，且保持字段声明顺序。我原本计划通过自定义snakeyaml的Representer实现这个需求，但是发现并不是很好这么搞（我没有充分研究，我觉得投入和产出不成比例），所以我决定绕一绕解决问题。\n我最终选择的方案是，将对象通过fastjson转换成一个json字符串，转换的过程中保持字段声明顺序，且驼峰转下滑线。然后再用fastjson将json字符串转换成一个LinkedHashMap，再使用snakeyaml的dump方法导出该map。具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /** * 将对象序列化成Yaml文件，序列化时保持字段顺序与声明一致 */ public static void dumpObject(TableRoot sourceObj, Path dirPath, String fileName) { try { if (!Files.exists(dirPath)) { Files.createDirectory(dirPath); } // 将原始的对象序列化成json（字段按照原对象的声明顺序）  JSON.DEFAULT_GENERATE_FEATURE \u0026amp;= ~SerializerFeature.SortField.getMask(); SerializeConfig serializeConfig = new SerializeConfig(true); serializeConfig.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase; String jsonWithFieldOrder = JSON.toJSONString(sourceObj, serializeConfig); // 将jsonWithFieldOrder转换成Map，并输出到yaml文件  FileWriter fileWriter = new FileWriter(Paths.get(dirPath.toString(), fileName).toString()); Yaml yaml = new Yaml(); fileWriter.write(yaml.dumpAsMap(JSON.parseObject(jsonWithFieldOrder, LinkedHashMap.class, Feature.OrderedField))); fileWriter.close(); } catch (IOException e) { throw new RuntimeException(\u0026#34;Dump Wrong...\u0026#34;); } }   这种解决问题的方案，成本非常的高，不过我用于工具的开发，问题倒不是很大。反序列话相对比较简单，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  /** * 将多个Yaml文件反序列化成对象列表 */ public static List\u0026lt;TableRoot\u0026gt; loadObject() { File outputDir = new File(Paths.get(ToolsConfig.TABLES_INFO_DIR, ProjectConfig.getProjectName()).toString()); if (!outputDir.isDirectory()) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } File[] yamlFiles = outputDir.listFiles(); if (yamlFiles == null) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } try { List\u0026lt;TableRoot\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (File file : yamlFiles) { String jsonMiddle = JSON.toJSONString(new Yaml().load(new FileReader(file))); TableRoot tableRoot = JSONObject.parseObject(jsonMiddle, TableRoot.class); result.add(tableRoot); } return result; } catch (FileNotFoundException e) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } }   参考资料   【需求】支持按照成员变量声明顺序，做序列化字段排序\n  Keep tags order using SnakeYAML\n针对该需求，这篇教程中似乎提到了更高级的解决方案，但是我目前没有使用该方案的需求。\n  JAVA使用SnakeYAML解析与序列化YAML\n这篇文章里有些高级的知识需要理解下。\n  ","description":"","id":222,"section":"notes","tags":null,"title":"snakeyaml驼峰与下滑线转化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/snakeyaml/snakeyaml%E9%A9%BC%E5%B3%B0%E4%B8%8E%E4%B8%8B%E6%BB%91%E7%BA%BF%E8%BD%AC%E5%8C%96/"},{"content":"我的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Data @NoArgsConstructor public class TableRoot { private String tblName; private String tblDesc; private List\u0026lt;ColumnRoot\u0026gt; columns; public TableRoot(String tblName, String tblDesc) { this.tblName = tblName; this.tblDesc = tblDesc; this.columns = new ArrayList\u0026lt;\u0026gt;(); } @Data @SuppressWarnings(\u0026#34;WeakerAccess\u0026#34;) private static class ColumnRoot { private String colName; private String colDesc; @JSONField(deserializeUsing = JavaTypeCodec.class, serializeUsing = JavaTypeCodec.class) private JavaType javaType; } }   序列化TableRoot对象时发现无法正常序列化，提示权限不足，需要将ColumnRoot改为public。我ColumnRoot其实没有暴露到外部的需求，但是因为snakeyaml的特性不得不暴露到外部，不是很爽。\n我目前没有找到资料解决这个问题。\n参考资料  can not access a member of class with modifiers \u0026ldquo;public\u0026rdquo;  ","description":"","id":223,"section":"notes","tags":null,"title":"snakyaml序列化时，类必须为public","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/snakeyaml/snakyaml%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E7%B1%BB%E5%BF%85%E9%A1%BB%E4%B8%BApublic/"},{"content":"我的工具监听的是socks协议，socks协议的dns请求仍然会通过原来的网络进行解析，而我们的工具中只能指定socks5://不能指定socks5h://，所以我们的dns无法被正确解析。于是我想将socks协议转换为http协议，我找到了polipo工具。\n安装polipo 指令如下：\n1 2 3 4 5 6 7 8  git clone https://github.com/jech/polipo.git cd polipo git checkout polipo-1.1.1 make all su -c \u0026#39;make install\u0026#39;   最后一步我遇到了一个关于text的报错，我执行下面的指令修复了这个问题：\n1 2 3  yum install texinfo   配置并启动polipo 配置指令如下（有时间改为echo版）：\n1 2 3 4 5 6 7 8 9 10  mkdir /opt/polipo vim /opt/polipo/config proxyAddress = \u0026#34;0.0.0.0\u0026#34; socksParentProxy = \u0026#34;127.0.0.1:2223\u0026#34; socksProxyType = socks5 proxyPort = 12345 dnsQueryIPv6 = no   使用如下指令进行启动：\n polipo -c /opt/polipo/config 参考资料  centos7 安装polipo Linux socks5转http  ","description":"","id":224,"section":"notes","tags":null,"title":"socks协议转http协议","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/socks%E5%8D%8F%E8%AE%AE%E8%BD%AChttp%E5%8D%8F%E8%AE%AE/"},{"content":"是这样的，我在合并分支的时候，删除了原来的源码，从Git上拉取了一份新的代码，然后再Idea导入该源码并启动该项目，结果再启动的过程中一致报如下错误：\n *************************** APPLICATION FAILED TO START *************************** Description: The bean 'http://metadata.FeignClientSpecification' could not be registered. A bean with that name has already been defined and overriding is disabled. Action: Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true 之前运气比较好，我在启动项目时一定会指定spring.profiles.active=local，所以我也是第一看到这个错误。我之前的项目中也从来没有进行过spring.main.allow-bean-definition-overriding=true配置，所以我主观上也不会想到在配置文件中进行该项配置。\n我在什么时候意识到是我自己出了问题，我在发现我昨天成功运行的分支突然也运行不了，后来才发现是自己忘记配置spring.profiles.active=local了（经过同事提醒）。在这次定位问题的过程中我也接触了一些新的东西，比如：\n实际上我是不需要配置spring.profiles.active=local的，我可以在profiles中选择local，就可以使用到local环境。经过同事了解到其原理：当选择了local后，我们在运行时会自动给带上spring.profiles.active=local参数。其实我是有点不理解的是，我运行的时候是通过Idea上的运行按钮，profiles配置属于Maven的配置，这两者之间是如何联系在一起的呢？\n","description":"","id":225,"section":"notes","tags":null,"title":"spring.main.allow-bean-definition-overriding配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/spring.main.allow-bean-definition-overriding%E9%85%8D%E7%BD%AE/"},{"content":"SpringBoot Actuator默认的地址是在server.servlet.context-path的基础上加上actuator/*，这个细节，我之前一直没有关注到。management.endpoints.web.base-path配置实际上只会影响到actuator段。\n举一个例子，如果项目按如下配置了context-path，那么actuator的地址就为：localhost:50001/demo/actuator\n server: port: 50001 servlet: context-path: /demo 此时如果修改了management.endpoints.web.base-path且值为tmp-actuator，那么actuator的地址就为：localhost:50001/demo/tmp-actuator\n这样其实挺好的，这样的话我们的actuator请求可以非常轻松的通过网关，不需要在额外配合什么东西了。\n参考资料 好东西，慢慢消化~~~\nSpring Boot (十九)：使用 Spring Boot Actuator 监控应用\n","description":"","id":226,"section":"notes","tags":null,"title":"SpringBoot Actuator的base-path配置项","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/springboot-actuator%E7%9A%84base-path%E9%85%8D%E7%BD%AE%E9%A1%B9/"},{"content":"代码如下：\n1 2 3 4 5 6  @PostConstruct void setDefaultTimezone() { TimeZone.setDefault(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); }   需要注意的是如下的写法并不会生效：\n1 2 3 4 5 6  public static void main(String[] args) { TimeZone.setDefault(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); SpringApplication.run(MybatisApplication.class, args); }   查看当前实例的时区，可用如下代码：\n1 2 3 4  ZoneId defaultZone = ZoneId.systemDefault(); System.out.println(defaultZone);   参考资料  springboot项目设置时区 java关于时区的获取的几种方式  ","description":"","id":227,"section":"notes","tags":null,"title":"SpringBoot修改默认的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"使用场景是这样的，一个记录配置信息的类，想使用静态方法、静态字段记录一些存储在配置文件中的信息。我选择定义这些静态的字段，然后再定义一些需要注入的字段，然后在一个方法中实现注入的字段往静态的字段中赋值的操作。\n大概代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Component public class Config{ @Autowire private String configItem1; @Autowire private String configItem2; public static String CONFIG_ITEM_1; public static String CONFIG_ITEM_2; @PostConstruct public void init(){ CONFIG_ITEM_1 = configItem1; CONFIG_ITEM_2 = configItem2; } }   目前这种写法我觉得非常的不优雅，原因有下：\n 我定义了两种含义一样的字段，只是一个是静态的，一个是对象的  如何解决这个问题了，我想到的方案是使用将@Autowire放置在set方法上，这样甚至可以免去init方法的开发，但是这样不是没有问题的：目前我的编码风格已经习惯性使用构造函数注入，最不济也是将@Autowire写在字段上，为了使用静态的信息，我需要将@Autowire写在方法上，这样非常不符合我的编码习惯。\n参考资料  Spring 容器启动完成后，执行初始化加载工作 SpringBoot使用@Value给静态变量注入值  ","description":"","id":228,"section":"notes","tags":null,"title":"SpringBoot容器初始化后执行回调","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%8E%E6%89%A7%E8%A1%8C%E5%9B%9E%E8%B0%83/"},{"content":"@Configuration的proxyBeanMethods参数 entity包\nUser.java\n1 2 3 4 5 6 7  @NoArgsConstructor @AllArgsConstructor public class User { private String name; }   Pet.java\n1 2 3 4 5 6 7  @NoArgsConstructor @AllArgsConstructor public class Pet { private String name; }   TmpConfiguration.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Configuration(proxyBeanMethods = false) public class TmpConfigration { @Bean public User user() { return new User(\u0026#34;张三\u0026#34;); } @Bean public Pet pet() { return new Pet(\u0026#34;旺财\u0026#34;); } }   三段测试代码：\n1 2 3 4 5 6  // 实验一 for (String name : configurableApplicationContext.getBeanDefinitionNames()) { System.out.println(name); }   实验一主要验证了加了@Bean注解的方法名，将会作为该Bean在容器中的名字。\n1 2 3 4 5 6 7 8 9 10 11  // 实验二 System.out.println(configurableApplicationContext.getBean(TmpConfigration.class)); System.out.println(configurableApplicationContext.getBean(TmpConfigration.class)); System.out.println(configurableApplicationContext.getBean(User.class)); System.out.println(configurableApplicationContext.getBean(User.class)); System.out.println(configurableApplicationContext.getBean(Pet.class)); System.out.println(configurableApplicationContext.getBean(Pet.class));   实验二验证了proxyBeanMethods无论是true或者false，都不会影响从容器中通过get方法获取Bean（这些Bean始终都是单例）\n1 2 3 4 5 6 7 8 9 10 11 12  // 实验三 TmpConfigration tmpConfigration = configurableApplicationContext.getBean(TmpConfigration.class); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.pet()); System.out.println(tmpConfigration.pet()); System.out.println(tmpConfigration.pet());   实验三验证了如果proxyBeanMethods设置为true，则即使通过Configuration Bean的方法获取Bean，这些Bean都是单例的。如果proxyBeanMethods设置为false，则通过Configuration Bean的方法获取Bean，这些Bean不是单例的。\n小结 proxyBeanMethods代表了两种不同的SpringBoot模式：\n FULL(proxyBeanMethod = true)，每个@Bean方法别调用多次时，返回的组件都是单实例的 LITE(proxyBeanMethod = false)，每个@Bean方法被调用多次时，返回的组件都是新创建的  如果存在组件间的依赖（Bean之间存在依赖），则需要使用FULL模式，否则可以使用Lite模式。\n","description":"","id":229,"section":"notes","tags":null,"title":"SpringBoot的@Configuration配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E7%9A%84configuration%E9%85%8D%E7%BD%AE/"},{"content":"其实相关的技术我很早前就用在了项目中，但是一直没有整理笔记，最近在重构我工具包的代码时，又使用到了相关的技术，所以顺便整理一下。我工具包有个工具类，其中的方法都是静态方法，但是这些静态方法会根据配置文件呈现出不同的功能。\n配置文件的配置的获取我还是使用的是传统的方法，使用一个@ConfigurationProperties(prefix = \u0026quot;xxx\u0026quot;)注解，那么我工具类中需要只用配置类的时候，我就需要先注入其中，我之前的写法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Component @RequiredArgsConstructor public class YamlUtils { private final ToolsConfig toolsConfig; private final ProjectConfig projectConfig; private static ToolsConfig toolsConfigStatic; private static ProjectConfig projectConfigStatic; @PostConstruct public void init() { toolsConfigStatic = toolsConfig; projectConfigStatic = projectConfig; } }   我觉得非常的怪异，不是很满意。经过调整后，我的写法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Component @RequiredArgsConstructor public class YamlUtils { private final ApplicationContext applicationContext; private static ToolsConfig toolsConfig; private static ProjectConfig toolsConfig; @PostConstruct public void init() { projectConfig = applicationContext.getBean(ProjectConfig.class); toolsConfig = applicationContext.getBean(ToolsConfig.class); } }   这种写法相对于之前的写法稍微优雅一点点，不需要同时提供一个对象字段和类字段了，而且两者的含义是一样的。但是其实我还是不太满意，我更期待的是ApplicationContext都不需要注入，而是通过一个工具类获取，或者存在支持静态字段注入的注解（目前没有找到相关的资料）。\n参考资料   从Spring 应用上下文获取 Bean 的常用姿势\n  spring项目中获取ApplicationContext对象，然后手动获取bean\n提到了一个继承ApplicationContextAware的方案，感觉很高级，但是在实践中获取到的bean为null，我也不知道为什么。\n  ","description":"","id":230,"section":"notes","tags":null,"title":"SpringBoot获取Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E8%8E%B7%E5%8F%96bean/"},{"content":"我们一部分接口在local环境并调不通，我将这些接口写在了manage层，我希望我有个开关当我在本地环境运行的时候，这些接口可以不被调用，我想到了使用SpringBoot的环境。\n如下代码：\n1 2 3 4 5 6 7 8 9 10  @Value(\u0026#34;${spring.profiles.active}\u0026#34;) private String env; public void test(){ if(\u0026#34;local\u0026#34;.equal(env)){ return; } }   我最后放弃这么搞了，因为这种方案在我们项目组中并不是很流行，我担心会给其他同事带来困惑。\n参考资料  SpringBoot获取当前运行环境三种方式  ","description":"","id":231,"section":"notes","tags":null,"title":"SpringBoot获取当前运行环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/"},{"content":"操作步骤   如图两个项目mmp-wuid和mmp-member-brand项目\n  mmp-wuid项目下有如下module，其中admin、api、fiegn都依赖于feign\n   mmp-global-admin-api mmp-global-api mmp-global-dmain mmp-global-api-feign  mmp-global-brand项目下，需要远程与mmp-wuid项目通信，所以mmp-global-admin-api模块依赖了mmp-wuid项目下mmp-global-api-feign项目  ","description":"","id":232,"section":"notes","tags":null,"title":"SpringCloud使用Feign方案","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springcloud%E4%BD%BF%E7%94%A8feign%E6%96%B9%E6%A1%88/"},{"content":"代码如下：\n1 2 3 4  ConfigurableEnvironment environment = applicationContext.getEnvironment(); environment.getProperty(\u0026#34;os.name\u0026#34;);   冷知识，第一次接触。\n","description":"","id":233,"section":"notes","tags":null,"title":"Spring获取操作系统信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/spring%E8%8E%B7%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF/"},{"content":"我对Spring的接触是直接从SpringBoot开始的，直接导致我没有接触一些原理层的东西，比如我们引入了starter-web后，SpringBoot到底做了哪些配置，这些配置的意义何在。所以我打算整理一下使用Spring配置Spring MVC的资料，从而更了解Spring MVC具体有哪些组件，各个组件的作用。这个整理的过程中我并不会进行任何实践，更多的是去理解。\n依赖的jar包   spring.jar\n  spring-core.jar\n 包含了Spring框架基本的核心工具类 Spring其它组件要都要使用到这个包里的类 可以在自己的应用系统中使用这些工具类    spring-beans.jar\n 这个jar文件是所有应用都要用到的， 它包含访问配置文件、创建和管理bean，以及进行IoC/DI操作相关的所有类。 如果应用只需基本的IoC/DI支持，引入spring-core.jar及spring-beans.jar文件就可以了。    spring-aop.jar\n 这个jar文件包含在应用中使用Spring的AOP特性时所需的类。 使用基于AOP的Spring特性，如声明型事务管理，也要在应用里包含这个jar包。    spring-context.jar　  这个jar文件为Spring核心提供了大量扩展。\n  可以找到使用Spring ApplicationContext特性时所需的全部类，JDNI所需的全部类，UI方面的用来与模板引擎如Velocity、FreeMarker、JasperReports集成的类，以及校验Validation方面的相关类。\n    spring-dao.jar　 这个jar文件包含Spring DAO、Spring Transaction进行数据访问的所有类。 为了使用声明型事务支持，还需在自己的应用里包含spring-aop.jar。    spring-hibernate.jar　 这个jar文件包含Spring对Hibernate 2及Hibernate 3进行封装的所有类。    spring-jdbc.jar　 这个jar文件包含对Spring对JDBC数据访问进行封装的所有类。    spring-orm.jar\n  这个jar文件包含Spring对DAO特性集进行了扩展，使其支持 iBATIS、JDO、OJB、TopLink，因为Hibernate已经独立成包了，现在不包含在这个包里了。\n  这个jar文件里大部分的类都要依赖spring-dao.jar里的类，用这个包时你需要同时包含spring-dao.jar包。\n    spring-remoting.jar\n 这个jar文件包含支持EJB、JMS、远程调用Remoting（RMI、Hessian、Burlap、Http Invoker、JAX-RPC）方面的类。    spring-support.jar\n 这个jar文件包含支持缓存Cache（ehcache）、JCA、JMX、邮件服务（Java Mail、COS Mail）、任务计划Scheduling（Timer、Quartz）方面的类。    spring-web.jar\n 这个jar文件包含Web应用开发时，用到Spring框架时所需的核心类， 包括自动载入WebApplicationContext特性的类、Struts与JSF集成类、文件上传的支持类、Filter类和大量工具辅助类。    spring-webmvc.jar\n 这个jar文件包含Spring MVC框架相关的所有类。 包含国际化、标签、Theme、视图展现的FreeMarker、JasperReports、Tiles、Velocity、XSLT相关类。 当然，如果你的应用使用了独立的MVC框架，则无需这个JAR文件里的任何类。    spring-mock.jar\n 这个jar文件包含Spring一整套mock类来辅助应用的测试。 Spring测试套件使用了其中大量mock类，这样测试就更加简单。 模拟HttpServletRequest和HttpServletResponse类在Web应用单元测试是很方便的。    我在我最新的一个SpringBoot项目中也发现了如上所述的一些jar包：\n这些包还有一些依赖包，我不整理这部分了，我核心只需要知道Spring的包做了什么。\nweb.xml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  \u0026lt;display-name\u0026gt;SpringMVC\u0026lt;/display-name\u0026gt; \u0026lt;welcome-file-list\u0026gt; \u0026lt;welcome-file\u0026gt;/login.jsp\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring/spring-core.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!-- 配置ContextLoaderListener --\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;!-- 配置DispatcherServlet --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring/spring-servlet.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt;   ContextLoaderListener指定了IOC容器初始化的方法。\nDispatcherServlet则定义了mvc的相关内容，并配置拦截的URL。\n为了方便理解，如下提供了另一份关于servlet和servlet-mapping的配置，在该配置中，所有以/example开头的请求都会被名字为example的DispatcherServlet处理。\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;example\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;example\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/example/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt;   DispatcherServlet的初始化过程中，Spring MVC会在Web应用的WEB-INF目录下查找一个名为[servlet-name]-servlet.xml的配置文件，并创建其中所定义的Bean。如果在全局上下文中存在相同名字的Bean，则它们将被新定义的同名Bean覆盖。\n配置spring-servlet.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;!-- 开启注解 --\u0026gt; \u0026lt;!-- 这块配置了一个HttpMessageConverter，看样子HttpMessageConverter是在切面中发挥作用 --\u0026gt; \u0026lt;mvc:annotation-driven\u0026gt; \u0026lt;mvc:message-converters register-defaults=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\u0026#34; p:supportedMediaTypes=\u0026#34;text/html; charset=UTF-8\u0026#34; /\u0026gt; \u0026lt;/mvc:message-converters\u0026gt; \u0026lt;/mvc:annotation-driven\u0026gt; \u0026lt;context:annotation-config /\u0026gt; \u0026lt;!-- 开启AOP自动代理功能 --\u0026gt; \u0026lt;aop:aspectj-autoproxy proxy-target-class=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 事务（注解 ）--\u0026gt; \u0026lt;tx:annotation-driven transaction-manager=\u0026#34;transactionManager\u0026#34; proxy-target-class=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 视图解释器 --\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/pages/\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.jsp\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 静态资源访问 --\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/js/**\u0026#34; location=\u0026#34;/resources/js/\u0026#34;/\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/css/**\u0026#34; location=\u0026#34;/resources/css/\u0026#34;/\u0026gt;   注解与BeanPostProcessor 如果使用@Autowired注解，则必须配置AutowiredAnnotationBeanPostProcessor的Bean，如果使用@Required注解，则必须配置RequiredAnnotationBeanPostProcessor的Bean。类似地，使用@Resource、@PostConstruct、@PreDestroy等注解就必须声明CommonAnnotationBeanPostProcessor，使用@PersistenceContext注解，就必须声明PersistenceAnnotationBeanPostProcessor的Bean。\n这样的声明不太优雅，Spring提供了一种极为方便的注册这些BeanPostProcessor的方法，即使用\u0026lt;context:annotation- config/\u0026gt;向Spring容器注册AutowiredAnnotationBeanPostProcessor、RequiredAnnotationBeanPostProcessor、CommonAnnotationBeanPostProcessor、PersistenceAnnotationBeanPostProcessor\n如果配置了\u0026lt;context:component-scan/\u0026gt;，其包含了自动注入上述processor的功能，此时可以省去\u0026lt;context:component-scan/\u0026gt;配置。\n（PostProcessor是Spring生命周期中的一个周期，我之前有简单的接触过这个东西）\n参考资料  springMVC各个包下的作用 Spring SpringMVC配置  ","description":"","id":234,"section":"notes","tags":null,"title":"Spring配置Spring MVC","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/spring%E9%85%8D%E7%BD%AEspring-mvc/"},{"content":"操作步骤  如下代码生成秘钥对，可以一致按回车，使用默认值（我设置了密码）   ssh-keygen 执行如下指令，将生成的pub秘钥添加到信任名单，并检查文件权限正确（权限太高，无法正常登录）   cd .ssh cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys chmod 600 authorized_keys chmod 700 ~/.ssh 通过/etc/ssh/sshd_config文件配置ssh服务器）（我服务器上没有找到RSAAuthentication，我只配置了PubkeyAuthentication），完成配置后，使用service sshd restart指令重启ssh服务。   RSAAuthentication yes PubkeyAuthentication yes service sshd restart  完成配置后，可以尝试用秘钥登录一次，具体操作为：下载id_rsa文件到本地，然后导入到XShell中，在登录的时候选择秘钥登录，然后设置秘钥的密码，就可以完成登录了。\n  完成登录后，配置ssh服务器，禁止用户用密码登录。\n   PasswordAuthentication no service sshd restart 参考教程  设置 SSH 通过密钥登录  ","description":"","id":235,"section":"notes","tags":null,"title":"SSH 配置只允许秘钥登录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/ssh/ssh-%E9%85%8D%E7%BD%AE%E5%8F%AA%E5%85%81%E8%AE%B8%E7%A7%98%E9%92%A5%E7%99%BB%E5%BD%95/"},{"content":"官方的starter命名：spring-boot-starter-*\n第三方的starter命名：*-spring-boot-starter\nMyBatis-Plus的starter命名：\n \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 遵循某种习惯，可以让代码和设计意图更容易被人理解。\n","description":"","id":236,"section":"notes","tags":null,"title":"Starter的命名习惯","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/starter%E7%9A%84%E5%91%BD%E5%90%8D%E4%B9%A0%E6%83%AF/"},{"content":"操作步骤  只用如下指令：   # 相比教程中的指令，增加了一个local参数（是因为我local-lvm不存在的原因） ./img2kvm openwrt.img 100 vm-100-disk-1 local ","description":"","id":237,"section":"notes","tags":null,"title":"storage 'local-lvm' does not exists","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/storage-local-lvm-does-not-exists/"},{"content":"两个大括号代表大括号本身，感觉不是很优雅。\n我本来准备了一段案例代码，案例代码和hugo有冲突，导致无法编译，所以我就清理掉了。\n","description":"","id":238,"section":"notes","tags":null,"title":"str.format输出大括号本身","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/str.format%E8%BE%93%E5%87%BA%E5%A4%A7%E6%8B%AC%E5%8F%B7%E6%9C%AC%E8%BA%AB/"},{"content":"写Demo时，StringReader可以让你不用新开一份文件，而是直接通过String实现相同的效果：\n Reader reader = new StringReader(\u0026quot;hhhhhh\u0026quot;); 参考资料  String 、InputStream、Reader 之间的转换  ","description":"","id":239,"section":"notes","tags":null,"title":"StringReader非常利于测试文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/stringreader%E9%9D%9E%E5%B8%B8%E5%88%A9%E4%BA%8E%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6/"},{"content":"StringUtils.trim()仅去除控制字符，且字符编码需要小于32\nStringUtils.strip()可以去除\\t\\r\\n等\nStringUtils.deleteWhitespace将删除所有的空白\n另外trim和strip还有xxxToNull和xxxToEmpty方法，如果字符串全部都为控制字符，则将得到Null或者空字符串。\ntrim和strip的区别在于能否去除全角和半角的空格字符。\n参考资料  StringUtils 去除空白 Java: trim()方法和strip()方法之间的区别  ","description":"","id":240,"section":"notes","tags":null,"title":"StringUtils去除文本首位空白","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/stringutils%E5%8E%BB%E9%99%A4%E6%96%87%E6%9C%AC%E9%A6%96%E4%BD%8D%E7%A9%BA%E7%99%BD/"},{"content":"tar不支持创建目录 tar使用-C参数时，如果目录不存在，是没有办法创建的，不要在徒劳的去寻找解压并创建目录的方法了，我感觉我已经尝试做这件事情好几次了！！！\n","description":"","id":241,"section":"notes","tags":null,"title":"tar在解压时不支持创建目录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip%E6%8C%87%E4%BB%A4/tar%E5%9C%A8%E8%A7%A3%E5%8E%8B%E6%97%B6%E4%B8%8D%E6%94%AF%E6%8C%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95/"},{"content":"对timestamptz的研究，是为了项目内部时间戳的统一。统一时间戳可以有如下好处：\n  统一的认知层次，大家都清晰的知道，前端、后端、数据库中的时间戳意味着什么（主要是时区问题）\n  统一的工具类，我们可以用通一的时间戳工具类，完成我们所有的时间戳需求\n  利于框架层面统一处理时间戳，请求进入服务、返回到前端、服务内部的反序列化时我们时间戳都能正确的表达我们想要的数据。\n  理解timestamp和timestamptz timestamp数据类型可以同时存储日期和事件，但它不存储时区，这意味着修改了数据库服务器所在的时区时，它里面存储的值不会改变。timestamptz数据类型在存储日期和事件的同时还能正确处理时区。\nPostgreSQL使用UTC值来存储Timestamptz数据。在想timestamptz字段插入值的时候，PostgreSQL会自动将值转换成UTC值，并保存到表里。当从一个timestamptz字段查询数据的时候，postgreSQL会把存储在其中的utc值转换成数据库服务器、用户或当前链接所在的时区（如何理解用户、点前链接所在的时区）。\n重要提示：timestamptz并不会存储时区，它只是存储了utc值，然后会和当前时区进行转换。\n参考资料  PostgreSQL TIMESTAMP类型  ","description":"","id":242,"section":"notes","tags":null,"title":"timestamptz类型的研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/timestamptz%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%A0%94%E7%A9%B6/"},{"content":"我是有需求将type-handler-package配置成字符串数组，但是官方给的文档中，该处只能配置成字符串，我觉得查看源码肯定可以找到配置成字符串数组的方案，只是这样做成本太高了，并不值得这么做。\n20210621后续：\n我在网上有看到type-handler-package配置成多个值，值之间用分号隔开，我没有验证过这个方案。\n参考资料   typehandlerspackage官方文档\n  spring boot 与mybatis整合，type-aliases-package、type-handlers-package等配置不起作用,导致类加载失败\n这篇文章似乎在讲源码怎么看，我简单看了下，目前不想花精力去研究这个。\n  ","description":"","id":243,"section":"notes","tags":null,"title":"typeHandlersPackage只能配置成字符串","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/typehandlerspackage%E5%8F%AA%E8%83%BD%E9%85%8D%E7%BD%AE%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"content":"我在开发新功能时发现如下的问题，我代码编写如下：\n在运行时候value字段的值是：\n是一个LinkedTreeMap，而不是我期待的Language对象。\n我意识到肯定是JsonbTypeHandler影响了我最终的结果，但是，当我将JsonbTypeHandler换成ObjectTypeHandler时，依旧无法达到我想要的效果。\n我还未开始系统研究MyBatis-Plus，这块的问题只能先放置。我最终选择的是通过FastjsonTypeHandler先绕开这个问题（FastJsonTypeHandler也不能很好的符合我的需求）。\n20210520后续：\n我后来开发的处理该问题的方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_option\u0026#34;, autoResultMap = true) public class OptionPo extends BasePo { private static final long serialVersionUID = 1L; private String orgId; private String fieldCode; private Integer sort; @TableField(typeHandler = LanguageTypeHandler.class) private List\u0026lt;Language\u0026gt; value; @Data @NoArgsConstructor @AllArgsConstructor public static class Language { private String languageCode; private String languageValue; } @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public static class LanguageTypeHandler extends AbstractJsonTypeHandler\u0026lt;Object\u0026gt; { private final Class\u0026lt;?\u0026gt; type = Language.class; @Override protected Object parse(String json) { JSON.parseObject(\u0026#34;\u0026#34;, type); Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;数据库数据格式错误\u0026#34;); } } @Override protected String toJson(Object obj) { return JSON.toJSONString(obj, SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullStringAsEmpty); } } }   考虑到后面需要开发自动化工具，所以我将Handler提取到了框架中，新代码如下：\nJsonTypeHandler.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class JsonTypeHandler extends AbstractJsonTypeHandler\u0026lt;Object\u0026gt; { protected Class\u0026lt;?\u0026gt; type = Object.class; @Override protected Object parse(String json) { JSON.parseObject(\u0026#34;\u0026#34;, type); Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;json数据格式错误\u0026#34;); } } @Override protected String toJson(Object obj) { return JSON.toJSONString(obj, SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullStringAsEmpty); } }   OptionPo.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package com.sdstc.dyf.admin.core.po; import com.sdstc.dyf.admin.core.handler.JsonTypeHandler; import com.sdstc.scdp.mybatis.plus.handler.JsonbTypeHandler; import com.baomidou.mybatisplus.annotation.TableName; import java.util.List; import com.sdstc.scdp.mybatis.plus.po.BasePo; import com.baomidou.mybatisplus.annotation.TableField; import lombok.*; import lombok.extern.slf4j.Slf4j; import org.apache.ibatis.type.JdbcType; import org.apache.ibatis.type.MappedJdbcTypes; import org.apache.ibatis.type.MappedTypes; /** * \u0026lt;p\u0026gt; * * \u0026lt;/p\u0026gt; * * @author wujj * @since 2021-05-17 */ @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_option\u0026#34;, autoResultMap = true) public class OptionPo extends BasePo { private static final long serialVersionUID = 1L; private String orgId; private String fieldCode; private Integer sort; @TableField(typeHandler = LanguageTypeHandler.class) private List\u0026lt;Language\u0026gt; value; @Data @NoArgsConstructor @AllArgsConstructor public static class Language { private String languageCode; private String languageValue; } @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public static class LanguageTypeHandler extends JsonTypeHandler { public LanguageTypeHandler() { this.type = Language.class; } } }   目前的实现上肯定不是非常的优雅，比如用FastJson解析的时候，一定需要先判断是Array还是Object，但是能达到我们想要的效果。\n自动化工具遇到类型为jsonb的字段时，会自动生成相应的对象和Handler。\n参考资料   MyBatis通过TypeHandler自动编解码对象的Json属性\n  关于mybatis中typeHandler的两个案例\n  【Mybatis】用TypeHandler将数据库中存储的json字符串处理为对象，包括对象含List以及复杂对象的情况, 并满足泛型可转成多种对象\n没有用到该资料，先记录在这块。\n  ","description":"","id":244,"section":"notes","tags":null,"title":"Typehandler转换出来的对象运行时状态和定义状态不符","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/typehandler%E8%BD%AC%E6%8D%A2%E5%87%BA%E6%9D%A5%E7%9A%84%E5%AF%B9%E8%B1%A1%E8%BF%90%E8%A1%8C%E6%97%B6%E7%8A%B6%E6%80%81%E5%92%8C%E5%AE%9A%E4%B9%89%E7%8A%B6%E6%80%81%E4%B8%8D%E7%AC%A6/"},{"content":"操作步骤  关闭用户图形界面，使用tty登录   sudo systemctl set-default multi-user.target sudo reboot 开启用户图形界面   sudo systemctl set-default graphical.target sudo reboot 参考资料  Ubuntu18.04 关闭和开启图形界面  ","description":"","id":245,"section":"notes","tags":null,"title":"Ubunt 18.04关闭和开启图形界面","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubunt-18.04%E5%85%B3%E9%97%AD%E5%92%8C%E5%BC%80%E5%90%AF%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2/"},{"content":"该教程为我工具机在公司访问网络用到的\n操作步骤  代码如下：  1 2 3 4 5 6 7  nmcli con edit CONNECTION_NAME nmcli\u0026gt; set ipv4.method auto nmcli\u0026gt; set 802-1x.eap peap nmcli\u0026gt; set 802-1x.identity sadegh.k@atu.com nmcli\u0026gt; set 802-1x.phase2-auth mschapv2 nmcli\u0026gt; save nmcli\u0026gt; quit   参考教程  Ubuntu 18.04终端802.1X认证设置？ 802.1x with NetworkManager using nmcli Ubuntu上通过802.1x认证联网  ","description":"","id":246,"section":"notes","tags":null,"title":"Ubuntu 18.04使用802.1x协议登录网络","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E4%BD%BF%E7%94%A8802.1x%E5%8D%8F%E8%AE%AE%E7%99%BB%E5%BD%95%E7%BD%91%E7%BB%9C/"},{"content":"操作步骤 准备基础环境：  克隆我的个人项目，启动三台虚拟机  1 2 3 4 5  git clone https://github.com/junjie2018/vagrant.git cd vagrant/cluster/ssh_kubernetes/kubernetes vagrant up   关闭工具机的防火墙，使开发机能直接访问虚拟机：  1 2 3  sudo ufw disable    开发机挂VPN，连接到三台虚拟机，并更新三台虚拟机的软件源为国内源\n  为三台虚拟机安装docker，并设置Docker容器加速\n  1 2 3  sudo apt-get install -y docker.io   安装Kubernetes  关闭swap，并测试关闭是否成功  1 2 3 4  sudo swapoff -a free -h   为三台虚拟机必要的基础工具（kubeadm需要用到的）  1 2 3 4  sudo apt update \u0026amp;\u0026amp; sudo apt install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -   配置镜像kubeadm仓库地址  1 2 3 4 5 6  sudo tee /etc/apt/sources.list.d/kubernetes.list \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF sudo apt update   安装 kubelet、kubeadm、kubectl并验证安装是否成功  1 2 3 4  sudo apt install -y kubelet kubeadm kubectl kubelet --version   初始化Kubernetes集群  1 2 3 4 5 6 7  kubeadm init \\  --image-repository registry.aliyuncs.com/google_containers \\  --kubernetes-version v1.18.2 \\  --pod-network-cidr=10.244.0.0/16 \\  --apiserver-advertise-address=172.17.30.101    安装flannel组件：  1 2 3 4 5  # 需要外网，可以在浏览器上下载下来，再传到虚拟机上 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml   漫长的等待后，验证是否成功：  1 2 3  kubectl get pods --all-namespaces   其他知识  忘记了node添加到master时的指令，可以通过如下指令获取  1 2 3  kubeadm token create --print-join-command --ttl 0   相关教程  ubuntu18.04安装kubernetes ubuntu18.04搭建 kubernetes（k8s）集群 Kubernetes集群的简单搭建（flannel.yml文件，及相关内容） Docker 镜像加速 kubenetes使用kubeadm查询添加节点到集群的命令  后记  我以为apiserver-advertise-address参数可以帮我解决双网卡的问题，没想到我还是踩到了双网卡的坑，见相关教程。  ","description":"","id":247,"section":"notes","tags":null,"title":"Ubuntu 18.04搭建Kubernetes（已作废）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ubuntu-18.04%E6%90%AD%E5%BB%BAkubernetes%E5%B7%B2%E4%BD%9C%E5%BA%9F/"},{"content":"处理步骤  三台虚拟机上运行如下指令  1 2 3 4 5 6 7  sudo tee -a /etc/resolvconf/resolv.conf.d/head \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; nameserver 172.17.30.1 nameserver 114.114.114.114 nameserver 114.114.115.115 EOF   重启所有虚拟机  相关教程   Kubernetes中的Pod无法访问外网-Ubuntu16.04 LTS\n  完美解决K8s中的Pod无法解析外网域名问题（该方案行不通，给了思路）\n  ","description":"","id":248,"section":"notes","tags":null,"title":"Ubuntu 18.04永久替换resolve.conf文件的方法","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E6%B0%B8%E4%B9%85%E6%9B%BF%E6%8D%A2resolve.conf%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95/"},{"content":"操作步骤  编辑/etc/netplan/01-network-manager-all.yaml（你的机器上可能不是这个文件名，也有可能有多个文件，需要注意观察，并自行分析修改哪个文件），代码如下：  1 2 3 4 5 6 7 8 9 10 11  network:version:2renderer:NetworkManagerethernets:enp34s0:dhcp4:noaddresses:[192.168.31.29/24]optional:truegateway4:192.168.31.1nameservers:addresses:[114.114.114.114,8.8.8.8]  运行如下指令：  1  sudo netplan apply   个人总结   整个过程其实并没有那么顺利，前几次试验都失败了，我意识到可能是路由和主机的接口出现了问题，我调整了一个路由器接口后发现enp34s0网口动态的获取到一个ip地址。\n  我尝试过新起一份文件，同时修改网关的名称为ens33，我期待重新配置一个端口出来，结果并没有生效（我觉着这块我对底层理解的不太到位）。\n  网卡的名称一定要与ifconfig查到的一致。\n  参考教程  ubuntu 18.04 设置静态ip方法  ","description":"","id":249,"section":"notes","tags":null,"title":"Ubuntu 18.04配置静态地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80/"},{"content":"我使用的方法  禁用ssytemd-resolved（不用犹豫，这东西占用我53号端口，是肯定不行的）   sudo systemctl disable systemd-resolved sudo systemctl stop systemd-resolved 修改/etc/NetworkManager/NetworkManager.conf文件   [main] dns=127.0.0.1 删除符号链接   rm /etc/resolv.conf 下载network-manager并重新启动   apt install -y network-manager sudo systemctl restart NetworkManager 我认为可行的方法（实践证明，这种方法可行） 实际上我觉得，关闭systemd-resolved后，删除/etc/resolv.conf符号链接，然后手动创建一份/etc/resolv.conf也是可行的。\n参考资料  如何在Ubuntu中禁用systemd-resolved？ 怎么安装network-manager  ","description":"","id":250,"section":"notes","tags":null,"title":"Ubuntu 20.04网络调整","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-20.04%E7%BD%91%E7%BB%9C%E8%B0%83%E6%95%B4/"},{"content":"操作步骤  https://jdk.java.net/java-se-ri/7下载openJDK 7安装包  解压，设置环境变量  1 2 3 4 5 6 7 8 9  tar -zxvf openjdk-7u75-b13-linux-x64-18_dec_2014.tar.gz sudo tee -a /etc/profile \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; JAVA_HOME=/home/vagrant/software/openjdk/java-se-7u75-ri PATH=${JAVA_HOME}/bin:${PATH} EOF source /etc/profile   ","description":"","id":251,"section":"notes","tags":null,"title":"Ubuntu18.04装OpenJDK 7","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu18.04%E8%A3%85openjdk-7/"},{"content":"最近按照教程配置了一份environment文件，在里面配置了代理，发现apt、curl都可以使用代理了，之前的方案是使用all_proxy，而且apt需要单独配置，先关注下这个问题。\n执行后需要使用source /etc/environment生效\n","description":"","id":252,"section":"notes","tags":null,"title":"Ubuntu中的environment文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E4%B8%AD%E7%9A%84environment%E6%96%87%E4%BB%B6/"},{"content":"操作步骤  安装openssh服务端  sudo apt-get install openssh-server 编辑配置文件/etc/ssh/sshd_config改PermitRootLogin为yes   # Authentication: LoginGraceTime 120 PermitRootLogin yes StrictModes yes  重启服务   /etc/init.d/ssh restart 相关资料  ubuntu 16.0 安装openssh和启动 Ubuntu如何开启SSH服务 Ubuntu ssh开机自动启动的设置方法  ","description":"","id":253,"section":"notes","tags":null,"title":"Ubuntu安装并配置OpenSSH","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E5%AE%89%E8%A3%85%E5%B9%B6%E9%85%8D%E7%BD%AEopenssh/"},{"content":"sudo systemctl disable systemd-resolved\nsudo systemctl stop systemd-resolved\nsudo systemctl enable systemd-resolved\nsudo systemctl start systemd-resolved\n","description":"","id":254,"section":"notes","tags":null,"title":"Ubuntu设置systemd-resolved","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E8%AE%BE%E7%BD%AEsystemd-resolved/"},{"content":"这个问题应该属于我们项目中的问题，我按照要求继承项目后，在mapper包下开发自己的Mapper，结果在启动的时候发现Mapper无法被注入。\n后来参考了案例代码后判断，应该要把包名改为dao，我之前有搞过类似的东西，通过ComponentScan组件完成指定包扫描路径，有点意思，哈哈。\n20210616后续：\n哈哈，这个框架已经被废弃了，我们项目不再使用这个新框架。\n","description":"","id":255,"section":"notes","tags":null,"title":"Unsatisfied dependency expressed through field 'baseMapper'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/unsatisfied-dependency-expressed-through-field-basemapper/"},{"content":"3种场景：\n alt+鼠标左键（光标点中一行算一行） alt+鼠标左键拖动（多次）（每次拖动选中一块内容） shift+alt+鼠标左键拖动（光标同时出现在多行）  这东西有需求的时候，实践下就可以掌握了。\n参考资料  VS Code 列编辑功能说明  ","description":"","id":256,"section":"notes","tags":null,"title":"vs code同时处理多行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/vscode/vs-code%E5%90%8C%E6%97%B6%E5%A4%84%E7%90%86%E5%A4%9A%E8%A1%8C/"},{"content":"不小心误触了键盘，打开了VS Code的全屏，我不是很需要这个功能，简单查了一下，F11键快速打开或关闭全屏。\n","description":"","id":257,"section":"notes","tags":null,"title":"VS Code开启和关闭全屏","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/vscode/vs-code%E5%BC%80%E5%90%AF%E5%92%8C%E5%85%B3%E9%97%AD%E5%85%A8%E5%B1%8F/"},{"content":"WebApplicationContext继承自ApplicationContext，它提供了一些web应用经常需要用到的特性。WebApplicationContext被绑定在ServletContext中。如果需要获取它，你可以通过RequestContextUtils工具类中的静态方法来拿到这个web应用的上下文WebApplicationContext。\nRequestContextUtils RequestContextUtils类是Spring提供的用于从HttpServletRequest上下文中获取特殊对象的工具类。该工具类虽然是属于Spring的一部分，但是如果在应用中我们有需要直接获取相关信息的需求，我们也可以直接使用。\n1 2 3 4 5 6 7 8 9 10 11 12  // 获取WebApplicationContext RequestContextUtils.getWebApplicationContext(request); // 获取LocaleResolver或Locale RequestContextUtils.getLocaleResolver(request); RequestContextUtils.getLocale(request); // 获取ThemeResolver或Theme（这个概念非常陌生） RequestContextUtils.getThemeResolver(request); RequestContextUtils.getTheme(request);   备注：这个request是ServletRequest类，所以我们日常用的Request DTO应该是没有办法获取到这些信息的，先记录一下，以后再慢慢研究。\n参考资料   Spring MVC DispatcherServlet详解\n  SpringMVC之RequestContextUtils工具类\n  ","description":"","id":258,"section":"notes","tags":null,"title":"WebApplicationContext是什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/webapplicationcontext%E6%98%AF%E4%BB%80%E4%B9%88/"},{"content":"目前先整理一下这部分资料，以后要深入学习的。\nWebApplicationInitializer是Spring MVC提供的一个接口，它会查找你所有基于代码的配置，并应用它们来初始化Servlet 3版本以上的Web容器。\n它有一个抽象的实现AbstractDispatcherServletInitializer，用以简化DispatcherServlet的注册工作：你只需要指定其Servlet映射即可。\n参考资料  Spring MVC DispatcherServlet详解  ","description":"","id":259,"section":"notes","tags":null,"title":"WebApplicationInitializer接口","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/webapplicationinitializer%E6%8E%A5%E5%8F%A3/"},{"content":"指令如下：\n ipconfig /all ","description":"","id":260,"section":"notes","tags":null,"title":"Win 10查看mac地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win-10%E6%9F%A5%E7%9C%8Bmac%E5%9C%B0%E5%9D%80/"},{"content":"懒的整理，这种东西就是十年半个月用不到一次：\nhttps://jingyan.baidu.com/article/e73e26c01bc1c364acb6a734.html\n","description":"","id":261,"section":"notes","tags":null,"title":"win10右下角图表显示","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E5%8F%B3%E4%B8%8B%E8%A7%92%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA/"},{"content":"另外需要说一下，win家庭版不支持远程桌面，打消这个念头吧。\n参考资料  win10怎么开启远程桌面  ","description":"","id":262,"section":"notes","tags":null,"title":"Win10开启远程桌面","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"},{"content":"打开控制面板，搜索程序，选择启用或者关闭Window功能：\n选择Telnet客户端，点击确定：\n参考资料  在windows10下面打开TELNET功能  ","description":"","id":263,"section":"notes","tags":null,"title":"win10打开telnet服务","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%89%93%E5%BC%80telnet%E6%9C%8D%E5%8A%A1/"},{"content":"用的少，但是又不得不用，截图如下：\n20210630后续:\n额，没想到这个东东我用的挺多的，我老是忘记打卡。\n","description":"","id":264,"section":"notes","tags":null,"title":"Win10查看关机事件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E5%85%B3%E6%9C%BA%E4%BA%8B%E4%BB%B6/"},{"content":"我将家庭内部网络切换成了172.20.11网段，避免内网穿透时与其他网络环境中的网段冲突。切换后我需要知道我网络中的所有新Ip地址，故找到了这些相关的资料。\n for /L %i IN (1,1,254) DO ping -w 2 -n 1 172.20.11.%i arp -a 参考资料  windows 查看局域网内所有已使用的IP  ","description":"","id":265,"section":"notes","tags":null,"title":"win10查看局域网中ip","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E5%B1%80%E5%9F%9F%E7%BD%91%E4%B8%ADip/"},{"content":"netstat -ano | findstr \u0026ldquo;192.168.13.113\u0026rdquo;\n一个指令多种使用场景。\n参考资料  Windows 下查看网络连接  ","description":"","id":266,"section":"notes","tags":null,"title":"win10查看活动的网络连接","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E6%B4%BB%E5%8A%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"content":"指令如下：\n tree /F 如果不要/F的话，则只显示目录。\n","description":"","id":267,"section":"notes","tags":null,"title":"win10查看目录树","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E7%9B%AE%E5%BD%95%E6%A0%91/"},{"content":"和Linux需求一致，有时候服务启动起来了，需要检查是否正在监听着：\n netstat -aon | findstr \u0026quot;9050\u0026quot; 参考资料  windows下查看端口监听情况  ","description":"","id":268,"section":"notes","tags":null,"title":"win10查看端口占用情况","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/"},{"content":"这个解决方案是我看教程的时候自己猜出来的，我没有找到很清晰的描述这个问题的解决方案。解决方法如下：\n pip config set global.proxy http://127.0.0.1:1080 我在整理笔记时发现，我之前解决过类似的问题，嗯，下次有问题先找一下自己的笔记。\n参考教程  【python】python3.x 在Windows 10 下的环境配置——pip永久换源成国内镜像  ","description":"","id":269,"section":"notes","tags":null,"title":"win10设置pip3代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/win10%E8%AE%BE%E7%BD%AEpip3%E4%BB%A3%E7%90%86/"},{"content":"route print\nroute delete 192.168.31.1 mask 255.255.255.0\n","description":"","id":270,"section":"notes","tags":null,"title":"Win10路由表常用操作（待完善）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E8%B7%AF%E7%94%B1%E8%A1%A8%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%BE%85%E5%AE%8C%E5%96%84/"},{"content":"Windows安装ElasticSearch，用于学习环境\n  下载二进制文件，解压后进入bin目录\n  使用管理员身份运行elasticsearch.bat文件\n  浏览器访问localhost:9200，看到如下内容，则成功：\n   { \u0026quot;name\u0026quot; : \u0026quot;WUJJ\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;5XBz9P4ZQXy-CBIqzZbCSw\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.12.1\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;zip\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;3186837139b9c6b6d23c3200870651f10d3343b7\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2021-04-20T20:56:39.040728659Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.8.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } ","description":"","id":271,"section":"notes","tags":null,"title":"Windows安装ElasticSearch","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/elasticsearch/windows%E5%AE%89%E8%A3%85elasticsearch/"},{"content":"操作步骤  指令如下  route print route print | findstr \u0026quot;172\u0026quot; route delete 172.17.0.0 route add 172.17.0.0 MASK 255.255.0.0 172.17.30.1 route add 172.17.0.0 MASK 255.255.0.0 10.8.0.1 route delete 172.17.0.0 route add 172.17.0.0 MASK 255.255.0.0 172.17.0.1 ","description":"","id":272,"section":"notes","tags":null,"title":"Windows查看路由信息","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/windows%E6%9F%A5%E7%9C%8B%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF/"},{"content":"如下代码可直接进入非C盘的目录：\n1 2 3  cd /D D:\\Blogs   如不不用/D参数，则该指令无法正常进入该目录。\n参考资料  bat文件直接进入某个盘符目录  ","description":"","id":273,"section":"notes","tags":null,"title":"win上进入非C盘的文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win%E4%B8%8A%E8%BF%9B%E5%85%A5%E9%9D%9Ec%E7%9B%98%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"测试自己接口用的，我使用的指令如下：\n curl --proxy socks5h://192.168.27.15:12345 -H token:1374675177769156610:web:8085e1bc1d7b3325cae1bcd6684f853b http://dyf/dyf/field ","description":"","id":274,"section":"notes","tags":null,"title":"win版本的curl设置代理及请求头","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win%E7%89%88%E6%9C%AC%E7%9A%84curl%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%8F%8A%E8%AF%B7%E6%B1%82%E5%A4%B4/"},{"content":"我在本地测试Dockerfile时，习惯性的将ENTRYPOINT写成如下形式：\n1 2 3  ENTRYPOINT [\u0026#34;./entrypoint.sh\u0026#34;]  但是如果这样写，在GitHub Actions中将会报错：\n1 2 3  docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: \u0026#34;./entrypoint.sh\u0026#34;: stat ./entrypoint.sh: no such file or directory: unknown.  需要用如下的写法：\n1 2 3  ENTRYPOINT [\u0026#34;/entrypoint.sh\u0026#34;]  原因分析 如下Github Actions在启动Docker容器时会传递如下的参数，而我使用的python:3.8.6镜像的默认位置是根目录，所以就无法使用相对路径找到我的脚本文件。\n","description":"","id":275,"section":"notes","tags":null,"title":"workdir参数导致docker启动时无法找到脚本","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/github/workdir%E5%8F%82%E6%95%B0%E5%AF%BC%E8%87%B4docker%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E8%84%9A%E6%9C%AC/"},{"content":"我也不知道误触了什么案件，XShell突然变透明了，通过如下方式改回来：\n我评估了下，感觉这个功能没有什么适用场景。\n","description":"","id":276,"section":"notes","tags":null,"title":"XShell不小心变透明了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/xshell/xshell%E4%B8%8D%E5%B0%8F%E5%BF%83%E5%8F%98%E9%80%8F%E6%98%8E%E4%BA%86/"},{"content":"一图胜千言万语\n","description":"","id":277,"section":"notes","tags":null,"title":"XShell导出配置文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/xshell/xshell%E5%AF%BC%E5%87%BA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"content":"不用再在跳板机上手动ssh生产机了，还能往生产机上传文件，不使用该技术，则需要先ssh跳板机，然后在ssh到生产机，而且还不能向生产机传文件\n原理部分   该方案至少要两个会话，一个会话需要登录跳板机并配置隧道，我叫它为跳板机会话。另一个会话就是我们日常使用的会话，我称为它为目标会话\n  如图，测试环境下跳板机就是我所说的跳板机会话，而192.168.52.157、192.168.52.168、192.168.52.169就是我所说的目标会话\n  使用的时候，需要先打开跳板机会话，然后再打开你需要的目标会话  操作步骤 配置跳板机会话   xshell上创建一个跳板机会话（这块不截图了，两部分，ip地址和登录信息，其中ip地址是跳板机的ip地址，登录信息为跳板机的用户名和密码）\n  跳板机会话设置登录脚本，设置登录脚本是为了防止跳板机长时间没有输入，给自动掉线了\n  跳板机会话设置隧道，添加两台生产机（观察两张截图，可以总结需要设置哪些内容）  配置目标会员  添加目标会员（右键，新建会话，登录信息部分是常规设置，需要注意主机部分）  完美收工，使用时需要先连接跳板机  ","description":"","id":278,"section":"notes","tags":null,"title":"XShell隧道技术的利用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/xshell/xshell%E9%9A%A7%E9%81%93%E6%8A%80%E6%9C%AF%E7%9A%84%E5%88%A9%E7%94%A8/"},{"content":"账号：admin@admin.com\n密码：ymfe.org\n参考资料  我想问下默认超级管理员的账号密码是啥  ","description":"","id":279,"section":"notes","tags":null,"title":"yapi默认账号密码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/yapi%E9%BB%98%E8%AE%A4%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81/"},{"content":"当目录过程，展开的时候超过了一屏的高度时，页面会出现抖动的情况，抖动的原因是因为超过一屏时浏览器右侧会出现滚动条，该滚动条影响了屏幕的宽度，会导致body标签左移，所以呈现页面抖动。\n我选择解决这个问题的办法是，让右侧的滚动条一直存在，这样就不存在宽度的变化了。\n操作步骤  准备如下css文件，放置在asserts/css/custom.css下：  1 2 3  body { overflow-y: scroll; }   配置config/_default/params.toml，增加如下配置   custom_css = [\u0026quot;css/custom.css\u0026quot;] 参考资料  解决因出现滚动条导致页面抖动 CSS  ","description":"","id":280,"section":"notes","tags":null,"title":"ZDoc主题直接抖动的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/zdoc%E4%B8%BB%E9%A2%98%E7%9B%B4%E6%8E%A5%E6%8A%96%E5%8A%A8%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"初始化K8S集群的时候，有如下报错：\n [root@node-template ~]# kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=172.20.11.201 [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \u0026quot;cgroupfs\u0026quot; as the Docker cgroup driver. The recommended driver is \u0026quot;systemd\u0026quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \u0026quot;/etc/kubernetes/pki\u0026quot; [certs] Generating \u0026quot;ca\u0026quot; certificate and key [certs] Generating \u0026quot;apiserver\u0026quot; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node-template] and IPs [10.96.0.1 172.20.11.201] [certs] Generating \u0026quot;apiserver-kubelet-client\u0026quot; certificate and key [certs] Generating \u0026quot;front-proxy-ca\u0026quot; certificate and key [certs] Generating \u0026quot;front-proxy-client\u0026quot; certificate and key [certs] Generating \u0026quot;etcd/ca\u0026quot; certificate and key [certs] Generating \u0026quot;etcd/server\u0026quot; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost node-template] and IPs [172.20.11.201 127.0.0.1 ::1] [certs] Generating \u0026quot;etcd/peer\u0026quot; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost node-template] and IPs [172.20.11.201 127.0.0.1 ::1] [certs] Generating \u0026quot;etcd/healthcheck-client\u0026quot; certificate and key [certs] Generating \u0026quot;apiserver-etcd-client\u0026quot; certificate and key [certs] Generating \u0026quot;sa\u0026quot; key and public key [kubeconfig] Using kubeconfig folder \u0026quot;/etc/kubernetes\u0026quot; [kubeconfig] Writing \u0026quot;admin.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;kubelet.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;controller-manager.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;scheduler.conf\u0026quot; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026quot;/var/lib/kubelet/kubeadm-flags.env\u0026quot; [kubelet-start] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026quot;/etc/kubernetes/manifests\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-apiserver\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-controller-manager\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-scheduler\u0026quot; [etcd] Creating static Pod manifest for local etcd in \u0026quot;/etc/kubernetes/manifests\u0026quot; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026quot;/etc/kubernetes/manifests\u0026quot;. This can take up to 4m0s [kubelet-check] Initial timeout of 40s passed. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - 'systemctl status kubelet' - 'journalctl -xeu kubelet' Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - 'docker ps -a | grep kube | grep -v pause' Once you have found the failing container, you can inspect its logs with: - 'docker logs CONTAINERID' error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster To see the stack trace of this error execute with --v=5 or higher 这个问题导致的原因是我将--apiserver-advertise-address=172.20.11.201写错了，应该写成--apiserver-advertise-address=172.20.11.202，好蠢。\n","description":"","id":281,"section":"notes","tags":null,"title":"一个蠢问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E4%B8%80%E4%B8%AA%E8%A0%A2%E9%97%AE%E9%A2%98/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  private List\u0026lt;Table\u0026gt; getOriginTableInfos() { if (this.jdbcTemplate.getDataSource() == null) { throw new RuntimeException(\u0026#34;数据库链接错误\u0026#34;); } try { Map\u0026lt;String, Table\u0026gt; tableName2TableMap = new HashMap\u0026lt;\u0026gt;(20); DatabaseMetaData dbMetaData = this.jdbcTemplate.getDataSource().getConnection().getMetaData(); // 处理表信息  // 此处抛出异常  ResultSet tables = dbMetaData.getTables( null, null, ProjectConfig.getTablePrefix() + \u0026#34;_%\u0026#34;, new String[]{\u0026#34;TABLE\u0026#34;}); while (tables.next()) { String tableName = tables.getString(\u0026#34;table_name\u0026#34;); String tableDesc = tables.getString(\u0026#34;remarks\u0026#34;); tableName2TableMap.put(tableName, new Table(tableName, tableDesc)); } // 处理列信息  ResultSet columns = dbMetaData.getColumns( null, null, ProjectConfig.getTablePrefix() + \u0026#34;%\u0026#34;, null); while (columns.next()) { String tableName = columns.getString(\u0026#34;table_name\u0026#34;); String columnName = columns.getString(\u0026#34;column_name\u0026#34;); String typeName = columns.getString(\u0026#34;type_name\u0026#34;); String remarks = columns.getString(\u0026#34;remarks\u0026#34;); Table table = tableName2TableMap.get(tableName); if (table == null) { throw new RuntimeException(\u0026#34;Data Wrong When Get Column Info\u0026#34;); } table.addColumn(new Column(columnName, remarks, typeName)); } return new ArrayList\u0026lt;\u0026gt;(tableName2TableMap.values()); } catch (Exception e) { throw new RuntimeException(\u0026#34;数据库获取数据错误\u0026#34;); } }   我在代码中注释了抛出异常的代码行，我之前一直以为是我的代码出错了，后来发现是传入的ProjectConfig.getTablePrefix() + \u0026quot;_%\u0026quot;参数，该参数的实现如下：\n1 2 3 4 5  public static String getTablePrefix() { return INSTANCE.tablePrefix; }   因为INSTANCE没有初始化，该字段应该为null，所以抛出来的异常应该为NullException，这个异常被捕获了，变成了一个迷惑我的数据库异常。\n","description":"","id":282,"section":"notes","tags":null,"title":"不要吞掉异常信息，否则只能自食其果","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E4%B8%8D%E8%A6%81%E5%90%9E%E6%8E%89%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF%E5%90%A6%E5%88%99%E5%8F%AA%E8%83%BD%E8%87%AA%E9%A3%9F%E5%85%B6%E6%9E%9C/"},{"content":"我计划自己将一个Linux系统变成路由器。\n为什么会有这样奇奇怪怪的需求呢？我原本是计划在J4125那台机器上做虚拟化，然后装OpenWRT外加一个CentOS系统的，但是用ESXI做虚拟化的过程中，并不是很顺利，这个工具问题太多了，经不起折腾。用PVE做虚拟化的时候，发现它本身也是一个Linux系统，我甚至只需要虚拟化出一个OpenWRT系统就可以满足我的需求了，其他的工具可以装在PVE上。我觉得花大量时间学习PVE，只为了维护一个OpenWRT实在是不值得，我决定寻找其他的方案。\n随着对OpenWRT的深入研究，我对自己需求也越来越清晰，我意识到自己可能并不需要OpenWRT，我需要的仅仅是一台机器做网关，实现对内网中流量的透明代理，同时我可以通过内网穿透工具暴露这台机器，使我在其他的网络环境中也可以连接到我的内网环境中。最好，整套方案不需要再引入其他的工具，增加我的学习成本。经过研究后我发现我的需求完全可以通过iptables实现，所以我决定自己动手，实现CentOS的路由化，这个过程中我还可以学习到大量的CentOS知识，非常划算。\n20210616后续：\n不要再有这种想法了，类似OpenWRT这种系统肯定是进行过内核级别的优化的，更适合做路由器的场景，我目前已经掌握了OpenWRT的编译技术，非常爽，哈哈。\n","description":"","id":283,"section":"notes","tags":null,"title":"不要尝试将一个Linux系统配置成网关服务器","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%B8%8D%E8%A6%81%E5%B0%9D%E8%AF%95%E5%B0%86%E4%B8%80%E4%B8%AAlinux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%88%90%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"content":"之前有考虑研究GitPython、PyGit，然后在python脚本中操作Git仓库，但是最近在使用的过程中发现相关资料有点少，而且运行的时候会出现一些我无法理解的问题，所以决定暂时不研究这些技术了。\n可能等我系统学习了Git后，我可能会再次研究相关技术。所以这也影响了我对python脚本的定位，我之前是期待python脚本为主，完全取代shell脚本，甚至在代码中都不调用shell脚本。可能这之后还是shell脚本为主，python脚本用于处理一些业务逻辑比较复杂的东西。\n","description":"","id":284,"section":"notes","tags":null,"title":"不计划对GitPython等技术进行研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%B8%8D%E8%AE%A1%E5%88%92%E5%AF%B9gitpython%E7%AD%89%E6%8A%80%E6%9C%AF%E8%BF%9B%E8%A1%8C%E7%A0%94%E7%A9%B6/"},{"content":"问题描述  # # There is insufficient memory for the Java Runtime Environment to continue. # Native memory allocation (malloc) failed to allocate 949216 bytes for Chunk::new # An error report file with more information is saved as: # D:\\Project\\dyf\\hs_err_pid20632.log [thread 15576 also had an error] # # Compiler replay data is saved as: # D:\\Project\\dyf\\replay_pid20632.log Disconnected from the target VM, address: '127.0.0.1:63994', transport: 'socket' Process finished with exit code 1 Idea在执行程序的时候，报如上的错误，处理过程如下：\n这个方案实际上并没有帮到我，我每次设置后都会重启，重启后就不会出现该问题了。但是该设置仍然是700M。\n20210615后续：\n后来已经证明是我操作系统出现了问题，当内存超过60%时，就无法正常的分配内存。\n","description":"","id":285,"section":"notes","tags":null,"title":"为Idea配置内存不足导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E4%B8%BAidea%E9%85%8D%E7%BD%AE%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3  sudo passwd root   ","description":"","id":286,"section":"notes","tags":null,"title":"为root用户添加密码","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%B8%BAroot%E7%94%A8%E6%88%B7%E6%B7%BB%E5%8A%A0%E5%AF%86%E7%A0%81/"},{"content":"说明  这不是一个优雅的方案，只是为了临时用一下 我感觉阿里云也是用的这个方案，但是可能它用的层次更高一些，我只是简单的照搬  操作步骤 master  切换到root用户，执行如下指令：  1 2 3 4 5  mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config   node  vagrant用户，指令如下  1 2 3 4  cd ~ \u0026amp;\u0026amp; mkdir .kube scp vagrant@172.17.30.101:~/.kube/config ~/.kube/config    root用户，指令如下  1 2 3 4 5  cd ~ \u0026amp;\u0026amp; mkdir .kube cp /home/vagrant/.kube/config ~/.kube/ sudo chown $(id -u):$(id -g) $HOME/.kube/config   相关教程   ubuntu18.04安装kubernetes(用于查看安装Kubernetes后，如何保证master机器能够使用kubectl)\n  通过kubectl连接Kubernetes集群(我的方案就是阿里云方案的照搬)\n  更多研究资料（我没有用这些，但是我认为这些方案更好一些）  kubectl客户端工具远程连接k8s集群（有关于证书的资料） 配置kubectl在Mac(本地)远程连接Kubernetes集群 使用 kubectl 连接远程 Kubernetes 集群(有kubectl配置资料) 使用 kubectl 连接远程 Kubernetes 集群(有kubectl配置资料) 配置远程工具访问kubernetes集群(有kubectl配置资料)  ","description":"","id":287,"section":"notes","tags":null,"title":"为root用户配置kubectl","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%B8%BAroot%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AEkubectl/"},{"content":"核心原因在于Date、SimpleDateFormat等是非线程安全的，而LocalDataTime是线程安全的。\n参考资料  为什么建议使用你LocalDateTime，而不是Date？  ","description":"","id":288,"section":"notes","tags":null,"title":"为什么要使用LocalDateTime","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/localdatetime/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8localdatetime/"},{"content":"我采用的方案比较简单：\n ls /dev/sd* // 进行分区 fdisk /dev/sdb n p 转折（使用默认） 转折（使用默认） w // 创建文件系统 mkfs -t ext4 /dev/sdb1 // 将硬盘信息写入/etc/fstab echo /dev/sdb1 /mnt/sdc1 ext4 defaults 1 2 \u0026gt;\u0026gt; /etc/fstab 参考资料  Proxmox VE（PVE）如何添加多块硬盘 Linux/VPS开机启动自动挂载分区的方法 linux中lost+found目录的作用  ","description":"","id":289,"section":"notes","tags":null,"title":"为系统新加一块硬盘","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%B8%BA%E7%B3%BB%E7%BB%9F%E6%96%B0%E5%8A%A0%E4%B8%80%E5%9D%97%E7%A1%AC%E7%9B%98/"},{"content":"我这个需求产生于修复EasyApi的官方提供的渲染服务的Bug。就是我按照官方说明做了镜像后，无法正常启动，所以我决定先在本地试试能否正常启动该服务。\n 首先确保你的容器处于正在运行的状态，如果没有办法保证，可以使用如下指令：   docker run -it --entrypoint top yapi-markdown-render:v3 --name tmp-for-test 使用如下指令，完成copy   docker cp vibrant_joliot:/easyyapi . 参考资料  docker中宿主机与容器（container）互相拷贝传递文件的方法 docker cmd 能够代替 entrypoint 的所有功能  ","description":"","id":290,"section":"notes","tags":null,"title":"从Docker容器内拷贝资料到宿主机","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E4%BB%8Edocker%E5%AE%B9%E5%99%A8%E5%86%85%E6%8B%B7%E8%B4%9D%E8%B5%84%E6%96%99%E5%88%B0%E5%AE%BF%E4%B8%BB%E6%9C%BA/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 硬件校准信息上报 */ @PostMapping(\u0026#34;/client/calibration/report\u0026#34;) @PassToken public ResponseVo\u0026lt;Object\u0026gt; clientCalibrationReport( @RequestHeader(value = \u0026#34;terminal\u0026#34;) Integer terminal, @Valid @RequestBody ClientCalibrationReportRequest request) { clientCalibrationReportService.saveClientCalibrationReport(terminal, request); return ResponseVo.createSuccess(); }   参考资料  java 获取HttpRequest Header 的几种方法  ","description":"","id":291,"section":"notes","tags":null,"title":"从Header中获取值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E4%BB%8Eheader%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%80%BC/"},{"content":"20210420后续：\n实际上我有点不想用Python去开发一些小工具了，Python好久不摸，API忘得太快了，Ide又给不到什么有用的信息，在观望一下吧。\n小小说明 这是我个人很久以前开发的一个辅助开发工具，最近有遇到类似的需求了，故记录下来。\n事情的起因是这样的：我们业务上经常需要和第三方对接，第三方提供的往往是一个json文件。我们在编写代码时，可能会构建一个map，然后把各个字段填充进去，我并不是很喜欢这种方案，感觉并不是太优雅。我比较喜欢用@Builder的方案，这样代码段落会比较清晰，看上去也很优雅。\n所以我就完成了这个辅助工具，这个工具可以解析一份json文件，然后输出类的定义代码。我在实现的时候，考虑了嵌套关系，所以生成的代码和实际情况是比较符合的，可以直接copy到项目中使用。\n这儿需要说明的是，因为当时编写的时候，只考虑了服务于接口开发，代码中充斥了很多和我们应用场景细细相关的东西，比如我解析时，是从data层开始解析的；最后生成的对象，也是很多个小对象包含在一个大的Data对象中；同时，我这边只考虑了String的场景。如果你有需求，可以自行调整一下代码。\n代码展示 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  import json outer_class = [] inner_class = {} class Field: def __init__(self, field_tame, field_type, is_list=False): self.fieldName = field_tame self.fieldType = field_type self.is_list = is_list def outer_dispose(data_element): for key in data_element: if isinstance(data_element[key], list): # 暂时不考虑list嵌套的问题 if len(data_element[key]) \u0026gt; 0: if isinstance(data_element[key][0], dict): outer_class.append(Field(key, key, True)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, data_element[key][0]) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;, True)) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;, True)) elif isinstance(data_element[key], dict): outer_class.append(Field(key, key)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, data_element[key]) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;)) def inner_dispose(class_name, element): for key in element: if isinstance(element[key], list): if len(element[key]) \u0026gt; 0: if isinstance(element[key][0], dict): inner_class[class_name].append(Field(key, key, True)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, element[key][0]) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;, True)) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;, True)) elif isinstance(element[key], dict): inner_class[class_name].append(Field(key, key)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, element[key]) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;)) def generateLine(prefix, field): result = \u0026#39;\u0026#39; if field.is_list: result += \u0026#39;%sprivate List\u0026lt;%s\u0026gt; %s;\\n\u0026#39; % (prefix, field.fieldType.capitalize(), field.fieldName) else: result += \u0026#39;%sprivate %s%s;\\n\u0026#39; % (prefix, field.fieldType.capitalize(), field.fieldName) return result def generateOuterClass(outer_class, inner_class_content): result = \u0026#39;\u0026#39; result += \u0026#39;@Data\\n\u0026#39; result += \u0026#39;@NoArgsConstructor\\n\u0026#39; result += \u0026#39;@AllArgsConstructor\\n\u0026#39; result += \u0026#39;public class %s{\\n\u0026#39; % \u0026#39;Temp\u0026#39; for field in outer_class: result += generateLine(\u0026#39;\\t\u0026#39;, field) result += \u0026#39;\\n\\n\u0026#39; result += inner_class_content result += \u0026#39;}\\n\u0026#39; return result def generateInnerClass(inner_class): result = \u0026#39;\u0026#39; for class_name in inner_class: result += \u0026#39;\\t@Data\\n\u0026#39; result += \u0026#39;\\t@Builder\\n\u0026#39; result += \u0026#39;\\t@NoArgsConstructor\\n\u0026#39; result += \u0026#39;\\t@AllArgsConstructor\\n\u0026#39; result += \u0026#39;\\tpublic static class %s{\\n\u0026#39; % class_name.capitalize() for field in inner_class[class_name]: result += generateLine(\u0026#39;\\t\\t\u0026#39;, field) result += \u0026#39;\\t}\\n\\n\u0026#39; return result if __name__ == \u0026#39;__main__\u0026#39;: with open(\u0026#39;input.json\u0026#39;, encoding=\u0026#39;utf8\u0026#39;) as file: root_element = json.load(file) data_element = root_element[\u0026#39;data\u0026#39;] if isinstance(data_element, list): if len(data_element) \u0026gt; 0: outer_dispose(data_element[0]) elif isinstance(data_element, dict): outer_dispose(data_element) else: raise Exception() inner_class_content = generateInnerClass(inner_class) print(generateOuterClass(outer_class, inner_class_content))   这份代码目前收录在python，如果你有兴趣，可以关注该项目最新的动态，或许我已经对这份代码进行了调整，且调整后更符合你的需求。\n","description":"","id":292,"section":"notes","tags":null,"title":"从json文件生成java对象的小工具","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%BB%8Ejson%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"content":"代码如下（该代码未执行，未在编辑器中编辑，纯粹记录使用）：\n1 2 3 4 5 6 7  // beans.xml ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;beans.xml\u0026#34;); // xxxConfiguration.class ApplicationContext applicationContext = new AnnotationConfigApplicationContext(xxxConfiguration.class)   ","description":"","id":293,"section":"notes","tags":null,"title":"从xml配置文件到基于注解的配置文件的演进","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BB%8Exml%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E6%BC%94%E8%BF%9B/"},{"content":"核心的目标是，用户传递的某个字段的值，在@RequestBody转换后，自动转换成枚举，因为枚举是全局的，所以可以直接赋值给entity的相应字段，然后调用mapper的方法进行入库。\n这个过程核心需求解决的问题如下：\n 用户提交数据时，需要将用户提交的值转换成一个枚举 controller方法是，需要将entity中的枚举的值返回回去 entity写入到库中时，需要完成枚举到值的转换 从库中读取数据到entity时，自动完成值到枚举的转换  提交、查询阶段 request类如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  @Data public class CreateDomainModelRequest { /** * 领域ID */ private String domainId; /** * 模型名 */ private String modelName; /** * 类型 * @see com.sdstc.dyf.meta.common.constant.enums.ModelType#value */ @JSONField(serializeUsing = EnumCodec.class, deserializeUsing = EnumCodec.class) private ModelType modelType; /** * 组织ID */ private String orgId; /** * 注意事项 */ private String note; }   其中ModelType枚举的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  package com.sdstc.dyf.meta.common.constant.enums; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.AccessLevel; /** * 类型 */ @AllArgsConstructor(access = AccessLevel.PROTECTED) public enum ModelType { /** * 系统 */ SYSTEM(\u0026#34;1\u0026#34;), /** * 自定义 */ CUSTOM(\u0026#34;3\u0026#34;), ; @Getter private String value; public static ModelType convert(String inputValue) { for (ModelType enumItem : ModelType.values()) { if (enumItem.getValue().equals(inputValue)) { return enumItem; } } throw new RuntimeException(\u0026#34;Enum Transfer Wrong.\u0026#34;); } }   入库、出库阶段 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_domain_model\u0026#34;, autoResultMap = true) public class DomainModelPo extends BasePo { /** * 领域ID */ private String domainId; /** * 模型名 */ private String modelName; /** * 类型 */ @TableField(typeHandler = ModelTypeTypeHandler.class) private ModelType modelType; /** * 组织ID */ private String orgId; /** * 注意事项 */ private String note; }   其中ModelTypeTypeHandler.java的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public class ModelTypeTypeHandler extends AbstractEnumTypeHandler\u0026lt;ModelType\u0026gt; { @Override protected ModelType parseValue(String inputParam) { return ModelType.convert(inputParam); } @Override protected String toValue(ModelType isModelRequired) { return isModelRequired.getValue(); } }   其中AbstractEnumTypeHandler.java的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public abstract class AbstractEnumTypeHandler\u0026lt;T\u0026gt; extends BaseTypeHandler\u0026lt;T\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException { ps.setObject(i, toValue(parameter)); } @Override public T getNullableResult(ResultSet rs, String columnName) throws SQLException { final Object inputParam = rs.getObject(columnName); return parseValue(String.valueOf(inputParam)); } @Override public T getNullableResult(ResultSet rs, int columnIndex) throws SQLException { final Object inputParam = rs.getObject(columnIndex); return parseValue(String.valueOf(inputParam)); } @Override public T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { final Object inputParam = cs.getObject(columnIndex); return parseValue(String.valueOf(inputParam)); } protected abstract T parseValue(String inputParam); protected abstract String toValue(T enumObject); }   参考资料   MybatisPlus中@TableField注解的使用\n  https://blog.csdn.net/intersting/article/details/93768803\n  深入解析Spring使用枚举接收参数和返回值机制并提供自定义最佳实践\n这部分内容包含了一些知识，但是我这次解决问题并没有使用到这些知识。\n  自定义fastjson对枚举类型的序列化及反序列化过程\n有参考该份文档。\n  ","description":"","id":294,"section":"notes","tags":null,"title":"从请求到入库都使用枚举","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E4%BB%8E%E8%AF%B7%E6%B1%82%E5%88%B0%E5%85%A5%E5%BA%93%E9%83%BD%E4%BD%BF%E7%94%A8%E6%9E%9A%E4%B8%BE/"},{"content":"这些依赖高频率的使用在我写Demo时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":295,"section":"notes","tags":null,"title":"代码开发常用依赖","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E4%BE%9D%E8%B5%96/"},{"content":"本次优化的目标：\n  Request、Response中不需要标注JSONField，序列化和反序列化时可自动完成Long类型到LocalDateTime类型的转换\n  当用对象接受参数中的传递的对象信息时，自动完成Long类型到LocalDateTime类型的转换，如下代码：\n  1 2 3 4 5 6  @Controller(/user) public void postUser(User user){ // todo something }    实现调用fastjson的序列化和反序列化化方法是，自动完成LocalDateTime类型到Long类型的转换\n  实体类上无需标注typeHandler，即可完成在数据出库入库时自动完成Long类型和LocalDateTime类型的转换（只需配置mybatis-plus的type-handler-packages，技术含量不好，所以不整理了）\n  Feign中的时间转换（临时加的这个目标，我只是将Fiegn的HttpMessageConverts换成了FastjsonHttpMessageConvert，我对Feign的了解还不深入，所以暂时不整理了）。\n  实现目标一 为了让实验环境了我们项目环境一致，我们进行如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { // 清除掉默认的HttpMessageConvert  converters.clear(); FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); fastJsonHttpMessageConverter.setSupportedMediaTypes(Arrays.asList( MediaType.APPLICATION_JSON, MediaType.ALL)); converters.add(fastJsonHttpMessageConverter); } }   并准备如下的测试类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @RestController public class TestController { @Data public static class User { private String username; private String password; private LocalDateTime time; } @PostMapping(\u0026#34;/createUser\u0026#34;) public User createUser(@RequestBody User user) { return user; } }   接下来进行如下实验：\n  Request中不加JSONField，完成用户输入的Long型到LocalDateTime类型的转换（实验中不需要任何配置，即可完成该目标）。\n  Response中不加入JSONFiled，可以将LocalDateTime类型转换成Long型。\n  第二个小实验 实验中，我们的请求和返回值分别如下：\n请求：\n1 2 3 4 5 6 7  { \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;time\u0026#34;: 1626696114000 }   返回值：\n1 2 3 4 5 6 7  { \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-07-19T20:01:54\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34; }   很显然time字段的返回目标并不符合我们的需求，我们期待该字段为number类型的时间戳。因此，我进行了如下配置（此处代码并不代表我最终的编码）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { // 清除掉默认的HttpMessageConvert  converters.clear(); FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); fastJsonHttpMessageConverter.setSupportedMediaTypes(Arrays.asList( MediaType.APPLICATION_JSON, MediaType.ALL)); SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器  serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); }); FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializeConfig(serializeConfig); converters.add(fastJsonHttpMessageConverter); }   实验结果表明，response中的LocalDateTime能够按照我们的需求，序列化成long型的时间戳（这段代码写的并不是很好，很容易看出来，写这段代码对Fastjson理解不足）。\n实现目标二 目标二和目标一看似是一样的，实际上千差万别。目标一中，请求数据放在请求体中，所以我们接受的时候必须使用@RequestBody，controller层方法由RequestMappingHandlerAdapter进行包装（我目前接触的几乎都是有这个适配器包装的），在RequestMappingHandlerAdapter中，经过层层处理后，我们寻找到了RequestResponseBodyMethodProcessor作为我们的参数处理器，然后由RequestResponseBodyMethodProcessor完成将请求体中的参数解析成我们方法中要的User对象。具体实现是根据MediaType寻找一个合适的HttpMessageConvert，所以我们只需要想办法在HttpMessageConvert做文章，就可以完成我们的目标。\n目标二中，我们构建实体的数据都是通过请求参数传递进来的。前面大部分内容时和实现目标一时一致的，但是到了参数绑定阶段，我们寻找到的是ServletModeAttributeMethodProcessor。在这个处理器的resolveArgument方法中，会寻找一些convert或者formatter完成String类型到目标类型的转换（我还没有找到相应的源码，但是原理上应该是这样的）。所以解决这个问题的方案就是增加一些我们自己的Convert或者Formatter，为了将所有MVC的配置集中在一起，我选择了实现Formatter，具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  @Override public void addFormatters(FormatterRegistry registry) { registry.addFormatter(new Formatter\u0026lt;LocalDateTime\u0026gt;() { @Override public String print(LocalDateTime object, Locale locale) { ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(object); return String.valueOf(object.toInstant(offset).toEpochMilli()); } @Override public LocalDateTime parse(String text, Locale locale) throws ParseException { long timestamp = Long.parseLong(text); Instant instant = Instant.ofEpochMilli(timestamp); ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone); } }); WebMvcConfigurer.super.addFormatters(registry); }   在我实际开发中，通过请求参数构建一个请求对象的需求比较少，可能只有刚接触SpringBoot的同学会不小心忘记写@RequestBody导致用参数接受数据。\n实现目标三 在进行目标一时，我已经很好的完成了该目标。在这个过程中，我意识到我对Fastjson的配置是全局的，所以不应该写在对MVC的配置类中，所以我仅仅进行了一些代码的重构，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @Configuration public class FastjsonConfig { @PostConstruct public void configFastjson() { SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器  serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); }); } }   我选择了用PostConstruct对Fastjson进行配置。实际上，这种全局配置我一直在担心一个问题，如果哪位同学在业务代码中不小心进行了该类的配置，那么这个功能类后续的表现将都不是我们想要的，这该怎么办呢？\n实现目标四 目标四的实现也非常的简单，我们仅仅只需要将MyBatis-Plus的配置项中增加如下配置即可：\n1 2 3 4  mybatis-plus:type-handlers-package:fun.junjie.mybatis.type  这时候，只要我们的字段为LocalDateTime类型，则会自动调用该TypeHandler，非常的优雅和舒服。\n","description":"","id":296,"section":"notes","tags":null,"title":"优化项目中LocalDateTime类型的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/localdatetime/%E4%BC%98%E5%8C%96%E9%A1%B9%E7%9B%AE%E4%B8%ADlocaldatetime%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"@Value注解我们平时用于从application.yml中获取配置，给到类中的字段，我一直以为这是这个字段存在的价值，知道最近才知道，这个注解其实是模拟的bean.xml配置文件中的属性注入配置。\n使用@Value支持三种赋值方式：\n 基本数值 使用SpEL：#{} 获取配置文件中的配置：${}  ","description":"","id":297,"section":"notes","tags":null,"title":"使用@Value赋值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BD%BF%E7%94%A8value%E8%B5%8B%E5%80%BC/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7  sudo docker pull docker.io/rabbitmq:3.8-management sudo docker run \\  --name rabbitmq -d \\  -p 15672:15672 -p 5672:5672 \\  docker.io/rabbitmq:3.8-management   添加账号  1 2 3 4 5 6 7  sudo docker exec -i -t rabbitmq bin/bash rabbitmqctl add_user root 123456 rabbitmqctl set_permissions -p / root \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; rabbitmqctl set_user_tags root administrator rabbitmqctl list_users   管理页面   http://192.168.30.174:15672 相关教程  docker安装RabbitMq  ","description":"","id":298,"section":"notes","tags":null,"title":"使用Docker快速启动一个RabbitMQ实例","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E4%BD%BF%E7%94%A8docker%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AArabbitmq%E5%AE%9E%E4%BE%8B/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class MyFactoryBean implements FactoryBean { @Override public Object getObject() throws Exception { return null; } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return null; } @Override public boolean isSingleton() { return false; } }   getObject：方法返回了用户创建的实例\ngetObjectType：指明了创建的实例的类型\nisSingleton：指明了创建的实例是否是单例\n具体使用时将FactoryBean注入到Spring上下文即可。注入后，通过id获取该FactoryBean得到的并不是该FactoryBean，而是getObject创建的Bean。如果在bean的名称前加一个\u0026amp;符号，则可以获得到该工厂的bean。\n1 2 3 4  run.getBean(\u0026#34;myFactoryBean\u0026#34;); // 获取的是getObject创建的bean run.getBean(\u0026#34;\u0026amp;myFactoryBean\u0026#34;); // 获取的是myFactoryBean    据说MyBatis等框架都是通过这种方式注入的。\n","description":"","id":299,"section":"notes","tags":null,"title":"使用FactoryBean注入Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BD%BF%E7%94%A8factorybean%E6%B3%A8%E5%85%A5bean/"},{"content":"常用指令  常用指令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  sudo docker pull nginx:alpine sudo docker tag nginx:alpine 192.168.30.174:80/test/nginx:alpine sudo docker push 192.168.30.174:80/test/nginx:alpine sudo docker tag jenkins/jenkins:lts 192.168.30.174:80/test/jenkins:lts sudo docker push 192.168.30.174:80/test/jenkins:lts sudo docker tag jenkins/jenkins:lts 192.168.30.174:80/test/jenkins:lts2 sudo docker push 192.168.30.174:80/test/jenkins:lts2 sudo docker tag cnych/jenkins:jnlp6 192.168.30.174:80/test/jenkins:jnlp6 sudo docker push 192.168.30.174:80/test/jenkins:jnlp6 sudo docker tag sonatype/nexus3:3.25.0 192.168.30.174:80/test/nexus3:3.25.0 sudo docker push 192.168.30.174:80/test/nexus3:3.25.0 sudo docker tag jenkinsci/jnlp-slave:latest 192.168.30.174:80/test/jnlp-slave:v1 sudo docker push 192.168.30.174:80/test/jnlp-slave:v1 sudo docker tag python:3.8.5 192.168.30.174:80/test/python:3.8.5 192.168.30.174:80/test/python:3.8.5 sudo docker tag busybox:latest 192.168.30.174:80/test/busybox:v1 sudo docker push 192.168.30.174:80/test/busybox:v1 sudo docker tag maven:alpine 192.168.30.174:80/test/maven:alpine sudo docker push 192.168.30.174:80/test/maven:alpine sudo docker tag google/cadvisor:latest 192.168.30.174:80/test/cadvisor:v1 sudo docker push 192.168.30.174:80/test/cadvisor:v1 sudo docker tag prom/prometheus:v2.1.0 192.168.30.174:80/test/prometheus:v2.1.0 sudo docker push 192.168.30.174:80/test/prometheus:v2.1.0   常用指令2  1 2 3 4 5 6 7  # junjie sudo docker tag jenkins/inbound-agent:4.3-4 192.168.30.174:80/test/inbound-agent:4.3-4 sudo docker push 192.168.30.174:80/test/inbound-agent:4.3-4 # 虚拟机 sudo docker pull 192.168.30.174:80/test/inbound-agent:4.3-4 sudo docker tag 192.168.30.174:80/test/inbound-agent:4.3-4 jenkins/inbound-agent:4.3-4   ","description":"","id":300,"section":"notes","tags":null,"title":"使用Harbor时的常用指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/harbor/%E4%BD%BF%E7%94%A8harbor%E6%97%B6%E7%9A%84%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"这块核心在于要调用一下matches或者find才能获取group中的值，我目前没有系统化的去研究这些Java中的正则，未来会系统研究一下。\n参考资料  Java写爬虫的时候，matcher.groupCount()返回为1，但是matcher.group(1)却抛异常  ","description":"","id":301,"section":"notes","tags":null,"title":"使用java正则时需要注意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E4%BD%BF%E7%94%A8java%E6%AD%A3%E5%88%99%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"这是一篇整理笔记，我很久前就开始使用这个技术了，但是一直没有整理。最近同事需要用，所以我简单整理一下，笔记中需要用到的资料我暂时去整理下载地址了，等以后有时间了，我在详细补充一下这份资料。\n准备二进制文件及K8S配置文件，并配置配置环境变量 如图，准备必要的二进制文件：\n然后配置环境变量，配置后，需要确保在命令行执行ktctl有输出（很基本的常识）。整个过程需要注意一点：不要修改者两个二进制文件的位置，如果你的系统里已经有了kubectl则可以删除kubectl这个二进制文件。因为ktctl中是直接调用kubectl，如果kubectl不在环境变量中，则无法启动。\n下一步是在你的home目录下建一个.kube目录，将kubernetes的config文件放在里面，这个大家都知道，是kubectl用来链接集群的配置文件，包含了用户名、密码，或者token之类的信息。\n启动二进制文件 下一步是在终端（终端需要管理员权限，因为需要修改host文件）运行如下如下指令：\n ktctl --namespace=dev connect --method=socks5 --dump2hosts 这条指令有两层含义：\n 去dump一下host文件， 使用的是socks代理（windows只支持socks代理）  下载Proxifier，并进行配置 如图，我只做了如下简单配置，便可以使用了（我把KT Connection运行在了我Linux服务器上，建议运行在自己本地）：\n我没有采用官网上建议的JVM Inject方案，因为这个方案在Windows上成功率非常的低。\n","description":"","id":302,"section":"notes","tags":null,"title":"使用KT Connect快速版","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/kt-connect/%E4%BD%BF%E7%94%A8kt-connect%E5%BF%AB%E9%80%9F%E7%89%88/"},{"content":"我在使用自编译的python3执行pyinstaller时遇到了如下问题：\n [root@base launch]# pyinstaller -F launch.py 31 INFO: PyInstaller: 4.3 31 INFO: Python: 3.8.9 62 INFO: Platform: Linux-3.10.0-1160.el7.x86_64-x86_64-with-glibc2.17 62 INFO: wrote /root/Software/launch/launch.spec 63 INFO: UPX is not available. 64 INFO: Extending PYTHONPATH with paths ['/root/Software/launch', '/root/Software/launch'] 67 INFO: checking Analysis 67 INFO: Building Analysis because Analysis-00.toc is non existent 67 INFO: Initializing module dependency graph... 67 INFO: Caching module graph hooks... 72 INFO: Analyzing base_library.zip ... 1333 INFO: Processing pre-find module path hook distutils from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/pre_find_module_path/hook-distutils.py'. 1334 INFO: distutils: retargeting to non-venv dir '/usr/local/python3/lib/python3.8' 3008 INFO: Caching module dependency graph... 3101 INFO: running Analysis Analysis-00.toc 3110 INFO: Analyzing /root/Software/launch/launch.py 3169 INFO: Processing pre-safe import module hook urllib3.packages.six.moves from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/pre_safe_import_module/hook-urllib3.packages.six.moves.py'. 3907 INFO: Processing module hooks... 3907 INFO: Loading module hook 'hook-certifi.py' from '/usr/local/python3/lib/python3.8/site-packages/_pyinstaller_hooks_contrib/hooks/stdhooks'... 3910 INFO: Loading module hook 'hook-_tkinter.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3954 INFO: checking Tree 3954 INFO: Building Tree because Tree-00.toc is non existent 3954 INFO: Building Tree Tree-00.toc 3958 INFO: checking Tree 3958 INFO: Building Tree because Tree-01.toc is non existent 3958 INFO: Building Tree Tree-01.toc 3983 INFO: checking Tree 3984 INFO: Building Tree because Tree-02.toc is non existent 3984 INFO: Building Tree Tree-02.toc 3985 INFO: Loading module hook 'hook-difflib.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3987 INFO: Loading module hook 'hook-distutils.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3993 INFO: Loading module hook 'hook-distutils.util.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3994 INFO: Loading module hook 'hook-encodings.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4026 INFO: Loading module hook 'hook-heapq.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4028 INFO: Loading module hook 'hook-lib2to3.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4053 INFO: Loading module hook 'hook-multiprocessing.util.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4054 INFO: Loading module hook 'hook-pickle.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-sysconfig.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-xml.etree.cElementTree.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-xml.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4091 INFO: Looking for ctypes DLLs 4111 INFO: Analyzing run-time hooks ... 4114 INFO: Including run-time hook '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/rthooks/pyi_rth_multiprocessing.py' 4116 INFO: Including run-time hook '/usr/local/python3/lib/python3.8/site-packages/_pyinstaller_hooks_contrib/hooks/rthooks/pyi_rth_certifi.py' 4120 INFO: Looking for dynamic libraries 4379 INFO: Looking for eggs 4379 INFO: Python library not in binary dependencies. Doing additional searching... Traceback (most recent call last): File \u0026quot;/usr/local/python3/bin/pyinstaller\u0026quot;, line 8, in \u0026lt;module\u0026gt; sys.exit(run()) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/__main__.py\u0026quot;, line 114, in run run_build(pyi_config, spec_file, **vars(args)) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/__main__.py\u0026quot;, line 65, in run_build PyInstaller.building.build_main.main(pyi_config, spec_file, **kwargs) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 737, in main build(specfile, kw.get('distpath'), kw.get('workpath'), kw.get('clean_build')) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 684, in build exec(code, spec_namespace) File \u0026quot;/root/Software/launch/launch.spec\u0026quot;, line 7, in \u0026lt;module\u0026gt; a = Analysis(['launch.py'], File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 242, in __init__ self.__postinit__() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/datastruct.py\u0026quot;, line 160, in __postinit__ self.assemble() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 476, in assemble self._check_python_library(self.binaries) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 581, in _check_python_library python_lib = bindepend.get_python_library_path() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/depend/bindepend.py\u0026quot;, line 956, in get_python_library_path raise IOError(msg) OSError: Python library not found: libpython3.8mu.so.1.0, libpython3.8m.so.1.0, libpython3.8m.so, libpython3.8.so.1.0 This would mean your Python installation doesn't come with proper library files. This usually happens by missing development package, or unsuitable build parameters of Python installation. * On Debian/Ubuntu, you would need to install Python development packages * apt-get install python3-dev * apt-get install python-dev * If you're building Python by yourself, please rebuild your Python with `--enable-shared` (or, `--enable-framework` on Darwin) 我执行了如下指令：\n ./configure --prefix=/usr/local/python3 --enable-shared make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 此时执行时，又有如下报错：\n [root@base launch]# pyinstaller -F launch.py /usr/local/python3/bin/python3.8: error while loading shared libraries: libpython3.8.so.1.0: cannot open shared object file: No such file or directory 我观察了Python3编译后的目录结构，发现了libpython3.8.so.1.0文件：\n我觉得很大可能性是make install指令没有将这个文件copy到相应的目录中，我手动完成了该操作：\n cp libpython3.8.so.1.0 /usr/lib64 同样的，因为编译安装的时候我已经设置了环境变量了，这块我不需要进行相应的配置。\n参考资料  Python打包方法——Pyinstaller CentOS下踩坑记录  ","description":"","id":303,"section":"notes","tags":null,"title":"使用自编译Python时执行pyinstaller时遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%BD%BF%E7%94%A8%E8%87%AA%E7%BC%96%E8%AF%91python%E6%97%B6%E6%89%A7%E8%A1%8Cpyinstaller%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"今天定位修复了一个比较难的问题。我们的项目将mybatis-plus升级到最新版后，发现了updateByBatch方法无效。最后层层排查下终于定位出这个问题：我们使用的hikari并将auto-commit配置成了false，而当我们使用updateByBatch方法时，有这样的一段逻辑判断：\n1 2 3 4 5 6 7  // PgStatement  if (connection.getAutoCommit()) { flags |= QueryExecutor.QUERY_SUPPRESS_BEGIN; }   这个时候得到的flags中就不包含自动提交的标记位，最终导致我们我们的executeBatch执行的sql最终没有提交。所以只需要将这个配置改为true就可以了。\n整个定位问题的过程发生了一些匪夷所思的问题，部分在定位的过程解决了，部分没有，先记录下来：\n  在同事的电脑上，我们步进的时候发现一行代码没有执行，直接跳过异常部分到了finally，这个很奇怪。以往的经验是我们使用的class文件和我们正在查看的class文件不一致才会导致这个问题，但是同事并没有手动配置class文件，完全是由Idea反编译的class文件。\n  我们使用了p6spy，但是只打印了select的sql语句，并没有打印update的语句（这直接导致我们认为update没有被执行，导致我寻找问题的重心一直是update为什么没有执行）。在定位问题的过程中，我发现，我们执行addBatch和executeBatch时，会直接跳过p6spy的Statement（甚至跳过了hikari的statement），这就是为什么p6spy没有打印执行的sql的原因。\n  还有一个问题，非常的迷惑，我在查看反射的时候，明明看到传入的是一个A的实例（A实例后面会跟一段描述：wrapping xxx），我在A实例的方法中断点，死活无法正常断到，我必须去wraping的实例中进行断点。甚至有些时候我去wrapping实例中断点，也无法成功的断点，我有点怀疑这些wrapping的实例时动态生成的。如果真的是这样，动态生成的实例，简直是调试的魔鬼。当然在这个场景下，我总结了一些定位问题的技巧，稍后会整理一下。\n  这次解决问题的过程中，我收获颇丰，整理如下：\n  学会了调式反射代码。\n  大致了解了MyBatis中整体架构，下次出问题了，知道该如何排查了。\n  因为了解了MyBatis的一些特点，所以我知道在定位问题中，不要被表象迷惑，可以直接在驱动器类上打断点。\n  简单了看了一下我们项目中MyBatis部分的架构，感觉功能挺丰富的，只是我在纠结，定制化过高，会不会不利于升级？\n  这次解决问题的过程中，我也产生了一些新的问题：\n 如果代码时动态生成了，我又该如何进行调试呢？  ","description":"","id":304,"section":"notes","tags":null,"title":"修复updateByBatch无法使用的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E4%BF%AE%E5%A4%8Dupdatebybatch%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"这个问题我之前从未遇到过，先说说我怎么发现这个问题的，我使用Helm安装chart时，发现Release一直处于Pending状态，所以我顺手查看了下nodes信息，发现除了Master节点，其他节点全部都处于NotReady状态。\n我采用如下方案修复了该问题，将所有节点重启，等待Master节点上的Kubectl指令可用（即Master上的服务启动成功）后，然后对所有从节点执行如下指令：\n systemctl restart docker systemctl restart kubelet 我分析是如下原因造成的，Master节点启动太慢了，导致从节点上的kubelet错误了连接时机。如果下次我重启PVE机器时该问题还会复现，我计划设置PVE的虚拟机启动延时。\n参考资料  k8s node节点重启后遇到的问题及解决 安全地清空一个节点  ","description":"","id":305,"section":"notes","tags":null,"title":"修复节点为NotReady的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E4%BF%AE%E5%A4%8D%E8%8A%82%E7%82%B9%E4%B8%BAnotready%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题描述 我们准备使用KT Connect，但是运维配置好了后，发现始终无法正常使用。我按照官方文档给的问题排查手册，发现最终报错为scoat，我自己搭建Istio时也遇到过关于socat的问题，但是当时没有深入研究，故对此理解并不够。\n我暂时依旧没有深入研究这些问题的计划，我计划等我有了稳定的实验环境时在系统研究这部分知识。\n","description":"","id":306,"section":"notes","tags":null,"title":"关于scoat的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E5%85%B3%E4%BA%8Escoat%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"Docker镜像源真的是非常让人头疼的东西，想将它们全部塞到自己的Harbor里，然后实现本地环境的高速拉取！！！\n  让 K8S 在 GFW 内愉快的航行\n  docker拉取镜像太慢的解决办法\n  https://blog.csdn.net/alex_yangchuansheng/article/details/106088715\n这个方案很高大上，如果以后要往这个方向深入发展，需要研究这份资料。\n  国内拉取google kubernetes镜像\n里面提到了镜像同步神器，很感兴趣，但是不知道用于什么场景。除此之外，这篇文章还提到了很多高级的知识，很要研究价值。\n  我思考的一些问题：\n 如果我将我所有K8S结点的Docker镜像源都设置成我的Harbor地址，能不能实现使用kubectl apply -f指令的时候也从我的Harbor里拉取镜像呢？感觉有很多未知的东西等待验证，不过我真的很期待这个方案。  ","description":"","id":307,"section":"notes","tags":null,"title":"关于镜像源的一些方案","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E5%85%B3%E4%BA%8E%E9%95%9C%E5%83%8F%E6%BA%90%E7%9A%84%E4%B8%80%E4%BA%9B%E6%96%B9%E6%A1%88/"},{"content":"下载地址如下：\n  alibaba/kt-connect\n  在 Linux 系统中安装并设置 kubectl\n  ","description":"","id":308,"section":"notes","tags":null,"title":"准备必要的二进制文件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/kt-connect/%E5%87%86%E5%A4%87%E5%BF%85%E8%A6%81%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"},{"content":"我选择的是将自己创建的Actions和源码放在一起，因为这些Actions使用的复用性挺低的，放在一起避免了创建另一个仓库，非常舒服：\n目录结构如下：\n其中Dockerfile文件如下：\n1 2 3 4 5 6 7 8 9 10  FROMalpine:3.10# Copies your code file from your action repository to the filesystem path `/` of the containerCOPY entrypoint.sh /entrypoint.shRUN chmod +x entrypoint.sh# Code file to execute when the docker container starts up (`entrypoint.sh`)ENTRYPOINT [\u0026#34;/entrypoint.sh\u0026#34;]  action.yml文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # action.ymlname:\u0026#39;Hello World\u0026#39;description:\u0026#39;Greet someone and record the time\u0026#39;inputs:who-to-greet:# id of inputdescription:\u0026#39;Who to greet\u0026#39;required:truedefault:\u0026#39;World\u0026#39;outputs:time:# id of outputdescription:\u0026#39;The time we greeted you\u0026#39;runs:using:\u0026#39;docker\u0026#39;image:\u0026#39;Dockerfile\u0026#39;args:- ${{ inputs.who-to-greet }}  entrypoint.sh如下：\n1 2 3 4 5 6 7  #!/bin/sh -l echo \u0026#34;Hello $1\u0026#34; time=$(date) echo \u0026#34;::set-output name=time::$time\u0026#34;   Reademe.md没有太多营养，这儿就不呈现了。\ngithub-actions-demo.yml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  on:[push]jobs:hello_world_job:runs-on:ubuntu-latestname:A job to say hellosteps:- name:Checkoutuses:actions/checkout@v2- name:Hello world action stepid:hellouses:./.github/actions/AdjustPicturesInMDFileswith:who-to-greet:\u0026#39;Mona the Octocat\u0026#39;# Use the output from the `hello` step- name:Get the output timerun:echo \u0026#34;The time was ${{ steps.hello.outputs.time }}\u0026#34;  参考资料   创建 Docker 容器操作\n我参考了官方的案例，但是官方的案例中存在一点小小的错误，所以Dockerfile文件应该参考我的。\n  ","description":"","id":309,"section":"notes","tags":null,"title":"创建Docker Action","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/github/%E5%88%9B%E5%BB%BAdocker-action/"},{"content":"命令如下：\n ","description":"","id":310,"section":"notes","tags":null,"title":"初始化项目的时候指定使用yaml格式的配置文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%97%B6%E5%80%99%E6%8C%87%E5%AE%9A%E4%BD%BF%E7%94%A8yaml%E6%A0%BC%E5%BC%8F%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"content":"C盘炸了，只剩下3G了，我基本不在C盘装任何东西，经同时提示发现是hiberfil.sys、pagefile.sys、swapfile.sys文件占用太大空间，这些文件没有什么价值，可以清理掉。\n清理hiberfil.sys 打开cmd工具，执行powercfg -h off，然后去删除hiberfil.sys文件（此时hiberfil.sys就消失了）\n调整pagefile.sys文件的大小 截图如下：\n（这一步需要点击一下当前页面上的设置按钮，然后再点确认按钮，我之前的截图忘记操作这一步，让人很迷惑，退回到高级页面没有任何效果）\n至于swapfile.sys，我暂时懒得管了，C盘已经腾出来不少空间了~\n参考资料   hiberfil.sys 可以删吗？【C盘清理】\n  如何删除pagefile.sys\n  ","description":"","id":311,"section":"notes","tags":null,"title":"删除hiberfil.sys","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E5%88%A0%E9%99%A4hiberfil.sys/"},{"content":"这项技术用于开发一些自动化脚本：\n1 2 3 4 5 6 7  if [ -z \u0026#34;$(git status --porcelain)\u0026#34; ]; then # Working directory clean else # Uncommitted changes fi   参考资料   从脚本确定Git工作目录是否干净\n这篇文章中还有一些其他技术的应用，比如忽略未跟踪的文件，因为我目前没有需求，故不关注这些技术了。\n  linux shell:判断git工作文件夹是否干净(clean)\n这篇文章中也有相关技术的讨论，我没有实践。\n  ","description":"","id":312,"section":"notes","tags":null,"title":"判断工作区是否干净","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/%E5%88%A4%E6%96%AD%E5%B7%A5%E4%BD%9C%E5%8C%BA%E6%98%AF%E5%90%A6%E5%B9%B2%E5%87%80/"},{"content":"我没有打算用DockerCompose，直接使用指令的方式也挺简单的。\n机器环境  系统CentOS 7.9 两块硬盘，一块装系统，一块挂载在/data目录下  网络环境  # 创建自定义bridge docker network create ToolNet # 将已有的容器链接到创建的网络（我没有使用该指令） docker network connect ToolNet [容器名称] # 查看网络信息 docker network inspect ToolNet MySQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 准备配置文件 mkdir -p /root/Software/Configuration/MySQL/conf tee /root/Software/Configuration/MySQL/conf/my.cnf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 [mysqld] sql-mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION character-set-server=utf8mb4 EOF # 启动Docker sudo docker run -d \\  --restart always -p 3306:3306 \\  --name mysql57 \\  --network ToolNet \\  -v /root/Software/Configuration/MySQL/conf/my.cnf:/etc/mysql/my.cnf \\  -v /data/MySQL/logs:/logs \\  -v /data/MySQL/data:/var/lib/mysql \\  -e MYSQL_ROOT_PASSWORD=HelloWorld \\  mysql:5.7.34   MongoDB 这个配置的细节处我还是不太了解，但是现在先这么搞着，方便使用\n docker run -d \\ --restart always -p 27017:27017 \\ --name mongodb \\ --network ToolNet \\ -v /data/MongoDB:/data/backup \\ -e MONGO_INITDB_ROOT_USERNAME=root \\ -e MONGO_INITDB_ROOT_PASSWORD=HelloWorld \\ mongo:4.4.6 docker run -d \\ --restart always -p 8081:8081 \\ --name mongodb-express \\ --network ToolNet \\ -e ME_CONFIG_MONGODB_SERVER=\u0026quot;mongodb\u0026quot; \\ -e ME_CONFIG_BASICAUTH_USERNAME=\u0026quot;junjie\u0026quot; \\ -e ME_CONFIG_BASICAUTH_PASSWORD=\u0026quot;junjie\u0026quot; \\ -e ME_CONFIG_MONGODB_ADMINUSERNAME=\u0026quot;root\u0026quot; \\ -e ME_CONFIG_MONGODB_ADMINPASSWORD=\u0026quot;HelloWorld\u0026quot; \\ mongo-express:0.54.0 YApi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  mkdir -p /root/Software/Configuration/YApi/conf tee /root/Software/Configuration/YApi/conf/config.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;port\u0026#34;: \u0026#34;3000\u0026#34;, \u0026#34;adminAccount\u0026#34;: \u0026#34;junjie2025@gmail.com\u0026#34;, \u0026#34;timeout\u0026#34;:120000, \u0026#34;db\u0026#34;: { \u0026#34;servername\u0026#34;: \u0026#34;mongodb\u0026#34;, \u0026#34;DATABASE\u0026#34;: \u0026#34;yapi\u0026#34;, \u0026#34;port\u0026#34;: 27017, \u0026#34;user\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;HelloWorld\u0026#34;, \u0026#34;authSource\u0026#34;: \u0026#34;admin\u0026#34; } } EOF docker run -it \\  --restart always \\  --network ToolNet \\  --entrypoint npm \\  --workdir /yapi/vendors \\  -v /root/Software/Configuration/YApi/conf/config.json:/yapi/config.json \\  registry.cn-hangzhou.aliyuncs.com/anoyi/yapi \\  run install-server docker run -d \\  --name yapi \\  --network ToolNet \\  --workdir /yapi/vendors \\  -p 3000:3000 \\  -v /root/Software/Configuration/YApi/conf/config.json:/yapi/config.json \\  registry.cn-hangzhou.aliyuncs.com/anoyi/yapi \\  server/app.js   可选操作，删除builder容器，这个好像没有什么用\n docker container rm -f boring_faraday 最后登录YApi时的账号密码为：junjie2025@gmail.com、ymfe.org\nEasyYApi 使用如下我自己开发Dockerfile，为什么要使用我自己的仓库了，是因为官方提供的仓库中的package.json中有个插件的版本会导致Bug，需要升级一下。但是我没有找到通过命令行方式升级某个插件版本的方法，所以就自己fork的了一个仓库。\n我对我这份Dockerfile还挺满意，我计划将YApi的安装也通过这种自己编辑Dockerfile的方式实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  FROMnode:12-alpine as builderWORKDIR/easyyapiRUN apk add --no-cache gitRUN git clone https://github.com/junjie2018/yapi-markdown-render.git .RUN npm installFROMnode:12-alpineENV TZ=\u0026#34;Asia/Shanghai\u0026#34;WORKDIR/easyyapiCOPY --from=builder /easyyapi /easyyapiEXPOSE3001ENTRYPOINT [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;3001\u0026#34;]  使用如下指令，构建该镜像，并启动该镜像\n docker build -t yapi-markdown-render:v1 . # 我还没测试，因为我测试Dockerfile时，该服务已经启动起来了，我懒得重搞，哈哈 docker run -d \\ --name yapi-markdown-render \\ --network ToolNet \\ -p 3001:3001 \\ yapi-markdown-render:v1 PostgresSQL  sudo docker run -d \\ --restart always -p 5432:5432 \\ --name postgres13 \\ --network ToolNet \\ -v /data/PostgresSQL:/var/lib/postgresql/data \\ -e POSTGRES_PASSWORD=HelloWorld \\ postgres:13.3-alpine 踩坑记录  我之前有这么一行配置：  这行配置的意思是说，将容器的/var/lib/mysql目录挂载到主机的目录上，我在抄写的时候，少了一层目录，导致无法无法正常启动数据库。\n相关教程 MySQL教程   docker 安装 mysql5.7\n  MySQL5.7 启动报错:initialize specified but the data directory has files in it. Aborting.\n  Docker自定义网络和运行时指定IP\n  Docker容器间通信方法\n非常重要的教程，在这篇教程里学会了自定义网络的使用。\n  MongoDB教程   Docker 下的 MongoDB + Mongo-Express 环境搭建\n学习了四个账号密码环境变量的配置。\n  Docker搭建MongoDB\n  学习了-v /mnt/mongo/backup:/data/backup配置，但是并不是太满意\n  学习了docker exec mongo sh -c 'exec var=date +%Y%m%d%H%M \u0026amp;\u0026amp; mongodump -h localhost --port 27017 -u test -p test1 -d dbname -o /data/backup/$var_test1.dat'，实际使用中，没有满足我的需求\n    官方Mongo镜像说明\n  官方MongoExpress镜像说明\n  Docker 安装 MongoDB\n  YAPI教程   顶尖 API 文档管理工具 (YAPI)\n我主要参考的是这个教程。\n  官方GitHub\n  使用docker安装yapi\n顶尖 API 文档管理工具 (YAPI)\nRyan-Miao/docker-yapi\nfjc0k/docker-YApi\nsilsuer/yapi\njayfong/yapi\nfjc0k/docker-YApi\n基本只是参考，并没有走这个方案。\n  EasyYApi资料  官方：easyyapi/yapi-markdown-render 我改的：junjie2018/yapi-markdown-render Markdown配置部分资料 使用 Dockerfile 定制镜像  PostgreSQL教程   Docker安装PostgreSQL\n  DockerHub PostgreSQL文档\n  ","description":"","id":313,"section":"notes","tags":null,"title":"利用Docker快速启动开发环境","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%88%A9%E7%94%A8docker%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"content":"我们的项目中有这样的一个需求：我们存在oss中的数据，仅记录其相对位置，但是当我们将这些数据返回给前端的时候，我们需要将这些相对位置转换成带有签名鉴权等信息的url。我们之前是如何处理这个问题的呢？当我们的数据从数据库查查来后，将这个数据转换成JSONObject或者JSONArray，然后一个一个字段的处理（拿出来，处理后，放回去）。\n我不是很满意这种处理方法，感觉代码量非常的大，而且非常的不优雅，所以我开发了如下的工具：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class OSSTagUtils { public static \u0026lt;T\u0026gt; T tagByJsonPaths(T target, Class\u0026lt;T\u0026gt; clazz, String[] jsonPaths) { // todo 研究一下能不能提升JSONPath的性能  // todo 寻找性能更高的的jsonPath框架  // todo 完善工具的边界检查  if (jsonPaths.length == 0) { return target; } // 这种写法是因为已有的Bean深拷贝工具对Map类型支持并不是很好，所以不如转换成JSONObject处理  JSONObject toDispose = (JSONObject) JSON.toJSON(target); for (String jsonPath : jsonPaths) { if (JSONPath.contains(toDispose, jsonPath)) { Object jsonPathValue = JSONPath.eval(toDispose, jsonPath); if (!(jsonPathValue instanceof String)) { throw new RuntimeException(\u0026#34;该jsonPath指向的值不为字符串类型\u0026#34;); } String accessUrl = OssUtil.storage.getAccessUrl(\u0026#34;\u0026#34;, (String) jsonPathValue); JSONPath.set(toDispose, jsonPath, accessUrl); } } return toDispose.toJavaObject(clazz); } }   从设计的角度来说，我这个工具还不是非常的强大，我仅对jsonPath指向的字段的值是String时才进行处理，而且我还没有考虑传入的jsonPath定位到一个字符串时如何处理。但是的但，这个工具目前是符合我自己的需求的，倘若我之后有其他的需求，我可以添加上相关的代码。\n过度设计和实现，价值意义并不大。\n参考资料  JsonPath - 根据表达式路径解析Json jsonpath - 使用 JSONPath 解析 JSON 完整内容详解 fastJson 之 JSONPath使用  ","description":"","id":314,"section":"notes","tags":null,"title":"利用JSONPath简化工作","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/%E5%88%A9%E7%94%A8jsonpath%E7%AE%80%E5%8C%96%E5%B7%A5%E4%BD%9C/"},{"content":"应用场景是这样的。我秉承的信念是，入库时每个字段都是需要被精细控制，所以我往往需要写一大堆setXXX方法，该工具就可以我快速生成这些代码：\n1 2 3 4 5 6 7 8 9 10 11  public static void main(String[] args) { for (Field field : FormPo.class.getDeclaredFields()) { System.out.println(String.format(\u0026#34;.%s(tmp.get%s())\u0026#34;, field.getName(), StringUtils.capitalize(field.getName()))); } }   有时间我会继续完善的。\n20210617后续：\n最近用Builder比较多，有时间改一下这个。\n","description":"","id":315,"section":"notes","tags":null,"title":"利用反射填充VO对象","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%88%A9%E7%94%A8%E5%8F%8D%E5%B0%84%E5%A1%AB%E5%85%85vo%E5%AF%B9%E8%B1%A1/"},{"content":"应用场景是这样的，你已经定义好的Request接受前端传递的参数，现在你需要测试下你的接口，你需要快速的生成一个可以被当前Request接受的json，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public static void main(String[] args) { for (Field field : PostFormRequest.class.getDeclaredFields()) { if (field.getType().equals(String.class)) { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%s\\\u0026#34;,\u0026#34;, field.getName(), \u0026#34;测试数据\u0026#34; + new Random().nextInt(100))); } else if (field.getType().equals(Integer.class)) { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%d\\\u0026#34;,\u0026#34;, field.getName(), new Random().nextInt(100000))); } else { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%s\\\u0026#34;,\u0026#34;, field.getName(), field.getType())); } } }   目前的这个我还不是太满意，我会花时间再优化这个工具的。\n","description":"","id":316,"section":"notes","tags":null,"title":"利用反射生成请求体","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%88%A9%E7%94%A8%E5%8F%8D%E5%B0%84%E7%94%9F%E6%88%90%E8%AF%B7%E6%B1%82%E4%BD%93/"},{"content":"当我感觉我有动态调整日志等级的需求时，我发现SpringBoot Actuator天然支持这种功能，进一步研究，我发现了SpringBoot Admin对SpringBoot Actuator进一步包装，提供了更友好的界面。但是SpringBoot Admin的定位不仅仅在于日志等级动态调整，且启用该功能需要每个服务都配置Admin Server，我并不是很满意这一点。\nSpringBoot Admin局限性在于在调整logger等级时比较好用，在其他方面，我还没有发现什么特色。至于监控、查看Bean信息等，这些功能使用的频率并不高。如果只是为了调整logger等级，我比较热衷于开发一个小脚本实现。\n如果SpringBoot Admin可以调整为用户主动添加式的，就是我启动一个Admin Server，然后我将我的一个服务地址给到它，它自动去请求数据，然后渲染服务相关的信息，如果我不需要它帮我监控了，我直接删除这个服务就好了。那么，我还是会选择Spring Boot Admin，并将这个工具作为我的工具箱之一。\n无意间看到了美团团队关于这个问题的讨论，他们是在超高并发场景下讨论动态调整日志等级的重要性，并开发了自己的框架，而且他们还考虑到RestFul服务和纯RPC服务对该功能的需求。我们的产品目前没有超高并发的需求，而且我们也不存在纯RPC服务。我打算收集这些资料，并持续关注着，至于我目前的需求，我还是打算找一款更简单的工具或者直接通过脚本实现。\n资料收集  Spring Boot 2动态修改日志级别 日志级别动态调整——小工具解决大问题 junjie2018/dynamic_adjust_log_level  ","description":"","id":317,"section":"notes","tags":null,"title":"动态调整日志等级","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E6%97%A5%E5%BF%97%E7%AD%89%E7%BA%A7/"},{"content":"公司开新项目，我参考以往的代码起了一个项目，项目启动很成功，但是请求时报如下错误：\n我们开发了相应的拦截器，负责解析请求中传递的token，将token中的信息塞到属性中（当且仅当请求不通过网关直接请求服务时）。但是从如上报错信息中可以看出我们的拦截器并没有起到作用。在我们的拦截器UserInfoInterceptor中打上断点，结果发现请求确实没有进入我们的拦截器。\n观察以往项目，发现我们的新项目结构和以往的包结构是有出入的，以往的项目包结构为com.abc.project，而新项目为com.abc.project.server，新项目想较以往的项目多了一层包结构。然后一些奇奇怪怪的原因，就导致我们的包无法被扫描到，从而无法加载UserInfoInterceptor到SpringBean中。\n后来我将我们的启动类改为如下配置，该问题恢复了。\n我对这个问题做了一些分析，com.sdstc.pdm.server包是肯定会被自动扫描到的，com.sdstc.core包是无法被自动扫描到，实际上com.sdstc.pdm.server也确实被自动扫描到了，而com.sdstc.core没有。想要实现com.sdstc.core包被自动扫描到，我们可以通过开发starter实现这个效果。\n","description":"","id":318,"section":"notes","tags":null,"title":"包扫描位置指定错误，导致无法进入自定义Intercepter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E5%8C%85%E6%89%AB%E6%8F%8F%E4%BD%8D%E7%BD%AE%E6%8C%87%E5%AE%9A%E9%94%99%E8%AF%AF%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95%E8%BF%9B%E5%85%A5%E8%87%AA%E5%AE%9A%E4%B9%89intercepter/"},{"content":"报错如下（这个报错不是我场景中的报错）：\n Installing GitBook 3.2.3 /home/travis/.nvm/versions/node/v12.18.3/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 if (cb) cb.apply(this, arguments) ^ TypeError: cb.apply is not a function at /home/travis/.nvm/versions/node/v12.18.3/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 at FSReqCallback.oncomplete (fs.js:169:5) The command \u0026quot;gitbook install\u0026quot; failed and exited with 1 during . 我采用的方案：\n cd /usr/lib/node_modules/gitbook-cli npm i graceful-fs@4.1.4 --save cd /usr/lib/node_modules/gitbook-cli/node_modules/npm npm i graceful-fs@4.1.4 --save 我觉得node.js是我一生之敌，各种各样的问题太多了！！！\n参考资料  Gitbook build stopped to work in node 12.18.3  ","description":"","id":319,"section":"notes","tags":null,"title":"升级Node到V14后，gitbook-cli无法正常运行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/%E5%8D%87%E7%BA%A7node%E5%88%B0v14%E5%90%8Egitbook-cli%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C/"},{"content":"定位这个问题差不多花了我半个小时，所以有必要将其记录下来，我在开发我的工具包，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @Data public class TableRoot { private String tblName; private String tblDesc; private List\u0026lt;ColumnRoot\u0026gt; columns; public TableRoot(String tblName, String tblDesc) { this.tblName = tblName; this.tblDesc = tblDesc; this.columns = new ArrayList\u0026lt;\u0026gt;(); } @Data @SuppressWarnings(\u0026#34;WeakerAccess\u0026#34;) public static class ColumnRoot { private String colName; private String colDesc; @JSONField(deserializeUsing = JavaTypeCodec.class, serializeUsing = JavaTypeCodec.class) private JavaType javaType; } }   我在反序列化json文件时，返现columns的值始终为空，而tblName和tblDesc的值正常，这种情况以往从未发生过。后来我发现是因为我TableRoot缺少默认的构造函数，这个还是蛮坑的。\n如果去分析fastjson的源码，我可以肯定我能清晰的知道背后的原因，但是现在实在是没有必要这么去做，哈哈。\n","description":"","id":320,"section":"notes","tags":null,"title":"反序列化时缺少默认构造函数导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E7%BC%BA%E5%B0%91%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"使用场景是这样的，我们要将本地的数据库导入到阿里的数据库中，如果通过shell执行这个导入工作，可能会因为shell链接中断，导致导入工作失败，所以想到了这个方案。\n我已经忘记了实施效果了。这个是很久前收藏的文档。\n20210615后续：\n现在看一看，我似乎有很多方案实现这种效果。\n参考资料  MySQL后台执行SQL导入  ","description":"","id":321,"section":"notes","tags":null,"title":"后台执行MySQL导入","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/mysql/%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8Cmysql%E5%AF%BC%E5%85%A5/"},{"content":"类似PostConstructor、PreDestroy等，我一直在代码中使用，但是我从来没有系统的去学习和调节它们，这次看到了，刚好一起整理一下。\n@PostConstructor、@PreDestroy JSR250规定了两个注解：\n @PostContructor：在bean创建完成并且属性赋值完成，来执行初始化方法 @PreDestroy：在容器销毁bean之前通知我们进行清理工作  在@Bean中指定initMethod和destroyMethod 代码如下：\n1 2 3  @Bean(initMethod = \u0026#34;init\u0026#34;, destroyMethod = \u0026#34;destroy\u0026#34;)   Bean实现InitializingBean和DisposableBean InitializingBean：定义初始化逻辑\nDisposableBean：定义销毁逻辑\n开发BeanPostProcesor bean的后置处理器，在bean初始化前后进行一些处理工作。\n这个后置处理器会在每个bean注入到容器时都调用一次，开发者可以通过名称、实例等判断出自己需要进行处理的bean，然后进行处理。\n","description":"","id":322,"section":"notes","tags":null,"title":"四种方式管理Bean的生命周期","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%AE%A1%E7%90%86bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"content":"纯粹整理一下，感觉实战意义不大。\n  包扫描+组件标注注解（@Controller、@Service、@Repository等）\n  @Bean导入第三方包里面的组件\n  @Import快速给容器中导入一个组件\n  @Import(要导入到容器中的组件)：id默认为全类名\n  @Import(ImportSelector的实现类)：返回需要导入的组件的全类名数组\n  @Import(ImportBeanDefinitionRegister的实现类)：手动注册bean到容器中\n    使用Spring提供的FactoryBean\n  后续：\n收集了一段有趣的代码，在SpringBoot中用的可能会比较少，但是有时候想快速测一些东西时，还是可以用到的。\n1 2 3 4 5 6  AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); applicationContext.register(XXXConfiguration.class); applicationContext.refresh();   ","description":"","id":323,"section":"notes","tags":null,"title":"四种方式给Spring容器注入组件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%BB%99spring%E5%AE%B9%E5%99%A8%E6%B3%A8%E5%85%A5%E7%BB%84%E4%BB%B6/"},{"content":"我在CentOS上，通过在github上下载release包的方式安装了hugo，但是安装后无法启动，报如下错误：\n [root@base junjie.com]# hugo server --minify --theme book --bind=\u0026quot;0.0.0.0\u0026quot; hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by hugo) 我解决了一阵子，没有什么优雅、方便、快捷、易于理解的解决方案，遂放弃了，转而在Ubuntu上研究hugo。\n解决这个问题的心得就是，以后新东西的研究还是在Ubuntu上搞吧，在CentOS上往往需要花费大量的时间。\n","description":"","id":324,"section":"notes","tags":null,"title":"因为centos依赖文件太旧，而无法启动hugo","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/%E5%9B%A0%E4%B8%BAcentos%E4%BE%9D%E8%B5%96%E6%96%87%E4%BB%B6%E5%A4%AA%E6%97%A7%E8%80%8C%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8hugo/"},{"content":"如图，我Idea编辑器中无运行按钮：\n当我注释掉一个类后，运行按钮恢复了：\n很奇怪的现象，之前没有注意到存在这个问题。\n","description":"","id":325,"section":"notes","tags":null,"title":"因为引入了错误的类，导致main方法无运行按钮","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%9B%A0%E4%B8%BA%E5%BC%95%E5%85%A5%E4%BA%86%E9%94%99%E8%AF%AF%E7%9A%84%E7%B1%BB%E5%AF%BC%E8%87%B4main%E6%96%B9%E6%B3%95%E6%97%A0%E8%BF%90%E8%A1%8C%E6%8C%89%E9%92%AE/"},{"content":"因为我的脚本会生成SUMMARY.md和Reademe.md，所以我一致认为gitbook init操作是没有意义的（其实我至今仍然认为这个操作没有任何意义），所以我选择直接使用gitbook build指令，结果发现我的折叠等插件根本没有生效。这个问题对我来说非常严重，如果笔记不能够折叠，看上就会有点乱糟糟的。\n我花费了一个晚上定位修复这个问题，最后定位到了gitbook init操作上。gitbook init操作做了什么，目前我认为它主要生成了SUMMARY.md和README.md文件，而之所以我没有运行gitbook init导致我插件失效的原因就是，我的脚本是在Windows上开发的，我的SUMMARY.md生成的时候使用的是Windows的分割符，而gitbook貌似不支持这种分割符。\n以往之所以能够成功，我觉得这里面更多的是运气吧，可能我运气好执行了gitbook init，又或者我的SUMMARY.md文件和gitbook init生成的几乎一致，所以导致我一直没有意识到这个问题。\n后续：\n这个问题可能没有我想象的这么简单，我又进行了一些尝试，如果我项目里原本没有READEME.md和SUMMARY.md则运行gitbook init后生成的SUMMARY.md也是空的（我需要再次验证这个问题），只有当我的项目里有SUMMARY.md时，gitbook init才会打印一些奇怪的create的日志信息（不是很理解这个日志信息）。\n我是真的很想换掉gitbook了，node.js的版本问题就像魔鬼一样，我永远都不知道该使用哪个版本？现在gitbook暴漏出太多我无法理解的问题，需要靠无数次尝试才能够解决的问题，加之GitBook构建速度实在是太慢了，加之官方已经没有对GitBook Cli工具进行维护了。我现在真的挺想放弃GitBook。\n","description":"","id":326,"section":"notes","tags":null,"title":"因为没有执行git init导致折叠插件不生效","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/%E5%9B%A0%E4%B8%BA%E6%B2%A1%E6%9C%89%E6%89%A7%E8%A1%8Cgit-init%E5%AF%BC%E8%87%B4%E6%8A%98%E5%8F%A0%E6%8F%92%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88/"},{"content":"今天我在某个分组下创建了一个项目，向这个项目推送代码时始终报错。我没有在第一时间联想到是权限的问题导致的错误，从而导致我花费了大量的时间来解决这个问题。\n其实奇怪的问题是，我在这组只有developer权限，但是其他项目我都可以正常的推送代码，只有这个我自己新建的项目不能正确的推送。\n先记录一下吧，防止下次在相同的问题上浪费太多的时间。\n","description":"","id":327,"section":"notes","tags":null,"title":"因缺少权限导致无法推送代码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/%E5%9B%A0%E7%BC%BA%E5%B0%91%E6%9D%83%E9%99%90%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81/"},{"content":"之所以选择卸载Docker，是因为我觉得简单工具的安装使用Docker只是提供了安装便利性，工具运行时并没有直接安装在物理机或虚拟机上那么高性能（直觉，未验证）。\n yum list installed | grep docker # 这种方式貌似会删除较多的东西，还是建议一个一个的删除，安全些 yum -y remove docker* rm -rf /var/lib/docker # 如果不执行这一步的话，docker的适配器不会消失 reboot 参考资料  [https://blog.csdn.net/liujingqiu/article/details/74783780](Centos 7 如何卸载docker)  ","description":"","id":328,"section":"notes","tags":null,"title":"在CentOS 7中卸载docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos-7%E4%B8%AD%E5%8D%B8%E8%BD%BDdocker/"},{"content":"问题描述 我在CenOS 8中搭建了Docker，然后启动了一个busybox，我在busybox中无法ping通任何IP地址。我大概知道是防火墙那块出了问题，我关闭防火墙，重启Docker后，这个问题会消失。我打算等系统学完iptables后再来解决这个问题。\n","description":"","id":329,"section":"notes","tags":null,"title":"在CentOS 8中Docker容器无法访问网络（待完成）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos-8%E4%B8%ADdocker%E5%AE%B9%E5%99%A8%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":" 20210504:\n该方案在CentOS 7和CentOS 8上均可用\n 使用Ubuntu时，一直是直接在网上找一篇教程来使用，这次求稳去官方找了篇文档，进行操作，我将我使用到的指令整理如下：\n 安装yum-utils（yum-utils提供了yun-config-manager工具），并设置文档的仓库（说实话，我对yum和dnf其实还不太熟悉）：  1 2 3 4 5 6  yum install -y yum-utils yum-config-manager \\  --add-repo \\  https://download.docker.com/linux/centos/docker-ce.repo   安装docker   yum install docker-ce docker-ce-cli containerd.io 这个遇到到了一些小插曲，安装的时候报如下错误：\n Last metadata expiration check: 0:02:47 ago on Sat 10 Apr 2021 02:02:50 PM CST. Error: Problem 1: problem with installed package podman-2.0.5-5.module_el8.3.0+512+b3b58dca.x86_64 - package podman-2.0.5-5.module_el8.3.0+512+b3b58dca.x86_64 requires runc \u0026gt;= 1.0.0-57, but none of the providers can be installed - package podman-2.2.1-7.module_el8.3.0+699+d61d9c41.x86_64 requires runc \u0026gt;= 1.0.0-57, but none of the providers can be installed - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - cannot install the best candidate for the job - package runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64 is filtered out by modular filtering Problem 2: problem with installed package buildah-1.15.1-2.module_el8.3.0+475+c50ce30b.x86_64 - package buildah-1.15.1-2.module_el8.3.0+475+c50ce30b.x86_64 requires runc \u0026gt;= 1.0.0-26, but none of the providers can be installed - package buildah-1.16.7-4.module_el8.3.0+699+d61d9c41.x86_64 requires runc \u0026gt;= 1.0.0-26, but none of the providers can be installed - package docker-ce-3:20.10.5-3.el8.x86_64 requires containerd.io \u0026gt;= 1.4.1, but none of the providers can be installed - package containerd.io-1.4.3-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - cannot install the best candidate for the job - package containerd.io-1.4.3-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package runc-1.0.0-56.rc5.dev.git2abd837.module_el8.3.0+569+1bada2e4.x86_64 is filtered out by modular filtering - package runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64 is filtered out by modular filtering (try to add '--allowerasing' to command line to replace conflicting packages or '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages) 经过查询资料了解，podman也是一种类似与Docker的容器服务，CentOS会默认安装podman，结果就导致了冲突，所以这个地方需要先将podman给卸载掉。\n yum -y erase podman buildah 网上对podman的评价还是蛮高的，但是我不清楚我目前研究的Kubernetes技术栈是否有使用podman的计划，如果有的话，我会安排时间研究下这个东西。\n启动并设置开机运行Docker   systemctl start docker systemctl enable docker 配置镜像加速  Docker镜像加速，我目前主要用阿里云的。首次使用阿里云镜像加速时需要注册（具体细节我忘记了，可以百度下）\n sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF' { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://coded9m2.mirror.aliyuncs.com\u0026quot;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 参考文档  Install Docker Engine on CentOS CentOS8卸载podman安装docker 阿里云镜像加速器 Docker 镜像加速教程  ","description":"","id":330,"section":"notes","tags":null,"title":"在CentOS中安装Docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos%E4%B8%AD%E5%AE%89%E8%A3%85docker/"},{"content":"核心就两点：\n 搜索json、md等文件中的内容，可以直接搜索 搜索编译后的字节码中的内容，需要先下载源码（参考我Idea分类下另外的笔记）  参考资料  https://blog.csdn.net/w8y56f/article/details/103292300  ","description":"","id":331,"section":"notes","tags":null,"title":"在Idea中搜索jar包中的内容","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%9C%A8idea%E4%B8%AD%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9/"},{"content":"问题描述 在导入项目时，我按下图配置了Maven，同时我的setting.xml文件是从我同事那要的。结果我项目中多处报红。\n解决步骤 修改setting.xml文件中如下标签，该标签需要与在Idea中配置位置对应。\n1 2 3  \u0026lt;localRepository\u0026gt;D:\\MavenRepository\\repository\u0026lt;/localRepository\u0026gt;   ","description":"","id":332,"section":"notes","tags":null,"title":"在Idea中配置Maven时遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E5%9C%A8idea%E4%B8%AD%E9%85%8D%E7%BD%AEmaven%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"自从用了RestTemplate，我已经很少在Java代码中使用HttpClient之类的东西了。RestTemplate的便利性，能够帮助我快速的开发一些小工具。\n我接下来需要研究的RestTemplate的技术是：看能不能脱离SpringBoot项目使用RestTemplate。现阶段使用这个工具时我还需要初始化一个SpringBoot项目，有点麻烦。\nRestTemplate的Get请求，优雅的传递参数的方法如下：\n1 2 3 4 5 6 7 8 9 10 11  UriComponents apiInterfaceListUrl = UriComponentsBuilder.fromUriString(YAPI) .path(YApi.API_INTERFACE_LIST.getPath()) .queryParam(\u0026#34;token\u0026#34;, TOKEN) .queryParam(\u0026#34;limit\u0026#34;, RESPONSE_ITEM_LIMIT) .build(); ApiInterfaceListResponse apiInterfaceListResponse = restTemplate.getForObject( apiInterfaceListUrl.toUriString(), ApiInterfaceListResponse.class);   queryParam方法是允许传递一个Map\u0026lt;String, String\u0026gt;类型的参数的，但是我没有找到一个很好的工具将一个对象转换成Map\u0026lt;String, String\u0026gt;，自己开发这个工具，我暂时又没有足够的动力，所以暂时先直接传递字符串了。\n参考教程  使用RestTemplate发送get请求,获取不到参数的问题  ","description":"","id":333,"section":"notes","tags":null,"title":"在RestTemplate的Get请求中，稍微优雅的传递参数的方式","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/%E5%9C%A8resttemplate%E7%9A%84get%E8%AF%B7%E6%B1%82%E4%B8%AD%E7%A8%8D%E5%BE%AE%E4%BC%98%E9%9B%85%E7%9A%84%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E7%9A%84%E6%96%B9%E5%BC%8F/"},{"content":"今天在调MyBatis-Plus Generator时，遇到一个奇怪的问题：我配置了表信息，断点调试的时候发现获取的tableInfo信息时，长度总为零。我敏锐的感觉到是数据库配置出现了问题。MyBatis-Plus Generator没有报任何错误，我使用PostgreSQL的经验比较少，很难定位到问题的原因，所以我决定用JdbcTemplate调试代码。\npom.xml文件如下，我基本上没怎么动，就是使用SpringBoot初始化器初始出一份代码，然后加上Generator相关的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;fun.junjie\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatisplus-code-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;mybatisplus-code-generator\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;spring-boot.version\u0026gt;2.3.7.RELEASE\u0026lt;/spring-boot.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.postgresql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;postgresql\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;42.2.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.freemarker\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;freemarker\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.31\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.8\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.7.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt;fun.junjie.mybatisplus.code.generator.MybatisplusCodeGeneratorApplication\u0026lt;/mainClass\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;repackage\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;   application.properties代码如下\n spring.application.name=mybatisplus-code-generator server.port=8888 spring.datasource.url=jdbc:postgresql://192.168.19.12:5432/dyf?currentSchema=dyf\u0026amp;stringtype=unspecified spring.datasource.username=postgres spring.datasource.password=dev.DB spring.datasource.driver-class-name=org.postgresql.Driver 这份配置文件中有很多地方需要了解一下：我们数据库结构为：dyf库下的dyf模式。如果在配置的时候不加currentSchema=dyf，则无法检索出目标表。\n测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package fun.junjie.mybatisplus.code.generator.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jdbc.core.JdbcTemplate; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.util.Map; /** * @author wujj */ @RestController public class TestController { @Autowired private JdbcTemplate jdbcTemplate; @GetMapping(\u0026#34;test\u0026#34;) public void test() { Map\u0026lt;String, Object\u0026gt; stringObjectMap = jdbcTemplate.queryForMap(\u0026#34;select * from t_dyf_app\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } }   整个实验环境让我花费时间最多的就是，找到currentSchema=dyf配置。在使用该配置前，我尝试了使用spring.datasource.scheme=dyf配置，结果无法正常启动。\n该配置在测试环境能正常运行了，但是在我做MyBatis-Plus Generator时，依旧没有作用。在MyBatis-Plus Generator中，需要在DataSourceConfig配置中通过setSchemaName指定dyf模式。因为我后来决定不使用MyBatis-Plus Generator，而是自己开发一个该工具，所以我暂时放弃了对该技术的研究。\n","description":"","id":334,"section":"notes","tags":null,"title":"在SpringBoot中使用JdbcTemplate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E5%9C%A8springboot%E4%B8%AD%E4%BD%BF%E7%94%A8jdbctemplate/"},{"content":"操作步骤  引入依赖  1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   准备配置文件  1 2 3 4 5 6 7  spring:rabbitmq:host:192.168.30.174port:5672username:adminpassword:123456virtual-host:/  准备配置类  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package cn.watsons.mmp.brand.api.config; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.support.converter.SimpleMessageConverter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitConfig { @Bean public Queue Queue() { return new Queue(\u0026#34;hello\u0026#34;); } }   准备测试文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package cn.watsons.mmp.brand.api.rabbit; import cn.watsons.mmp.brand.api.BrandMemberApiApplication; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.amqp.core.AmqpTemplate; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.Date; @RunWith(SpringRunner.class) @SpringBootTest(classes = {BrandMemberApiApplication.class}) public class RabbitMQTest { @Autowired private AmqpTemplate rabbitTemplate; @Test public void send() { String context = \u0026#34;hello \u0026#34; + new Date(); System.out.println(\u0026#34;Sender : \u0026#34; + context); this.rabbitTemplate.convertAndSend(\u0026#34;hello\u0026#34;, context); } }   相关教程  Spring Boot(八)：RabbitMQ 详解  ","description":"","id":335,"section":"notes","tags":null,"title":"在SpringBoot中配置RabbitMQ","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/rabbitmq/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AErabbitmq/"},{"content":"操作步骤  引入依赖  1 2 3 4 5 6 7 8 9  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   准备配置文件  1 2 3 4 5 6 7 8 9 10 11 12  spring:redis:database:12host:192.168.75.62port:6379timeout:60slettuce:pool:max-active:100max-idle:100min-idle:50max-wait:6000  准备配置类  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  package cn.watsons.mmp.brand.api.config.redis; import com.alibaba.fastjson.support.spring.FastJsonRedisSerializer; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.cache.annotation.CachingConfigurerSupport; import org.springframework.cache.annotation.EnableCaching; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.*; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.net.UnknownHostException; /** * redis配置类 * * @program: springbootdemo * @Date: 2019/1/25 15:20 * @Author: Mr.Zheng * @Description: */ @Configuration @EnableCaching //开启注解 public class RedisConfig extends CachingConfigurerSupport { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(LettuceConnectionFactory connectionFactory) { RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new FastJsonRedisSerializer\u0026lt;\u0026gt;(Object.class)); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; } @Bean public StringRedisTemplate stringRedisTemplate(LettuceConnectionFactory connectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(connectionFactory); return template; } @Bean public HashOperations\u0026lt;String, String, Object\u0026gt; hashOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForHash(); } @Bean public ValueOperations\u0026lt;String, Object\u0026gt; valueOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForValue(); } @Bean public ListOperations\u0026lt;String, Object\u0026gt; listOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForList(); } @Bean public SetOperations\u0026lt;String, Object\u0026gt; setOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForSet(); } @Bean public ZSetOperations\u0026lt;String, Object\u0026gt; zSetOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForZSet(); } }   准备测试文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package cn.watsons.mmp.brand.api.redis; import cn.watsons.mmp.brand.api.BrandMemberApiApplication; import cn.watsons.mmp.brand.api.utils.RedisUtil; import lombok.RequiredArgsConstructor; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.test.context.junit4.SpringRunner; import org.springframework.web.client.RestTemplate; @RequiredArgsConstructor @RunWith(SpringRunner.class) @SpringBootTest(classes = {BrandMemberApiApplication.class}) public class RedisTest { @Autowired private RedisTemplate redisTemplate = new RedisTemplate(); @Autowired private RedisUtil redisUtil; @Test public void test() { redisUtil.set(\u0026#34;temp\u0026#34;, \u0026#34;you are fun...\u0026#34;); System.out.println(redisUtil.get(\u0026#34;temp\u0026#34;)); } }   ","description":"","id":336,"section":"notes","tags":null,"title":"在SpringBoot中配置Redis","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AEredis/"},{"content":"问题描述  描述如下   java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:123) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:244) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redisUtil': Unsatisfied dependency expressed through field 'redisTemplate'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:893) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:120) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 24 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:797) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 43 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:884) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:788) ... 56 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:650) ... 70 more Caused by: java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration$LettucePoolingClientConfigurationBuilder.\u0026lt;init\u0026gt;(LettucePoolingClientConfiguration.java:94) at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration.builder(LettucePoolingClientConfiguration.java:51) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration$PoolBuilderFactory.createBuilder(LettuceConnectionConfiguration.java:159) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.createBuilder(LettuceConnectionConfiguration.java:107) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.getLettuceClientConfiguration(LettuceConnectionConfiguration.java:92) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.redisConnectionFactory(LettuceConnectionConfiguration.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 71 more Caused by: java.lang.ClassNotFoundException: org.apache.commons.pool2.impl.GenericObjectPoolConfig at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 82 more 解决步骤  引入commons-pool2  1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":337,"section":"notes","tags":null,"title":"在SpringBoot中配置了Redis连接池后链接失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AE%E4%BA%86redis%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%90%8E%E9%93%BE%E6%8E%A5%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":" 依赖文件   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; application.yml文件   spring: datasource: # driver-class-name: org.postgresql.Driver # 原始的 driver-class-name: com.p6spy.engine.spy.P6SpyDriver # 使用p6spy后的 password: HelloWorld # url: jdbc:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 原始的 url: jdbc:p6spy:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 使用p6spy后的 username: postgres 参考资料  spring boot整合使用JdbcTemplate之详解!!  ","description":"","id":338,"section":"notes","tags":null,"title":"在SpringBoot项目整合JdbcTemplate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E5%9C%A8springboot%E9%A1%B9%E7%9B%AE%E6%95%B4%E5%90%88jdbctemplate/"},{"content":"操作步骤  指令如下  sudo apt install -y docker-ce ","description":"","id":339,"section":"notes","tags":null,"title":"在Ubuntu 18.04中安装Docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8ubuntu-18.04%E4%B8%AD%E5%AE%89%E8%A3%85docker/"},{"content":"操作步骤  指令如下   # 创建docker用户组 sudo groupadd docker # 将当前用户添加到docker组 sudo gpasswd -a ${USER} docker # 重启服务 sudo service docker restart # 切换当前会话到新组 newgrp - docker 相关资料  Ubuntu16.04 添加 Docker用户组  ","description":"","id":340,"section":"notes","tags":null,"title":"在Ubuntu 18.04中添加Docker用户组","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8ubuntu-18.04%E4%B8%AD%E6%B7%BB%E5%8A%A0docker%E7%94%A8%E6%88%B7%E7%BB%84/"},{"content":"我为试验机设置了全新的网络环境，完全不必担心镜像下载速度过慢、镜像无法下载的问题。所以相应的教程也非常的清晰明了。\n另外需要说明的是，我的所有节点都是根据我制作的模板生成的，我在模板中安装了许多的工具。可以参考我模板配置相关的说明。\n基础环境准备： 我这次是失误了，这些工作应该在模板节点上做的。这样生成的所有节点都已经被配置好了。\n 关闭防火墙  1 2 3 4  systemctl disable firewalld systemctl stop firewalld   关闭selinux  1 2 3 4 5 6 7 8  # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config   关闭交换分区  1 2 3 4 5 6 7  # 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab   修改内核参数  1 2 3 4 5 6 7  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system   重启后检查各台机器的状态   reboot sestatus swapon -s 安装K8S 注意事项：\n 我推荐指定apiserver-advertise-address参数，是因为有些虚拟机是双网卡的，一张是nat，用于虚拟机访问外部网络，一张是private，用于虚拟机内部访问。如果让kubeadm自己选，可能会选错网卡。 我推荐不指定版本号，用最新的，比较香 不需要指定仓库，我这边基础设施上已经做了处理了，可以很快的拉取到各个镜像。  1 2 3 4 5 6 7 8 9 10 11 12  # 可不必执行 kubeadm config images list kubeadm config images pull kubeadm init \\  --pod-network-cidr=10.244.0.0/16 \\  --apiserver-advertise-address=172.20.11.201 # 用于还原kubeadm init对系统进行的任何改变（用于重装） kubeadm reset   添加节点 参考资料  kubeadm reset  ","description":"","id":341,"section":"notes","tags":null,"title":"在实验机上安装Kubernetes","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E5%9C%A8%E5%AE%9E%E9%AA%8C%E6%9C%BA%E4%B8%8A%E5%AE%89%E8%A3%85kubernetes/"},{"content":"问题描述 我也是第一次意识到这个问题，我在Chrome上打开了一个无痕窗口，进入项目首页，因为没有登录，直接跳转到登录页面，这是我需要的。然后我再打开一个无痕窗口，进入项目首页，结果直接以登录状态进入了项目首页。额，这个肯定不是我想要的，因为我需要同时测试多个账号的登录。\n解决方案 我目前选择的是绕开这个问题，我新建了一个Chrome用户，每个用户登录一个账号。\n","description":"","id":342,"section":"notes","tags":null,"title":"多个无痕窗口共用一套Cookie","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%A4%9A%E4%B8%AA%E6%97%A0%E7%97%95%E7%AA%97%E5%8F%A3%E5%85%B1%E7%94%A8%E4%B8%80%E5%A5%97cookie/"},{"content":"配置如下：\n","description":"","id":343,"section":"notes","tags":null,"title":"如何为Idea设置代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%A6%82%E4%BD%95%E4%B8%BAidea%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"这个技术存在的意义是可以让我对服务端的数据包管理更严格，避免一些不必要的问题造成我无法正常使用。\n 使用如下指令得到数据包的文件：  1 2 3 4 5  tcpdump -tttt -s0 -X -vv tcp port 8080 -w captcha.cap tcpdump -i eth0 -w captcha.cap tcpdump -i enp34s0 -w captcha.cap   下载capcha.cap文件到开发机，用鲨鱼进行分析（我这块很简单，东西down下来后，直接可以点开）。  ","description":"","id":344,"section":"notes","tags":null,"title":"如何使用tcpdump抓包，并用鲨鱼分析","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8tcpdump%E6%8A%93%E5%8C%85%E5%B9%B6%E7%94%A8%E9%B2%A8%E9%B1%BC%E5%88%86%E6%9E%90/"},{"content":"\u0026lt;? extends T\u0026gt; 表示类型的上界，也就是说，参数化的类型可能是T或者T的子类型。例如下面的写法都是合法的赋值语句： ~~~ java Listlist = new ArrayList(); Listlist = new ArrayList(); Listlist = new ArrayList(); ~~~ ### 读数据分析 1. 不管给list如何赋值，可以保证list里面存放的一定是Number类型或其子类，因此可以从list列表里读取Number类型的值。 2. 不能从list中读取Integer，因为list里面可能存放的是Float值，同理，也不可以从list里面读取Float。 ### 写数据分析 1. 不能向list中写Number，因为list中有可能存放的是Float 1. 不能向list中写Integer，因为list中有可能存放的是Float 2. 不能向list中写Float，因为list中有可能存放的是Integer 从上面的分析可以发现，只能从List读取T，因为无法确认它实际执行列表的类型，从而无法确定列表里面存放的实际的类型，所以无法向列表里面添加元素。 *（个人表示怀疑吧，如果只能读取，那完全不知道这个容器存在的意义）* ## 表示类型下届，也就是说，参数化的类型是此类型的超类型。 ~~~ java Listlist = new ArrayList(); Listlist = new ArrayList(); Listlist = new ArrayList(); ~~~ 被设计为用来写数据的泛型（只能写入T或者T的子类类型），不能用来读，分析如下。 ### 读数据分析 无法保证list里面一定存放的是Float类型或Number类型，因此有可能存放的是Object类型，唯一能确定的是list里面存放的是Object或其他子类，但是无法确定子类的类型。正是由于无法确认list里面存放数据的类型，因此无法从list里面读取数据。 ### 写数据分析 1. 可以向list里面写入Float类型的数据（不管list里面实际存放的是Float、Number或Object，写入Float都是允许的）；同理，也可以向list里面添加Float子类类型的元素。 2. 不可以向list里面添加Number或Object类型的数据，因为list中可能存放的是Float类型的数据。 ## 使用案例 代码如下： ~~~ java public static  void copy(Listdest, Listsrc) { for (int i = 0; i ","description":"","id":345,"section":"notes","tags":null,"title":"如何区分？extends T与？ super T","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%86extends-t%E4%B8%8E-super-t/"},{"content":"之前有被这个问题困惑过，今天看书的时候，遇到了相关的资料，故记载下来。\n可以比较U盘插入计算机前后dmesg命令输出的最后一行内容，也可以用lsblk。\n实践dmesg 实践中使用dmesg后，新增内容如下：\n [ 2650.933707] usb 1-2: new high-speed USB device number 4 using xhci_hcd [ 2651.082193] usb 1-2: New USB device found, idVendor=0781, idProduct=5571, bcdDevice= 1.00 [ 2651.082196] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [ 2651.082198] usb 1-2: Product: Cruzer Fit [ 2651.082199] usb 1-2: Manufacturer: SanDisk [ 2651.082200] usb 1-2: SerialNumber: 4C530001160824101320 [ 2651.094526] usb-storage 1-2:1.0: USB Mass Storage device detected [ 2651.094773] scsi host2: usb-storage 1-2:1.0 [ 2651.094891] usbcore: registered new interface driver usb-storage [ 2651.095645] usbcore: registered new interface driver uas 我并没有看出任何有用的信息，稍后，信息变为如下内容，依旧没有看出任何信息：\n [ 2650.933707] usb 1-2: new high-speed USB device number 4 using xhci_hcd [ 2651.082193] usb 1-2: New USB device found, idVendor=0781, idProduct=5571, bcdDevice= 1.00 [ 2651.082196] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [ 2651.082198] usb 1-2: Product: Cruzer Fit [ 2651.082199] usb 1-2: Manufacturer: SanDisk [ 2651.082200] usb 1-2: SerialNumber: 4C530001160824101320 [ 2651.094526] usb-storage 1-2:1.0: USB Mass Storage device detected [ 2651.094773] scsi host2: usb-storage 1-2:1.0 [ 2651.094891] usbcore: registered new interface driver usb-storage [ 2651.095645] usbcore: registered new interface driver uas [ 2652.102859] scsi 2:0:0:0: Direct-Access SanDisk Cruzer Fit 1.00 PQ: 0 ANSI: 6 [ 2652.103259] sd 2:0:0:0: Attached scsi generic sg0 type 0 [ 2652.104008] sd 2:0:0:0: [sda] 30842880 512-byte logical blocks: (15.8 GB/14.7 GiB) [ 2652.105118] sd 2:0:0:0: [sda] Write Protect is off [ 2652.105120] sd 2:0:0:0: [sda] Mode Sense: 43 00 00 00 [ 2652.105338] sd 2:0:0:0: [sda] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA [ 2652.129919] sda: sda1 sda2 [ 2652.131186] sd 2:0:0:0: [sda] Attached SCSI removable disk 额，结合我lsblk的实验，可以看出U盘的设备名为sda1和sda2。\nlsblk实践 U盘插入前后lsblk输出：\n # U盘插入前 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:0 0 465.8G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot/efi ├─nvme0n1p2 259:2 0 464.3G 0 part / └─nvme0n1p3 259:3 0 976M 0 part [SWAP] # U盘插入后 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 1 14.7G 0 disk ├─sda1 8:1 1 14.1G 0 part └─sda2 8:2 1 298M 0 part nvme0n1 259:0 0 465.8G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot/efi ├─nvme0n1p2 259:2 0 464.3G 0 part / └─nvme0n1p3 259:3 0 976M 0 part [SWAP] ","description":"","id":346,"section":"notes","tags":null,"title":"如何找到U盘设备名（未实践）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0u%E7%9B%98%E8%AE%BE%E5%A4%87%E5%90%8D%E6%9C%AA%E5%AE%9E%E8%B7%B5/"},{"content":"这个需求基本操作一次就不会忘记了，哈哈，还是整理一下吧。\n","description":"","id":347,"section":"notes","tags":null,"title":"如何查看Idea日志","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bidea%E6%97%A5%E5%BF%97/"},{"content":"测试 测试非DTO参数 准备如下测试代码：\n1 2 3 4 5 6 7 8 9  @Validated @Service public class TmpService { public void doService(@JNotBlank String inputParam) { // do something  } }   这份代码有两个地方需要注意：\n 类上的注解只能为@Validated，@Valid并不会生效。 方法参数不需要@Validated、@Valid，我看网上有些教程写了，其实是不需要的。  测试DTO参数 准备如下代码：\n1 2 3 4 5 6 7 8 9  @Validated @Service public class TmpService { public void doService(@Valid TestRequest request) { // do something  } }   在我的测试中，类上的@Validated注解和方法上的@Valid注解，缺一不可，我觉得这是一种非常让人迷惑的写法，一不小心就可能翻车。\n小结 message提示的问题 实验中我其实是有其他收获的，我发现当方法校验失败时，得到的返回结果是（基于我小小开发了一下的校验框架）：\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;doService.inputParam 为空或长度为0\u0026#34; }   也就是说basePath会指明方法及方法的参数。这说明了一个问题，我们开发的用于Request的注解，最好只用于Controller层，否则的话会将内部实现的一些细节暴露给用户。当然不仅仅是我们开发的注解，框架的注解也同样需要存在这个问题，甚至因为没有足够的提示信息，框架的提示信息更让人迷惑。\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;不能为空\u0026#34; }   貌似说我们为注解加上message就可以完事了，这样用户就可以得到清晰明了的信息了，但是，我们应该好好思考一下，我们应该将service层参数校验的信息抛给用户么？我决定在下面好好讨论一下。\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;inputParam不能为空\u0026#34; }   关于异常的讨论 异常目前主要分为两种：系统异常和业务异常，数据库无法获取链接，属于系统异常，一个给定的Id无法从数据库中找到数据，属于业务异常。这些异常都能很好的区分。\n但是因为我们开发的Service往往需要提供给第其他人用，我们需要对传入的参数进行非空等校验，校验失败的时候，我们该抛出什么样的异常呢？系统的还是业务的？我目前的想法还是算作业务异常吧，因为我们写的Service本质上就是业务Service，所以这些Service抛出的异常理应为业务异常。\n从这个分析的角度，我们Controller中对Request的校验失败属于业务异常、Service层方法对参数的校验数据也属于业务异常，我们可以用相同的方式处理。\n异常捕获的问题 目前在参数校验方面，我发现了三种不同的异常，但是我目前用到的主要是两种：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @ResponseBody @ExceptionHandler(value = { MethodArgumentNotValidException.class, ConstraintViolationException.class, BindException.class}) public Response exceptionHandler(Exception e) { String message = \u0026#34;参数校验失败\u0026#34;; if (e instanceof BindException) { message = ((BindException) e).getBindingResult().getFieldError().getDefaultMessage(); } else if (e instanceof ConstraintViolationException) { Optional\u0026lt;String\u0026gt; messageOptional = ((ConstraintViolationException) e).getConstraintViolations() .stream() .map(ConstraintViolation::getMessage) .findFirst(); message = messageOptional.get(); } else { message = ((MethodArgumentNotValidException) e).getBindingResult().getFieldError().getDefaultMessage(); } return new Response(0, message); }   Service层校验失败，抛出来的就是ConstraintViolationException异常。\n另外，关于异常处理，我收集了一段非常不错的代码，之所以觉得它用的好，是因为它使用了orElse，这个方法我使用的次数非常的少。\n1 2 3 4 5 6 7  message e.getConstraintViolations() .stream() .findFirst() .map(ConstraintViolation::getMessage) .orElse(\u0026#34;参数校验失败\u0026#34;))   这是我目前收集的信息。\n参考资料  spring boot 参数校验这么做简洁实用  ","description":"","id":348,"section":"notes","tags":null,"title":"如何校验普通的方法参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%A6%82%E4%BD%95%E6%A0%A1%E9%AA%8C%E6%99%AE%E9%80%9A%E7%9A%84%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0/"},{"content":"我昨天一直在思考Maven Profile与SpringBoot配置文件的关系，想知道Maven Profile中的配置是如何传递给SpringBoot配置文件的，是通过环境变量么？\n我最终获取到了一个项目启动时的Idea运行指令（相关笔记在Idea分类下寻找），我发现这条指令平平无奇，并没有传递任何参数到应用程序。\n我又观察target下classes目录中的配置文件，发现该目录下的application.properties中原有的配置已经被替换为如下内容：\n所以我作出了如下分析，Idea启动前会自动的调用Maven的打包功能，从而生产target目录下的classes等文件，这个过程中我们在Maven项目中配置的Maven过滤器会发挥作用，将文件中引用的特定符号转换成指定的值。\n其实我的代码中并没有配置Maven过滤器插件，为什么application.properties中的@spring.profiles.active@会被Maven过滤器插件转换为Profile的值呢，我个人认为是因为我引入了SpringBoot的打包插件，该插件默认配置了Maven打包插件（我没有证据）。\n我看过网上关于如何使用Maven过滤器插件的文章，它们都是针对application*.yml进行处理，我猜想SpringBoot的打包插件也是这样的（实际上我做了实验，非application*.yml文件的确不会被处理）。\n为了验证我的，我设计了如下实验：先准备一份application-tmp.properties，包含@spring.profiles.active@，然后运行package指令，在target目录下观察application-tmp.properties文件，的确发现进行了字符串的替换。\n综上，我可以解释另一篇笔记中提到的疑问：我如何在application.yml中使用该机制，我只需要在编辑了applicaiton.yml文件后，运行一下package指令就好了（也可以不运行，貌似启动指令会根据Maven Profile帮我们生成新的application.yml文件），如下：\n参考资料  在Spring Boot YML配置文件中使用MAVEN变量@var@ Maven Profile 与 SpringBoot Profile 多环境打包指派指定环境  ","description":"","id":349,"section":"notes","tags":null,"title":"如何理解Maven Profile与SpringBoot配置文件的关系","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3maven-profile%E4%B8%8Espringboot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"content":"Java NIO（同步不阻塞）：服务器实现模式为一个线程处理多个请求（链接），即客户端发送的连接请求会注册到多路复用器上，多路复用器轮询连接有IO请求就进行处理。\n应该就是c++的epoll模式的java实现吧。\n","description":"","id":350,"section":"notes","tags":null,"title":"如何理解NIO（同步非阻塞模型）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3nio%E5%90%8C%E6%AD%A5%E9%9D%9E%E9%98%BB%E5%A1%9E%E6%A8%A1%E5%9E%8B/"},{"content":"操作步骤   下载CentOS 8 dvd的镜像文件（可以避免安装时的网络需求）\n  使用Win32DiskImager制作U盘启动盘（目前这是事最少的方案了）\n  在物理机上进行安装，安装时不要忘记如下工作：\n 在Software Selection中将默认的Server With GUI换成Server（可以节省内存资源） 在Time \u0026amp; Date中将时区改为我们常用的时区 在Network \u0026amp; Host Name中将主机名改为我们cpu的型号，但是不建议打开网络（我个人习惯） 在User Creating中创建一个用户，不建议将这个用户设置为管理员（我个人习惯）    遇到的问题 如果安装以上步骤进行安装，遇到的坑可能是最少的，我尝试过的方案及遇到的问题如下：\n  使用dvd镜像，使用Ultraiso制作U盘启动，目前的问题在于找不到引导程序，这个是存在解决方案的，我在我另一篇文章说明了如何解决这个问题。另外，因为这个方案是很久前用的，我并没有关注是否会遇到我下面描述的其他问题。总之，不推荐这种方案。\n  使用dvd镜像，使用rufus-3.13.exe制作U盘启动，问题在于我使用的是dvd镜像，但是安装引导程序中选择软件源的时候我无法进行任何选择我本地的源，只能使用网络源，这和我的目标并不太相符。\n  使用boot镜像，使用rufus-3.13.exe制作U盘启动，问题是：如果不打开网络，则无法配置软件仓库地址，如果打开网络，安装引导程序就会卡死，我觉得可能是我网络访问外网时速度太慢导致的。\n  我还没有尝试使用Win32DiskImager制作Centos 8 boot版的启动U盘进行安装，不确定这个方案会不会在网络源配置时卡死。但是，还是比较推荐使用dvd版的镜像。\n","description":"","id":351,"section":"notes","tags":null,"title":"安装CentOS 8（推荐）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E5%AE%89%E8%A3%85centos-8%E6%8E%A8%E8%8D%90/"},{"content":"因为之前使用Ubuntu系统的时候，总是会遇到一些奇奇怪怪的问题，而且这些问题并不是很好查到资料（Ubuntu更新的太快了，网上的教程往往落后于系统发展，而且我们有时候遇到的问题都是别人未遇到过的）。\n所以我一直有计划将我工具机的系统更新为CentOS。之前使用工具机时，我会在工具机里再装虚拟机，为了在我开发机上能通过IP直接访问到工具机上的虚拟机，我又在工具机上安装了OpenVPN，这样我的开发机就可以通过挂OpenVPN，访问工具机上的虚拟网络了，很方便一些软件的测试。另外，我还在工具机上装了形形色色的环境和工具软件，时间长了，我也忘记我工具机的具体环境是怎样的了。\n所以我计划乘着这次重装CentOS系统，我将这些教程再整理一遍，方便我未来还原我工具机的环境。\nCentOS系统的安装 操作步骤 核心操作步骤：\n  下载CentOS 7的镜像文件\n  用Ultraiso制作启动盘\n  在物理机上进行安装\n  这一部分比较简单，具体细节不贴出来了，如果有需要的建议自行百度“物理机上装CentOS”，我参考的教程如下：\n 物理机安装linux系统（centos7.6）  遇到的问题 本着学新不学旧方针，我觉得将Centos 7换成Centos 8，结果在装CentOS 8时就遇到了 dracut initqueue timeout 问题。我参考了如下的教程解决该问题：\n Linux（CentOs 7）系统重装笔记(一) dracut-initqueue timeout 安装CentOS7出现dracut-initqueue timeout的解决办法  我解决该问题的步骤为（这些步骤请参考以上教程食用）：\n 在一次完整的失败安装后，安装并不会退出，而会出现一个命令行工具，在命令行中执行如下代码（我估计我的U盘是sda打头的）：  1 2 3 4  cd /dev/ ls | grep sda   执行该代码后，会显示出两个结果（此时我U盘保持插着的状态），拔下U盘，再次执行该指令，该指令执行结果为空。可以确定U盘为sda4（猜的成分更多）\n重启电脑，进入安装界面，先按TAB后按e，将指令改为：  1 2 3  vmlinuz initrd=initrd.img inst.stage2=hd:/dev/sda4 quiet   如此这个问题就解决了。  20210404补充：\n之前用Ultraiso装Centos 8时出现了一些奇奇怪怪的问题，我用了相对复杂的方案解决这个问题了，但是我越想越不对劲，我认为是引导出问题了，所以换成了rufus-3.13做U盘启动，结果成功解决该问题。即上述的问题，在使用rufus-3.13做U盘启动的时候，并不会出现。\n20210410补充：\nUltraiso和rufus-3.13方案都存在不足，我已经更新为Win32DiskImager方案，目前该方案问题最少。\n","description":"","id":352,"section":"notes","tags":null,"title":"安装CentOS 8，使用Ultraiso制作U盘启动（不推荐）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E5%AE%89%E8%A3%85centos-8%E4%BD%BF%E7%94%A8ultraiso%E5%88%B6%E4%BD%9Cu%E7%9B%98%E5%90%AF%E5%8A%A8%E4%B8%8D%E6%8E%A8%E8%8D%90/"},{"content":"指令如下：\n1 2 3 4 5 6  sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.29.1/docker-compose-Linux-x86_64\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version    mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version 参考资料   Docker Compose\n教程里的版本太旧了，我用了最新版。\n  docker/compose\n  ","description":"","id":353,"section":"notes","tags":null,"title":"安装Docker Compose","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%AE%89%E8%A3%85docker-compose/"},{"content":" 下载二进制文件，并解压二进制文件   tar -zxvf helm-v3.5.4-linux-amd64.tar.gz 将二进制文件移动$PATH目录下   mv linux-amd64/helm /usr/local/bin/helm Helm常用指令  添加一个chart仓库，并查看charts列表   helm repo add bitnami https://charts.bitnami.com/bitnami helm search repo bitnami 查看chart详细信息，并安装、卸载chart   helm show chart bitnami/mysql helm show all bitnami/mysql helm install bitnami/mysql --generate-name helm uninstall mysql-1612624192 helm uninstall mysql-1612624192 --keep-history 查看哪些chart被发布了   helm ls helm list 获取帮助信息   helm get -h 参考资料  官方教程：安装Helm Helm二进制文件下载地址 快速入门指南  ","description":"","id":354,"section":"notes","tags":null,"title":"安装Helm","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/%E5%AE%89%E8%A3%85helm/"},{"content":"问题描述   我们通过切面编程，自动为进入controller的参数进行aes加密，然而这个接口在window上表现正常，在Linux系统上表现异常。\n  最后发现这个问题很常见，我没有参与这个问题的解决，记录该篇博客，是为了便于下次出现这种问题时，能够第一时间联想到是这个问题。\n  20210440补充：\n我记得网上提供的方法是需要下载个什么jar包，但是我们嫌这种方式太麻烦了，直接改了加密的长度，额，我不确定这种方式好不好。\n","description":"","id":355,"section":"notes","tags":null,"title":"定位Java在Linux上AES加密失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%AE%9A%E4%BD%8Djava%E5%9C%A8linux%E4%B8%8Aaes%E5%8A%A0%E5%AF%86%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题的表现：\n 我们数据库中使用了timestamptz类型 我们代码中使用了LocalDateTime类型 我们的代码使用了LocalDateTimeTypeHandler注解  数据能够正常的入库，但是当从数据库中读取数据的时候，会报timestamp转换异常。我断点发现，报异常的时候，代码并没有进入LocalDateTimeTypeHandler，而是走了PGResultSet，我断定是LocalDateTimeTypeHandler无法进入导致的错误。我以该现象为关键字，寻找解决方案，最后有如下解决方案：\n mybatis-plus: type-handlers-package: com.sdstc.core.mybatisplus.type 参考资料   mybatis plus坑之 - @TableField(typeHandler) 查询时不生效为null\n  更新时自定义的TypeHandler不生效\n我没有看这个教程，但是这篇教程似乎讨论的更深入\n  ","description":"","id":356,"section":"notes","tags":null,"title":"定位并修复TypeHandler的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E5%AE%9A%E4%BD%8D%E5%B9%B6%E4%BF%AE%E5%A4%8Dtypehandler%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我目前通过GitBook发布的笔记大约有300多篇，执行gitbook build的时间大约需要5分钟作用，我觉得这个真的是一个让人无法接受的时间！\n我有计划去探索一些新的文档工具，比如VuePress、docsify、HuGo等，我对新工具的要求是对文档编辑零侵入性，编译速度足够块（VuePress、docsify似乎不需要编译）。\n最近时间比较紧张，我可能没有足够的时间去研究，而且这方面的需求貌似没有那么急。\n","description":"","id":357,"section":"notes","tags":null,"title":"对GitBook不满意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/%E5%AF%B9gitbook%E4%B8%8D%E6%BB%A1%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"我的代码如下：\nRequest:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  @Data public class ClientCalibrationReportRequest { /** * 上报内容详情 */ @NotNull private Detail detail; @Data public static class Detail { /** * 白平衡校准数据 */ @NotBlank private String wbs; } }   Controller:\n1 2 3 4 5 6 7 8 9 10 11  @PostMapping(\u0026#34;/client/calibration/report\u0026#34;) public ResponseVo\u0026lt;Object\u0026gt; clientCalibrationReport( @RequestHeader(value = \u0026#34;terminal\u0026#34;) Integer terminal, @Valid @RequestBody ClientCalibrationReportRequest request) { clientCalibrationReportService.saveClientCalibrationReport(terminal, request); return ResponseVo.createSuccess(); }   问题是这样的，我在测试时使用了如下的json：\n1 2 3 4 5 6 7  { \u0026#34;detail\u0026#34;: { // \u0026#34;wbs\u0026#34;: \u0026#34;100\u0026#34;, } }   结果校验依旧通过了，这不符合我的设计，后来我在detail字段上加上了@Valid注解后，能够正常的进行校验。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  @Data public class ClientCalibrationReportRequest { /** * 上报内容详情 */ @NotNull @Valid private Detail detail; @Data public static class Detail { /** * 白平衡校准数据 */ @NotBlank private String wbs; } }   后来我尝试将controller方法中的@Valid移动到ClientCalibrationReportRequest类上，我期待实现统一的注解位置配置，但是很失望，这样是不能够达到我的目标的。这次实验中我使用的是javax.validation.Valid，但是我知道Spring有一个org.springframework.validation.annotation.Validated注解，我不确定该注解能否实现我的目标。\n参考资料  javax框架之@Valid对象嵌套的效验  ","description":"","id":358,"section":"notes","tags":null,"title":"对Request的内部对象进行校验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%AF%B9request%E7%9A%84%E5%86%85%E9%83%A8%E5%AF%B9%E8%B1%A1%E8%BF%9B%E8%A1%8C%E6%A0%A1%E9%AA%8C/"},{"content":"之前的实验中，我发现了如下的问题：\n 没有相应的ifcfg，我手动copy的（已解决） 有很多时候执行nmcli c reload并不会让/etc/sysconfig/network-scripts下的配置文件生效（已解决） enp2s0的ifcfg配置文件不知道该如何写（已解决） 四份ifcfg配置文件中的defaultroute都为yes 存在断线的情况，断线后重连也无法ping通8.8.8.8（已解决）   我的网线是六类网线，B450M上显示1000m，J4125上显示100M，同一个网线的两端 全部机器都重启后，笔记本只能ping通192.168.31.1，其他的都显示Ping：传输事故。常见故障（已解决） 很奇怪的一件事，我笔记长时间未动后，无法正常ping，包括不能ping 172.16.100.1/24网段和ping 8.8.8.8。之前与172.16.100.1/24建立的连接不会受到任何印象，但是无法建立新的连接，表现为之前的ssh连接始终是可用的，但是无法创建新的ssh连接。重启笔记本网卡后，这个问题恢复了。而且，我是可以正常与J4125建立连接的。  我目前挨个挨个解决这些问题，有些问题可能还没有解决方案。\n问题一   删除/etc/sysconfig/network-scripts/下所有的配置文件，然后执行下nmcli c reload\n  然后执行如下4条指令：\n   nmcli conn add con-name enp2s0 ifname enp2s0 type ethernet nmcli conn add con-name enp3s0 ifname enp3s0 type ethernet nmcli conn add con-name enp4s0 ifname enp4s0 type ethernet nmcli conn add con-name enp5s0 ifname enp5s0 type ethernet 如此就在/etc/sysconfig/network-scripts/目录下就生成了4份ifcfg配置文件\n还原拨号上网   nmcli conn add con-name pppoe-home type pppoe ifname enp2s0 username 13022052202D396 password 123456 nmcli conn up pppoe-home nmcli conn up pppoe-home # 关闭 这个地方有些小插曲，我执行了ppp-home添加后，又执行up操作，会提示我出错了，让我看日志信息。我注意到这个时候已经可以ping通了8.8.8.8，所以我分析，add后会理解执行拨号（不太确定哦），我再执行up时发生了冲突，所以报错了。\n而且这个时候执行ifconfig，会发现第一次试验时截图中的ppp1变成了ppp0，我觉得这个应该是没有什么印象的。\n还原192.168.31.1，确保能够在笔记本上ssh  我这次用了如下指令，相比直接改配置文件更优雅一点：\n nmcli connection modify enp3s0 ipv4.addresses 192.168.31.1/24 ipv4.method manual connection.autoconnect yes nmcli connection modify enp4s0 ipv4.addresses 192.168.41.1/24 ipv4.method manual connection.autoconnect yes 这个地方也有小插曲，我执行完指令后注意到：192.168.31.1这个ip地址被分配给了enp5s0网卡，这不符合我的意愿，我注意到nmcli生成的配置文件中没有DEVICE，我手动为4份配置文件加上了DEVICE后，执行nmcli c reload，恢复到正常情况。（我简单验证了下，nmcli命令行貌似不支持DEVICE的设置）\n对比配置文件，我发现connection.autoconnect yes等配置项似乎没有映射到我的配置文件。\n 恢复笔记本上网   iptables -t nat -A POSTROUTING -s 192.168.31.0/24 -j MASQUERADE iptables -t nat -A POSTROUTING -s 172.16.100.0/24 -j MASQUERADE 问题二 ~~~该现象发生的时候，使用nmcli connection modify也无法正常的修改ip地址。~~~ 解决这个问题还有一个办法，就是使用nmcli c reload先加载一下，~~~然后使用nmcli c down先关闭网卡，~~~使用SSH的话，使用down然后再执行up会导致SSH断开链接，我发现直接使用up就可以了，然后再重启，我比较喜欢这个方案，更方便一些。 ## 问题三 使用问题的方法，自动生成一份配置文件，不进行任何改写。 ## 问题四 我目前做了如下的分析： 1. 我使用-j MASQUERADE前，一般都是先ssh到J4125上，然后执行这条指令，我认为此时我的笔记本与J4125已经建立了某种连接，所以导致我此时仍然可以正常访问该机器 2. 当192.168.31.1不可ping通的时候，8.8.8.8也不可ping通，之前认为的将所有的数据包转给了ens2s0网卡的分析应该是站不住脚的，因为这个时候8.8.8.8应该是可以ping通的。 3. VirtualBox的nat模式有个特点：就是虚拟机可以访问主机，访问主机所在网络中的其他机器，但是主机和其他机器无法访问主机。我目前的网络拓补和VirbualBox的nat模式很像，从原理来说，J4125上应该是访问不到我的笔记本的（难道这个是核心的原因么）。但是VMWare中的nat模式，主机和虚拟机是可以互相访问的，这个也没有足够的说服力。 我设计了一写实验： 1. 断开ssh连接，使用netstat -an监控tcp连接，直到两台机器之间没有相关的连接信息了，然后再来进行ping实验（实验结果是依然可以ping通） 2. 重启J4125，然后直接在机器上执行nat指令，在笔记本上进行ping实验（实验结果是依然可以ping通） ## 问题七 我发现网上有其他人也遇到类似的的问题了，在[这篇文章](https://askubuntu.com/questions/1287967/cant-get-rtl8125-realtek-driver-working-on-version-20-04)里，原文简单的摘抄如下： \u0026gt; When you write \u0026quot;...Well the 9.003.05-1 version I found on ElRepo turned out to be buggy...\u0026quot; are you talking about the sub-par speed in one direction when connected to a 1 GbE network? Or something else? ## 问题八 需要再提供更多的关于这个问题的资料。3400G装的是Linux，这台机器可以正常的ping通192.168.31.1、192.168.41.1。我windows机器只能ping通192.168.31.1。 我将window机器的以太网断掉一段时间后，再重新连接，此时连192.168.31.1都无法正常的ping通。 我将3400G机器重启一下后，再重新连接，此时连192.168.41.1都无法正常的ping通。 这个时候将J4125重启一下，可以笔记本就可以正常的ping通192.168.31.1、192.168.41.1了。3400G机器也在J4125重启后可以正常的ping通。 如果重启笔记本，还是无法正常的ping通的，我可以确定不是iptables遭横的原因，我在该问题发生后，清除了所有的iptables，依旧无法ping通。 我现在基本把问题定位在J4125上了。 我注意到每次重连后，arp都无法正确的显示： 重连前 XiaoQiang (192.168.80.1) at ec:41:18:9f:60:45 [ether] on enp2s0\n? (192.168.31.154) at 6c:2b:59:75:6b:e8 [ether] on enp3s0\n? (192.168.41.203) at 2c:f0:5d:24:73:f8 [ether] on enp4s0\n重连后 XiaoQiang (192.168.80.1) at ec:41:18:9f:60:45 [ether] on enp2s0\n? (192.168.31.154) at 6c:2b:59:75:6b:e8 [ether] on enp3s0\n? (192.168.41.203) at  on enp4s0\n 同时我注意到，3400G重启后一直在发送ARP报文 ![2021-05-03-14-17-52](https://junjie2018sz.oss-cn-shenzhen.aliyuncs.com/images/2021-05-03-14-17-52.png) 我是这么分析的，J4125的网卡驱动出了问题，没有正确处理设备的重连，导致3400G实际上根本就没有链接到该机器，也就导致ARP无法更新。怎么验证这个问题呢，我计划加上usb网卡，然后看看能够在usb网卡上重现这个问题。 很难受，我现在基本定位是网卡驱动除了问题，但是这样的话，这个问题就变得非常的复杂了。 我尝试了把驱动降为r8125-9.003.05，没有解决问题！！！ 哈哈哈，终于搞定了，我把内核将到了5.4，然后这个问题恢复了，哈哈哈，很开心。 ## 参考资料 1. [VMware-centos7 添加网卡后发现没有ifcfg-ens网卡配置文件 使用nmcli来配置ip地址并生成配置文件](https://blog.csdn.net/weixin_44654329/article/details/106575526) 学习了如何为新网卡增加配置文件，及一些nmcli指令的应用 2. [linux配置网络，nmcli配置法及直接修改配置文件法](https://www.bilibili.com/read/cv4560096/) 学习到了nmcli conn modify的使用 ","description":"","id":359,"section":"notes","tags":null,"title":"将CentOS配置成路由器问题收集","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E5%B0%86centos%E9%85%8D%E7%BD%AE%E6%88%90%E8%B7%AF%E7%94%B1%E5%99%A8%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"content":"我记得我之前用的并不是这个方案，但是我又找不到之前的资料了，先用下这个方案先。代码如下：\n1 2 3 4  List\u0026lt;String\u0026gt; cities = Arrays.asList(\u0026#34;Milan\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;San Francisco\u0026#34;); String citiesCommaSeparated = String.join(\u0026#34;,\u0026#34;, cities);   参考资料  Java8-如何将List转变为逗号分隔的字符串  ","description":"","id":360,"section":"notes","tags":null,"title":"将List转变成逗号分隔符的字符串","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%B0%86list%E8%BD%AC%E5%8F%98%E6%88%90%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E7%AC%A6%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"content":"操作步骤  指令如下   sudo yum -y install mysql 不是整个mysql服务，而仅仅只是mysql客户端，非常好的测试工具。\n","description":"","id":361,"section":"notes","tags":null,"title":"将MySQL客户端安装在CentOS上","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/mysql/%E5%B0%86mysql%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E5%9C%A8centos%E4%B8%8A/"},{"content":"我测试工具用的，所以细节处没有太讲究：\n1 2 3 4 5 6 7  sudo yum install epel-release sudo yum install nodejs # 我没有执行这行代码 sudo yum install npm   参考教程  如何在 CentOS 安装 node.js  ","description":"","id":362,"section":"notes","tags":null,"title":"将Node.js安装在CentOS上","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/node.js/%E5%B0%86node.js%E5%AE%89%E8%A3%85%E5%9C%A8centos%E4%B8%8A/"},{"content":"还不错，打包出来后只有6M多一点，哈哈，虽然我只写了几行代码。\n20210628后续：\n该工具还可以将脚本打包成Linux可执行的文件，记录一下步骤：\n 安装工具pip3 install pyinstaller 检查工具版本pyinstaller -v 执行pyinstaller -F launch.py指令 在dist目录下找生成的可执行文件  参考资料  使用pycharm将python项目打包成exe运行文件  ","description":"","id":363,"section":"notes","tags":null,"title":"将Python脚本打包成可执行文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E5%B0%86python%E8%84%9A%E6%9C%AC%E6%89%93%E5%8C%85%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/"},{"content":"操作步骤  从官网下载源码包   yum install -y gcc mkdir -p ~/software/redis \u0026amp;\u0026amp; cd ~/software/redis wget http://download.redis.io/releases/redis-5.0.8.tar.gz?_ga=2.113561735.1252722932.1596592540-1218236159.1596592540 mv redis-5.0.8.tar.gz* redis-5.0.8.tar.gz # 不知道行不行 解压并编译安装  1 2 3 4 5 6 7 8  # yum install -y gcc tar -zxvf redis-5.0.8.tar.gz cd redis-5.0.8 make make install PREFIX=/usr/local/redis   设置环境变量  1 2 3 4 5 6 7  sudo tee -a /etc/profile \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; REDIS_HOME=/usr/local/redis PATH=${REDIS_HOME}:${PATH} EOF source /etc/profile   常用指令  常用指令如下   redis-cli -h host.com.cn -p auth password select 12 keys C* del xxxx 相关教程  Centos7安装Redis redis使用redis-cli查看所有的keys及清空所有的数据 通过redis-cli批量删除多个指定模式的key(几乎没用到)  ","description":"","id":364,"section":"notes","tags":null,"title":"将Redis安装在CentOS 7上","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%B0%86redis%E5%AE%89%E8%A3%85%E5%9C%A8centos-7%E4%B8%8A/"},{"content":"应用场景是这样的，平时解决问题时会查大量的资料然后解决问题，等解决了问题后需要将这些资料整理成笔记，但是有时候因为忙暂时无法整理。\n我之前的方式是：设置Chrome开启时打开上次未关闭的页面，结果发现多窗口的场景下可能会导致我的页面丢失，结果就是我的知识丢失。\n新的方案为Ctrl + Shift + D，一键将所有页面保存为书签，书签文件夹在设置为一个时间戳，完美解决这个问题。\n","description":"","id":365,"section":"notes","tags":null,"title":"将当前所有打开的Tab保存到书签","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%B0%86%E5%BD%93%E5%89%8D%E6%89%80%E6%9C%89%E6%89%93%E5%BC%80%E7%9A%84tab%E4%BF%9D%E5%AD%98%E5%88%B0%E4%B9%A6%E7%AD%BE/"},{"content":"之前没有发现Chrome导出书签的时候默认不支持导出某个文件夹，只能将全部的书签到导出来。解决方案是新创建一个Chrome账户，然后将需要导出的文件夹拖过去，再导出来。\n目前没有发现更好的方案了，难受。\n","description":"","id":366,"section":"notes","tags":null,"title":"将某个文件夹下的书签导出来","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%B0%86%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E7%9A%84%E4%B9%A6%E7%AD%BE%E5%AF%BC%E5%87%BA%E6%9D%A5/"},{"content":" 查看CPU和硬盘概要：   pveperf 查看设备信息   lspci ","description":"","id":367,"section":"notes","tags":null,"title":"常用指令","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"因为kc connect在windows机器上存在太多问题，每个人都有不同的状况，所以我想在linux上开一个kt connect，然后大家将代理设置成这个实例即可。\n代码如下：\n ktctl -n dev -c /root/.kube2/config connect --method socks5 --dump2hosts 实践的过程中有如下问题：\n 我机器上已经在管理一个k8s集群了，所以我需要为ktctl工具指定另一份配置文件。 ktctl默认监听在127.0.0.1，而且没有提供参数修改这个地址，所以我选择使用一些特殊的工具完成端口映射。具体的笔记在Linux分类下可以找到，我这儿就不呈现了。  ","description":"","id":368,"section":"notes","tags":null,"title":"开一个kt connect服务多台机器","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/kt-connect/%E5%BC%80%E4%B8%80%E4%B8%AAkt-connect%E6%9C%8D%E5%8A%A1%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8/"},{"content":"一个约束注解可以关联多个验证器，根据要验证的属性类型选择合适的验证器，及代码中可能有如下写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE }) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {AgeIntegerValidtor.class, AgeStringValidtor.class}) public @interface Age { } public class AgeIntegerValidtor implements ConstraintValidator\u0026lt;Age, Integer\u0026gt; { @Override public boolean isValid(Integer value, ConstraintValidatorContext context) { } } public class AgeStringValidtor implements ConstraintValidator\u0026lt;Age, Integer\u0026gt; { @Override public boolean isValid(Integer value, ConstraintValidatorContext context) { } }   之所以单独提一下这件事，是因为这件事我之前从未注意到。\n","description":"","id":369,"section":"notes","tags":null,"title":"开发自定义参数校验注解时需要注意的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%BC%80%E5%8F%91%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"先直接呈现各种调试后的代码吧\napplication.yml\n1 2 3 4  tmp2:weight:10kg  Weight.java\n1 2 3 4 5 6 7 8  @Data @AllArgsConstructor @NoArgsConstructor public class Weight { private Long weight; }   WeightConvert.java\n1 2 3 4 5 6 7 8 9 10 11  public class WeightConverter implements Converter\u0026lt;String, Weight\u0026gt; { @Override public Weight convert(String source) { if (source.endsWith(\u0026#34;kg\u0026#34;)) { return new Weight(Long.valueOf(source.substring(0, source.length() - 2))); } return null; } }   TmpConfiguration.java\n1 2 3 4 5 6 7 8 9 10  @Configuration public class TmpConfiguration { @Bean @ConfigurationPropertiesBinding public WeightConverter weightConverter() { return new WeightConverter(); } }   Tmp2Properties.java\n1 2 3 4 5 6 7 8  @Data @Component @ConfigurationProperties(prefix = \u0026#34;tmp2\u0026#34;) public class Tmp2Properties { private Weight weight; }   实验总结 本次实验中最核心的一点是要将WeightConverter注入到Spring Context中，并让Spring Context知道这个类是用来做转换的。实验中采用了如下的代码实现：\n1 2 3 4 5 6 7  @Bean @ConfigurationPropertiesBinding public WeightConverter weightConverter() { return new WeightConverter(); }   其中@ConfigurationPropertiesBinding注解就是让Spring Boot知道使用该住户按期做数据绑定。在理解这个实验核心的部分后，我们可以使用如下的方式开发Converter，并移除TmpConfiguration.java。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Component @ConfigurationPropertiesBinding public class WeightConverter implements Converter\u0026lt;String, Weight\u0026gt; { @Override public Weight convert(String source) { if (source.endsWith(\u0026#34;kg\u0026#34;)) { return new Weight(Long.valueOf(source.substring(0, source.length() - 2))); } return null; } }   参考资料  @ConfigurationProperties 注解使用姿势，这一篇就够了  ","description":"","id":370,"section":"notes","tags":null,"title":"开发自己的Convert，用在application.yml解析中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84convert%E7%94%A8%E5%9C%A8application.yml%E8%A7%A3%E6%9E%90%E4%B8%AD/"},{"content":"引入如下依赖：\n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   SpringBoot做了如下工作：\n  自动配置好SpringMVC\n 引入SpringMVC全套组件 自动配置SpringMVC常用组件（功能）    自动配置Web常见功能\n SpringBoot帮我们配置好了所有web开发的常见场景    默认的包结构\n 主程序所在包及其下面的所有子包里面的组件都会被默认扫描进来 无需以前的包配置扫描 如果想该表扫描路径  @SpringBootApplication(scanBasePackages=\u0026ldquo;com.atguigu\u0026rdquo;) 或者@ComponentScan 指定扫描路径      各种配置拥有默认值\n 默认配置最终都是映射到某个类上，如：MultipartProperties 配置文件的值最终会绑定每个类上，这个类会在容器中创建对象    按需加载所有自动配置项\n 引入非常多的Starter 引入了哪些场景这个场景的自动配置才会开启 SpringBoot所有的自动配置功能都在spring-boot-autoconfigure包里面    ","description":"","id":371,"section":"notes","tags":null,"title":"引入spring-boot-starter-tomcat时做了什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E5%BC%95%E5%85%A5spring-boot-starter-tomcat%E6%97%B6%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88/"},{"content":"问题描述 系统更新前，在语言选项中删除了微软输入法，但是系统更新后，微软输入法又被系统自动添加进来了。且这个时候去输入法选项中看的时候，是没有微软输入法的，感觉微软输入法貌似成了内置不可修改的选项（我被迷惑了很长时间，直到忍无可忍）。\n这个时候你只需要先添加一下微软输入法，然后再删除掉它就可以了。\n可能很少人遇到类似的问题吧。哈哈\n","description":"","id":372,"section":"notes","tags":null,"title":"微软输入法已禁用但是还是可以切换出来","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E5%BE%AE%E8%BD%AF%E8%BE%93%E5%85%A5%E6%B3%95%E5%B7%B2%E7%A6%81%E7%94%A8%E4%BD%86%E6%98%AF%E8%BF%98%E6%98%AF%E5%8F%AF%E4%BB%A5%E5%88%87%E6%8D%A2%E5%87%BA%E6%9D%A5/"},{"content":"快速使用的指令如下：\n nodeppt new slide.md nodeppt serve slide.md nodeppt build slide.md 有意思的是，使用了nodeppt serve指令后，可以实时的编辑并渲染ppt。\nDemo代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  title: Demo speaker: JJ plugins: - echarts \u0026lt;slide class=\u0026#34;bg-black-blue aligncenter\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; # Demo {.text-landing.text-shadow}  By JJ {.text-intro} [:fa-github: Github](https://github.com/ksky521/nodeppt){.button.ghost} \u0026lt;slide class=\u0026#34;bg-black-blue\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; 第一页 \u0026lt;slide class=\u0026#34;bg-black-blue\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; 第二页   参考资料  nodeppt 2.0  ","description":"","id":373,"section":"notes","tags":null,"title":"快速使用NodePPT的指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/nodeppt/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8nodeppt%E7%9A%84%E6%8C%87%E4%BB%A4/"},{"content":"我之前为了避免all_proxy给我实验代理不好的影响，我会直接新起一个shell。新的方案如下：\n unset all_proxy 参考资料  pip install报错：Missing dependencies for SOCKS support解决方法  ","description":"","id":374,"section":"notes","tags":null,"title":"快速取消代理设置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%BF%AB%E9%80%9F%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"},{"content":"我之前用VS Code打开一个文件夹，需要先打开这个文件夹，然后右键选择使用VS Code打开，感觉操作步骤还挺多的。所以我开发了下面的小脚本，感觉还不错。\n1 2 3 4 5 6 7  @echo off REM start your program, if the path has space start \u0026#34;\u0026#34; \u0026#34;D:\\Software\\Microsoft VS Code\\Code.exe\u0026#34; \u0026#34;D:\\Blogs\u0026#34; REM exit this cmd exit   因为bat的图标不好看，我又修改了一下文件的图标，具体操作如下：\n 将bat放到D盘中，然后再桌面上创建一个快捷方式 修改快捷方式名称为Blogs 右键快捷方式，选择属性，选择修改图表，然后选择一个新的图标（可以参考其他快捷方式的图标）  幸福度+1，非常满意。\n","description":"","id":375,"section":"notes","tags":null,"title":"快速用VSCode打开一个文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E5%BF%AB%E9%80%9F%E7%94%A8vscode%E6%89%93%E5%BC%80%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"我竟然发现我一直没有整理这个，今天急用，找不到相关的笔记。\npom配置如下：\n \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; application.yml配置如下：\n management: endpoints: web: exposure: include: '*' 观察日志：\n我有几次这样配置了，接口还是无法访问，重启多次后才恢复，我不确定是哪块出问题了，所以建议看到日志文件后再访问接口。\n","description":"","id":376,"section":"notes","tags":null,"title":"快速配置Actuator","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AEactuator/"},{"content":"打包成tar文件 这条指令需要传递两个参数，我容易忘记另一个参数：\n tar -cvf feeds.tar feeds/ ","description":"","id":377,"section":"notes","tags":null,"title":"打包成tar文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip%E6%8C%87%E4%BB%A4/%E6%89%93%E5%8C%85%E6%88%90tar%E6%96%87%E4%BB%B6/"},{"content":"报错如下：\n SyntaxError: Non-ASCII character '\\xe2' in file 我选择的解决方式是从调用python3而不是python，我系统里存在两个版本的python3，经常用错这个东西。其他解决方案有：Python报错：(编码问题)SyntaxError: Non-ASCII character \u0026lsquo;\\xe2\u0026rsquo; in file，但是我并没有实践过。\n","description":"","id":378,"section":"notes","tags":null,"title":"报错Non-ASCII character in file","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E6%8A%A5%E9%94%99non-ascii-character-in-file/"},{"content":"指令如下：\n1 2 3 4 5 6 7  npm install gitbook-cli -g # 进入一个新文件夹后 gitbook init gitbook serve   参考教程  如何用gitbook搭建自己的文档整合平台  ","description":"","id":379,"section":"notes","tags":null,"title":"搭建GitBook","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/gitbook/%E6%90%AD%E5%BB%BAgitbook/"},{"content":"典型的自己挖坑自己填。\n问题是这样的，我的Postman登录我的账号后，进行请求时一直报代理错误，浏览器可以正常访问的URL，在Postman中请求都是代理错误，但是实际上我系统压根就没有开代理。\n我此时已经开始怀疑我测试Python的Request类的代理时，添加的ALL_PROXY、HTTP_PROXY、HTTPS_PROXY环境变量影响到我的Postman了，果断去掉这几个环境变量，然后重启Postman，发现Postman恢复正常了。\n我觉得这种问题很怪异，于是去看了看Postman的配置，结果发现我本机的Postman有如下配置：\n这个是真的巧合的不能再巧合了。\n参考教程  Postman设置网络代理  ","description":"","id":380,"section":"notes","tags":null,"title":"无奇不有的“Bug”","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/%E6%97%A0%E5%A5%87%E4%B8%8D%E6%9C%89%E7%9A%84bug/"},{"content":"我肯定会划分一段时间去解决日志相关的问题，但是现阶段该问题该优先级并没有那么高，我先记录下我遇到的问题，未来系统学习的时候再解决这些问题。\n在做RestTemplate日志输出的时候，我发现如果我日志如果是Debug级别的，系统并不会输出我的日志。当然，我是知道设置日志输出级别的问题的，但是问题的关键点在于：我明明看到日志中有Debug级别的日志输出。\n刚才在解决新框架的问题时又遇到了一个类似的情况，ExceptionHandler在打印异常信息的时候用的是Debug级别，我听同事说，需要在SpringBoot的配置文件中配置路径，然后就可以打印相关的日志了。额，相关的知识我也了解过，只是我的知识还停留在log4j的时代，我记得上logbak和log4j2时一般不会在SpringBoot的配置文件中配置什么东西，都是直接通过一个xml文件进行配置。\n先收集一下这些问题，等系统去学习时再解决吧。\n","description":"","id":381,"section":"notes","tags":null,"title":"日志输出的一些事","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/"},{"content":"DipatcherServlet使用默认的Bean处理请求 Spring的DispatcherServlet使用了内置在WebApplicationContext中的特定的Bean来处理请求、渲染视图等，这些Bean是Spring MVC框架的一部分。\n如果你想指定使用哪个特定的Bean，可以在WebApplicationContext中简单地配置它们。当然这只是可选的，Spring MVC维护了一个默认的Bean列表，如果没有进行特别的配置，框架将会使用默认的Bean。DispatcherServlet都依赖的这些Bean如下所示。\nHandlerMapping处理器映射 HandlerMapping处理器映射。它会根据某些规则将进入容器的请求映射到具体的处理器以及一系列前处理器和后处理器（即处理器拦截器）上。\n具体的规则视HandlerMapping类的实现不同而有所不同。其最常用的一个实现支持你在控制器上添加注解，配置请求路径。当然，也存在其他的实现。\n（这里提到了前处理器和后处理器，即处理器拦截器，这部分知识我接触的比较少）\nHandlerAdapter处理器适配器 HandlerAdapter处理器适配器。拿到请求所对应的处理器后，适配器将负责去调用该处理器，这使得DispatcherServlet无需关心具体的调用细节。\n比方说，要调用的是一个基于注解配置的控制器，那么调用前还需要从许多注解中解析出一些相应的信息。因此，HandlerAdapter的主要任务就是对DispatcherServlet屏蔽这些具体的细节。\n（能够理解其需要进行的工作，将请求体转换成Request DTO可能是在这个处理器中做的）\nMultipartResolver解析器 MultipartResolver解析multi-part的传输请求，比如支持通过HTML表单进行的文件上传等。\n其他的Bean HandlerExceptionResolver处理器异常解析器它负责将捕获的异常映射到不同的视图上去，此外还支持更复杂的异常处理代码。\nViewResolver视图解析器。它负责将一个代表逻辑视图名的字符串（String）映射到实际的视图类型View上。\nLocaleResolver \u0026amp; LocaleContextResolver地区解析器 和 地区上下文解析器。它们负责解析客户端所在的地区信息甚至时区信息，为国际化的视图定制提供了支持。\nThemeResolver主题解析器。它负责解析你web应用中可用的主题，比如，提供一些个性化定制的布局等。\nFlashMapManagerFlashMap管理器。它能够存储并取回两次请求之间的FlashMap对象。后者可用于在请求之间传递数据，通常是在请求重定向的情境下使用。\nDispatcherServlet.properties文件 这个Bean列表保存在包org.springframework.web.servlet下的DispatcherServlet.properties文件中。\nDispatcherServlet的处理流程   首先，搜索应用的上下文对象WebApplicationContext并把它作为一个属性（attribute）绑定到该请求上，以便控制器和其他组件能够使用它。属性的键名默认为DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE\n  将地区（locale）解析器绑定到请求上，以便其他组件在处理请求（渲染视图、准备数据等）时可以获取区域相关的信息。如果你的应用不需要解析区域相关的信息，忽略它即可\n  将主题（theme）解析器绑定到请求上，以便其他组件（比如视图等）能够了解要渲染哪个主题文件。同样，如果你不需要使用主题相关的特性，忽略它即可\n  如果你配置了multipart文件处理器，那么框架将查找该文件是不是multipart（分为多个部分连续上传）的。若是，则将该请求包装成一个MultipartHttpServletRequest对象，以便处理链中的其他组件对它做进一步的处理。\n  为该请求查找一个合适的处理器。如果可以找到对应的处理器，则与该处理器关联的整条执行链（前处理器、后处理器、控制器等）都会被执行，以完成相应模型的准备或视图的渲染\n  如果处理器返回的是一个模型（model），那么框架将渲染相应的视图。若没有返回任何模型（可能是因为前后的处理器出于某些原因拦截了请求等，比如，安全问题），则框架不会渲染任何视图，此时认为对请求的处理可能已经由处理链完成了\n  如果在处理请求的过程中抛出了异常，那么上下文WebApplicationContext对象中所定义的异常处理器将会负责捕获这些异常。通过配置你自己的异常处理器，你可以定制自己处理异常的方式。\nSpring的DispatcherServlet也允许处理器返回一个Servlet API规范中定义的最后修改时间戳（last-modification-date） 值。决定请求最后修改时间的方式很直接：DispatcherServlet会先查找合适的处理器映射来找到请求对应的处理器，然后检测它是否实现了LastModified接口。若是，则调用接口的long getLastModified(request)方法，并将该返回值返回给客户端。\n参考资料  Spring MVC DispatcherServlet详解  ","description":"","id":382,"section":"notes","tags":null,"title":"更多的了解DispatcherServlet","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BA%86%E8%A7%A3dispatcherservlet/"},{"content":"事情是这样的，我们dev环境发现一些接口不可用，这个问题追溯到源码，发现一份源码文件被删除了。我对这种问题非常敏感，因为我常常使用Idea的一些操作，很容易就影响到别的文件，而我自己还不知道（我最近一次发现的问题是我修改实体的delete为isDelete时，xml文件、@Select中的delete也跟着一起被修改了，非常恐怖），所以我计划定位出这个问题来。\n我先使用了git log -- RoleController.java指令查看了该文件的日志信息，找到了我最近作出修改的commitId，然后我用git checkout commitId切换到该分支上，我发现该文件确实消失了，其实基本上已经可以定位是我的操作导致了该文件的消失。\n我又使用git show commitId查看了该提交时做出来的修改，有如下信息：\n这基本上就定位了，就是我的误操作导致了该文件的丢失。\n我有时候操作会过快，会触发一些误操作，这次误删除的是顶级的Controller类，导致这个问题暴露的比较晚。\n参考资料  Git 查看某次commit的内容  ","description":"","id":383,"section":"notes","tags":null,"title":"查文件误删","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/%E6%9F%A5%E6%96%87%E4%BB%B6%E8%AF%AF%E5%88%A0/"},{"content":"我记得当时的需求是我的集群中出现了不明白的问题，我判断是etcd出现了问题，我需要查看etcd中的数据。\n这是对以前收藏的整理。\n 查看k8s的etcd pod中的数据  ","description":"","id":384,"section":"notes","tags":null,"title":"查看etcd中的数据","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9F%A5%E7%9C%8Betcd%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE/"},{"content":"我在尝试通过JdbcTeamplate获取数据库中列的元数据，有如下一段代码：\n1 2 3 4 5 6 7 8  ResultSet columns = dbMetaData.getColumns(null, null, \u0026#34;t_dyf_%\u0026#34;, null); while(columns.next()){ String tableName = columns.getString(\u0026#34;COLUMN_NAME\u0026#34;); System.out.println(tableName); }   我并不知道columns.getString(columnTable)方法能够传递哪些参数，我查看了这个方法的源码，也没有说清楚。我懒得找文章，最后我通过断点的方式查看了该方法支持的所有参数：\n这件事情中唯一让我感觉到意外的是，我断点查看columns的实现时，显示的是HikariProxyResultSet，但是在这个类中的断点不会执行到，需要在PgResultSet中进行断点。\n","description":"","id":385,"section":"notes","tags":null,"title":"查看getString方法支持哪些参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E6%9F%A5%E7%9C%8Bgetstring%E6%96%B9%E6%B3%95%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E5%8F%82%E6%95%B0/"},{"content":"开始 \u0026gt; 设置 \u0026gt; 系统 \u0026gt; 关于\n参考资料  我运行的是哪个 Windows 操作系统版本？  ","description":"","id":386,"section":"notes","tags":null,"title":"查看Windows的版本和版本号","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E6%9F%A5%E7%9C%8Bwindows%E7%9A%84%E7%89%88%E6%9C%AC%E5%92%8C%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"我这里只是纯粹记录的，方便我查阅相关注解实现的源码。相应的知识积累多了，也有助于我寻找Spring的设计思路。\n注解：\n @PreDestroy: InitDestroyAnnotationBeanPostProcessor @Autowired: AutowiredAnnotationBeanPostProcessor  Aware：\n ApplicationContextAware: ApplicationContextAwareProcessor  ","description":"","id":387,"section":"notes","tags":null,"title":"注解、Aware及其实现类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E6%B3%A8%E8%A7%A3aware%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E7%B1%BB/"},{"content":"操作步骤  注释如下/etc/apt/sources.list.d/pve-enterprise.list中相关代码（如果你没有该文件，则无需该操作）:  个人小结 因为该文件配置的源为企业版用的，只有你购买了证书后才能够从该源下载软件，如果不注释的话，可能会导致安装软件时报错。\n","description":"","id":388,"section":"notes","tags":null,"title":"注释企业源，防止安装软件时报错","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E6%B3%A8%E9%87%8A%E4%BC%81%E4%B8%9A%E6%BA%90%E9%98%B2%E6%AD%A2%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99/"},{"content":"以前用到的，但是忘记使用场景了，想记录下来。\n参考资料  Pipeline Steps Reference  ","description":"","id":389,"section":"notes","tags":null,"title":"流水线相关的资料","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/jenkins/%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9B%B8%E5%85%B3%E7%9A%84%E8%B5%84%E6%96%99/"},{"content":"操作步骤  安装nc工具：   yum install -y nc 服务端监听   nc -l -u 0.0.0.0 80001 客户端发送数据报   nc -u 192.168.31.210 数据报一 数据报二 现象：客户端发送的数据报会显示在服务端  参考资料  测试udp服务的端口是否可用   ","description":"","id":390,"section":"notes","tags":null,"title":"测试udp数据报是否可以正常传递","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E6%B5%8B%E8%AF%95udp%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E4%BC%A0%E9%80%92/"},{"content":"问题描述  异常如下：   org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records. at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:820) ~[kafka-clients-2.3.1.jar!/:?] at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:692) ~[kafka-clients-2.3.1.jar!/:?] at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1454) ~[kafka-clients-2.3.1.jar!/:?] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:2026) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:1849) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:981) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:927) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_242] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_242] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_242] 探索过程  直接Google查到了是因为消费者没有在Kafka指定的时间内确认消费，直接导致了该异常。我们修改了该指定时间，从默认的300秒改为了500秒，问题依旧。 我尝试使用stack查看jvm运行信息，没有结果（很多东西忘记，加之之前主要学习JProfile，总之基本功不到位） 我尝试配置log4j2让log4j2打印更详细的日志，失败了（log4j2的使用经验比较少，配置没有研究过） 其实我想拥有命令行权限，尝试使用更高级的工具，但是没有获得该权限（所以放弃了） 最后欣哥告诉我们，该问题出现过，是一个已知的问题，于是智敏直接操作了数据库中相关的数据，该问题应该可能被解决了（没有验证，参考下一点） 运维的同事也知道这是一个已知的问题，之前的解决方案为跳过Kafka中的该消息，我们采用该方案，该问题立即得到解决  问题原因  我们在消费消息的时候，会拿到某个消息中的数据，然后去查相关的记录，查到的记录有一千多条，我们会在一个循环中通过同步调用完成我们的功能，最后导致消费该消息的时间非常的长，最终抛出如上异常。 我们在该主题的消费为顺序消费，所以一旦一个消息阻塞就会导致消息积压，而且有个更恐怖的问题，如果消费者总是无法消费确认，最终会导致消费者掉线，最终导致整个job-center都不是正常的（需要再确认细节）  解决问题时的不足  无法看到Kafka中目前阻塞流程的消息是什么？ 对jvm提供的命令行工具使用不熟练，之前有意识到命令行工具才是服务端的利器，但是一直没有下定决心去学习 对Kafka不够了解，基础概念忘了很多（之前学习大数据时有系统学习过，不过都差不多忘记了） 对log4j2不熟悉，不能随心所欲的进行配置，这个必须花时间去学习。  总结  其实我也没有办法，最近的这段时间里，我根本没有搭起自己服务端环境，所以相关技术学习动力不够强。 我可能不想再花太多时间在前端学习上了，我自己想要的编辑器，固然很酷炫，但是工作做的不够好，也不行啊  ","description":"","id":391,"section":"notes","tags":null,"title":"消费确认失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/kafka/%E6%B6%88%E8%B4%B9%E7%A1%AE%E8%AE%A4%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"hugo主要有四种布局：single、list、index、404。index就是主页，404就是url找不到时的错误页面，这两个都挺好理解的。\n至于single和list，我目前是这么理解的，如下为content中的内容：\n如果我们的url为localhost:1313/contact，则hugo会使用single布局，因为contact.md在content中是一个文件（叶子），如果我们的url为localhost:1313/blogs，则hugo会使用list布局，因为blogs在content中是一个文件夹（分支）。\n为此我做了一个小小的实验：\n我创建了如下sigle.html和list.html文件（因为我目前正在做内容类型相关的实验，所以我就在此基础上进行我新的实验了）：\n {{/* layouts/acme/sigle.html */}} {{define \u0026quot;body\u0026quot;}} \u0026lt;h1\u0026gt;sigle.html\u0026lt;/h1\u0026gt; {{end}} {{/* layouts/acme/list.html */}} {{define \u0026quot;body\u0026quot;}} \u0026lt;h1\u0026gt;list.html\u0026lt;/h1\u0026gt; {{end}} 此时我重启hugo server是不会看到任何变化的，然后访问markdown和news资源，是不会有任何变化的。我需要怎么做？因为我的sigle和list定义在了acme目录下，所以我需要修改markdow.md文件的type和news文件夹下_index.md的type，将其值改为acme。\n完成上面的步骤后，重启hugo，有如下页面：\n非常棒，和我猜想的一样。\n小结 我学习hugo是为了开发一款我自己的主题，我希望我的主题能呈现gitbook的风格。我掌握了list.html和single.html后，我已经可以完成我想要的效果了（我仅仅只需要开发一个single.html，将css调成gitbook的那种即可）。\n不过，我还是决定再多学习一些，哈哈，感觉hugo真的非常的强大，很喜欢。\n","description":"","id":392,"section":"notes","tags":null,"title":"理解Hugo中的single.html和list.html","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/hugo/%E7%90%86%E8%A7%A3hugo%E4%B8%AD%E7%9A%84single.html%E5%92%8Clist.html/"},{"content":"我一直以为KT Connect命令行工具有一定的玄学因素，参数只是位置放错了，就无法正常的运行，后来才发现是自己理解错了。\n如图：KT Connect的命令行工具是分段的，不同的参数只能位于不同的段：\n图中Global Options参数只能放置在命令行的global options配置项。然后需要写上需要执行的command（可以执行哪些command也在命令行中写了）。\n如何看connect命令支持哪些命令行参数呢，如下执行ktctl connect -help即可。\n按照要求放置各个参数，就不会出现问题了。\n","description":"","id":393,"section":"notes","tags":null,"title":"理解KT Connect命令执行","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/kt-connect/%E7%90%86%E8%A7%A3kt-connect%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"content":"需求产生于我们有两张表，一张表A中的数据为量一张表B中数据的复制品，结果B表结构增加了一些字段，A表未增加这些字段，最后导致接口数据不一致，目标是为A表添加这些字段，并用B表的数据更新A表以后数据。我开发的SQL如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ALTERTABLE\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;ADDCOLUMNapplicable_product_lineVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNcategoryVARCHAR(32)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNdesign_contentVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNmaterials_technologyVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNsurface_technicsVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;applicable_product_line\u0026#34;IS\u0026#39;适用产品线\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;category\u0026#34;IS\u0026#39;类目\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;design_content\u0026#34;IS\u0026#39;图案内容\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;materials_technology\u0026#34;IS\u0026#39;材料工艺\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;surface_technics\u0026#34;IS\u0026#39;表面工艺\u0026#39;;UPDATEt_mat_mall_favorites_infoSETapplicable_product_line=t_mat_mall_material.applicable_product_line,category=t_mat_mall_material.category,design_content=t_mat_mall_material.design_content,materials_technology=t_mat_mall_material.materials_technology,surface_technics=t_mat_mall_material.surface_technics,gmt_modify_time=now()FROMt_mat_mall_materialWHEREt_mat_mall_favorites_info.ID=t_mat_mall_material.ID  20210508后续：\n这件事情有后续的，上面开发的SQL无法在DMS中使用，我开发了下面的SQL：\n UPDATE t_mat_mall_favorites_info SET applicable_product_line = ( SELECT applicable_product_line FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), category = ( SELECT category FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), design_content = ( SELECT design_content FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), materials_technology = ( SELECT materials_technology FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), surface_technics = ( SELECT surface_technics FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ) 但是非常奇怪的是，之前版本开发的SQL只修改了\n","description":"","id":394,"section":"notes","tags":null,"title":"用一张表中的数据去更新另一张表","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E7%94%A8%E4%B8%80%E5%BC%A0%E8%A1%A8%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%BB%E6%9B%B4%E6%96%B0%E5%8F%A6%E4%B8%80%E5%BC%A0%E8%A1%A8/"},{"content":"对模板的配置 我在模板上执行了如下指令（凭记忆回忆的）：\n 配置下网络环境（我在配置模板机时，网络环境还没有搭起来，所以只能走全局代理的方式了）   # 公司 export all_proxy=http://192.168.13.113:1080 # 家（通过OpenWrt代理的） nmcli connection modify eth0 \\ ipv4.addresses 172.20.11.200/24 \\ ipv4.dns 172.20.11.210 \\ ipv4.method manual \\ ipv4.gateway 172.20.11.210 \\ connection.autoconnect yes nmcli c up eth0  安装docker（相关内容，我有更完整的文档说明，可以参考下）。   yum install -y yum-utils yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io systemctl start docker systemctl enable docker 安装lrzsz   yum install -y lrzsz 关闭firewalld、selinux、swap，配置内核参数（应该做而忘记做了的）   # 关闭防火墙 systemctl disable firewalld systemctl stop firewalld # 临时禁用selinux setenforce 0 sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux sed -i \u0026quot;s/SELINUX=enforcing/SELINUX=disabled/g\u0026quot; /etc/selinux/config # 禁用交换分区 swapoff -a sed -i 's/.*swap.*/#\u0026amp;/' /etc/fstab # 修改内核参数 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system # 重启后检查配置是否生效 reboot systemctl status firewalld sestatus swapon -s 我目前就记起了这四步，之后想起来了再整理。\n安装K8S的工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubectl kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   对虚拟机的配置  修改hostname   hostnamectl set-hostname base hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 hostnamectl set-hostname node4 hostnamectl set-hostname node5 编辑/etc/hosts文件（不编辑这个文件，Kubernetes集群初始化时会出现问题）   tee /etc/hosts \u0026lt;\u0026lt;-'EOF' 127.0.0.1 localhost 192.168.13.68 base 192.168.13.195 node1 192.168.13.83 node2 192.168.13.32 node3 192.168.13.105 node4 192.168.13.236 node5 EOF tee /etc/hosts \u0026lt;\u0026lt;-'EOF' 127.0.0.1 localhost 172.20.11.201 base 172.20.11.202 node1 172.20.11.203 node2 172.20.11.204 node3 172.20.11.205 node4 172.20.11.206 node5 EOF  配置网络环境：   nmcli connection modify eth0 \\ ipv4.addresses 192.168.13.195/24 \\ ipv4.dns 192.168.13.77 \\ ipv4.method manual \\ ipv4.gateway 192.168.13.77 \\ connection.autoconnect yes nmcli c up eth0 完成以上工作，就完成了一个集群的基本配置了。\n","description":"","id":395,"section":"notes","tags":null,"title":"用于K8S集群的模板配置及对生成的虚拟机的调整","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E7%94%A8%E4%BA%8Ek8s%E9%9B%86%E7%BE%A4%E7%9A%84%E6%A8%A1%E6%9D%BF%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%AF%B9%E7%94%9F%E6%88%90%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E8%B0%83%E6%95%B4/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  package com.sdstc.pdm.common.codec; import com.alibaba.fastjson.parser.DefaultJSONParser; import com.alibaba.fastjson.parser.deserializer.ObjectDeserializer; import com.alibaba.fastjson.serializer.JSONSerializer; import com.alibaba.fastjson.serializer.ObjectSerializer; import java.io.IOException; import java.lang.reflect.Type; import java.time.LocalDateTime; import java.time.ZoneOffset; public class LocalDateTimeCodec implements ObjectSerializer, ObjectDeserializer { @Override public \u0026lt;T\u0026gt; T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { if (type != LocalDateTime.class) { throw new RuntimeException(\u0026#34;Wrong Type\u0026#34;); } Long timestamp = Long.valueOf((String) parser.parse()); //noinspection unchecked  return (T) LocalDateTime.ofEpochSecond( timestamp / 1000, 0, ZoneOffset.ofHours(8)); } @Override public int getFastMatchToken() { return 0; } @Override public void write(JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) throws IOException { if (!(object instanceof LocalDateTime)) { throw new RuntimeException(\u0026#34;Wrong Type\u0026#34;); } LocalDateTime time = (LocalDateTime) object; serializer.write(time.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)).toEpochMilli()); } }   目前还是临时方案，我会持续迭代这个Codec。\n参考资料  localdatetime实现时间戳(相互转换)  ","description":"","id":396,"section":"notes","tags":null,"title":"用于LocalDateTime的Codec","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/localdatetime/%E7%94%A8%E4%BA%8Elocaldatetime%E7%9A%84codec/"},{"content":"Autowired 虽然我们现在开发的时候基本用不上这个注解（我们基本用构造函数注入），但是有些东西还是需要了解一下的。\n @Autowired默认按照类型去容器中找对应的组件，如果找到了多个相同的组件，将再按照属性的名称作为组件的id去容器中查找。在实验中，如果在容器中按照类型寻找到了多个组件，且此时这些组件的id和属性名不相等，则会报如下错误（这个时候Idea也会报红，注意下就好）：   org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.example.jj.demo.configuration.TempTmpConfiguration': Unsatisfied dependency expressed through field 'user'; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.example.jj.demo.damain.User' available: expected single matching bean but found 2: user01,user02 可以通过@Qualifier注解，该注解会让@Autowire所有的默认行为都失效，而直接通过该注解给定的组件Id从容器中寻找。  1 2 3 4 5  @Autowired @Qualifier(\u0026#34;bookDao2\u0026#34;) private BookDao bookDao    使用了@Autowired注解，则容器中一定要有符合条件的组件进行装配，否则会报错。当然可以指定@Autowired的required参数为false。\n  @Autowired是可以结合@Primary注解使用的，当我们注入Bean的时候，如果某个Bean上使用了@Primary注解，则@Autowired会有限注入该Bean（想一想，感觉这些注解的实现逻辑会错综复杂，也不知道Spring的开发团队是如何清晰的管理这些框架逻辑的）。在实验中，如果你同时为多个Bean标注了该注解，且注入的时候仅使用了@Autowired注解（我以为会回归到@Autowired的默认行为，看样子不行），则会抛如下的错误，此时如果使用@Qualifier，则不会抛出任何错误。\n   org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.example.jj.demo.configuration.TestTmpConfiguration': Unsatisfied dependency expressed through field 'user01'; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.example.jj.demo.damain.User' available: more than one 'primary' bean found among candidates: [user01, user02] @Autowired可以注解在构造器、参数、方法上。    标注在方法上时，如果该方法同时也被@Bean注解，则可以省略@Autowired注解（额，我大概能猜到原理）\n  标注在构造器上时，如果组件只有一个有参构造器，则这个有参构造器上可以省略@Autowired（这个的原理不好猜）。\n  @Resource和@Inject 如下两个注解皆为Java规范，而@Autowired为Spring定义的：\n  @Resource默认是按照组件名称进行装配的，不支持@Primary功能，不支持required=false参数。\n  @Inject需要导入javax.inject包，和@Autowired的功能一样\n  自定义组件需要使用ApplicationContext、BeanFactory等 自定义组件实现xxxAware，在创建对象的时候，会调用接口规范的方法注入相关的组件。该方案主要用于将Spring底层的一些组件注入到自定义的Bean中。在实现层面，每个xxxAware基本都对应一个xxxAwareProcessor，例如ApplicationContextAware对应ApplicationContextAwareProcessor。\n","description":"","id":397,"section":"notes","tags":null,"title":"用于注入Bean的一些注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E7%94%A8%E4%BA%8E%E6%B3%A8%E5%85%A5bean%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B3%A8%E8%A7%A3/"},{"content":"如下为实验目录及文件：\n其中gihub-actions-demo.yml内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  name:GitHub Actions Demoon:[push]jobs:Explore-GitHub-Actions:runs-on:ubuntu-lateststeps:- run:echo \u0026#34;🎉 The job was automatically triggered by a ${{ github.event_name }} event.\u0026#34;- run:echo \u0026#34;🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!\u0026#34;- run:echo \u0026#34;🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\u0026#34;- name:Check out repository codeuses:actions/checkout@v2- run:echo \u0026#34;💡 The ${{ github.repository }} repository has been cloned to the runner.\u0026#34;- run:echo \u0026#34;🖥️ The workflow is now ready to test your code on the runner.\u0026#34;- name:List files in the repositoryrun:|ls ${{ github.workspace }}- run:echo \u0026#34;🍏 This job\u0026#39;s status is ${{ job.status }}.\u0026#34;  当push到仓库时，可以Actions选项卡中看到如下内容（实验中我共Push了三次，触发了Actions三次）：\n左侧为我们在yml中定义的所有工作流，右侧为该工作流执行结果。可以点击执行结果查看执行详情：\n此时右侧为我们定义的Job，点击Job查看Job执行详情：\n本次实验到此结束，这是我第一次接触Github Actions，感觉还是挺有趣的。\n参考资料  GitHub Actions 快速入门  ","description":"","id":400,"section":"notes","tags":null,"title":"简单使用GitHub Actions","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/github/%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8github-actions/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Max(150) @Min(0) @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE}) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {}) public @interface JAge { @OverridesAttribute(constraint = Max.class, name = \u0026#34;message\u0026#34;) @OverridesAttribute(constraint = Min.class, name = \u0026#34;message\u0026#34;) String message() default \u0026#34;年龄超出范围\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; }   需要注意的两个地方：\n 类上的@Max(150)，@Min(0)这两个注解是真正的实现校验的注解。 message上的@OverridesAttribute，如果不存在这个，则提示信息将会为@Max和@Min的提示信息。@OverridesAttribute注解可以覆盖组合约束的一些属性  参考资料  spring boot 参数校验这么做简洁实用  ","description":"","id":401,"section":"notes","tags":null,"title":"组合约束","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E7%BB%84%E5%90%88%E7%BA%A6%E6%9D%9F/"},{"content":"公司电脑锁屏后，重登时都会出现与工作站失去信任关系的问题，解决该问题必须重启机器。运维同事帮我解决了很多次，都没有效果，非常绝望。更绝望的是我有随手按Win + L的习惯。\n与其指望自己不按Win + L键，不如把这个键给禁了。\n操作步骤   打开注册表（Win + R，输入regedit进入）\n  进入如下目录：\n   计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies  在左侧：鼠标右键Policies，新建项，命名为System\n  点开System，在右侧，新建DWORD (32-bit) ，命名为DisableLockWorkstation\n  右键点击新建的DisableLockWorkstation，点击修改，将值改为1\n  参考资料  How to Disable the Lock Screen Shortcut Key (Win + L) in Windows  个人小结 本想截图把过程说清晰，但是我打开注册表时，Snapaste就无法使用。参考资料里有清楚的图片，如果不是太理解可以参考那些图片。参考资料可能会无法访问，可以直接谷歌“how to disable lock screen hotkey in win10”。\n这个需求要的人应该非常的少，我百度了很长时间都没有找到解决方案。\n3.20号，运维大大帮我解决这个问题了，非常开心~\n","description":"","id":402,"section":"notes","tags":null,"title":"绝望的Win10锁屏与解决方案","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E7%BB%9D%E6%9C%9B%E7%9A%84win10%E9%94%81%E5%B1%8F%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"content":"具体报Redis的错误我忘记整理了，但是该错误我曾经遇到过，如下（日志来自另一篇笔记）：\n java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:123) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:244) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redisUtil': Unsatisfied dependency expressed through field 'redisTemplate'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:893) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:120) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 24 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:797) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 43 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:884) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:788) ... 56 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:650) ... 70 more Caused by: java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration$LettucePoolingClientConfigurationBuilder.\u0026lt;init\u0026gt;(LettucePoolingClientConfiguration.java:94) at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration.builder(LettucePoolingClientConfiguration.java:51) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration$PoolBuilderFactory.createBuilder(LettuceConnectionConfiguration.java:159) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.createBuilder(LettuceConnectionConfiguration.java:107) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.getLettuceClientConfiguration(LettuceConnectionConfiguration.java:92) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.redisConnectionFactory(LettuceConnectionConfiguration.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 71 more Caused by: java.lang.ClassNotFoundException: org.apache.commons.pool2.impl.GenericObjectPoolConfig at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 82 more 这个错误的原因是没有引入连接池，我们这次报错也是同样的错误原因，但是导致我们没有成功引入连接池的原因确实我们忘记设置项目的parent了。在sdstc-core项目中，我们定义了连接池依赖，在ststc-spring-boot-parent-start中，我们定义了变量，值为依赖的版本，由于我们设置parent标签，导致这些变量不可用，最终导致我们依赖引入失败。\n","description":"","id":403,"section":"notes","tags":null,"title":"缺乏父依赖，导致项目报Redis链接错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E7%BC%BA%E4%B9%8F%E7%88%B6%E4%BE%9D%E8%B5%96%E5%AF%BC%E8%87%B4%E9%A1%B9%E7%9B%AE%E6%8A%A5redis%E9%93%BE%E6%8E%A5%E9%94%99%E8%AF%AF/"},{"content":"解决步骤  修改插件源为：  https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json  修改updates/default.json文件：\n updates.jenkins-ci.org/download修改为：mirrors.tuna.tsinghua.edu.cn/jenkins www.google.com修改为：www.baidu.com    重启Jenkins\n  相关教程  【Jenkins】插件更改国内源  ","description":"","id":404,"section":"notes","tags":null,"title":"解决Jenkins下载插件慢","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/jenkins/%E8%A7%A3%E5%86%B3jenkins%E4%B8%8B%E8%BD%BD%E6%8F%92%E4%BB%B6%E6%85%A2/"},{"content":"解决步骤  拿到原镜像地址：  1 2 3  kubectl describe po xxx -n xxx # quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   替换为国内的站点  1 2 3  sudo docker pull quay.mirrors.ustc.edu.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   推送到harbor，方便其他虚拟机进行下载  1 2 3 4  sudo docker tag quay.mirrors.ustc.edu.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 sudo docker push 192.168.30.174:80/test/nginx-ingress-controller:0.30.0   其他虚拟机拉下代码，重新打回原tag  1 2 3 4  sudo docker pull 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 sudo docker tag 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   相关资料   在国内如何拉取 quay.io 的镜像\n  烂泥：docker.io、gcr.io、quay.io镜像加速(20200413更新)(未实践)\n  【docker 镜像源】解决quay.io和gcr.io国内无法访问的问题(未实践)\n  ","description":"","id":405,"section":"notes","tags":null,"title":"解决Kubernetes从国外站点下载镜像慢的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E8%A7%A3%E5%86%B3kubernetes%E4%BB%8E%E5%9B%BD%E5%A4%96%E7%AB%99%E7%82%B9%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题描述  console下会不显示任何东西），在最上面会有一个提示，说客户端事件和服务器实践不一致  解决步骤  调整客户端时间，与服务器一致（分钟级别的），该问题修复  问题小记  我原本想调整服务器事件为世界时间，结果花了很长时间没有解决这个问题，这也激发我以后自己搭ntpd的想法  ","description":"","id":406,"section":"notes","tags":null,"title":"解决Prometheus管理页面的Console下没有任何东西显示","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/prometheus/%E8%A7%A3%E5%86%B3prometheus%E7%AE%A1%E7%90%86%E9%A1%B5%E9%9D%A2%E7%9A%84console%E4%B8%8B%E6%B2%A1%E6%9C%89%E4%BB%BB%E4%BD%95%E4%B8%9C%E8%A5%BF%E6%98%BE%E7%A4%BA/"},{"content":"在装kubernetes时，因为部分镜像下载太慢，我强行终止了下载。待我通过别的网速较快的机器将该镜像拉取并上传到内部的镜像服务器后，然后再次前往这个网速较慢的机器拉取镜像时，即使我已经换了镜像源，镜像始终从断点处拉取。\n解决步骤  查看docker的root目录：  1 2 3  sudo docker info    切换到root用户，进入该目录，删除tmp文件，重docker  1 2 3 4 5 6 7  su root \\  \u0026amp;\u0026amp; cd /var/lib/docker \u0026amp;\u0026amp; rm -r tmp sudo systemctl restart docker   20210504后续：\n没想到今天竟然还有相关的需求。\n参考资料  docker踩坑记  ","description":"","id":407,"section":"notes","tags":null,"title":"解决从不同源拉取同一个镜像多次，始终从断点处执行","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E8%A7%A3%E5%86%B3%E4%BB%8E%E4%B8%8D%E5%90%8C%E6%BA%90%E6%8B%89%E5%8F%96%E5%90%8C%E4%B8%80%E4%B8%AA%E9%95%9C%E5%83%8F%E5%A4%9A%E6%AC%A1%E5%A7%8B%E7%BB%88%E4%BB%8E%E6%96%AD%E7%82%B9%E5%A4%84%E6%89%A7%E8%A1%8C/"},{"content":"解压tar.xz 1 2 3  tar -xvJf node-v8.11.1-linux-x64.tar.xz   ","description":"","id":408,"section":"notes","tags":null,"title":"解压tar.xz文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip%E6%8C%87%E4%BB%A4/%E8%A7%A3%E5%8E%8Btar.xz%E6%96%87%E4%BB%B6/"},{"content":"解压时去掉最外层文件夹 主要是使用--strip-components 1\n1 2 3  tar -xvJf node-v8.11.1-linux-x64.tar.xz --strip-components 1   ","description":"","id":409,"section":"notes","tags":null,"title":"解压是去掉最外层文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip%E6%8C%87%E4%BB%A4/%E8%A7%A3%E5%8E%8B%E6%98%AF%E5%8E%BB%E6%8E%89%E6%9C%80%E5%A4%96%E5%B1%82%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"之前开发一个功能时需要用到yaml文件记录配置信息，刚开始使用snakeyml，但是snakeyml有个小小的问题，就是它解析后得到的map的key的顺序与文件中的并不一致。这种情况在很多需求下都是无所谓的，但是因为我们的功能恰巧很重视这个顺序，故只能放弃使用yml。（不知道snakeyml有没有办法通过配置保证key的顺序与文件中的一致）\n后来偶尔发现SpringBoot提供了一些工具，可以简单的处理yaml文件，且能够保证key的顺序，记录如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import org.springframework.beans.factory.config.YamlPropertiesFactoryBean; import org.springframework.core.io.ClassPathResource; @SpringBootTest class YAMLTest{ @SuppressWarnings(\u0026#34;Duplicates\u0026#34;) public void execute() { YamlPropertiesFactoryBean factoryBean = new YamlPropertiesFactoryBean(); factoryBean.setResources(new ClassPathResource(\u0026#34;config/auto-create-tables-schedule.yml\u0026#34;)); Properties properties = factoryBean.getObject(); if (properties != null) { properties.forEach((table, tableCreateSql) -\u0026gt; { }); } } }   这个功能是很久前写的，但是最近因为又遇到了这个问题，故记录之，可能刚好记反了这两个yaml解析工具的特点，见谅，我下次遇到该问题时会及时更新该博客。\n","description":"","id":410,"section":"notes","tags":null,"title":"解析yaml文件的时候维持文件中字段的顺序","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E8%A7%A3%E6%9E%90yaml%E6%96%87%E4%BB%B6%E7%9A%84%E6%97%B6%E5%80%99%E7%BB%B4%E6%8C%81%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AD%97%E6%AE%B5%E7%9A%84%E9%A1%BA%E5%BA%8F/"},{"content":"CentOS拨号上网时导致的无法通过192.168.31.217进行ssh的问题。我的解决方案非常的暴力，我拆掉了J4125上的USB网卡，然后将我的笔记本和J4125的enp3s0网卡直连。我对enp3s0网卡进行了如下配置：\n# /etc/sysconfig/network-scripts/ifcfg-enp3s0 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp3s0 UUID=2a6cd38f-6405-4c45-9bd0-2648e1f26a15 DEVICE=enp3s0 ONBOOT=yes IPADDR=192.168.31.1 NETMASK=255.255.255.0 GATEWAY=192.168.31.1 ifcfg-enp3s0这份文件原本是不存在的，我是从系统为我的USB网卡生成的文件中copy出来的，然后改了改。\n接下来配置Windows，Windows配置很简单，就是给一个静态的IP地址就好了。只是我在配置的时候遇到了一些怪异的现象，我填好了ip地址后，退出来后。然后在终端执行ipconfig，会发现我配置的ip地址并没有生效，会变成169.254.69.105，奇奇怪怪，我完全不知道这个ip地址是怎么产生的。\n我多次尝试后，地址依然会变成这个，我只好一一禁用我的网卡，貌似知道我禁用了无线网卡后，该问题才恢复，我其实一开始就断开了我无线的连接，没想到无线网卡还会影响到这个ip的配置，不过我之前无线分配的ip和我这次想设置的ip确实是一样的，可能是发生了什么冲突。\n我好奇的是从网络拓补上来讲，目前的网络拓补和使用USB网卡时的网络拓补基本一样的，这次却可以成功的SSH到J4125上。\n","description":"","id":411,"section":"notes","tags":null,"title":"记录CentOS拨号上网时的一个奇怪的问题","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E8%AE%B0%E5%BD%95centos%E6%8B%A8%E5%8F%B7%E4%B8%8A%E7%BD%91%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%A5%87%E6%80%AA%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"Digoal.Zhou\u0026rsquo;s Blog\n我暂时没有条件研究这个技术，环境还没有搭好，最近时间也安排的比较满。\n","description":"","id":412,"section":"notes","tags":null,"title":"记录一个大佬的Blog","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E5%A4%A7%E4%BD%AC%E7%9A%84blog/"},{"content":"我想通过SpringBoot Actuator查看正在运行的应用的一些配置信息，当我引入如下依赖后，启动引用报如下错误：\n \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/D:/MavenRepository/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.3/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/D:/MavenRepository/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory] Exception in thread \u0026quot;main\u0026quot; java.lang.ExceptionInInitializerError at com.sdstc.dyf.provider.StartDyfProviderTest.main(StartDyfProviderTest.java:26) Caused by: org.apache.logging.log4j.LoggingException: log4j-slf4j-impl cannot be present with log4j-to-slf4j at org.apache.logging.slf4j.Log4jLoggerFactory.validateContext(Log4jLoggerFactory.java:49) at org.apache.logging.slf4j.Log4jLoggerFactory.newLogger(Log4jLoggerFactory.java:39) at org.apache.logging.slf4j.Log4jLoggerFactory.newLogger(Log4jLoggerFactory.java:30) at org.apache.logging.log4j.spi.AbstractLoggerAdapter.getLogger(AbstractLoggerAdapter.java:54) at org.apache.logging.slf4j.Log4jLoggerFactory.getLogger(Log4jLoggerFactory.java:30) at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:363) at org.apache.commons.logging.LogAdapter$Slf4jAdapter.createLocationAwareLog(LogAdapter.java:130) at org.apache.commons.logging.LogAdapter.createLog(LogAdapter.java:91) at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:67) at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:59) at org.springframework.boot.SpringApplication.\u0026lt;clinit\u0026gt;(SpringApplication.java:196) ... 1 more 因为我们的项目使用了Maven的SnapShot版本机制，在确定该问题不是同事造成的后，我认为该报错可能是因为jar包冲突。跟架构师了解到，我们的框架默认开启了spring-boot-starter-actuator，所以不需要在引入依赖，我暂时先放置这个问题吧。\n","description":"","id":413,"section":"notes","tags":null,"title":"记录一些解决jar冲突（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E8%A7%A3%E5%86%B3jar%E5%86%B2%E7%AA%81%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"问题简单的描述是这样的：我发现网线两端的网速并不匹配，一边显示100M，一边显示1000M，显示100M的是我的R8125网卡，我就很不开心，想手动速度调整为1000，于是我使用了如下指令:\n ethtool -s enp4s0 speed 1000 autoneg off 发现该操作无效后，我又对着网线的另一端做了类似的操作，最终导致两端的自动协商都被关闭了。于是两个系统就无法正常的通信了，且网口的灯都不闪烁了。\n我刚开始并没有意识到是关闭自动协商导致的问题。\n后来经过实验发现：该操作是可以实现将高速变为低速的，无法将低速变成高速，可能是因为自动协商的结果已经是最高速了。\n","description":"","id":414,"section":"notes","tags":null,"title":"记录一次关闭链路自动协商带来的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/rtl8125/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%85%B3%E9%97%AD%E9%93%BE%E8%B7%AF%E8%87%AA%E5%8A%A8%E5%8D%8F%E5%95%86%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题是这样的，我们的项目需要使用到GRpc的9090端口，所以申请运维帮我们暴露一下该端口，等我们自己测试该端口时，发现该端口无法正常使用（原80端口是正常的），检查了POD、Service后，可以确认该端口应该处于开启状态的。我后来注意到，运维帮我们配置的Service如下：\n spec: clusterIP: 10.254.73.68 ports: - name: http-tcp port: 80 protocol: TCP targetPort: 8080 - name: http-tcp-9090 port: 9090 protocol: TCP targetPort: 9090 selector: app: dyf-provider sessionAffinity: None type: ClusterIP 我记得我学习Istio时了解到，Istio会根据你Service暴露端口时取的名字，做一些什么操作，我觉得是http-tcp-9090前的http影响到我们了，所以我去掉了http，测试该端口服务正常。我们最后尝试将tpc换成grpc，该端口也是正常使用的。\n最后的最后，为了确认不是巧合，我们又换成了http，该端口服务果然不可以访问了，哈哈，可以肯定就是这个http前缀影响了这个端口的正常使用。\n","description":"","id":415,"section":"notes","tags":null,"title":"记录一次超高速解决Istio问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes%E6%96%B0/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E8%B6%85%E9%AB%98%E9%80%9F%E8%A7%A3%E5%86%B3istio%E9%97%AE%E9%A2%98/"},{"content":"Maven配置代理及常用setting.xml文件 阿里源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;localRepository\u0026gt;F:\\repository\u0026lt;/localRepository\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;proxy\u0026gt; \u0026lt;id\u0026gt;my-proxy\u0026lt;/id\u0026gt; \u0026lt;active\u0026gt;true\u0026lt;/active\u0026gt; \u0026lt;protocol\u0026gt;http\u0026lt;/protocol\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;1080\u0026lt;/port\u0026gt; \u0026lt;/proxy\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt;\u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;aliyunmaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;ali public\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt;\u0026lt;/profiles\u0026gt; \u0026lt;activeProfiles\u0026gt;\u0026lt;/activeProfiles\u0026gt; \u0026lt;/settings\u0026gt;   默认源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;pluginGroups\u0026gt;\u0026lt;/pluginGroups\u0026gt; \u0026lt;localRepository\u0026gt;F:\\repository\u0026lt;/localRepository\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;proxy\u0026gt; \u0026lt;id\u0026gt;my-proxy\u0026lt;/id\u0026gt; \u0026lt;active\u0026gt;true\u0026lt;/active\u0026gt; \u0026lt;protocol\u0026gt;http\u0026lt;/protocol\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;1080\u0026lt;/port\u0026gt; \u0026lt;/proxy\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt;\u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt;\u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt;\u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt;   ","description":"","id":416,"section":"notes","tags":null,"title":"记录两份配置文件，可用于网络限制的场景中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E4%B8%A4%E4%BB%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%AF%E7%94%A8%E4%BA%8E%E7%BD%91%E7%BB%9C%E9%99%90%E5%88%B6%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%AD/"},{"content":"还原命案现场，deploy的时候出现了如下错误：\n [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for thirdplatformcenter 1.0.0: [INFO] [INFO] thirdplatformcenter ................................ FAILURE [ 0.667 s] [INFO] thirdplatform-common ............................... SKIPPED [INFO] thirdplatform-client ............................... SKIPPED [INFO] thirdplatform-server ............................... SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.074 s [INFO] Finished at: 2021-04-26T18:25:18+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project thirdplatformcenter: Failed to deploy artifacts: Could not find artifact com.sdstc:thirdplatformcenter:pom:1.0.0 in project-repo (http://192.168.20.9:8081/repository/projectrepo/) -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 很熟悉是吧，我在两个不同的场景遇到了相同的报错，而且它们核心的原因都是一样的：仓库的地址找不到。\n我先说说这次发生错误的起因后果，我们的项目依赖了一个内部的框架项目：\n \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.sdstc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sdstc-spring-boot-parent-start\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; 框架项目的maven中配置了仓库信息：\n \u0026lt;!-- 本地快照 和release 发布 的配置 --\u0026gt; \u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!-- ID要和MAVEN中conif/setting.xml 中的server保持一致 --\u0026gt; \u0026lt;id\u0026gt;project-repo\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;project-repo\u0026lt;/name\u0026gt; \u0026lt;!-- project-repo的url地址 --\u0026gt; \u0026lt;url\u0026gt;${REMOTE_REPO}\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;central\u0026lt;/name\u0026gt; \u0026lt;!-- 配置仓库的地址 --\u0026gt; \u0026lt;url\u0026gt;${REMOTE_PUBLIC}\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 这些仓库信息的具体值是在我们的setting.xml文件中配置的：\n \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;remote-repo\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;REMOTE_REPO\u0026gt;http://192.168.20.9:8081/repository/projectrepo/\u0026lt;/REMOTE_REPO\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;remote-public\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;REMOTE_PUBLIC\u0026gt;http://192.168.20.9:8081/repository/mavenpublic\u0026lt;/REMOTE_PUBLIC\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; 问题在于哪？在于我们的remote-repo在传承的过程中，将http://192.168.20.9:8081/repository/project-repo/地址改为了http://192.168.20.9:8081/repository/projectrepo/，而后者是一个不可访问的地址。\n解决这个问题的方法有哪些了？第一将地址改为正确的，第二在项目的pom.xml文件中加如下配置（后者用在我定位问题和测试我的思路，前者是我最终的采用的方案）：\n \u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!-- ID要和MAVEN中conif/setting.xml 中的server保持一致 --\u0026gt; \u0026lt;id\u0026gt;project-repo\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;project-repo\u0026lt;/name\u0026gt; \u0026lt;!-- project-repo的url地址 --\u0026gt; \u0026lt;url\u0026gt;http://192.168.20.9:8081/repository/project-repo/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; 问题解决了，我其实产生了很多新的问题，我之前想尽办法为Maven配置代理的目的是什么？其实上我们的maven-public仓库是配置了阿里云的（感谢小勇，教会我看这个），我使用公司的setting.xml文件时应该是可以拉取到我想要的jar包的。但是当时问题确实太巧合了，我无论如何都拉不到我想要的包，我降了好几个版本都不行，所以我认为是因为仓库原因。\n另外，我本地不能使用中央仓库不能使用阿里云仓库，这本来就不符合我的开发习惯，就像透明代理一样，是一种我必须解决的技术问题。\n后续：\n这个问题更有趣的一点是：我们的pom.xml文件是从pdf文件中复制下来，而pdf中这两个仓库地址刚好处于换行的地方，所以在复制的时候被视为单词的换行符，给自动合并了，这是一个什么鬼？？？后面是Adobe PDF中复制出来的结果（貌似Adobe PDF中所有的横线都会变成空格）。\n \u0026lt;REMOTE_REPO\u0026gt;http://192.168.20.9:8081/repository/project repo/\u0026lt;/REMOTE_REPO\u0026gt; \u0026lt;/prop erties\u0026gt; \u0026lt;/ \u0026lt; \u0026lt;id\u0026gt;remote public\u0026lt;/id\u0026gt; \u0026lt; \u0026lt;REMOTE_PUBLIC\u0026gt;http://192.168.20.9:8081/repository/maven public\u0026lt;/REMOTE_PUBLIC\u0026gt; \u0026lt;/ \u0026lt;/ \u0026lt;/ ","description":"","id":417,"section":"notes","tags":null,"title":"记录解决Maven问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E8%A7%A3%E5%86%B3maven%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://cr58lvy7.mirror.aliyuncs.com\u0026#34;], \u0026#34;insecure-registries\u0026#34;:[\u0026#34;192.168.30.174:80\u0026#34;] } EOF sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;insecure-registries\u0026#34;:[\u0026#34;172.16.100.100:80\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker   相关教程  Docker 镜像加速 镜像加速器  ","description":"","id":418,"section":"notes","tags":null,"title":"设置Docker容器加速及允许通过http协议拉取镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E8%AE%BE%E7%BD%AEdocker%E5%AE%B9%E5%99%A8%E5%8A%A0%E9%80%9F%E5%8F%8A%E5%85%81%E8%AE%B8%E9%80%9A%E8%BF%87http%E5%8D%8F%E8%AE%AE%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F/"},{"content":" 拷贝配置文件到家目录：  1 2 3 4 5 6 7  # ubuntu cp /etc/vim/vimrc ~/.vimrc # centos cp /etc/vimrc ~/.vimrc   编辑该配置文件，增加如下内容   set tabstop=4 参考资料  Linux下设置vim的缩进为4个空格  ","description":"","id":419,"section":"notes","tags":null,"title":"设置VIM缩进为4个空格","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E8%AE%BE%E7%BD%AEvim%E7%BC%A9%E8%BF%9B%E4%B8%BA4%E4%B8%AA%E7%A9%BA%E6%A0%BC/"},{"content":"完成往我OSS推送图片的脚本后，我发现了一个问题，我的本地的图片打不开了。检查代理时发现最有可能导致该问题的就是如下代码：\n本应该是读的代码，我写成了写。我将所有本地图片全部改为正确的图片后，清掉OSS，将wb改成了rb，又重新跑了一遍脚本，发现.images里的图片都可以正常的访问。为了确认就是wb造成的问题，我又清掉了OSS里所有正确的图片，用wb重新上传了一次，发现果然图片都不可访问了。已经很明确就是wb造成的问题。\n额，很奇怪的，之前如果wb写rb写错了，程序会立即报错，这次竟然没有报错，还导致我原件损坏。\n","description":"","id":420,"section":"notes","tags":null,"title":"读写文件时wb和rb写错导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%97%B6wb%E5%92%8Crb%E5%86%99%E9%94%99%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"添加依赖：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   开发application.yml:\n1 2 3 4 5 6 7 8 9  project-config:template-dir:\u0026#39;D:\\Download\\spring-demo-master\\spring-demo-master\\cn\\AutoTools\\src\\main\\resources\\templates\u0026#39;temp-dir:\u0026#39;C:\\Users\\wujj\\Desktop\\Temp\u0026#39;default-primary-key-name:\u0026#39;id\u0026#39;table-info-dir:\u0026#39;D:\\Download\\spring-demo-master\\spring-demo-master\\cn\\AutoTools\\src\\main\\resources\\tables\u0026#39;enum-comment-pattern:\u0026#39;^([\\\\u4e00-\\\\u9fa5]{1,})（(([A-Za-z0-9-]+：[\\\\u4e00-\\\\u9fa5]{1,}，?)+)）$\u0026#39;number-pattern:\u0026#39;^[0-9]*$\u0026#39;  开发配置Bean：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  @Data @Component @ConfigurationProperties(prefix = \u0026#34;project-config\u0026#34;) public class ProjectConfig { /** * 模板文件根目录 */ private String templateDir; /** * 临时文件夹 */ private String tempDir; /** * 默认的主键字段名 */ private String defaultPrimaryKeyName; /** * 储存表信息Yaml文件的文件夹 */ private String tableInfoDir; /** * 枚举的模式 */ private String enumCommentPattern; /** * 数字的模式 */ private String numberPattern; }   @Value与@ConfigurationProperties的对比 之前没有关注到这个层面的问题，之后的使用中需要注意一下这个问题。\n参考资料  SpringBoot 获取yml配置文件信息  ","description":"","id":421,"section":"notes","tags":null,"title":"读取application.yml的配置信息到Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E8%AF%BB%E5%8F%96application.yml%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%88%B0bean/"},{"content":"好久没有用Python写脚本了，感觉API都不太熟悉了，完成脚本后，舍不得关闭网页，整理一份看看自己都查了哪些资料（我罗列的都是我用到的）：\n  Python统计字符串里某个字符出现的次数\n  Python os.path() 模块\n查了os.path.relpath API\n  Python format 格式化函数\n查了格式化输出字符串\n  Python3 字典\n忘记了字典是怎么操作的\n  Python中os.sep的用法\n查看分隔符的问题，其实我想在Window平台也使用Linux平台的路径分隔符。但是没有还找到方案\n  python字典遍历的几种方法\n  感觉写脚本还是用Python舒服些。\n","description":"","id":422,"section":"notes","tags":null,"title":"资料整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"我核心想实现的是：自动的完成笔记源文件到Gitbook源文件到Gitbook编译后文件推送到github仓库的工作。\n该工作如果手动完成，有如下步骤：\n 调整md文件中的图片引用，防止更改过md文件的层级关系，无法找到图片的位置 将图片上传到OSS，然后记录图片对应的OSS的位置，这个值在生成Gitbook源文件时要用到 调整md文件中图片引用为OSS中的位置，生成Gitbook源文件 生成GitBook需要的Summary文件 下载GitBook所需要的插件 得到静态的GitBook编译后文件，将编译后的文件推送到github仓库  为了更充分使用这次Github Actions学习机会，我计划开发自己的Github Actions，我的Github Actions设计如下：\n  Adjust Pictures In MD Files\n这个Actions的目标是调整md文件中图片引用，确保修改了笔记文件的目录层级，不会找不到相应的图片。\n  Push Pictures To OSS\n这个Actions的目标是将md文件中用到图片资源推送到阿里云OSS上\n  Generate Summary.md Book.json And Readme.md\n这个Actions如其名所述，用于生成book.json、Summary.md、Readme.md文件用的\n  Build Static Htmls\n这个Actions调用Gitbook相关的方法，生成所需要的静态文件。\n  Push Static Htmls To Github\n将编译后的静态文件推送到Github中。\n  在实践中，因为不想倒腾中间产物，为了我将3、4、5步合并成了一个Actions。\n方案小结 本次实验结果已经完全满足了我最开始的设想，我可以通过我自己开发的Actions完成我博客的自动化部署。但是由于对GitHub Actions知识积累不足，导致我在如下方面做的并不是太好：\n  没有利用官方提供的action，我现在并不知道官方提供了哪些action，所以我全部都是靠“蛮力”解决的（即自己控制Action的每一步）\n  冗余数据太多了。我并不是以官方提供的文件夹为工作目录，而是以所使用的Docker镜像的根文件夹为目录，也就是说我开发的每个Action都会首先将源码拉取到当前镜像的Docker根目录中，整个构建工作，该拉取任务供执行了3次。\n  目录位置混乱，因为GitHub Action在启动我的Action时会指定一个工作目录，导致我不得不在我的脚本中使用觉得路径，所以最终导致我的脚本可读性非常化，目录使用有点混乱。\n  没有利用Action之间的文件的流转，和第二点一样，我没有研究到这些技术，所以目前选择的是直接在工作区准备一份全量的数据。\n  脚本没有介个GitHub Action的错误码，我发现有时我的脚本错误，可能不会导致GitHub Action退出，这个问题非常的严重，我后面一定需要花时间优化一下。\n  密码等重要数据硬编码在Action中，因为目前blogs为私有项目，将密码存在该仓库里分享并不是很大，所以我并没有花时间去研究GitHub相关的技术。\n  Action运行不稳定。因为Action中依赖了许多其他的插件和工具等，这些插件我并没有指定版本，这导致我的Action在运行的时候，有一定的概率发生错误。\n  我将持续关注这些技术，然后优化我的方案，知道我的方案足够优雅。\n","description":"","id":423,"section":"notes","tags":null,"title":"通过GitHub Actions实现博客自动化部署的方案","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/github/%E9%80%9A%E8%BF%87github-actions%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E7%9A%84%E6%96%B9%E6%A1%88/"},{"content":"我添加了如下配置后，SpringBoot无法正常启动（只针对我们的项目框架）：\n management: endpoints: web: exposure: include: * 架构师说我们项目已经开启了相关的功能，而且*的用法不对。额，我在我自己的实验项目中，这个配置是完全没有问题的，奇奇怪怪，暂时先不研究了。\n","description":"","id":424,"section":"notes","tags":null,"title":"配置Actuator导致项目无法启动","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/%E9%85%8D%E7%BD%AEactuator%E5%AF%BC%E8%87%B4%E9%A1%B9%E7%9B%AE%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/"},{"content":"Idea初始化项目时使用阿里的源：\nhttps://start.aliyun.com/\n","description":"","id":425,"section":"notes","tags":null,"title":"配置Idea初始化SpringBoot项目时使用阿里的源","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%85%8D%E7%BD%AEidea%E5%88%9D%E5%A7%8B%E5%8C%96springboot%E9%A1%B9%E7%9B%AE%E6%97%B6%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E7%9A%84%E6%BA%90/"},{"content":"我注意到MyBatis-Plus的配置文件中有如下配置：\n1 2 3 4  mybatis-plus:mapper-locations:classpath:mapper/*Mapper.xml  我觉得在配置文件中使用classpath:表示当前项目的资源文件是一件非常优雅的编码方式，我也想在我自己的配置项中使用这种写法。但是当我发现将classpath:应用到自己的配置项时发现，根本就没有自动将classpath:转换成资源目录，断点如下：\n针对这个问题，我其实开发了自己的解决方案，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public String getTemplateDir() { return templateDir.startsWith(\u0026#34;classpath:\u0026#34;) ? classpathLabelToAbsolute(templateDir) : templateDir; } public String getTableDataDir() { return tableDataDir.startsWith(\u0026#34;classpath:\u0026#34;) ? classpathLabelToAbsolute(tableDataDir) : tableDataDir; } private String classpathLabelToAbsolute(String path) { try { return ResourceUtils.getFile(templateDir).getAbsolutePath(); // 以后验证一下这个方法  // return this.getClass().getClassLoader().getResource(templateDir).getFile().toString()  } catch (IOException e) { throw new RuntimeException(\u0026#34;TemplateDir Config Wrong\u0026#34;); } }   但是我觉得代码并不是很优雅，所以我决定参考一下MyBatis-Plus对此的实现。\nMyBatis-Plus 寻找MyBatis-Plus的配置类： 我这次寻找配置类，完全是靠运气，一下子就找到了，我想规则大概就是配置类都放放在starter中的吧。\nMyBatis-Plus的实现 MyBatis-Plus的处理代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  private static final ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver(); public Resource[] resolveMapperLocations() { return Stream.of(Optional.ofNullable(this.mapperLocations).orElse(new String[0])) .flatMap(location -\u0026gt; Stream.of(getResources(location))) .toArray(Resource[]::new); } private Resource[] getResources(String location) { try { return resourceResolver.getResources(location); } catch (IOException e) { return new Resource[0]; } }   我们的代码除列使用的工具类不一样，其他的思路基本是一致的。我看过MyBatis-Plus使用的工具类源码，挺复杂的，暂时不想深入研究。\nSpring Datasource 我注意到Spring Datasource也是支持classpath:配置的，我就好奇它是怎么实现对该配置的支持。\n1 2 3 4 5 6  spring:datasource:schema:classpath:h2/schema.sqldata:classpath:h2/data.sql  找到Spring Datasource配置类 我这次鸟枪换泡，用更高级更强大的方法找到了配置类（实际上是因为我一个一个文件翻找，找了半天都找不到），思路如下：\n 先在Idea中下载下载所有Maven依赖的源码 使用全局搜索spirng.datasource  Spring DataSource中的写法 代码如下，我没有深度分析，直接贴过来了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  boolean createSchema() { List\u0026lt;Resource\u0026gt; scripts = getScripts(\u0026#34;spring.datasource.schema\u0026#34;, this.properties.getSchema(), \u0026#34;schema\u0026#34;); if (!scripts.isEmpty()) { if (!isEnabled()) { logger.debug(\u0026#34;Initialization disabled (not running DDL scripts)\u0026#34;); return false; } String username = this.properties.getSchemaUsername(); String password = this.properties.getSchemaPassword(); runScripts(scripts, username, password); } return !scripts.isEmpty(); } private List\u0026lt;Resource\u0026gt; getScripts(String propertyName, List\u0026lt;String\u0026gt; resources, String fallback) { if (resources != null) { return getResources(propertyName, resources, true); } String platform = this.properties.getPlatform(); List\u0026lt;String\u0026gt; fallbackResources = new ArrayList\u0026lt;\u0026gt;(); fallbackResources.add(\u0026#34;classpath*:\u0026#34; + fallback + \u0026#34;-\u0026#34; + platform + \u0026#34;.sql\u0026#34;); fallbackResources.add(\u0026#34;classpath*:\u0026#34; + fallback + \u0026#34;.sql\u0026#34;); return getResources(propertyName, fallbackResources, false); } private List\u0026lt;Resource\u0026gt; getResources(String propertyName, List\u0026lt;String\u0026gt; locations, boolean validate) { List\u0026lt;Resource\u0026gt; resources = new ArrayList\u0026lt;\u0026gt;(); for (String location : locations) { for (Resource resource : doGetResources(location)) { if (resource.exists()) { resources.add(resource); } else if (validate) { throw new InvalidConfigurationPropertyValueException(propertyName, resource, \u0026#34;The specified resource does not exist.\u0026#34;); } } } return resources; } private Resource[] doGetResources(String location) { try { SortedResourcesFactoryBean factory = new SortedResourcesFactoryBean(this.resourceLoader, Collections.singletonList(location)); factory.afterPropertiesSet(); return factory.getObject(); } catch (Exception ex) { throw new IllegalStateException(\u0026#34;Unable to load resources from \u0026#34; + location, ex); } }   小结 我最终肯定还是选择我自己的方案，因为我主要用于工具包的开发，使用我这种方案更易读（其实我觉得MyBatis-Plus也挺好的）。另外使用ResourceUtils貌似打包成Jar包后无法正确的读取路径，我并没验证这个问题。\n我决定当我在生产环境中需要使用相关技术时我再继续探索这个解决方案。\n参考资料  SpringBoot读取resources目录下的文件 springboot获取资源文件、编译文件路径（打包后） Spring 应用访问Classpath路径下的文件  ","description":"","id":426,"section":"notes","tags":null,"title":"配置文件中的classpath配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84classpath%E9%85%8D%E7%BD%AE/"},{"content":"我从源码导入了一个Maven项目，因为我默认的Maven配置中使用的是setting.xml文件，但是我没有这份配置文件（我的文件为setting-default.xml），但是我忽视了这个问题。\n当我配置了Maven Profile，然后启动项目的一个测试用例时，项目正常启动了，但是并没有获取到Maven Profile的值。这个现象其实很奇怪：\n Maven都没有进行导入，为什么测试方法能正常启动 为什么正常启动后，不能获取到Maven Profile的值呢  ","description":"","id":427,"section":"notes","tags":null,"title":"配置错误setting.xml文件，导致的一个奇怪的现象","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AFsetting.xml%E6%96%87%E4%BB%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E4%B8%AA%E5%A5%87%E6%80%AA%E7%9A%84%E7%8E%B0%E8%B1%A1/"},{"content":"实际上我已经有技术实现针对List的TypeHandler了，之所以还开发这个TypeHandler是因为我们的旧代码使用了JSONArray、JSONObject，旧代码之前的使用方案是先将数据检索成字符串，然后再用fastjson转成JSONObject或者JSONArray，为了兼顾这部分需求，所以我开发了这个TypeHandler。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  @Slf4j @MappedTypes({JSONObject.class, JSONArray.class}) public class FastJsonTypHandler extends BaseTypeHandler\u0026lt;Object\u0026gt; { @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, Object parameter, JdbcType jdbcType) throws SQLException { PGobject insertObj = new PGobject(); insertObj.setType(\u0026#34;jsonb\u0026#34;); insertObj.setValue(JSON.toJSONString(parameter)); preparedStatement.setObject(i, insertObj); } @Override public Object getNullableResult(ResultSet resultSet, String columnName) throws SQLException { final String jsonInDb = resultSet.getString(columnName); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } @Override public Object getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException { final String jsonInDb = resultSet.getString(columnIndex); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } @Override public Object getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException { final String jsonInDb = callableStatement.getString(columnIndex); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } }   这里踩了一个坑，我之间将@MappedTypes设置成@MappedTypes({Object.class})，结果MyBatis-Plus生成出来的SQL都包含一个双引号，估计是每个字段都走了这个TypeHandler。\n框架中原来的TypeHandler生成的jsonb字段的值，双引号前会加反斜线，不是太方便使用。\n","description":"","id":428,"section":"notes","tags":null,"title":"针对JSONObject、JSONArray的typeHandler","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-plus/%E9%92%88%E5%AF%B9jsonobjectjsonarray%E7%9A%84typehandler/"},{"content":"是这样的，我参考之前的写法，在Request对象中用JSONObject去接受了前端请求传递了一个对象（我并不关心这个对象的结构）。结果接口有如下返回值：\n1 2 3 4 5 6 7 8  { \u0026#34;code\u0026#34;: 100101, \u0026#34;data\u0026#34;: null, \u0026#34;message\u0026#34;: \u0026#34;params invalidate: JSON mapping problem: com.sdstc.show.controller.external.DynamicFormController$PostDataRequest[\\\u0026#34;extraData\\\u0026#34;]-\u0026gt;com.google.gson.JsonObject[\\\u0026#34;asString\\\u0026#34;]; nested exception is com.fasterxml.jackson.databind.JsonMappingException: JsonObject (through reference chain: com.sdstc.show.controller.external.DynamicFormController$PostDataRequest[\\\u0026#34;extraData\\\u0026#34;]-\u0026gt;com.google.gson.JsonObject[\\\u0026#34;asString\\\u0026#34;])\u0026#34;, \u0026#34;success\u0026#34;: false }   抱着试试看的心态，我去掉了@Data注解，该问题消失了。额，但是我是@Data的忠实用户，所以我最后用如下方式改写：\n1 2 3 4 5 6  @Data private static class PutDataRequest { private Map\u0026lt;?, ?\u0026gt; extraData; }   关于@Data，从细节上讲，我有很多想不明白的地方，当我们从Controller接受对象的时候，我们可以不要这个注解，接受没有任何问题；但是，当我们从RestTemplate接受的时候，如果没有这个注解，接受到的所有字段都为null。更奇怪的时，本次开发时，Controller和RestTemplate的HttpMessageConvert都是FastJsonHttpMessageConverter。\n现在唯一能让我信服的理由就是，Controller可能用了字段名反射，而RestTemplate走的是Getter和Setter。\n20210607后续：\n其实这个问题的原因在于JsonObject和JSONObject根本不是同一个东西\n","description":"","id":429,"section":"notes","tags":null,"title":"错将JSONObject写成JsonObject了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%94%99%E5%B0%86jsonobject%E5%86%99%E6%88%90jsonobject%E4%BA%86/"},{"content":"好久不写泛型代码，突然会想不起来怎么写了，所以记录一下。最近开发了一个工具方法，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class PageUtils { public static \u0026lt;T, R\u0026gt; Page\u0026lt;R\u0026gt; entityPageToResponseDataPage(Page\u0026lt;T\u0026gt; entityPage, Class\u0026lt;R\u0026gt; clazz) { return entityPageToResponseDataPage(entityPage, clazz, null); } public static \u0026lt;T, R\u0026gt; Page\u0026lt;R\u0026gt; entityPageToResponseDataPage(Page\u0026lt;T\u0026gt; entityPage, Class\u0026lt;R\u0026gt; clazz, BiConsumer\u0026lt;T, R\u0026gt; disposer) { List\u0026lt;R\u0026gt; pageRecords = new ArrayList\u0026lt;\u0026gt;(); for (T record : entityPage.getRecords()) { R pateRecordItem = BeanUtil.copyProperties(record, clazz); if (disposer != null) { disposer.accept(record, pateRecordItem); } pageRecords.add(pateRecordItem); } Page\u0026lt;R\u0026gt; result = new Page\u0026lt;\u0026gt;(); BeanUtils.copyProperties(entityPage, result); result.setRecords(pageRecords); return result; } }   应用场景是这样的，我们分页查询时用的是实体，但是返回给前端时用的是DTO，所以需要进行一些转换工作，这个类就是帮忙快速转换的。\n参考资料  JAVA——泛型类和泛型方法（静态方法泛型）  ","description":"","id":430,"section":"notes","tags":null,"title":"静态泛型方法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E9%9D%99%E6%80%81%E6%B3%9B%E5%9E%8B%E6%96%B9%E6%B3%95/"},{"content":"我注意到我们的starter-parent配置中有如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources/\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;!--先排除所有的配置文件--\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;application*.yml\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;!--引入所需环境的配置文件--\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;application.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;application-${spring.profiles.active}.yml\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;   这段配置是说，当我们打包处理资源文件时我们先不包含所有的application*.yml文件。然后application.yml文件，及application-${spring.profiles.active}.yml文件。\n这段配置完全没有存在的必要，主要有一下的原因：\n SpringBoot打包插件默认开启过滤器，会对进行@@字符串过滤的处理。 我们项目中使用的是bootstrap.properties和bootstrap-xxx.yml，所以这个配置完全起不到任何作用  ","description":"","id":431,"section":"notes","tags":null,"title":"项目中starter-parent中可以优化的点","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/%E9%A1%B9%E7%9B%AE%E4%B8%ADstarter-parent%E4%B8%AD%E5%8F%AF%E4%BB%A5%E4%BC%98%E5%8C%96%E7%9A%84%E7%82%B9/"}]