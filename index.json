[{"content":"今天看一篇关于如何在Kubernetes中搭建Redis集群的博文时，看到了如下关于Headless Service的描述：\n 简单的说，Headless Service就是没有指定Cluster IP的Service，相应的，在k8s的dns映射里，Headless Service的解析结果不是一个Cluster IP，而是它所关联的所有Pod的IP列表。\n  另外需要说明的是，StatefulSet必须要配合Headless Service使用，它会在Headless Service提供的DNS映射上再加一层，最终形成精确到每个pod的域名映射，格式如下：$(podname).$(headless service name)复制代码有了这个映射，就可以在配置集群时使用域名替代IP，实现有状态应用集群的管理\n 我对以上知识理解的都不够深刻，随意需要花点时间研究一下。\n参考资料  在K8S上搭建Redis集群  ","description":"","id":0,"section":"notes","tags":null,"title":"00.Headless Service的初步研究","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/headlessservice/00.headless-service%E7%9A%84%E5%88%9D%E6%AD%A5%E7%A0%94%E7%A9%B6/"},{"content":"https://kuboard.cn/learning/\n","description":"","id":1,"section":"notes","tags":null,"title":"00.教程地址","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/00.%E6%95%99%E7%A8%8B%E5%9C%B0%E5%9D%80/"},{"content":"https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/common-labels/\n","description":"","id":2,"section":"notes","tags":null,"title":"00.教程地址","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/00.%E6%95%99%E7%A8%8B%E5%9C%B0%E5%9D%80/"},{"content":"按优先级整理：\n 实现UserMapper.java中定义的方法与UserMapper.xml中的sql实现间的相互跳转。  目前是无法实现这个效果的，我需要寻找解决方案，并验证这些解决方案，并整理方案的使用方法。\n该需求的产生，是因为我们希望在UserMapper.java代码中看到某个方法对应的SQL，为了达到这个效果，我们在代码中使用了@Select、@Delete、@Update等注解，我个人认为这些注解只只适合SQL比较简单的情况，一旦SQL复杂了，阅读@Select、@Delete、@Update中的SQL将是灾难级别的。\n如果相应的代码写在UserMapper.xml文件中，SQL阅读起来就不会那么难受了。所以我们目前需要的就是一个快速查看定义和兼顾SQL可阅读性的方案。\n实现UserMapper.xml文件的自动排版。目前的话在UserMappr.xml文件中ctrl+arl+l快捷键是无法生效的，我以往的开发流程是：在sql美化工具中美化我的SQL，然后贴到UserMapper.xml文件中，我希望可以直接将sql从navicat等工具贴到userMapper.xml文件中，然后进行格式化。  去掉上图中的黄色提示。我从事开发以来，上面的提示是一直存在的，但是我从来没有下定角色将它们给干点，我计划这次将它们一起给干掉。  ","description":"","id":3,"section":"notes","tags":null,"title":"00.本次实验想达成的目标","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/00.%E6%9C%AC%E6%AC%A1%E5%AE%9E%E9%AA%8C%E6%83%B3%E8%BE%BE%E6%88%90%E7%9A%84%E7%9B%AE%E6%A0%87/"},{"content":"考虑到实在不想再OpenWRT上花费过多的时间，我拟定了如下的方案。\n  镜像和包，使用官方提供的最新稳定版，同时为了避免之后无法升级（旧的稳定版官方不在维护），将爬取这些资源存在本地。\n  对于一些需要编译的插件，我将在GitHub上拉取相应版本的源码，构造编译环境（我暂时还没有掌握编译单个插件的技术，需要学习）\n  针对从官方下载的包，我准备了一些骚技术，从而实现既可以利用opkg的依赖包管理，又可以可以避免引入技术的复杂度。\n  相关资料  官方资源下载地址：  https://downloads.openwrt.org/\n我目前使用的版本：  https://downloads.openwrt.org/releases/21.02.1/targets/\n我是用的爬虫代码：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  import urllib2 import re import os dict = { \u0026#39;openwrt_core\u0026#39;: \u0026#39;https://downloads.openwrt.org/releases/21.02.1/targets/x86/64/packages/\u0026#39;, \u0026#39;openwrt_base\u0026#39;: \u0026#39;https://downloads.openwrt.org/releases/21.02.1/packages/x86_64/base/\u0026#39;, \u0026#39;openwrt_luci\u0026#39;: \u0026#39;https://downloads.openwrt.org/releases/21.02.1/packages/x86_64/luci/\u0026#39;, \u0026#39;openwrt_packages\u0026#39;: \u0026#39; https://downloads.openwrt.org/releases/21.02.1/packages/x86_64/packages/\u0026#39;, \u0026#39;openwrt_routing\u0026#39;: \u0026#39;https://downloads.openwrt.org/releases/21.02.1/packages/x86_64/routing/\u0026#39;, \u0026#39;openwrt_telephony\u0026#39;: \u0026#39;https://downloads.openwrt.org/releases/21.02.1/packages/x86_64/telephony/\u0026#39; } for key, baseurl in dict.items(): savedir = \u0026#39;./{}/\u0026#39;.format(key) if not os.path.exists(savedir): os.makedirs(savedir) print(\u0026#39;fetching package list from \u0026#39; + baseurl) content = urllib2.urlopen(baseurl, timeout=15).read() print(\u0026#39;packages list ok, analysing...\u0026#39;) pattern = r\u0026#39;\u0026lt;a href=\u0026#34;(.*?)\u0026#34;\u0026gt;\u0026#39; items = re.findall(pattern, content) cnt = 0 for item in items: if item == \u0026#39;/\u0026#39;: continue else: cnt += 1 print(\u0026#39;downloading item %d: \u0026#39; % (cnt) + item) if os.path.isfile(os.path.join(savedir, item)): print(\u0026#39;file exists, ignored.\u0026#39;) else: print (baseurl + item) try: rfile = urllib2.urlopen(baseurl + item) with open(savedir + item, \u0026#34;wb\u0026#34;) as code: code.write(rfile.read()) except urllib2.HTTPError, error: print error print(\u0026#39;done!\u0026#39;)   该脚本我运行了多次，才确保将所有的包下载下来。\n一些探讨点  为什么我要走本地软件源的方案？如果想使用OpenWRT的软件源，我必须为opkg设置代理，然而我的OpenWRT多用作主路由，甚至我装OpenWRT的虚拟机系统（PVE），其网关也设置为OpenWRT。总之，在进行OpenWRT相关技术的研究时，我的网络环境尝尝因为主路由的原因崩坏，此时我没有办法找到一个锚点，为OpenWRT的opkg提供代理服务，相反，为了为OpenWRT提供代理，我需要想尽一切办法去调整我的网络，这导致我实验过程非常的痛苦，所以不如使用本地软件源。  我放弃的方案   我放弃了自己编译固件方案，我本来想自己编译固件，及所有的插件，但是这样做太浪费时间了，而且还需要对OpenWRT有足够的了解。\n  我放弃了升级内核以便使用下载软件包的方案（前提也是我使用的是自己编译的固件），太折腾啦。\n  我放弃了爬取所有软件包，然后用Nginx建立服务的方案，因为增加了学习Nginx的学习成本，且在我的环境中，这个方案会增加我的复杂度。\n  参考资料   建立一个Openwrt软件源的镜像\n  openwrt设置本地软件源安装第三方ipk\n  ","description":"","id":4,"section":"notes","tags":null,"title":"00.稳定、事少的方案","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/00.%E7%A8%B3%E5%AE%9A%E4%BA%8B%E5%B0%91%E7%9A%84%E6%96%B9%E6%A1%88/"},{"content":"由于各个Spring Data模块的启动日期不同，它们中的大多数带有不同的主要和次要版本号。找到兼容版本的最简单方法是依赖官方随定义的兼容版本一起提供的Spring Data Release Train BOM。\n在Maven项目中，您将在POM的\u0026lt;dependencyManagement /\u0026gt;部分声明此依赖项，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-bom\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;   我对这种技术比较陌生，阿里整理的SpringBoot中也用了类似的技术进行SpringBoot的依赖版本仲裁，这样我们可以不用继承SpringBoot官方提供parent。\n这个技术是为了让我们脱离SpringBoot使用Spring Date redis么？\n","description":"","id":5,"section":"notes","tags":null,"title":"001.BOM的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/spring-data-redis%E6%96%87%E6%A1%A3/001.bom%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"Memcached和Redis都可以用于存储键值映射，彼此的性能也相差无几，但是Redis能够自动以两种不同的方式将数据写入硬盘（RDB、AOF），并且Redis除了能存储普通的字符串键之外，还可以存储其他4中数据类型（五种为：String、List、Set、Hash、ZSet），而Memcached只能存储普通的字符串键。\n这些不同之处使得Redis可以用于解决更为广泛的问题，并且既可以用作主数据库使用，又可以作为其他存储数据库的辅助数据库使用。\n","description":"","id":6,"section":"notes","tags":null,"title":"001.Redis于Memcached的对比","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/001.redis%E4%BA%8Ememcached%E7%9A%84%E5%AF%B9%E6%AF%94/"},{"content":"在Spring Data中，用户（自定义）类型和原始数据（反之亦然）之间的转换由org.springframework.data.redis.serializer包中的Redis处理。这个包包含三种序列化器：\n RedisSerializer：双向序列化器 RedisElementReader：负责读取 RedisElementWriter：负责写入  这些变体之间的主要区别在于，RedisSerializer主要序列化为byte[]，而reader和writers使用ByteBuffer。\n有多种实现可用：\n JdkSerializationRedisSerializer（默认用于RedisCache、RedisTemplate） StringRedisSerializer OxmSerializer（有Spring OXM支持）（这是个什么东西） Jackson2JsonRedisSerializer GenericJackson2JsonRedisSerializer  ","description":"","id":7,"section":"notes","tags":null,"title":"002.序列化器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/spring-data-redis%E6%96%87%E6%A1%A3/002.%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8/"},{"content":"数据库的一个常见用法是存储长期的报告数据，并将这些报告数据用作固定时间范围内的聚合数据。\n收集聚合数据的常见做法是：先将各个行插入一个报告表里面，之后再通过扫描这些行来收集聚合数据，并根据收集到的聚合数据来更新聚合表中已有的那些行。\n之所以使用插入行的方式来存储，是因为对于大部分数据库来说，插入行操作的执行速度非常快（插入行只会在硬盘文件末尾进行写入）。不过，对表里面的行进行更新却是一个速度相当慢的操作，因为这种更新除了会引起一次随机读之外，还可能会引起一次随机写。\n而在Redis里面，用户可以直接使用原子的INCR命令及其变种来计算聚合数据，并且因为Redis将数据存储在内存里面，而且发送给Redis的命令请求并不需要经过典型的查询分析器或者查询优化器进行处理，所以对Redis存储的数据执行随机写的速度总是非常迅速的。\n小结 这块让我惊讶的是一个小小的记录报告数据，并利用报告数据获取聚合数据的功能，都有这么多性能点可以考虑。Redis的INCR命令是原子性的，同时其不需要查询分析器或者查询优化器进行处理，这些都会增加性能。\n","description":"","id":8,"section":"notes","tags":null,"title":"002.数据库和Redis在存储报告数据方面的区别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/002.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8Credis%E5%9C%A8%E5%AD%98%E5%82%A8%E6%8A%A5%E5%91%8A%E6%95%B0%E6%8D%AE%E6%96%B9%E9%9D%A2%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"content":"STRING 对整个字符串或者字符串中的其中一部分执行操作，对整数、浮点数执行自增或者自减操作。\nSET\nGET\nDEL\nLIST 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪；读取单个或者多个元素；根据值查找或者移除元素。\nLPUSH、RPUSH\nLPOP、RPOP\nLINDEX：获取列表给定位置的一个元素\nLRANGE：获取列表给定范围内的所有元素\nSET 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素\nSADD\nSREM\nSISMEMBER：检查一个元素是否已经存在于集合中\nSMEMBERS：获取集合包含的所有元素（集合中元素比较多时需要谨慎使用该接口）\nSINTER：交集\nSUNION：并集\nSDIFF：差集\nHASH 添加、获取、移除单个键值对；获取所有键值对。\nHSET\nHGET\nHGETALL\nHDEL\nZSET 添加、获取、删除单个元素；根据分值范围或者成员范围来获取元素。\n有序集合的键被称为成员，每个成员都是各不相同的；有序集合的值被称为分值，分值必须为浮点数。有序集合是Redis里面唯一一个既可以根据成员访问元素（和散列一样），又可以根据分值的排列顺序来访问元素的结构。\nZDD\nZRANGE：根据元素在有序排列中所处的位置，从有序集合里面获取多个元素\nZRANGEBYSCORE：获取有序集合在给定分值范围内的所有元素\nZREM\n小结 粗体都是我在工作中应用的比较少的技术点。\n","description":"","id":9,"section":"notes","tags":null,"title":"003.Redis中得数据类型，及支持的操作","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/003.redis%E4%B8%AD%E5%BE%97%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E6%94%AF%E6%8C%81%E7%9A%84%E6%93%8D%E4%BD%9C/"},{"content":"发布消息 要发布消息，可以使用与其他操作一样的低级RedisConnection或高级RedisTemplate。两个实体都提供发布方法，该方法接受消息和目标通道作为参数。RedisConnection需要原始数据（字节数组），RedisTemplate允许将任意对象作为消息传入。\n1 2 3 4 5 6 7 8 9 10 11 12  @Test public void test() { byte[] msg = \u0026#34;msg1\u0026#34;.getBytes(StandardCharsets.UTF_8); byte[] channel = \u0026#34;channel1\u0026#34;.getBytes(StandardCharsets.UTF_8); stringRedisTemplate.getConnectionFactory().getConnection().publish(channel, msg); stringRedisTemplate.convertAndSend(\u0026#34;channel2\u0026#34;, \u0026#34;msg2\u0026#34;); System.out.println(\u0026#34;\u0026#34;); }   （实验中，我发送了消息，似乎在ARDP中看不到）\n接受消息 在接收端可以通过直接命名或使用模式来匹配订阅一个或多个频道。后一种方法非常有用，因为它不仅允许使用一个命令创建多个订阅，而且还可以侦听订阅时尚未创建的频道（只要它们与模式匹配）。\n在底层，RedisConnection提供subscribe和pSubscribe方法，它们分别映射Redis命令以按通道或按模式订阅。请注意，多个通道或模式可以用作参数。\nRedisConnection提供了getSubscription和isSubscribed方法来更改连接的订阅或查询它是否正在侦听。\nSpring Data Redis中的订阅命令是阻塞的。 也就是说，在连接上调用subscribe会导致当前线程在开始等待消息时阻塞。 仅当取消订阅时才释放线程，这发生在另一个线程在同一连接上调用unsubscribe或pUnsubscribe时。\nMessage Listener Containers 因为原生的写法是阻塞的，所以没有太大的意义，而且还需要对每个Listener进行连接和线程管理。\nSpring Data提供了RedisMessageListenerContainer，它完成了所有繁复的工作。\nRedisMessageListenerContainer充当消息侦听器容器。它用于从Redis通道接收消息并驱动注入其中的MessageListener实例。侦听器容器负责消息接收的所有线程，并分派到侦听器中进行处理。消息侦听器容器是MDP 和消息传递提供者之间的中介，负责注册以接收消息、资源获取和释放、异常转换等。这使您作为应用程序开发人员可以编写与接收消息（并对其作出反应）相关的（可能很复杂的）业务逻辑，并将样板Redis基础架构问题委托给框架。\n此外，为了最小化应用程序占用空间，RedisMessageListenerContainer允许多个侦听器共享一个连接和一个线程，即使它们不共享订阅。因此，无论应用程序跟踪多少侦听器或通道，运行时成本在其整个生命周期内都保持不变。此外，容器允许更改运行时配置，以便您可以在应用程序运行时添加或删除侦听器，而无需重新启动。此外，容器使用惰性订阅方法，仅在需要时使用RedisConnection。如果所有侦听器都取消订阅，则会自动执行清理，并释放线程。\n为了帮助处理消息的异步特性，容器需要一个java.util.concurrent.Executor（或 Spring 的 TaskExecutor）来分派消息。根据负载、侦听器的数量或运行时环境，您应该更改或调整执行器以更好地满足您的需求。特别是在托管环境（例如应用服务器）中，强烈建议选择合适的TaskExecutor以利用其运行时。\nMessageListenerAdapter MessageListenerAdapter允许将任何类公开为MDP。\n（这部分知识很酷，但是我对Redis的Pub和Sub的用法兴趣并不是很高，生产中这部分知识几乎没有用到，所以暂时不深入研究了）\n","description":"","id":10,"section":"notes","tags":null,"title":"003.消息的发布和订阅","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/spring-data-redis%E6%96%87%E6%A1%A3/003.%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%91%E5%B8%83%E5%92%8C%E8%AE%A2%E9%98%85/"},{"content":"可以使用Redis哈希实现更复杂的结构化对象映射，Spring Data Redis提供了将数据映射到哈希的各种决策：\n 直接映射，使用HashOperations和序列化程序 使用Redis存储库（我暂时不想考虑这个层面的应用，因为这个技术目前应用的可能比较少） 使用HashMapper和HashOperations  Hash Mappers Hash Mappers需要和Redis的哈希类型一起使用，其有多种实现：\n BeanUtilsHashMapper使用Spring的BeanUtils。 ObjectHashMapper使用对象到哈希映射。 Jackson2HashMapper使用FasterXML Jackson。  Jackson2HashMapper Jackson2HashMapper可以将顶级属性映射为Hash字段名称，并且可以选择展平结构。简单类型映射到简单值，复杂类型（嵌套对象、集合、映射等）表示为嵌套JSON。\n扁平化为所有嵌套属性创建单独的哈希条目，并且尽可能的解析为简单类型。\n嵌套：\n展平：\n","description":"","id":11,"section":"notes","tags":null,"title":"004.哈希映射","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/spring-data-redis%E6%96%87%E6%A1%A3/004.%E5%93%88%E5%B8%8C%E6%98%A0%E5%B0%84/"},{"content":"要构建一个文章投票网站，我们首先要做的就是为了这个网站设置一些数值和限制条件：\n 如果一篇文章获得了至少200张支持票，那么网站就认为这篇文章是一篇有趣的文章 假如这个网站每天发布1000篇文章，而其中的50篇符合网站对有趣文章的要求，那么网站要做的就是把这50篇文章放到文章列表前100位至少一天； 另外，这个网站暂时不提供投反对票的功能  （直观上的第一方案是，记录每篇文章的投票数，然后按照投片进行排序，这样带来的问题是历史投票数最多的文章永远在前面。）\n为了产生一个能够随着时间流逝而不断减少的评分，程序需要根据文章的发布时间和当前时间来计算文章的评分，具体的计算方法为：将文章得到的支持票数量乘以一个常量，然后加上文章的发布时间，得出的结果就是文章的评分。\n我们使用从UTC时区1970年1月1日到现在为止经过的秒数来计算文章的评分，这个值通常被称为Unix时间。之所以选择使用Unix时间，是因为在所有能够运行Redis的平台上面，使用编程语言获取这个值都是一件非常简单的事情。\n另外，计算评分时与支持票数量相乘的常量为432，这个常量是通过将一天的秒数除以文章展示一天所需的支持票数量得出的：文章每获得一张支持票，程序就需要将文章的评分增加432分。\n构建文章投票网站除了需要计算文章评分之外，还需要使用Redis结构存储网站上的各种信息。对于网站里的每篇文章，程序都使用一个散列来存储文章的标题、指向文章的网址、发布文章的用户、文章的发布时间、文章得到的投票\n数量等信息，\n我们的文章投票网站将使用两个有序集合来有序地存储文章：第一个有序集合的成员为文章ID，分值为文章的发布时间；第二个有序集合的成员同样为文章ID，而分值则为文章的评分。通过这两个有序集合，网站既可以根据文章发布的先后顺序来展示文章，又可以根据文章评分的高低来展示文章。\n为了防止用户对同一篇文章进行多次投票，网站需要为每篇文章记录一个已投票用户名单。为此，程序将为每篇文章创建一个集合，并使用这个集合来存储所有已投票用户的ID。\n为了尽量节约内存，我们规定当一篇文章发布期满一周之后，用户将不能再对它进行投票，文章的评分将被固定下来，而记录文章已投票用户名单的集合也会被删除。\n当用户尝试对一篇文章进行投票时，程序需要使用ZSCORE命令检查记录文章发布时间的有序集合，判断文章的发布时间是否未超过一周。如果文章仍然处于可以投票的时间范围之内，那么程序将使用SADD命令，尝试将用户添加到记录文章已投票用户名单的集合里面。如果添加操作执行成功的话，那么说明用户是第一次对这篇文章进行投票，程序将使用ZINCRBY命令为文章的评分增加432分（ZINCRBY命令用于对有序集合成员的分值执行自增操作），并使用HINCRBY命令对散列记录的文章投票数量进行更新（HINCRBY命令用于对散列存储的值执行自增操作）。\n从技术上来讲，要正确地实现投票功能，我们需要SADD ZINCRBY和HINCRBY这3个命令放到一个事务里面执行。\n小结 功能设计  如果一篇文章获得了200个赞，则认为其是一个有趣的文章。 如果网站一天发布1000篇文章，其中50篇满足有趣的文章的定义，则需要将这50篇文章放在文章前100中至少一天。（这个地方就是将昨天的有趣文章，排在列表中） 不提供反对票的功能。 文章发布超过一周，则不支持投票。 不允许用户对同一篇文章进行多次投票。 支持按时间排序。 支持按评分排序。 可以查看文章的详细信息。 需要有对文章进行分组的功能  数据结构设计 Redis类型：zset\n键为：time:\n成员为：article:文章编号\n评分为：文章发布时间戳\nRedis类型：zset\n键为：score：\n成员为：article:文章编号\n评分为：文章的评分\n上面的zset可以实现文章按时间排序，按评分排序。\nRedis类型：hash\n键为：article:文章编号\n散列键为： title、link、poster、time、votes、groups\n上面的hash可以用于存储文章的详细信息。\nRedis类型：set\n键为：voted:文章编号\n上面的set可以用于记录某篇文章已经投票的用户信息，防止用户多次投递。\nRedis类型：set\n键为：group:群组名称\n值为：article:文章编号\n算法设计 用户发表文章时，将发布时间记为文章的初始评分。每有一个用户点赞，则评分加432。当点赞数超过200时，则文章将会比24小时候发布的文章的评分高，所以排名也就可以会比较靠前。\n投票流程 用户10001对文章20001进行投票\n 使用zscore time:artile:20001获取文章的发布时间，判断是否能够进行投票。 使用sadd voted:20001判断该用户是否已经投递过了，如果未投递，则该操作返回true。 使用zincrby scored: artile:20001 1，为文章增加积分 使用hincrby article:20001 votes 1，为文章增加投票数  发布文章流程 用户10001发布文章20001\n 使用incr获取一个文章的Id：20001 使用sadd voted:20001 user:10001，将发布文章的用户添加到已投票的集合中 使用sadd groups:群组名称 article:20001，将文章添加到某个分组中（执行多次） 使用expire为voted:20001设置一个过期时间，因为文章发布超过一周就不可以投票了 使用hmset article:20001 title '' link ''存储文章的信息 使用zadd timed: article:20001，记录文章的发布时间 使用zadd scored: article:20001，记录文章的评分  取出评分最高的文章  使用zrevrange取出多个文章id 对上面步骤获取的id使用hgetall id  取出最新发布的文章  使用zrevrange取出多个文章id 对上面步骤获取的id使用hgetall id  根据评分对群组文章进行排序和分页  使用zinterstore命令接受groups:群组名和score:，找出同时存在于集合和有序集合中得成员 在执行zinterstore时，需要注意分值合并的方式  ","description":"","id":12,"section":"notes","tags":null,"title":"004.在一个简单的投票网站中使用Redis","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/004.%E5%9C%A8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%8A%95%E7%A5%A8%E7%BD%91%E7%AB%99%E4%B8%AD%E4%BD%BF%E7%94%A8redis/"},{"content":"Token 书中这块设计描述的有点乱，整理候结果如下：\n  书中记录Token采用的是Hash结构，而我们生产中使用的是String结构。书中用一个类型为Hash，键名为login:的数据结构来存放登录用户的Token，当用户请求时，使用hget login: token来判断Cookie中得令牌是否登录。\n  当用户登录候，我们还需要在login:下为该用户创建一个键值对，键为token，值为userId。同时我们还要在recent:中使用zadd recent: token timestamp记录令牌最后一次出现的时间。\n  针对用户的浏览数据，我们使用zdd viewed:token item timestamp记录用户的浏览数据。在此操作的同时，我们还需要使用zremrangebyrank viewed:token 0 -26移除旧的记录，只保留用户最近浏览过的25个商品。（大数据时代，这种应用应该比较低吧）\n  为了限制会话数据的数量，只保存最新的1000万个会话。使用一个循环去清除会话，该循环每次执行的逻辑为：\n   判断recent:的长度是否超过了限制，如果超过了则执行清理，否则不进行清理 调用zrange 0 end_index-1获取需要删除的令牌的id（end_index = min(size - LIMIT, 100)） 得到需要删除的viewed:键（因为登录令牌已经需要删除了，这些viewed:键也没有任何意义了） 调用delete session_keys批量删除viewed:键 调用hdel login: tokens批量删除令牌 调用zrem recent: tokens批量删除最近浏览记录  另外的解决方案：和我们目前的项目一样，使用string接口，加上过期时间，实现Token的自动清理。但是使用这种方案，没有办法限制会话的数量在1000万之内，并且也没有办法对废弃的购物车进行任何处理了。  购物车 数据结构：\nRedis类型：Hash\n键：card:session\n值：商品Id\n值的值：商品的数量\n流程设计：\n  添加购物车时的逻辑：\n  判断用户传入的数量，如果大于零，调用hset card:session item cound，如果小于零，调用hrem card:session item\n  Token清理部分用的清理函数也需要定时清理掉相关的card:session。\n    网页缓存 数据结构：\nRedis类型：string\n键：cache:hash(request) // 这个地方书上说的并不好，这个最好是全局唯一的请求类名 + 方法名\n值：缓存的内容\n数据缓存 方案设计：\n为了应对促销活动带来的大量负载，需要对数据进行缓存，具体的做法是：编写一个持续运行的守护进程函数，让这个函数将指定的数据行缓存到Redis里面，并不定期地对这些缓存进行更新。缓存函数会将数据行编码为JSON字段并存储在Redis的字典里面，其中，数据列的名字被映射为JSON字典的键，而数据行的值则被映射为JSON字典的值。\n（实际开发中，似乎没有这么做过，我们更多做的事接口级的缓存，这个应该数据数据级的，MyBatis的二级缓存应该和这个原理差不多。）\n程序使用了两个有序集合来记录应该在何时对缓存进行更新：第一个有序集合为调度有序集合，它的成员为数据行的行Id，而分值则是一个时间戳，这个时间戳记录了应该在何时将指定的数据行缓存到Redis里面；第二个有序集合为延时有序集合，它的成员也是数据行的行ID，而分值则记录了指定数据行的缓存需要每隔多少秒更新一次。\n为了让缓存函数定期地缓存数据行，程序首先需要将行ID和给定的延迟值添加到延迟有序集合里面，然后再将行ID和当前时间的时间戳添加到调度有序集合里面。实际执行缓存操作的函数需要用到数据行的延迟值，如果某个数据行的延迟值不存在，那么程序将取消对这个数据行的调度。如果我们想要移除某个数据行已有的缓存，并且让缓存函数不再缓存那个数据行，那么只需要把那个数据行的延迟值设置为小于或等于0就可以了。\n（这个地方我已经看出来了，我的想法和作者的并不一致）\n数据结构：\nRedis类型：zset\n键：schedule:\n成员：row_id\n分值：待更新的时间\nRedis类型：zset\n键：delay:\n成员：row_id\n分值：延时\n流程设计：\n  将需要进行缓存的row_id和缓存的delay值放到delay:中，同时在schedule:中放一份，放入schedule:时用的是当前的时间戳，这样确保了之后一定会被缓存。\n  负责缓存数据行的函数会尝试读取调度有序集合的第一个元素以及该元素的分值，如果调度集合中没有元素，或者所指定的时间戳未来临，则函数休眠50毫秒，然后重新检查。\n  当函数发现一个需要立即进行更新的数据行时，缓存函数会检查这个数据行的延迟值，如果该数据行的延时值小于或者等于0 ，那么缓存函数会从延时集合和调度集合里面移除这个数据行的Id，并从缓存中删除这个数据行已有的缓存，然后再重新检查，对于延迟值大于0的数据行来说，缓存函数会从数据库里面取出这些行，将它们编码为JSON格式并存储到Redis里面，然后更新这些行的调度时间。\n  网页分析 目标：\n 记录用户常访问的商品Id。 确保数据不会两级分化严重（一部分数据经常被访问，一部分数据从来不会被访问）。 调整缓存函数，让其仅缓存榜上拥有的数据（避免全量缓存）  实现：\n 用户浏览商品时，调用zincreby viewed: item -1，让经常被浏览的商品的分值降低，这样能够拍到前面。 定期修改viewed:有序集合的长度（调用zremrangebyrank viewed: 0, -20001），并调用zinterstore vieded {'viewed': .5}，让浏览次数降低为原来的一半（这块表示怀疑，因为前面登录的时候，增加的是-1。）  ","description":"","id":13,"section":"notes","tags":null,"title":"005.Redis在一个购物网站中的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/005.redis%E5%9C%A8%E4%B8%80%E4%B8%AA%E8%B4%AD%E7%89%A9%E7%BD%91%E7%AB%99%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"可以通过使用键名来模拟嵌套结构特性：比如使用键user：123表示存储用户信息的散列，并使用键user:123:posts表示存储用户最近发表文章的有序集合；又或者直接将嵌套结构存储到JSON或者其他序列化格式里面。\n（感觉这样会导致键暴增，引入键管理的新问题）\n","description":"","id":14,"section":"notes","tags":null,"title":"006.关于Redis嵌套的一些思路","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/006.%E5%85%B3%E4%BA%8Eredis%E5%B5%8C%E5%A5%97%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%B7%AF/"},{"content":"字符串  Redis中得自增命令和自减命令  INCR：\nDECR：\nINCRBY：\nDECRBY：\nINCRBYFLOAT：\n确实没有DECRBYFLOAT这个指令，而且好像执行了INCRBYFLOAT后，值的类型就会变成字符串。实际上执行INCR等指令值类型也是字符串，之所以会让我误判是因为使用redis-cli工具执行INCRBYFLOAT后，返回的结果带有字符串。\n当用户将一个值存储到Redis字符串里面的时候，如果这个值可以被解释为十进制整数或者浮点数，那么Redis会察觉到这一点，并允许用户对这个字符串执行各种INCR*和DECR*操作。\n如果用户对一个不存在的键或者一个保存了空串的键执行自增或者自减操作，那么Redis在执行操作时会将这个键的值当作是0来处理。\n如果用户尝试对一个值无法被解释为整数或者浮点数的字符串键执行自增或者自减操作，那么Redis将向用户返回一个错误。\n针对字符串的一部分进行操作  APPEND：\nappend keyName value\n将value追加到keyName当前存储的值的末尾\nGETRANGE：\ngetrange keyName start end\n获取一个由偏移量start至偏移量end范围内所有字符组成的字串，包括start和end在内\nSETRANGE：\nsetrange keyName offset value\n将从start偏移量开始的字串设置为给定值\nGETBIT：\ngetbit keyName offset\n将字节串看作成二进制位串，并返回位串中偏移量位offset的二进制位的值\nSETBIT：\nsetbit keyName offset value\n将字节串看作成二进制位串，将位串中偏移量位offset的二进制位的值设置为value\nBITCOUNT：\nbitcount keyName [start end]\n统计二进制位串里面值为1的二进制的数量，如果给定了可选的start和end，那么只对偏移量指定范围内的二进制位进行统计。\nBITOP：\nbitop operation destKey keyName [keyName keyName \u0026hellip;]\n对一个或多个二进制位串执行并、或、异或、非在内的任意一种位运算，并将结果保存在destKey中\n（可能需要了解Redis采用什么方案编码，否则针对一些非英文字符的话，变现会有点怪异。）\n在使用SETRANGE或者SETBIT命令对字符串进行写入的时候，如果字符串当前的长度不能满足写入的要求，那么Redis会自动地使用空字节来将字符串扩展至所需的长度，然后才执行写入或者更新操作。\n在使用GETRANGE读取字符串的时候，超出字符串末尾的数据会被视为是空串，而在使用GETBIT读取二进制位串的时候，超出字符串末尾的二进制位会被视为是0。\n通过使用子串操作和二进制位操作，配合WATCH命令、MULTI命令和EXEC命令，用户甚至可以自己动手去构建任何他们想要的数据结构。（我对这部分内容很感兴趣）\n列表  常用的列表命令：  RPUSH\nLPUSH\nRPOP\nLPOP\nLINDEX\nlindex keyName offset\n返回列表中偏移量位offset的元素\nLRANGE\nlrange keyName start end\n返回列表从start偏移量到end偏移量范围内的所有元素，其中偏移量为start和偏移量为end的元素也会包含在被返回的元素之内\nLTRIM\nltrim keyName start end\n对列表进行修剪，只保留从start偏移量到end偏移量范围内的元素，其中偏移量为start和偏移量为end的元素也会保留\n需要注意，没有RINDEX、RRANGE、RTRIM指令。\n可以组合使用LTRIM、LRANGE指令构建出一个在功能上类似LPOP和RPOP，但是却能够一次返回多个元素的操作。（需要原子性执行多个命令的方法）\n将元素从一个列表移动到另一个列表，或者阻塞执行命令的客户端  BLPOP\nblpop keyName [keyName \u0026hellip;] timeout\n从第一个非空列表中弹出位于最左端的元素，或者在timeout秒之内阻塞并等待可弹出的元素出现。\nBRPOP\nRPOPLPUSH\nbpoplpush sourceKey destKey\n从sourceKey列表中弹出位于最右端的元素，然后将这个元素推入destKey列表的最左端，并向用户返回这个元素。\nBRPOPLPUSH\nbrpoplpush sourceKey destKey timeout\n从sourceKey列表弹出位于最右端的元素，然后将这个元素推入到destKey列表的最左端，并向用户返回这个元素；如果sourceKey为空，那么在timeout秒之内阻塞并等待可弹出的元素出现。\n对于阻塞弹出命令和弹出并推入命令，最常见的用例就是消息传递和任务队列。\n集合  常用的集合指令列表  SADD\nSREM\nSISMEMBER\nSCARD（set cardinality）\nscard keyName\n返回集合包含的元素的数量\nSMEMBERS\nsmembers keyName\n返回集合包含的所有元素\nSRANDMEMBER\nsrandmember keyName [count ]\n从集合里面随机返回一个或多个元素。当count为正数时，命令返回的随机元素不会重复；当count为负数时，命令返回的随机元素可能会出现重复。\nSPOP\nspop keyName\n随机地移除集合中得一个元素，并返回被移除的元素。\nSMOVE\nsmove sourceKey destKey item\n如果集合sourceKey包含元素item，那么从集合sourceKey里面移除元素item，并将元素item添加到集合destKey中。如果item被成功移除，那么命令返回1，否则返回0。\n组合和关联多个集合  SDIFF\nsdiff keyName [keyName \u0026hellip;]\n返回那些存在于第一个集合，但是不存在于其他集合中得元素（数学中的差集运算）\nSDIFFSTORE\nsdiffstore destKey keyName [keyName \u0026hellip;]\n将那些存在于第一个集合，但是不存在于其他集合中得元素（数学中的差集运算）存储到destKey键里面\nSINTER\nsinter keyName [keyName \u0026hellip;]\n返回那些同时存在于所有集合中的元素（数学上的交集运算）\nSINTERSTORE\nSUNION\nsunion keyName [keyName \u0026hellip;]\n返回那些至少存在于一个集合中得元素（数学中得并集运算）（对这个描述表示怀疑）\nSUNIONSTORE\n散列  散列常用命令  HMGET\nhmget keyName key [key \u0026hellip;]\n从散列里获取一个或多个键的值\nHMSET\nhmset keyName key value [key value \u0026hellip;]\n为散列里面的一个或多个键设置值\nHDEL\nhdel keyName key [key \u0026hellip;]\n删除散列里面的一个或多个键值对，返回成功找到并删除的键值对数量\nHLEN\nhlen keyName\n返回散列包含的键值对数量\n常用批量处理命令  HEXISTS\nhexists keyName key\n检查给定键是否存在散列中\nHKEYS\nhkeys keyName\n获取散列包含的所有键\nHVALS\nhvals keyName\n获取散列包含的所有值\nHGETALL\nhgetall keyName\n获取散列包含的所有键值对\nHINCRBY\nhincrby keyName key increment\n将键key存储的值加上整数increment\nHINCRBYFLOAT\nhincrebyfloat keyName key increment\n将键key存储的值加上浮点数increment\n尽管有hgetall，但hkeys和hvals也是非常有用的：如果散列的值非常大，那么用户可以先使用hkeys取出散列包含的所有键，然后再使用hget一个接一个地取出键值，从而避免因为一次获取多个大体积的值而导致服务器阻塞。\n有序集合  有序集合常用命令  ZDD\nZREM\nZCARD\nzcard\n返回有序集合包含的成员数量\nZINCRBY\nzincrby keyName member increment\n将member成员的分值加上increment。\nZCOUNT\nzcount keyName min max\n返回分值介于min和max之间的成员数量。\nZRANK\nzrank keyName member\n返回成员member在有序集合中的排名\nZSCORE\nzscore keyName member\n返回成员member的分值。\nZRANGE\nzrange keyName start stop [WITHSCORES ]\n返回有序集合中排序介于start和stop之间的成员，如果给定了可选的WITHSCORE选项，那么米宁会将成员的分值一并返回。\n有序集合中的另外一些用法  REV reversal的缩写\nZREVRANK\nzrevrank keyName member\n返回有序集合里成员member的排名，成员按照分值从大到小排列。\nZREVRANGE\nZRANGEBYSCORE\nzrangebyscore keyName min max [WITHSCORES ] [LIMIT offset count]\n返回有序集合中，分值介于min和max之间的所有成员。\nZREVRANGEBYSCORE\nzrevrangebyscore keyName max min [WITHSCORES ] [LIMIT offset count]\n返回有序集合中，分值介于min和max之间的所有成员，并按照分值从大到小的顺序来返回它们。\nZREMRANGEBYRANK\nzremrangebyrank keyName start stop\n移除有序集合中排名介于start和stop之间的所有成员。\nZREMRANGEBYSCORE\nzremrangebyscore keyName min max\n移除有序集合中分数介于min和max之间的所有成员。\nZINTERSTORE\nzinterstore destKey keyCount key [key \u0026hellip;] [WEIGHTS weight [weight \u0026hellip;]] [aggregate SUM|MIN|MAX]\n对给定的有序集合执行类似于集合的交集运算。\nZUNIONSTORE\nzunionstore destKey keyCount key [key \u0026hellip;] [weights weight [weight \u0026hellip;]] [aggregate SUM|MIN|MAX]\n对给定的有序集合执行类似于集合的并集运算。\n","description":"","id":15,"section":"notes","tags":null,"title":"007.Redis中的数据类型及相关的操作","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/007.redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%9A%84%E6%93%8D%E4%BD%9C/"},{"content":"第一个原因和Redis系统的稳定性有关。对于旧版Redis来说，如果一个客户端订阅了某个或某些频道，但它读取消息的速度却不够快的话，那么不断积压的消息就会使得Redis输出缓冲区的体积变得越来越大，这可能会导致Redis的速度变慢，甚至直接崩溃。也可能会导致Redis被操作系统强制杀死，甚至导致操作系统本身不可用。新版的Redis不会出现这种问题，因为它会自动断开不符合client-output-buffer-limit pubsub配置选项要求的订阅客户端（本书第8章将对这个选项做更详细的介绍）。\n（这部分知识不是很理解，为什么自动断掉了订阅客户端有利用系统的稳定性，这样不会导致消息堆积的越来越严重么）\n第二个原因和数据传输的可靠性有关。任何网络系统在执行操作时都可能会遇上断线情况，而断线产生的连接错误通常会使得网络连接两端中的其中一端进行重新连接。但是，如果客户端在执行订阅操作的过程中断线，那么客户端将丢失在断线期间发送的所有消息，因此依靠频道来接收消息的用户可能会对Redis提供的PUBLISH命令和SUBSCRIBE命令的语义感到失望。\n（这块也不是很理解，断线期间的消息不会放入到队列中么，感觉就想UDP一样，这东西好鸡肋呀）\n","description":"","id":16,"section":"notes","tags":null,"title":"008.不考虑使用Redis的发布和订阅模式的原因","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/008.%E4%B8%8D%E8%80%83%E8%99%91%E4%BD%BF%E7%94%A8redis%E7%9A%84%E5%8F%91%E5%B8%83%E5%92%8C%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8E%9F%E5%9B%A0/"},{"content":"发布与订阅 SUBSCRIBE\nsubscribe channel [channel \u0026hellip;]\n订阅给定的一个或多个频道\nUNSUBSCRIBE\nunsubscribe [channel [channel \u0026hellip;]]\n退订给定的一个或多个频道，如果执行时没有给定任何频道，那么退订所有频道。\nPUBLISH\npublish channel message\n向给定频道发送消息\nPSUBSCRIBE\npsubscribe [pattern [pattern \u0026hellip;]]\n订阅给定模式向匹配的所有频道\nPUNSUBSCRIBE\npunsubscribe [pattern [pattern \u0026hellip;]]\n退订给定的模式，如果执行时没有给定任何模式，那么退订所有模式\nSORT指令 SORT\nsort sourceKey [by pattern] [limit offset count] [get pattern [get pattern]] [asc|desc] [alpha] [sotore destKey]\n案例一：\n rpush sort_input 23 15 110 7 sort sort_input sort sort_input ALPHA 案例二（非常的不理解）：\n hset d-7 field 5 hset d-15 field 1 hset d-23 field 9 hset d-110 field 3 // 将散列的域用作权重，对sort-input列表进行排序 sort sort_input BY 'd-*-\u0026gt;field' // 获取外部数据，并将它们用作命令的返回值，而不是返回被排序的数据 sort sort_input BY 'd-*-\u0026gt;field' get 'd-*-\u0026gt;field' MULTI、EXEC指令 过期指令 PERSIST\npersist keyName\n移除键的过期时间\nTTL\nttl keyName\n查看给定键距离过期还有多少秒\nEXPIRE\nexpire\nexpire keyName seconds\n让给定键在指定的秒数之后过期\nEXPIREAT\nexpireat keyName timestamp\n将给定的过期时间设置为给定的UNIX时间戳\nPTTL（毫秒级）\nPEXPIRE（毫秒级）\nPEXPIREAT（毫秒级）\n","description":"","id":17,"section":"notes","tags":null,"title":"009.Redis的其他指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/009.redis%E7%9A%84%E5%85%B6%E4%BB%96%E6%8C%87%E4%BB%A4/"},{"content":"resolv.conf resolv.conf是解析器配置文件，其中包含如下内容：\n nameserver：将DNS查询转发到的位置。 search：表示特定域的搜索路径。 ndots：ndots表示查询名称中点数的阈值，以将其视为“完全合格”域名。  ","description":"","id":18,"section":"notes","tags":null,"title":"01.CoreDNS的一些知识（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/headlessservice/01.coredns%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E5%BA%9F%E5%BC%83/"},{"content":"Master组件 Master组件是集群的控制平台：\n Master组件负责集群中得全局决策（例如调度） Master组件探测并响应集群事件（例如，当Deployment的实际Pod副本数未达到replicas字段的规定时，启动一个新的Pod）  Master组件可以运行于集群中的任何机器上，但是为了简洁性，通常在同一台机器上运行所有的Master组件，且不在此机器上运行用户容器。\nkube-apiserver etcd kube-scheduler 此Master组件监听所有新创建尚未分配到节点上的Pod，并且自动为Pod选择一个合适的节点去运行。影响调度的因素有：\n 单个或多个Pod的资源需求 硬件、软件、策略的限制 亲和与反亲和的约定 数据本地化要求（不是很熟悉） 工作负载键的相互作用  kube-controller-manager 此Master组件运行了所有的控制器。逻辑上来说，每一个控制器都是一个独立的进程，但是为了降低复杂度，这些控制器被合并运行在一个进程里。kube-controller-manager中包含的控制器有：\n 节点控制器：负责监听节点停机的事件并作出对应响应 副本控制器：负责为集群中每一个副本控制器对象维护期望的Pod副本数 端点控制器：负责为端点对象赋值（不是很熟悉） Service Account \u0026amp; Token控制器：负责为新的名称空间创建Default Service Account以及API Access Token。  cloud-controller-manager 此Master组件运行了与具体云基础设施供应商互动的控制器，默认是不安装该组件的。（暂时不研究该组件）\nNode组件 kubelet 此组件是运行在每一个集群节点上的代理程序，它确保Pod中得容器处于运行状态。Kubelet通过多种途径获得PodSpec定义，并确保PodSpec定义中所描述的容器处于运行和健康的状态。Kubectl只管理通过Kubernetes创建的容器。\nkube-proxy 此组件是一个网络代理程序，运行在集群中的每一个节点上，是实现Kubernetes Service概念的重要部分。kube-proxy在节点上维护网络规则，这些规则确保能正确的与各个Pod进行通信，目前最新版的Kubernetes是通过LVS实现的。\n容器引擎 容器引擎负责运行容器。Kubernetes支持多种容器引擎：Docker、containerd、cri-o、rktlet以及任何实现了Kubernetes容器引擎接口的容器引擎（这方面不是很熟悉）。\nAddons（非常不熟悉） Addons使用Kubernetes资源（DaemonSet、Deployment等）实现集群的功能特性。由于它们提供集群级别的功能特性，Addons使用到的Kubernetes资源都放置在kube-system命名空间下。\nDNS 除了DNS Addon以外，其他的Addon都不是必须的，所有Kubernetes集群都应该有Cluster DNS。Cluster DNS是一个DNS服务器，是对您已有环境中其他DNS服务器的一个补充，存放了Kubernetes Service的DNS记录。Kubernetes启动容器时，自动将该DNS服务器假如到容器的DNS搜索列表中。\nWebUI Kuboard ContainerResource Monitoring 此组件将容器的度量指标记录在时间序列数据库中，并提供了UI界面查看这些数据。\nCluster-Level Logging 此组件负责将容器的日志存储到一个统一存储中，并提供搜索浏览的界面。\n","description":"","id":19,"section":"notes","tags":null,"title":"01.Kubernetes组件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/01.kubernetes%E7%BB%84%E4%BB%B6/"},{"content":" APPEND key STRLEN key LCS key1 key2 [LEN] [IDX] [MINMATCHLEN len] [WITHMATCHLEN] # 设置 SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET] SETNX key value SETEX key seconds value PSETEX key milliseconds value SETRANGE key offset value # 获取 GET key GETSET key value GETRANGE key start end GETDEL key GETEX key [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|PERSIST] MGET key [key ...] MSET key value [key value ...] MSETNE key value [key value ...] # 自减 DECR key DECRBY key value # 自增 INCR key INCRBY key value INCRBYFLOAT key increment LCS指令 LCS指令用于求两个字符串的最大公共子序列，目前在开发中用的比较少，所以暂时不进行研究。\nSET指令 SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET]\nEX 过期秒数\nPX 过期毫秒数\nEXAT 期待在某个时间戳（秒）过期\nPXAT 期待在某个时间戳（毫秒）过期\nKEEPTTL 保留与键关联的生存时间（如果原来的键设置了ttl，set的默认行为是取消这些ttl的关联）\nNX 只有key不存在时，才进行设置\nXX 只有key存在时，才进行设置\nGET 返回旧的字符串，如果旧字符串不存在则返回nil。\nSET命令选项可以替代SETNX、SETEX、PSETEX、GETSET，因此在未来，这些指令可能被弃用，最终被删除。\nMSETNE MSETNE key value [key value \u0026hellip;]\n同时设置一个或多个key-value对，当且仅当所有给定key都不存在时。\n数据结构 String的数据结构为简单动态字符串（SDS）。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。\n如图所示为字符串实际分配的空间。其中capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过了1M，扩容时只会多扩1M的空间。字符串最大长度为512M。\n参考资料  Redis#String Redis STRALGO LCS命令与实现  ","description":"","id":20,"section":"notes","tags":null,"title":"01.String相关命令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/01.string%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/"},{"content":"增加一块存储盘  更新opkg，下载fdisk、cfdisk、e2fsprogs  1 2 3 4 5 6 7  opkg update opkg install e2fsprogs opkg install fdisk # 这个貌似没用到，我只是习惯性安装 opkg install cfdisk    关闭OpenWRT，PVE虚拟机上为其在增加一块硬盘，重启OpenWRT，然后执行fdisk -l：  接下下的步骤，我在为PVE系统扩容时做过的，哈哈。我只是在选择主分区还是扩展分区时手动选择了主分区，其他的步骤都是走默认的。\n fdisk /dev/sdb 再次执行fdisk -l：\n比较两次执行结果，这一次已经看到/dev/sdb已经完成了分区。使用cat /proc/partitions查看系统识别的分区:\n我这边成功识别了，如果没有识别，可以在我下面列出的参考资料找到解决方案。\n创建文件系统  1 2 3  mkfs.ext4 /dev/sdb1    设置挂载，我之前使用的是block-mount，但是这个工具在扩容Overlay的实验中重启后无法自动挂载，所以我改为编辑/etc/rc.local文件方案（该方案需要确保/mnt/sda3已经手动创建）：   # Put your custom commands here that should be executed once # the system init finished. By default this file does nothing. # 增加的内容 mount /dev/sdb1 /mnt/sdb1 exit 0  完工大吉。  扩容Overlay   参考上面的方案安装软件、分区，并建立文件系统\n  执行如下代码（执行前需要确保/mnt/sda3已经手动创建）：\n   mount /dev/sda3 /mnt/sda3 cp -r /overlay/* /mnt/sda3 修改/etc/rc.local文件后，重启系统。   # Put your custom commands here that should be executed once # the system init finished. By default this file does nothing. # 增加的内容 mount /dev/sda3 /overlay exit 0 完工大吉  参考资料   Openwrt软件包空间扩容\n创建文件系统用的是该教程里的方案，Overlay扩容也参考了该教程，但是无法直接使用。\n  fdisk+mount案例实操\n核心参考的资料。\n  OpenWrt扩容Overlay，为你的固件增加可用空间，从此安装程序随心所欲~\n很好的Overlay扩容的教程，我Overlay相关的实验参考的该教程，但是无法直接使用。\n  openwrt\u0026mdash;-Luci WEB界面增加挂载点\n我的luci管理界面没有挂载点功能，通过该教程解决该问题。但是我最终没有使用这个工具，因为重启后不稳定。\n  \n解决了Overlay无法自动挂载的问题。\n  ","description":"","id":21,"section":"notes","tags":null,"title":"01.技术点01：OpenWRT扩容","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/01.%E6%8A%80%E6%9C%AF%E7%82%B901openwrt%E6%89%A9%E5%AE%B9/"},{"content":"为Kubernetes集群添加用户\n本实验没有达到目标，稍后再整理\nUser Account应该是被创造出来的概念，我不确定Kubernetes中是否有这个概念。\nKubernetes不管理用户，但是在接受API请求时，是可以认知到发出请求的用户的。实际上，所有对Kubernetes的API请求都需要绑定身份信息（UserAccount或者ServiceAccount），这就意味着，可以为User配置Kubernetes集群中的请求权限。\nKubernetes不会管理User，所以User的创建、编辑、注销等都需要依赖外部的管理机制，Kubernetes所能认知的只有一个用户名。\n尽管Kubernetes认知用户靠的只有用户的名字，但是只需要一个名字就能请求Kubernetes的API显然是不合理的，所以依然需要验证此用户的身份。Kubernetes中有如下验证方式：\n  X509客户端证书\n客户端证书验证通过为API Server指定\u0026ndash;client-ca-file=xxx选项启动，API Servier通过此ca文件来验证API请求中携带的客户端证书的有效性，一旦验证成功，API Server就会将客户端证书Subject里的CN属性作为此次请求的用户名。\n  静态Token文件（暂不研究）\n  静态密码文件（暂不研究）\n  为用户生成证书 假设我们操作的用户名为Tom\n 为用户创建一个私钥  1 2 3  openssl genrsa -out tom.key 2048   为此私钥创建一个csr（证书签名请求）文件，需要在subject里带上用户信息（CN为用户名，O为用户组）  1 2 3  openssl req -new -key tom.key -out tom.csr -subj \u0026#34;/CN=tom/O=MGM\u0026#34;   找到Kubernetes集群（API Server）的CA证书文件（/etc/kubernetes/pki/ca.crt），通过集群的CA证书和之前创建的csr文件来为用户颁发证书：  1 2 3 4 5 6 7 8 9  openssl x509 -req \\  -in tom.csr \\  -CA /etc/kubernetes/pki/ca.crt \\  -CAkey /etc/kubernetes/pki/ca.key \\  -CAcreateserial \\  -out tom.crt \\  -days 365   /etc/kubernetes/pki下会有两个文件，一个是CA证书（ca.crt），一个是CA私钥（ca.key）。\n为用户添加基于角色的访问控制 这儿我采用使用Kubernetes集群中内置的admin的ClusterRole的方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  kind:RoleBindingapiVersion:rbac.authorization.k8s.io/v1beta1metadata:name:tom-admin-bindingnamespace:defaultsubjects:- kind:Username:tomapiGroup:\u0026#34;\u0026#34;roleRef:kind:ClusterRolename:adminapiGroup:\u0026#34;\u0026#34;  为kubectl配置用户 ","description":"","id":22,"section":"notes","tags":null,"title":"01.理解Kubernetes中得User Account、Service Account","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/%E5%8D%9A%E6%96%87/01.%E7%90%86%E8%A7%A3kubernetes%E4%B8%AD%E5%BE%97user-accountservice-account/"},{"content":"本次实验我准备使用H2数据库，虽然我现在有足够多的脚本快速启动一个MySQL、PG，但是这毕竟会增加我下次启动该项目时的时间成本。H2数据库用于技术验证是非常不错的，可以将代码和数据库集中在一个项目中，很有研究价值，所以我决定使用H2数据库，顺便积累这个数据的使用经验。\n准备工作 引入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.h2database\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;h2\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   进行配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  spring:application:name:mybatisdatasource:schema:classpath:h2/schema.sqldata:classpath:h2/data.sqlusername:sanpassword:driver-class-name:org.h2.Driverurl:jdbc:h2:file:~/testh2:console:enabled:truepath:/h2-consolesettings:web-allow-others:truetrace:truemybatis-plus:mapper-locations:classpath:mapper/*Mapper.xml  开发Entity和Mapper User.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package fun.junjie.mybatis.entity; import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; @Data @Builder @NoArgsConstructor @AllArgsConstructor @TableName(\u0026#34;t_user\u0026#34;) public class User { /** * 主键 */ private String id; /** * 用户名 */ private String name; }   UserMapper.java\n1 2 3 4 5 6 7 8 9 10 11 12  package fun.junjie.mybatis.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import fun.junjie.mybatis.entity.User; import org.springframework.stereotype.Repository; @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { }   准备schema.sql和data.sql schema.sql\n1 2 3 4 5 6 7 8  DROPTABLEt_user;CREATETABLEt_user(idvarchar(100)PRIMARYKEYNOTNULL,namevarchar(100)NOTNULL);  data.sql\n1 2 3  INSERTINTOt_userVALUES(\u0026#39;1000\u0026#39;,\u0026#39;zhansan\u0026#39;)  测试工作 测试MyBatis-Plus集成是否生效 测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package fun.junjie.mybatis.mapper; import fun.junjie.mybatis.entity.User; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class UserMapperTest { @Autowired private UserMapper userMapper; @Test void selectById() { User user = userMapper.selectById(\u0026#34;1000\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } }   断点发现，user正确的获取到值了，说明h2、MyBatis的集成是有效的。\n测试mapper.xml文件能否正常使用 修改UserMapper文件，代码如下：\n1 2 3 4 5 6 7 8  @Repository public interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; { User selectByIdCustom(String userId); }   开发相应的mapper.xml文件，代码如下：\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34; \u0026gt; \u0026lt;mapper namespace=\u0026#34;fun.junjie.mybatis.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectByIdCustom\u0026#34; resultType=\u0026#34;fun.junjie.mybatis.entity.User\u0026#34;\u0026gt; SELECT * FROM t_user WHERE id = #{userId} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   开发相应的测试方法：\n1 2 3 4 5 6 7  @Test void selectByIdCustom() { User user = userMapper.selectByIdCustom(\u0026#34;1000\u0026#34;); System.out.println(\u0026#34;\u0026#34;); }   断点发现，最后获取的数据是我需要的。\n截止到目前，我已经完成了基础的实验环境搭建，接下将一一实现我的实验目标。\n","description":"","id":23,"section":"notes","tags":null,"title":"01.配置MyBatis-Plus测试环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/01.%E9%85%8D%E7%BD%AEmybatis-plus%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/"},{"content":"一段简单的配置如下：\n save 60 1000 // 多久执行一次自动快照操作 stop-write-on-bgsave-error no // 创建快照失败候是否仍然继续执行写命令 rdbcompression yes // 是否对快照文件进行压缩 dffilename dump.rdb // 如何命名硬盘上的快照文件 dir ./ 创建快照的办法有以下几种：\n 客户端发送BGSAVE指令（fork一个进程进行处理） 客户端调用SAVE指令（在当前进程中进行处理） save 60 1000 通过redis-cli执行shutdown指令时，或者收到标准term信号时，会执行一个save命令 当一个Redis服务器连接到另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令。   理解save 60 1000 如果用户设置了save配置选项，比如save 60 10000，那么从Redis最近一次创建快照之后算起，当“60秒之内有100000次写入”这个条件满足时，Redis就会自动触发BGSAVE命令。如果用户设置了多个save配置选项，那么当任意一个save配置选项所设置的条件被满足时，Redis就会触发一次BGSAVE命令。\n（配置参考：个人开发服务器上可以配置成save 900 1）\n","description":"","id":24,"section":"notes","tags":null,"title":"010.快照持久化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/010.%E5%BF%AB%E7%85%A7%E6%8C%81%E4%B9%85%E5%8C%96/"},{"content":"  首先要确认自己能丢失多长时间的数据，如果可以丢失一小时内产生的数据，可以使用save 3600 1。\n  其次在进行数据恢复时，要搞清楚我们丢失了哪些数据。为了弄明白这一点，我们需要在处理日志的同时记录被处理日志的相关信息。\n  1 2 3 4 5  def process_logs(conn, path, callback): current_file, offset = conn.mget(\u0026#39;progress:file\u0026#39;, \u0026#39;progress:position\u0026#39;) pipe = conn.pipeline()   核心就是在处理时，增加一个字段用于记录处理的日志的偏移量，看的出来，这种方案是用于处理离线数据，现阶段处理离线数据的需求貌似不是很强列。\n","description":"","id":25,"section":"notes","tags":null,"title":"011.日志聚合、页面浏览量分析时对Redis的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/011.%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88%E9%A1%B5%E9%9D%A2%E6%B5%8F%E8%A7%88%E9%87%8F%E5%88%86%E6%9E%90%E6%97%B6%E5%AF%B9redis%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"一段简单的配置如下：\n // 可能注释对不上，我瞎写的 appendonly no // 是否使用AOF持久化 appendfsync everysec // 多久执行一次AOF压缩 no-appendfsync-no-rewrite no // 在对AOF进行压缩的时候能否执行同步操作 auto-aof-rewrite-percentage 100 // 多久才将写入的内容同步到硬盘 auto-aof-rewrite-min-size 64mb // dir ./ 可以显示地发送BGREWRITEAOF命令，这个命令会通过移除AOF文件中的冗余来重写AOF文件，使AOF文件的体积变得尽可能小。\n额，这块我有点不理解，为什么是用一个子进行来处理AOF的文件，不如直接开一个线程来处理，这样可以避免进程空间的复制。\nappendfsync选项及同步频率 always：每个Redis写命令都要不同写入硬盘。这样做会严重降低Redis速度。\neverysec：每秒执行一次同步，显示地将多个写命令同步到硬盘。\nno：让操作系统来决定应该何时进行同步。\n设置BGREWRITEAOF  // 当AOF文件的体积大于64MB时进行BGREWRITEAOF。 auto-aof-rewrite-percentage 100 // 当AOF文件比上一次重写之后的体积大了至少一倍（100%）时，执行BGREWRITEAOF。 auto-aof-rewrite-min-size 64mb ","description":"","id":26,"section":"notes","tags":null,"title":"012.Redis AOF持久化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/012.redis-aof%E6%8C%81%E4%B9%85%E5%8C%96/"},{"content":"配置开启主从复制  配置文件中   slaveof host port 如果用户使用SALVEOF配置选项，那么Redis在启动时首先会载入当前可用的任何快照文件或者AOF文件，然后连接主服务器执行复制过程（总之，要让Redis先运行起来）。\n通过指令   slaveof on one slaveof host port Redis复制的启动过程   主服务器：（等待命令进入）\n从服务器：连接（或重连接）主服务器，发送SYNC命令\n  主服务器：开始执行BGSAVE，并使用缓冲记录区记录BGSAVE之后执行的所有写命令\n从服务器：根据配置选项来决定是继续使用现有的数据（如果有的话）来处理客户端的命令请求，还是向发送请求的客户端返回错误。\n  主服务器：BGSAVE执行完毕，向从服务器发送快照文件，并在发送期间继续使用缓冲记录被执行的写命令。\n从服务器：丢弃所有旧数据（如果有的话），开始载入主服务器发来的快照文件\n  主服务器：快照文件发送完毕，开始向从服务器发送存储在缓冲区里面的写命令。\n从服务器：完成对快照文件的解释操作，像往常一行开始接受命令请求。\n  主服务器：缓存区存储的写命令发送完毕；从现在开始每执行一个写命令，就想从服务器发送相同的写命令。\n从服务器：执行主服务器发送的所有存储在缓冲区里面的写命令；并从现在开始，接受并执行主服务器传来的每个写命令。\n  ","description":"","id":27,"section":"notes","tags":null,"title":"013.Redis的主从复制","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/013.redis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"content":"用户及用户包裹的数据结构如下：\n市场的数据结构如下：\n商品上架 为了将商品放到市场上进行销售，程序除了要使用MULTI命令和EXEC命令之外，还需要配合使用WATCH命令，有时候甚至还会用到UNWATCH或DISCARD命令。\n在用户使用WATCH命令对键进行监视之后，直到用户执行EXEC命令的这段时间里面，如果有其他客户端抢先对任何被监视的键进行了替换、更新或删除等操作，那么当用户尝试执行EXEC命令的时候，事务将失败并返回一个错误（之后用户可以选择重试事务或者放弃事务）。\n通过用WATCH，MULTI/EXEC UNWATCH/DISCARD等命令，程序可以在执行某些重要操作的时候，通过确保自己正在使用的数据没有发生变化来避免数据出错。\n理解Discard UNWATCH命令可以在WATCH命令执行之后、MULTI命令执行之前对连接进行重置（reset）；同样地，DISCARD命令也可以在MULTI命令执行之后、EXEC命令执行之前对连接进行重置。\n这也就是说，用户在使用WATCH监视一个或多个键，接着使用MULTI开始一个新的事务，并将多个命令入队到事务队列之后，仍然可以通过发送DISCARD命令来取消WATCH命令并清空所有已入队命令。\n小总结：\n  WATCH、MULTI、EXEC的使用流程是：先试用watch监视一两个键，然后使用multi开启管道，然后输入执行命令，然后调用exec进行执行。\n  如果调用了watch之后，在调用multi之前，可以使用unwatch取消监控，如果在multi之后，则可以调用discard进行取消。\n  我先简单的这么理解。\n购买商品   程序首先使用WATCH对市场以及买家的个人信息进行监视，然后获取买家拥有的钱数以及商品的售价，并检查买家是否有足够的钱来购买该商品。\n  如果买家没有足够的钱，那么程序会取消事务；相反地，如果买家的钱足够，那么程序首先会将买家支付的钱转移给卖家，然后将售出的商品移动至买家的包裹，并将该商品从市场中移除。\n  当买家的个人信息或者商品买卖市场出现变化而导致WatchError异常出现时，程序将进行重试，其中最大重试时间为10秒。\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  stringRedisTemplate.execute((RedisCallback\u0026lt;Object\u0026gt;) connection -\u0026gt; { String buyer = String.format(\u0026#34;users:%s\u0026#34;, buyerId); String seller = String.format(\u0026#34;users:%s\u0026#34;, sellerId); String item = String.format(\u0026#34;%s.%s\u0026#34;, itemId, sellerId); String inventory = String.format(\u0026#34;inventory:%s\u0026#34;, buyerId); LocalDateTime end = LocalDateTime.now().plusSeconds(10); // 这个地方肯定写法有问题，但是不纠结  while (LocalDateTime.now().isBefore(end)) { try { // 对商品买卖市场以及买家的个人信息进行监视  connection.watch(String.format(\u0026#34;market:%s\u0026#34;, buyer).getBytes(StandardCharsets.UTF_8)); // 检查买家想购买的商品的价格是否出现了变化，以及买家是否有  // 足够的钱来购买这件商品  Double price = connection.zScore( \u0026#34;market:\u0026#34;.getBytes(StandardCharsets.UTF_8), item.getBytes(StandardCharsets.UTF_8)); Double founds = Double.valueOf(Arrays.toString(connection.hGet( buyer.getBytes(StandardCharsets.UTF_8), \u0026#34;funds\u0026#34;.getBytes(StandardCharsets.UTF_8)))); if (price != lprice || price \u0026gt; founds) { connection.unwatch(); return null; } // 先将买家支付的钱转义给卖家，然后将被购买的商品移交给买家  connection.multi(); connection.hIncrBy( seller.getBytes(StandardCharsets.UTF_8), \u0026#34;founds\u0026#34;.getBytes(StandardCharsets.UTF_8), price); connection.hIncrBy( buyer.getBytes(StandardCharsets.UTF_8), \u0026#34;founds\u0026#34;.getBytes(StandardCharsets.UTF_8), price); connection.sAdd( inventory.getBytes(StandardCharsets.UTF_8), itemId.getBytes(StandardCharsets.UTF_8)); connection.zRem( \u0026#34;market:\u0026#34;.getBytes(StandardCharsets.UTF_8), item.getBytes(StandardCharsets.UTF_8)); connection.exec(); return true; } catch (Exception e) { // 如果买家的个人信息或者商品买卖市场在交易的过程中出现了变化，  // 那么进行重试  e.printStackTrace(); } } return false; });   ","description":"","id":28,"section":"notes","tags":null,"title":"014.Redis事务案例研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/redis%E5%AE%9E%E6%88%98/014.redis%E4%BA%8B%E5%8A%A1%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6/"},{"content":" # List操作 LLEN key LSET key index element LREM key count element LTRIM key start stop LINDEX key index LINSERT key BEFORE|AFTER pivot element LPOS key element [Rank rank] [COUNT num-matches] [MAXLEN len] LRANGE key start stop # 队列操作 LPUSH key element [element ...] LPUSHX key element [element ...] LPOP key [count] RPUSH key elemet [element ...] RPUSHX key element [element ...] RPOP key [count] RPOPLRPUSH source destination # 阻塞操作 BLPOP key [key ...] timeout BRPOP key [key ...] timeout BRPOPLPUSH source destination timeout BLMOVE source destination LEFT|RIGHT LEFT|RIGHT timeout BLMPOP timeout numkeys key [key ...] LEFT|RIGHT [COUNT count] LMPOP numkeys key [key ...] LEFT|RIGHT [COUNT count] LMOVE source destination LEFT|RIGHT LEFT|RIGHT 数据结构 List的数据结构为快速链表QuickList。\n在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ZipList，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才改成QuickList。\n因为普通的链表需要的附加指针空间太大，会浪费空间。所以Redis将链表和ZipList结合起来组成了QuickList，也就是将多个ZipList使用双向链表串起来使用。这样即满足了插入删除性能，又不会出现太大的空间冗余。\n参考资料  Redis#List  ","description":"","id":29,"section":"notes","tags":null,"title":"02.List相关命令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/02.list%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/"},{"content":"ServiceAccount\n当您创建Pod的时候，如果您没有指定一个ServiceAccount，系统会自动得在与该pod相同的namespace下为其指派一个Default ServiceAccount。如果您获取刚创建的pod的原始json或yaml信息，您将看到spec.serviceAccountName字段已经被设置为default。\n在1.6以上版本中，您可以选择取消为ServiceAccount自动挂载API凭证，只需在ServiceAccount中设置automountServiceAccountToken: false（我已经进行了相关的实验，可以在相关类目下找到）。\n1 2 3 4 5 6 7  apiVersion:v1kind:ServiceAccountmetadata:name:build-robotautomountServiceAccountToken:false  在1.6以上的版本中，也可以选择只取消单个Pod的API凭证自动挂载。\n1 2 3 4 5 6 7 8 9 10  apiVersion:v1kind:Podmetadata:name:my-podspec:serviceAccountName:build-robotautomountServiceAccountToken:false...  如果同时在ServiceAccount和Pod中设置了automountServiceAccountToken，则Pod的优先级更高。\n","description":"","id":30,"section":"notes","tags":null,"title":"02.ServiceAccount","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/%E5%8D%9A%E6%96%87/02.serviceaccount/"},{"content":"在我的环境中，base-environment下有相应Service和HeadlessService可以用来实验，所以我计划在该命名空间下进行实验。\n1 2 3 4 5 6 7 8  kubectl get svc -n base-environment # NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE # redis-headless ClusterIP None \u0026lt;none\u0026gt; 6379/TCP 21h # redis-master ClusterIP 10.101.228.148 \u0026lt;none\u0026gt; 6379/TCP 21h # redis-replicas ClusterIP 10.110.178.186 \u0026lt;none\u0026gt; 6379/TCP 21h    准备一个Busybox：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  apiVersion:v1kind:Podmetadata:name:mybusyboxnamespace:base-environmentlabels:name:mybusyboxspec:containers:- name:mybusyboximage:busyboxcommand:- sh- -c- \u0026#34;while true;do echo hello docker;sleep 10;done\u0026#34;resources:limits:memory:\u0026#34;128Mi\u0026#34;cpu:\u0026#34;500m\u0026#34;  查看各个service   nslookup redis-headless.base-environment.svc.cluster.local nslookup redis-master nslookup redis-replicas ","description":"","id":31,"section":"notes","tags":null,"title":"02.关于Headless Service的一些实验（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/headlessservice/02.%E5%85%B3%E4%BA%8Eheadless-service%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AE%9E%E9%AA%8C%E5%BA%9F%E5%BC%83/"},{"content":" 仓库  1 2 3 4  helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx helm repo update   获取默认的Values.yaml，并反复调试   helm inspect values ingress-nginx/ingress-nginx \u0026gt; values.yaml helm install ingress-nginx ingress-nginx/ingress-nginx \\ --values values.yaml \\ --namespace base \\ --create-namespace \\ --dry-run \u0026gt; tmp.yaml 安装服务   helm install ingress-nginx ingress-nginx/ingress-nginx \\ --values values.yaml \\ --namespace base \\ --create-namespace 进行升级（升级前也可以调试一下）   helm upgrade ingress-nginx ingress-nginx/ingress-nginx \\ --values values.yaml \\ --namespace base \\ --create-namespace 测试安装结果 测试一下服务安装成果\n kubectl create deployment demo --image=httpd --port=80 kubectl expose deployment demo kubectl create ingress demo-localhost \\ --class=nginx \\ --rule=demo.localdev.me/*=demo:80 对默认配置文件作出的改动  修改LoadBalancer类型为NodePort 为80端口指定30080 为443端口指定30443 为6379端口指定36379（如果需要装Redis）  ","description":"","id":32,"section":"notes","tags":null,"title":"02.安装IngressNginx","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/02.%E5%AE%89%E8%A3%85ingressnginx/"},{"content":"20210126后续： 我换成MyBatisX插件了 ## 参考资料 1. [idea中生成mapper xml文件，快速从代码跳转到mapper及从mapper返回代码的插件安装](https://blog.csdn.net/weixin_45151960/article/details/108461378) ","description":"","id":33,"section":"notes","tags":null,"title":"02.实现Mapper.java与Mapper.xml中方法的跳转","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/02.%E5%AE%9E%E7%8E%B0mapper.java%E4%B8%8Emapper.xml%E4%B8%AD%E6%96%B9%E6%B3%95%E7%9A%84%E8%B7%B3%E8%BD%AC/"},{"content":" 建立目录：   mkdir -p ~/ipks 从下载器上用scp指令拷贝文件：   scp -r ~/ipks/openwrt_core root@192.168.31.199:/mnt/sdb1/ipks/openwrt_core scp -r ~/ipks/openwrt_base root@192.168.31.199:/mnt/sdb1/ipks/openwrt_base scp -r ~/ipks/openwrt_luci root@192.168.31.199:/mnt/sdb1/ipks/openwrt_luci scp -r ~/ipks/openwrt_packages root@192.168.31.199:/mnt/sdb1/ipks/openwrt_packages scp -r ~/ipks/openwrt_routing root@192.168.31.199:/mnt/sdb1/ipks/openwrt_routing scp -r ~/ipks/openwrt_telephony root@192.168.31.199:/mnt/sdb1/ipks/openwrt_telephony 配置/etc/opkg/distfeeds.conf如下：   src/gz openwrt_core file:///mnt/sdb1/ipks/openwrt_core src/gz openwrt_base file:///mnt/sdb1/ipks/openwrt_base src/gz openwrt_luci file:///mnt/sdb1/ipks/openwrt_luci src/gz openwrt_packages file:///mnt/sdb1/ipks/openwrt_packages src/gz openwrt_routing file:///mnt/sdb1/ipks/openwrt_routing src/gz openwrt_telephony file:///mnt/sdb1/ipks/openwrt_telephony 实验结果如下:   root@OpenWrt:~# opkg update Downloading file:///mnt/sdb1/ipks/openwrt_core/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_core Downloading file:///mnt/sdb1/ipks/openwrt_core/Packages.sig Signature check passed. Downloading file:///mnt/sdb1/ipks/openwrt_base/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_base Downloading file:///mnt/sdb1/ipks/openwrt_base/Packages.sig Signature check passed. Downloading file:///mnt/sdb1/ipks/openwrt_luci/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_luci Downloading file:///mnt/sdb1/ipks/openwrt_luci/Packages.sig Signature check passed. Downloading file:///mnt/sdb1/ipks/openwrt_packages/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_packages Downloading file:///mnt/sdb1/ipks/openwrt_packages/Packages.sig Signature check passed. Downloading file:///mnt/sdb1/ipks/openwrt_routing/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_routing Downloading file:///mnt/sdb1/ipks/openwrt_routing/Packages.sig Signature check passed. Downloading file:///mnt/sdb1/ipks/openwrt_telephony/Packages.gz Updated list of available packages in /var/opkg-lists/openwrt_telephony Downloading file:///mnt/sdb1/ipks/openwrt_telephony/Packages.sig Signature check passed. 参考资料  openwrt设置本地软件源安装第三方ipk  ","description":"","id":34,"section":"notes","tags":null,"title":"02.技术点02：Opkg配置使用本地文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/02.%E6%8A%80%E6%9C%AF%E7%82%B902opkg%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6/"},{"content":"指令如下：\n kubectl get nodes kubectl describe node NODE_NAME 输出如下（这儿只关注status字段中得addresses、capacity、allocatable、conditions）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139  status:addresses:- address:192.168.23.61type:InternalIP- address:node2type:Hostnameallocatable:cpu:\u0026#34;2\u0026#34;ephemeral-storage:\u0026#34;27761957638\u0026#34;hugepages-2Mi:\u0026#34;0\u0026#34;memory:3777764Kipods:\u0026#34;110\u0026#34;capacity:cpu:\u0026#34;2\u0026#34;ephemeral-storage:30123652Kihugepages-2Mi:\u0026#34;0\u0026#34;memory:3880164Kipods:\u0026#34;110\u0026#34;conditions:- lastHeartbeatTime:\u0026#34;2021-12-24T09:47:07Z\u0026#34;lastTransitionTime:\u0026#34;2021-12-24T09:47:07Z\u0026#34;message:Flannel is running on this nodereason:FlannelIsUpstatus:\u0026#34;False\u0026#34;type:NetworkUnavailable- lastHeartbeatTime:\u0026#34;2021-12-29T06:26:44Z\u0026#34;lastTransitionTime:\u0026#34;2021-12-24T09:46:37Z\u0026#34;message:kubelet has sufficient memory availablereason:KubeletHasSufficientMemorystatus:\u0026#34;False\u0026#34;type:MemoryPressure- lastHeartbeatTime:\u0026#34;2021-12-29T06:26:44Z\u0026#34;lastTransitionTime:\u0026#34;2021-12-24T09:46:37Z\u0026#34;message:kubelet has no disk pressurereason:KubeletHasNoDiskPressurestatus:\u0026#34;False\u0026#34;type:DiskPressure- lastHeartbeatTime:\u0026#34;2021-12-29T06:26:44Z\u0026#34;lastTransitionTime:\u0026#34;2021-12-24T09:46:37Z\u0026#34;message:kubelet has sufficient PID availablereason:KubeletHasSufficientPIDstatus:\u0026#34;False\u0026#34;type:PIDPressure- lastHeartbeatTime:\u0026#34;2021-12-29T06:26:44Z\u0026#34;lastTransitionTime:\u0026#34;2021-12-24T09:46:43Z\u0026#34;message:kubelet is posting ready statusreason:KubeletReadystatus:\u0026#34;True\u0026#34;type:ReadydaemonEndpoints:kubeletEndpoint:Port:10250images:- names:- rancher/rancher@sha256:f411ee37efa38d7891c11ecdd5c60ca73eb03dcd32296678af808f6b4ecccfff- rancher/rancher:v2.6.3sizeBytes:1162917989- names:- rancher/shell@sha256:9c33c0e58ceb0b3cb6a85d2a6349b1f7fe818e383e6a3cb46671558fbb2f7781- rancher/shell:v0.1.14sizeBytes:170950834- names:- rancher/fleet-agent@sha256:c929f1f23b69a7269921aba5b7c4c407428fb978939101659f72e441863b332b- rancher/fleet-agent:v0.3.8sizeBytes:154998416- names:- nginx@sha256:c97ee70c4048fe79765f7c2ec0931957c2898f47400128f4f3640d0ae5d60d10- nginx:1.8sizeBytes:133241734- names:- k8s.gcr.io/kube-proxy@sha256:d5334eee53a3f0ddff4588b25e7e7f5bbd96b9a728eee0ae1a19c0e1b23c29d5- k8s.gcr.io/kube-proxy:v1.21.8sizeBytes:103567283- names:- nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451- nginx:1.7.9sizeBytes:91664166- names:- rancher/fleet@sha256:b83872e82bf2f1b47133e6052823a8854297f974dc0e236142fcec2173b48218- rancher/fleet:v0.3.8sizeBytes:73351324- names:- quay.io/coreos/flannel@sha256:9a296fbb67790659adc3701e287adde3c59803b7fcefe354f1fc482840cdb3d9- quay.io/coreos/flannel:v0.15.1sizeBytes:69516425- names:- quay.io/jetstack/cert-manager-controller@sha256:330f19ed47bdbd34a0c11c5a58ccceead1b118eb29aa7202d374e71003937d48- quay.io/jetstack/cert-manager-controller:v1.5.1sizeBytes:63334645- names:- rancher/gitjob@sha256:6c0ecbe6f566cee572d572689a569aed67661ce7b2a1ec22581821dabc9aad58- rancher/gitjob:v0.1.23sizeBytes:61509831- names:- eipwork/metrics-server@sha256:2a8e43d89e434b6235858444bb0701c44bd03475d2937fdf6831a7bb4ee14240- eipwork/metrics-server:v0.3.7sizeBytes:55367782- names:- quay.io/jetstack/cert-manager-webhook@sha256:45934ab42749e8c90da0726734155374f4ea55d7796246264e7adea87569918a- quay.io/jetstack/cert-manager-webhook:v1.6.1sizeBytes:46625554- names:- quay.io/jetstack/cert-manager-webhook@sha256:d6c8924dc61a2d6e83f21f4bf584ff6b5a8837afe7342a044a90bc3c0f75009a- quay.io/jetstack/cert-manager-webhook:v1.5.1sizeBytes:46396684- names:- quay.io/jetstack/cert-manager-cainjector@sha256:910eb00317ccb8482f39f395027fb40f1ed6a28f834970b5ff66aeb1bb89f8c8- quay.io/jetstack/cert-manager-cainjector:v1.5.1sizeBytes:42243730- names:- quay.io/jetstack/cert-manager-cainjector@sha256:916ef12af73c8a4cbdfb6127d6f513f476f3aeed2447ec7f1a58a95113bda713- quay.io/jetstack/cert-manager-cainjector:v1.6.1sizeBytes:42000784- names:- wangyanglinux/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513- wangyanglinux/myapp:v1sizeBytes:15504557- names:- rancher/mirrored-flannelcni-flannel-cni-plugin@sha256:bfe8f30c74bc6f31eba0cc6659e396dbdd5ab171314ed542cc238ae046660ede- rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0sizeBytes:9031177- names:- k8s.gcr.io/pause@sha256:6c3835cab3980f11b83277305d0d736051c32b17606f5ec59f1dda67c9ba3810- k8s.gcr.io/pause:3.4.1sizeBytes:682696nodeInfo:architecture:amd64bootID:9661796e-a93d-4f48-8999-b80eb2d48cadcontainerRuntimeVersion:docker://20.10.6kernelVersion:3.10.0-1160.el7.x86_64kubeProxyVersion:v1.21.0kubeletVersion:v1.21.0machineID:9cf3ac32ce194bcf946e35b4419afbe4operatingSystem:linuxosImage:CentOS Linux 7 (Core)systemUUID:5979B22F-C64B-4F24-A195-64A08DC3AC84  addresses capacity allocatable conditions 描述了节点的状态，conditons的例子有：\n OutOfDisk：磁盘空间不足，无法运行新的Pod时则为True，否则为False Ready：节点健康且可以接受新的Pod，则为True，否则我False MemoryPressure：内存紧张则为True，否则为False PIDPressure：进程过多则为True，否则为False DiskPressure：磁盘空间紧张则为True，否则为False NetworkUnvailable：网络配置有问题则为True，否则为False  ","description":"","id":35,"section":"notes","tags":null,"title":"02.查看节点的状态","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/02.%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E7%9A%84%E7%8A%B6%E6%80%81/"},{"content":" SADD key member [member ...] SREM key member [member ...] SISMEMBER key member SMISMEMBER key member [member ...] SCARD key SMEMBERS key SCAN key cursor [MATCH pattern] [COUNT count] SMOVE source destination member SPOP key [count] SRANDMEMBER key [count] # 集合操作 SUNION key [key ...] SUNIONSTORE destination key [key ...] SINTER key [key ...] SINTERSTORE destination key [key ...] SDIFF key [key ...] SDIFFSTORE destination key [key ...] SINTERCARD numkeys key [key ...] [LIMIT limit] 数据结构 Set数据结构是Dict字典，字典使用哈希表实现的。Java中的HashSet的内部实现使用的是HashMap，只不过所有的Value都指向了同一个对象。Redis的Set结构也是一样的，它的内部也使用Hash结构，所有的value都指向同一个内部值。\n参考资料  Redis#Set  ","description":"","id":36,"section":"notes","tags":null,"title":"03.Set相关命令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/03.set%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/"},{"content":" 如图打开数据源视图   如图添加一个H2数据源  直接将application.yml中的url填写到URL处，界面会发生变化，将用户名改为和application.yml文件中的一致（我目前不知道这个用户名有什么用）  最后配置一下SQL Dialect就可以愉快的使用ctrl + art + l快捷键了。  参考资料  IDEA配置Database数据源 IDEA 为 sql 文件配置方言 IntelliJ IDEA 如何配置数据源  ","description":"","id":37,"section":"notes","tags":null,"title":"03.实现mapper.xml文件的格式化及去除黄色警告","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%9B%86%E6%88%90mybatis-plus%E5%88%B0springboot%E5%8F%8A%E5%AF%B9idea%E7%9A%84%E9%85%8D%E7%BD%AE/03.%E5%AE%9E%E7%8E%B0mapper.xml%E6%96%87%E4%BB%B6%E7%9A%84%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%8F%8A%E5%8E%BB%E9%99%A4%E9%BB%84%E8%89%B2%E8%AD%A6%E5%91%8A/"},{"content":"需求还是不够硬，还是可以有别的方案替代。\n","description":"","id":38,"section":"notes","tags":null,"title":"03.技术点03：攻克单独编译某个插件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/03.%E6%8A%80%E6%9C%AF%E7%82%B903%E6%94%BB%E5%85%8B%E5%8D%95%E7%8B%AC%E7%BC%96%E8%AF%91%E6%9F%90%E4%B8%AA%E6%8F%92%E4%BB%B6/"},{"content":"在K8S中创建节点时，仅仅是创建了一个描述该节点的API对象。节点API对象创建成功后，K8S将检查该节点是否有效。\n1 2 3 4 5 6 7 8  kind:NodeapiVersion:v1metadata:name:\u0026#34;10.240.79.157\u0026#34;labels:name:\u0026#34;my-first-k8s-node\u0026#34;  K8S在APIServer上创建一个节点对象（节点描述），并且基于metadata.name字段对节点进行健康检查。如果节点组件正在运行，则可以向该节点调度Pod，否则，该节点对象将被忽略，直到节点变为有效状态。\nK8S将保留无效的节点对象，并不断地检查该节点是否有效。除非使用kubectl delete node my-first-k8s-node\n节点控制器 节点控制器是一个负责管理节点的生命周期的K8S组件：\n  节点控制器在注册节点时为节点分配CIDR地址块\n  节点控制器检查节点列表中每一个节点对应的虚拟机是否可用。\n  节点控制器监控节点的健康状态，如果节点不可达（例如节点停机，节点无法再收到来自节点的心跳信号），节点控制器将节点对象的NodeStatus Conditon取值从NodeReady更新为Unknown，然后在等待pod-eviciton-timeout时间后，将节点上的所有Pod从节点驱逐（似乎最新版不是这样实现的，新版的Node描述中不存在pod-eviciton-timeout）。\n 默认40秒未收到心跳，修改NodeStatus Conditon为Unknown 默认pod-eviciton-timeout为5分钟 节点控制器每隔--node-monitor-period秒检查一次节点的状态    ","description":"","id":39,"section":"notes","tags":null,"title":"03.节点相关的知识","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/03.%E8%8A%82%E7%82%B9%E7%9B%B8%E5%85%B3%E7%9A%84%E7%9F%A5%E8%AF%86/"},{"content":" HEXISTS key field HKEYS key HLEN key HSTRLEN key field HVALS key HSCAN key cursor [MATCH pattern] [COUNT count] HSET key field value [field value ...] HSETNX key field value HMSET key field value [field value ...] HDEL key field [field ...] HGET key field HGETALL key HMGET key [field ...] HRANDFIELD key [count [WITHVALUES]] HINCREBY key field increment HINCREBYFLOAT key field increment 数据结构 Hash类型对应的数据结构是两种：ZipList和HashTable。当FieldValue长度较短且个数较少时，使用ZipList，否则使用HashTable。\n参考资料  Redis#Hash  ","description":"","id":40,"section":"notes","tags":null,"title":"04.Hash相关命令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/04.hash%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/"},{"content":"Names 可以通过namespace + name唯一性确定一个RESTFul对象，例如：\n /api/v1/namespaces/{namespace}/pods/{name} 同一个名称空间下，同一类型的对象，可以通过name唯一性确定。如果删除该对象之后，可以再重新创建一个同名对象。以下是暗中资源名称的限制类型：\n  DNS Subdomain Names\n绝大部分资源类型的名称必须符合DNS Subdomain：\n 最长不超过253个字符 必须由小写字母、数字、减号、小数点组成 由字母开始 由字母结束    DNS Label Names\n部分类型的资源名称要求符合DNS Label的命名规则：\n 最长不超过63个字符 必须由小写字母、数字、建好、小数点组成 由字母开始 由字母结束    Path Segment Names\n部分类型的资源要求其名称可以被编码到路径中。换句话说，名称中不能包含.,..,/,%。\n  UIDS 很好理解，不整理了~\n","description":"","id":41,"section":"notes","tags":null,"title":"04.K8S中的Names和UIDS","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/04.k8s%E4%B8%AD%E7%9A%84names%E5%92%8Cuids/"},{"content":" # 阻塞 BZPOPMIN key [key ...] BZPOPMAX key [key ...] BZPOP timeout numkeys key [key ...] MIN|MAX [COUNT count] # 针对分数的操作 ZPOPMIN key min max ZPOPMAX key [count] ZMPOP numkeys key [key ...] ZLEXCOUNT key min max ZADD key [NX|XX] [GT|LT] [CH] [INCR] score member [score member ...] ZCARD key ZCOUNT key min max ZSCAN ZINCREBY key increment member ZSCORE ZMSCORE ZRANGE ZRANGESTORE ZRANGEBYLEX ZREVRANGEBYLEX ZRANGEBYSCORE ZLEXCOUNT key min max # 集合操作 ZINTER numkeys increment member ZINTERCARD destination numkeys key [key ...] ZUNION ZUNIONSTORE ZDIFF numkeys key [key ...] [WITHSCORES] ZDIFFSTORE destination numkeys key [key ...] ZINTERSTORE numkeys key [key ...] [LIMIT limit] 数据结构 ZSet底层使用了两个数据结构：Hash和跳跃表。Hash的作用是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。跳跃表的目的是给元素value排序，根据score的范围获取元素列表。\n参考资料  Redis#SortedSet  ","description":"","id":42,"section":"notes","tags":null,"title":"05.ZSet相关的命令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AC%94%E8%AE%B0/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/05.zset%E7%9B%B8%E5%85%B3%E7%9A%84%E5%91%BD%E4%BB%A4/"},{"content":"当创建一个Service时，Kubernetes为其创建一个对应的DNS条目。该DNS记录的格式为：\u0026lt;service-name\u0026gt;.\u0026lt;namespace-name\u0026gt;.svc.cluster.local。也就是说，如果在容器中只使用\u0026lt;service-name\u0026gt;，其DNS将被解析到同名名称下得Service。\n这个特点在多环境的情况下非常有用，例如将开发环境、测试环境、生产环境部署到不同的名称空间下，应用程序只需要使用\u0026lt;service-name\u0026gt;即可进行服务发现，无需为不同的环境修改配置。如果需要跨名称空间访问服务，则必须使用完整的域名。\n","description":"","id":43,"section":"notes","tags":null,"title":"05.名称空间与DNS","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/05.%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4%E4%B8%8Edns/"},{"content":"写在前面 这次运气非常不好，我用一种非常直观的方式去还原之前的方案，结果一点都不好使，表现上似乎是luci上按钮的指令并没有调到底层的工具，logread甚至看不到任何相关的日志（我还没有掌握调试luci界面的技术），当然最让人崩溃的是整个过程中偶尔会出现虚假的成功，且伴随着整个系统崩溃的情况，这大大误导我的判断，促使我浪费了大量时间分析不成功的原因。\n我其实可以肯定是Luci出了问题，我将之前的成功的方案的/etc目录换到了新实验环境中，新环境所有的功能都是正常的，对比两个环境的/etc目录，发现似乎是一些Luci的触发器在软件包安装后并没有自动创建，所以导致无法响应界面上的按钮。通过移植/etc目录来作为一种方案，是非常的不优雅，我拒绝这种该方案。\n我之前使用的方案使用了如下的软件包，这些包都不是OpenWRT官方提供的，在我初次研究该技术总有博主建议不要使用官方的包，因为官方包的版本太落后了，但是在实验中我对比了软件的版本，发现官方提供的包中的Shadowsocks-libev是最新版本，所以我最终放弃了之前的方案，转而探索官方提供的软件包的方案。\nshadowsocks/openwrt-shadowsocks\nshadowsocks/luci-app-shadowsocks\naa65535/openwrt-dns-forwarder\naa65535/openwrt-dist-luci\n方案的核心思路 核心思路如下：\n 使用ss-redir开启透明代理服务并使用防火墙将所有的流量转到ss-redir暴露出来的端口 使用unbound软件将UDP协议的DNS请求转换成TCP协议，然后请求会通过防火墙转到ss-redir暴露的端口 设置OpenWRT的DNS服务，unbound保留的端口提供唯一的DNS服务  大体思路如上，可能在实现细节上有少许的差异。这套方案其实是我之前方案的翻版，而我之前的方案我应用了很长时间，非常的稳定。\n使用ss-redir开启透明代理服务  执行如下指令安装所需要的软件包，下面的软件包不是都是必须的，只是我已经习惯一并都安装上了：   opkg update opkg install shadowsocks-libev-config opkg install shadowsocks-libev-ss-local opkg install shadowsocks-libev-ss-redir opkg install shadowsocks-libev-ss-rules opkg install shadowsocks-libev-ss-server opkg install shadowsocks-libev-ss-tunnel opkg install luci-app-shadowsocks-libev opkg install luci-i18n-shadowsocks-libev-zh-cn opkg install luci-i18n-base-zh-cn  下载v2ray-plugin插件，放到/usr/bin目录下，且将该插件重命名为v2ray-plugin，并添加执行权限。\n  登录管理页面，进入到Shadowsocks-libev服务，清除所有的本地实例、远端服务器，清除后要保存。\n  创建自己的远端服务器，如下：\n  创建自己的本地实例，如下：  （本地实例的名称和远端服务器的名称最好不要一样，可能会引发一个Bug：保存远端服务器时，创建好的本地实例消失了，保存本地实例时，创建的远端服务器消失）\n测试端口是否开启：  1 2 3 4 5 6  netstat -nltp | grep 12345 # 输出 tcp 0 0 0.0.0.0:12345 0.0.0.0:* LISTEN 7378/ss-redir   此时还无法实现透明代理，需要设置一下转发规则，我的设置如下：   测试透明代理是否设置成功：  1 2 3 4 5 6 7 8 9 10 11 12  # 172.217.24.110为谷歌服务器地址 curl http://172.217.24.110 # 输出 \u0026lt;HTML\u0026gt;\u0026lt;HEAD\u0026gt;\u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html;charset=utf-8\u0026#34;\u0026gt; \u0026lt;TITLE\u0026gt;301 Moved\u0026lt;/TITLE\u0026gt;\u0026lt;/HEAD\u0026gt;\u0026lt;BODY\u0026gt; \u0026lt;H1\u0026gt;301 Moved\u0026lt;/H1\u0026gt; The document has moved \u0026lt;A HREF=\u0026#34;http://www.google.com/\u0026#34;\u0026gt;here\u0026lt;/A\u0026gt;. \u0026lt;/BODY\u0026gt;\u0026lt;/HTML\u0026gt;   使用Unbound将DNS的UDP请求转为TCP请求  安装软件包   opkg install luci-app-unbound opkg install luci-i18n-unbound-zh-cn 配置unbound为手动配置并保存：   选择通过Luci管理界面，或者直接修改/etc/unbound/unbound.conf文件为如下内容。（ubuntu是一个很强大的工具，建议替换前对原配置文件进行备份，方便以后进行研究。）   # The server clause sets the main parameters. server: # whitespace is not necessary, but looks cleaner. # verbosity number, 0 is least verbose. 1 is default. verbosity: 1 # Self jail Unbound with user \u0026quot;unbound\u0026quot; to /var/lib/unbound # The script /etc/init.d/unbound will setup the location username: \u0026quot;unbound\u0026quot; directory: \u0026quot;/var/lib/unbound\u0026quot; chroot: \u0026quot;/var/lib/unbound\u0026quot; # The pid file is created before privleges drop so no concern pidfile: \u0026quot;/var/run/unbound.pid\u0026quot; # no threads and no memory slabs for threads num-threads: 1 msg-cache-slabs: 1 rrset-cache-slabs: 1 infra-cache-slabs: 1 key-cache-slabs: 1 # don't be picky about interfaces but consider your firewall interface: 0.0.0.0 interface: ::0 access-control: 0.0.0.0/0 allow access-control: ::0/0 allow # this limits TCP service but uses less buffers outgoing-num-tcp: 1 incoming-num-tcp: 1 # use somewhat higher port numbers versus possible NAT issue outgoing-port-permit: \u0026quot;10240-65335\u0026quot; # uses less memory but less performance outgoing-range: 60 num-queries-per-thread: 30 # exclude large responses msg-buffer-size: 8192 # tiny memory cache infra-cache-numhosts: 200 msg-cache-size: 100k rrset-cache-size: 100k key-cache-size: 100k neg-cache-size: 10k # gentle on recursion target-fetch-policy: \u0026quot;2 1 0 0 0 0\u0026quot; harden-large-queries: yes harden-short-bufsize: yes port: 5353 tcp-upstream: yes forward-zone: name: \u0026quot;.\u0026quot; forward-addr: 8.8.8.8 forward-addr: 8.8.4.4 forward-first: no （修改后似乎要重启Unbound。）\n设置Dnsmasq  Dnsmasq配置比较简单，我的配置如下：  小结 Unbound的方案惊艳到我了，我明显的感觉出浏览网页的速度被以前快了很多，因祸得福。\n参考资料   在 OpenWrt 上配置 unbound 使用 DNS over TLS\n学习了通过Unbound管理页面配置Unbound的方法，主要学习到了：\n 配置Manual Conf 在界面上应用配置文件    Openwrt架设DNS转发器，解决污染问题_D2O | 重水-程序员宅基地\n我的配置文件就来自这个教程。\n  ","description":"","id":45,"section":"notes","tags":null,"title":"05.新方案：搭建Shadows-libev透明代理","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/05.%E6%96%B0%E6%96%B9%E6%A1%88%E6%90%AD%E5%BB%BAshadows-libev%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86/"},{"content":"  Cloudflare上随便为自己的域名创建一条A记录\n  安装如下软件：\n   opkg update opkg install bind-host opkg install ddns-scripts opkg install ddns-scripts-cloudflare opkg install luci-app-ddns opkg install luci-i18n-ddns-zh-cn 进行如下配置，配置后注意要启动：  配置完成后可以点击一下开启DDNS，这样就可以在Cloudflare上立即看到更新后的IP地址。\n遇到的问题 因为我CloudFlare上配置A记录时，写错了域名，始终配置失败。最后是怎么发现这个问题的呢？我手动执行了ddns脚本执行的指令，发现提示说找不到A记录，然后我开始检查CloudFlare的配置，最后发现了这个问题。\n注意事项  校验设置是否成功，建议是直接查看Cloudflare的面板，其他查看的地方都有延迟，不好判断是否设置成功 密码一栏，应该是Cloudflare的Global API Key，之前忘记记录这个，导致花费了一点时间进行尝试  参考资料  保姆教程 OpenWrt 配置 Cloudflare DDNS 基于CloudFlare的DDNS解析 | 进阶版  ","description":"","id":47,"section":"notes","tags":null,"title":"06.新方案：搭建DDNS","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/06.%E6%96%B0%E6%96%B9%E6%A1%88%E6%90%AD%E5%BB%BAddns/"},{"content":"该笔记中密钥已全部暴漏在公网，请不要尝试直接使用\n（这是第一次使用这个方案，踩坑可不是很充足，所以暂时记录下自己的主要步骤吧，下次遇到问题在丰富这份文档）\n整个搭建的过程是非常顺利的，只是在打开路由端口时出了一些问题，花费了我大量的时间去解决问题。\n核心步骤如下：\n 准备服务端的公钥、私钥，并在OpenWRT上创建WireGuard的接口，并进行配置 准备客户端的公钥、私钥、预分享秘钥，并在OpenWRT上为WireGuard接口增加相应的Peer 安卓手机上安装客户端，并进行配置，进行局域网内测试（可以观察到接口数据包增加） 打开OpenWRT相应的端口，在安卓手机上进行公网环境测试  前提 安装如下软件包：\n opkg update opkg install luci-proto-wireguard opkg install luci-app-wireguard opkg install luci-i18n-wireguard-zh-cn 第一步  创建公钥、私钥   mkdir -p ~/WireGuard/Server cd ~/WireGuard/Server wg genkey | tee privatekey | wg pubkey \u0026gt; publickey 在OpenWRT中创建接口，设置如下项：   Private Key为上一步生成的Key 监听端口选择一个大于1024的值 这个IP相当于设置这个接口下的网段  保存设置，检查22345端口是否开启  第二步  创建公钥、私钥、预分享秘钥  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # HonorX10 mkdir -p ~/WireGuard/HonorX10 cd ~/WireGuard/HonorX10 wg genpsk \u0026gt; sharekey wg genkey | tee privatekey | wg pubkey \u0026gt; publickey # KubernetesHome mkdir -p ~/WireGuard/KubernetesHome cd ~/WireGuard/KubernetesHome wg genpsk \u0026gt; sharekey wg genkey | tee privatekey | wg pubkey \u0026gt; publickey # Test mkdir -p ~/WireGuard/Test cd ~/WireGuard/Test wg genpsk \u0026gt; sharekey wg genkey | tee privatekey | wg pubkey \u0026gt; publickey   在OpenWRT的WireGuard接口中添加该Peer   公钥为客户端的公钥 预分享秘钥为刚才创建的sharekey 允许的IP，可以理解为这个客户端的连接后分配的地址  保存并应用（最好重启整个OpenWRT）  第三步  安卓手机上下载WireGuard，并导入如下配置文件：   [Interface] PrivateKey = KOA1MheOB4h3kGdcP82gYcOS9HJXIgPmzYUW/NLgonU= Address = 192.168.21.31/32 DNS = 192.168.31.1 [Peer] PublicKey = ZK44Ey1LiCOphk50kbhLl8cLgtvpRZCwVSc8FKHwOSY= PresharedKey = ccdv1ug4EDiFYqnzIjzEwxr6/cX4j8+FlXn9uYW2ktk= AllowedIPs = 192.168.31.0/24 Endpoint = \u0026lt;你路由器的IP地址，需要公网可访问\u0026gt;:22345  进行测试  第四步  配置防火墙如下：  安卓手机在公网环境下进行测试  注意事项  开始实验前已经需要确保自己已经配置好了DDNS，且域名可以正确解析到自己的公网IP（除非不用域名测试） 添加的接口是需要配置防火墙的，如果没有VPN，则配置成LAN（我已经在这个上面踩过坑了）。  参考资料  【软路由应用】如何优雅的连接到家里的网络? OpenWrt中使用wireguard教程 OpenWRT 配置 WireGuard 服务端及客户端配置教程  ","description":"","id":49,"section":"notes","tags":null,"title":"07.新方案：搭建Wireguard服务端","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B9%E6%A1%88/07.%E6%96%B0%E6%96%B9%E6%A1%88%E6%90%AD%E5%BB%BAwireguard%E6%9C%8D%E5%8A%A1%E7%AB%AF/"},{"content":"Kubernetes支持两种形式的标签选择器，基于等式的和基于集合的。标签选择器可以包含多个条件，并使用逗号分隔，此时只有满足所有条件的Kubernetes对象才会被选中。\n基于等式的选择方式 可以使用两种操作符==,!=（=不讨论了，增加记忆成本），例如：\n environment = production tier != fronted # 或者用如下的写法 environment = production, tier != fronted 案例（如下案例被调度到包含标签accelerator = nvidia-tesla-p100等节点）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  apiVersion:v1kind:Podmetadata:name:cuda-testspec:containers:- name:cuda-testimage:\u0026#34;k8s.gcr.io/cuda-vector-add:v0.1\u0026#34;resources:limits:nvidia.com/gpu:1nodeSelector:accelerator:nvidia-tesla-p100  基于集合的选择方式 可以使用的操作符包括：in，notin，exists，例如：\n # 包含environment标签，且environment的取值在productin、qa environment in (production, qa) tier notin (frontend, backend) # 选择包含partition标签的对象（第一次听说） partition # 选择不包含partition标签的对象（第一次听说） !partition 可以组合多个选择器，用逗号分隔，相当于AND操作符，例如：\n partition,environment notin (qa) 在API中使用标签选择器 两种方式在kubectl和watch命令中使用：\n kubectl get pods -l environment=production,tier=frontend # 我比较喜欢这种 kubectl get pods -l 'environment in (production),tier in (frontend)' 在Kubernetes对象中使用标签选择器  service通过spec.selector字段来选择一组Pod，并将服务请求转发到选中的Pod上。 Job、Deployment、ReplicaSet、DaemonSet同时支持基于等式的选择方式和基于集合的选择方式  1 2 3 4 5 6 7 8  selector:matchLabels:component:redismatchExpressions:- {key: tier, operator: In, values:[cache]}- {key: environment, operator: NotIn, values:[dev]}  matchLabels是一个{key,value}组成的map。map中的一个 {key,value} 条目相当于matchExpressions中的一个元素，其key为map的key，operator为In，values数组则只包含value一个元素。\nmatchExpression等价于基于集合的选择方式，支持的operator有In、NotIn、Exists和DoesNotExist。当 operator为In或NotIn时，values数组不能为空。所有的选择条件都以AND的形式合并计算，即所有的条件都满足才可以算是匹配。\n（这么说对象使用标签选择器的时候，其实是不支持基于等式的标签选择器的）\n","description":"","id":50,"section":"notes","tags":null,"title":"07.理解标签选择器","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/07.%E7%90%86%E8%A7%A3%E6%A0%87%E7%AD%BE%E9%80%89%E6%8B%A9%E5%99%A8/"},{"content":"语法如下：\n kubectl get pods --field-selector status.phase==Running 字段选择器本质上是一个filter，默认情况下，没有添加selector/filter时，代表着指定资源类型的所有对象被选中。\n支持的操作符有==，!=，可以指定多个字段选择器，用逗号分隔。字段选择器可以跨资源种类使用。\n kubectl get services --all-namespaces --field-selector metadata.namespace!=default kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default ","description":"","id":52,"section":"notes","tags":null,"title":"08.理解字段选择器","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/08.%E7%90%86%E8%A7%A3%E5%AD%97%E6%AE%B5%E9%80%89%E6%8B%A9%E5%99%A8/"},{"content":"imagePullPolicy和image tag可能的取值可能会影响到kubelet如何拉取镜像：\n IfNotPresent：仅在节点上没有该镜像时，从镜像仓库抓取 Always：每次启动Pod时，从镜像仓库抓取 Never：假设本地存在该镜像，并且不会尝试从镜像仓库抓取镜像 不填写：镜像tag为:latest或者未填写，则同Always每次启动Pod时，从镜像仓库抓取 不填写：镜像tag已填写但不是:latest，则同IfNotPresent仅在节点上没有该镜像时，从镜像仓库抓取  生产实践中，我们应该在每次重新Build镜像并推送镜像时是以当前时间戳为Tag，所以以上的描述应该都是准确的。\n那么从这个角度讲，我们的image字段到底该如何处理了？我认为应该模板化，由调用着每次调用时决定该字段的取值，而不是写死在配置文件中（生产上应该也是如此实践的）。\n","description":"","id":53,"section":"notes","tags":null,"title":"09.容器拉取镜像规则","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/09.%E5%AE%B9%E5%99%A8%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E8%A7%84%E5%88%99/"},{"content":" 文本输入框（前后端支持非空、长度、整数、小数、小数位数、数范围校验） 单选下拉框（前后端支持非空、值是否属于正确范围校验） 多选下拉框（前后端支持非空、值是否属于正确范围校验） 二级联动下拉框（前后端支持非空、值是否属于正确范围校验） 三级联动下拉框（前后端支持非空、值是否属于正确范围校验）  ","description":"","id":54,"section":"notes","tags":null,"title":"1. 组件选择","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/1.-%E7%BB%84%E4%BB%B6%E9%80%89%E6%8B%A9/"},{"content":"使用篇 ==\u0026gt;Go 如果项目相关信息已经在syncd上设置好了，参考该文档，可以快速的完成项目的部署。\n项目管理篇 ==\u0026gt;Go 如果项目未在syncd上设置，参考该文档，可以快速在syncd上添加一个gitlab中的项目\n项目管理篇2 ==\u0026gt;Go 对项目管理篇 的中使用的脚本的更新，里面的脚本全部都是线上正在利用的脚本，并对脚本进行了一定的优化，将易变的参数调整到脚本头部，便于修改\nsyncd部署篇 ==\u0026gt;Go 如果机器中没有syncd，参考该文档，可以快速在机器中搭建出syncd的环境\n注意事项： 我们的使用方案有些地方看上去不是很直观，这是因为环境所迫，不能自由的使用各种技术，必须绕开各种限制造成的。\n","description":"","id":55,"section":"notes","tags":null,"title":"1.syncd的使用方案","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/syncd/1.syncd%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%A1%88/"},{"content":" id languages jsonb # 关联到名次表中的wordId，用来做国际化的 language  id:1000 language: { \u0026quot;cn\u0026quot;: \u0026quot;中国\u0026quot;, \u0026quot;us\u0026quot;: \u0026quot;美国\u0026quot; } id:1001 language: { \u0026quot;cn\u0026quot;:\u0026quot;这是一条帮助信息\u0026quot;, \u0026quot;us\u0026quot;:\u0026quot;这是一条帮助信息\u0026quot;, } 对于名词表的一些想法 我突然对名词表有些想法了，两个方面：一是，我需要它支持500个字符长度的句子；二是，我不想帮助翻译人员减轻任何工作了，我在插入这张表的时候不进行任何查询了，我会直接插入。\n我做的这些改动完全是模拟了我们在游戏开发中的处理方案，我想了想，这应该是最正确的做法了，搞的太复杂，是完全没有必要的。\n如果用户真的提出了他不想为多条相同的记录做多次国际化，我其实也是有办法的哦。我可以开发一个专门处理国际化的页面，将所有内容完全一致的记录聚合在一起，形成记录到记录IDs的map，用户修改一条，所有的都会跟着改。最终我们的目的还是达成了，哈哈。\n另外，对于国际化，一般都是我们提供名词表，公司统一委托翻译机构进行翻译，翻译完成后我们在使用新的表（Excel方案），之后有新的名词，我们提交增量数据到翻译机构就可以了。我们这个应该也是一样的，所以在名词表插入数据时，我觉得真的不必担心插入了多条相同内容的数据。\n","description":"","id":56,"section":"notes","tags":null,"title":"1.名词表设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1/1.%E5%90%8D%E8%AF%8D%E8%A1%A8%E8%AE%BE%E8%AE%A1/"},{"content":"关于表设计部分，我已经在数据源表中讨论过了。\n","description":"","id":57,"section":"notes","tags":null,"title":"1.数据源详细设计说明","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1%E8%AF%B4%E6%98%8E/1.%E6%95%B0%E6%8D%AE%E6%BA%90%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1%E8%AF%B4%E6%98%8E/"},{"content":"表单列表页 页面功能  创建：打开表单设计器页，设计一张新的表单 按表单名称查询：按照名称查找表单。 按属性查询：按照名称查找表单（开发需要用到）。 按数据源查询：按照名称查找表单（开发需要用到）。 按检查器查询：按照名称查找表单（开发需要用到）。  记录功能  编辑：打开表单设计器页，对表单进行重新设计。 测试：渲染出一张表单，用户可以进行填写，点击提交后，会提交大校验接口，完成校验后，直接返回校验结果。  记录字段 id、表单名称、创建者、创建时间、修改者、修改时间\n说明 目前就单纯的展示已经开发的表单，并提供编辑和测试入口。\n未来会新增的功能：\n 与我们目前的系统进行对接，确保在需要的时候能获取指定的表单设计数据（具体方案还未设计）  ","description":"","id":60,"section":"notes","tags":null,"title":"1.表单管理页设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E9%A1%B5%E9%9D%A2%E8%AE%BE%E8%AE%A1/1.%E8%A1%A8%E5%8D%95%E7%AE%A1%E7%90%86%E9%A1%B5%E8%AE%BE%E8%AE%A1/"},{"content":"使用postStart和preStop的案例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  apiVersion:v1kind:Podmetadata:name:lifecycle-demospec:containers:- name:lifecycle-demo-containerimage:nginxlifecycle:postStart:exec:command:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;echo Hello from the postStart handler \u0026gt; /usr/share/message\u0026#34;]preStop:exec:command:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;nginx -s quit; while killall -0 nginx; do sleep 1; done\u0026#34;]  相关实验代码如下：\n1 2 3 4 5 6 7 8  kubectl apply -f lifecycle-demo.yaml kubectl get pod lifecycle-demo kubectl exec -it lifecycle-demo -- /bin/bash # 在容器内执行 cat /usr/share/message   注意事项：\n Kubernetes在容器启动后立刻发送postStart事件，并不确保postStart事件处理程序在容器的EntryPoint之前执行 postStart事件处理程序相对于容器中的进程来说是异步的 Kubernetes在管理容器时，将一直等到postStart事件处理程序结束之后，才会将容器的状态标记为Running Kubernetes在决定关闭容器时，立刻发送preStop事件，并且，将一直等到preStop事件处理程序结束或者Pod 的--grace-period超时，才删除容器。  小结 其实相关技术我可能用的会比较少，我目前并没有使用postStart和preStop的需求。\n","description":"","id":61,"section":"notes","tags":null,"title":"10.postStart和preStop","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/10.poststart%E5%92%8Cprestop/"},{"content":"Pod为其成员容器提供了两种类型的共享资料：网络和存储。\n网络 每一个Pod被分配一个独立的IP地址。Pod中的所有容器共享一个网络名称空间：\n 同一个Pod中的所有容器 IP 地址都相同 同一个Pod中的不同容器不能使用相同的端口，否则会导致端口冲突 同一个Pod中的不同容器可以通过localhost:port进行通信 同一个Pod中的不同容器可以通过使用常规的进程间通信手段，例如SystemV semaphores或者POSIX共享内存（这个不太熟悉）  存储 Pod中可以定义一组共享的数据卷。Pod中所有的容器都可以访问这些共享数据卷，以便共享数据。Pod中数据卷的数据也可以存储持久化的数据，使得容器在重启后仍然可以访问到之前存入到数据卷中的数据。\n","description":"","id":62,"section":"notes","tags":null,"title":"11.Pod提供的两种类型的共享资源","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/11.pod%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%85%B1%E4%BA%AB%E8%B5%84%E6%BA%90/"},{"content":"Pod的状态 Pod的状态如下：\n  Pending：Kubernetes已经创建并确认该Pod。此时可能有两种情况：\n Pod还未完成调度（例如没有合适的节点） 正在从docker registry下载镜像    Running：该Pod已经被绑定到一个节点，并且该Pod所有的容器都已经成功创建。其中至少有一个容器正在运行，或者正在启动/重启\n  Succeeded：Pod中的所有容器都已经成功终止，并且不会再被重启\n  Failed：Pod中的所有容器都已经终止，至少一个容器终止于失败状态：容器的进程退出码不是0，或者被系统 kill\n  Unknown：因为某些未知原因，不能确定Pod的状态，通常的原因是master与Pod所在节点之间的通信故障\n  容器的状态   Waiting：容器的初始状态。处于Waiting状态的容器，仍然有对应的操作在执行，例如：拉取镜像、应用 Secrets等。\n  Running：容器处于正常运行的状态。容器进入Running状态之后，如果指定了postStart hook，该钩子将被执行。\n  Terminated：容器处于结束运行的状态。容器进入Terminated状态之前，如果指定了preStop hook，该钩子将被执行。\n  ","description":"","id":63,"section":"notes","tags":null,"title":"12.Pod及容器的状态","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/12.pod%E5%8F%8A%E5%AE%B9%E5%99%A8%E7%9A%84%E7%8A%B6%E6%80%81/"},{"content":"探针是指Kubelet周期性地检查容器的状况，有三种类型的探针：\n ExecAction：在容器内执行一个指定的命令。如果该命令的退出状态码为0，则成功 TCPSocketAction：探测容器的指定TCP端口，如果该端口处于open状态，则成功 HTTPGetAction：探测容器指定端口/路径上的HTTP Get请求，如果HTTP响应状态码在200到400（不包含400）之间，则成功  探针有三种可能的结果：\n Success：容器通过检测 Failure：容器未通过检测 Unknown：检测执行失败，此时kubelet不做任何处理  Kubelet可以在两种情况下对运行中的容器执行Probe：\n  就绪检查：确定容器是否已经就绪并接收服务请求。如果就绪检查失败，kubernetes将该Pod的IP地址从所有匹配的Service的资源池中移除掉。\n  健康检查：确定容器是否正在运行。如果健康检查失败，kubelete将结束该容器，并根据重启策略确定是否重启该容器。\n  合适使用健康检查和就绪检查：\n  如果容器中的进程在碰到问题时可以自己crash，就不需要执行健康检查；kubelet 可以自动的根据Pod的重启策略执行对应的动作\n  如果您希望在容器的进程无响应后，将容器kill掉并重启，则指定一个健康检查liveness probe，并同时指定 重启策略为Always或者OnFailure\n  如果您想在探测Pod确实就绪之后才向其分发服务请求，请指定一个就绪检查readiness probe。此时，就绪检查的内容可能和健康检查相同。就绪检查适合如下几类容器：\n 初始化时需要加载大量的数据、配置文件 启动时需要执行迁移任务 其他    对此的理解：\n容器的进程在出现问题时自己退出了，则我们可以不使用健康检查。SpringBoot项目，Redis、Datasource等出现问题时，是不会自动退出进程的，所以我们需要使用健康检查。\n使用健康检查时，当判断到容器此时无响应时，应该只会将容器标记为死亡（或者其他的东西），并不会进行一些其他的处理。稍后，控制器发现这个容器被标记为死亡了，然后根据其重启策略对其进行处理。（我自己猜的，也不知道正确不正确）\n","description":"","id":64,"section":"notes","tags":null,"title":"13.容器的检查","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/13.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%A3%80%E6%9F%A5/"},{"content":"以“声明”的方式管理Pod和ReplicaSet，其本质是将一些特定场景的一系列运维步骤固化下来，以便快速准确无误的执行。\nDeployment为我们确定了几种运维场景：\n  创建Deployment：创建Deployment后，Deployment控制器将立刻创建一个ReplicaSet副本集，并由 ReplicaSet创建所需要的Pod。\n  更新Deployment：更新Deployment中Pod的定义（例如，发布新版本的容器镜像）。此时 Deployment 控制器将为该Deployment创建一个新的ReplicaSet副本集，并且逐步在新的副本集中创建Pod，在旧的副本集中删除 Pod，以达到滚动更新的效果。\n  回滚Deployment：回滚到一个早期Deployment版本。\n  伸缩Deployment：水平扩展Deployment，以便支持更大的负载，或者水平收缩Deployment，以便节省服务器资源。\n  暂停和继续Deployment\n  查看Deployment状态\n  清理策略\n  金丝雀发布\n  ","description":"","id":65,"section":"notes","tags":null,"title":"14.另一个角度理解声明式管理","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/14.%E5%8F%A6%E4%B8%80%E4%B8%AA%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3%E5%A3%B0%E6%98%8E%E5%BC%8F%E7%AE%A1%E7%90%86/"},{"content":"创建Deployment  使用如下配置文件创建资源：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentlabels:app:nginxspec:replicas:3selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80  可以为该命令增加--record选项，此时kubectl会将kubectl apply -f deployment1.yaml --record写入Deployment的注解kubernetes.io/change-cause中。这样，这样可以在将来就可以回顾某一个 Deployment 版本变化的原因。\n我实验了--record选项，其表现如下，我觉得意义不大：\n1 2 3 4 5 6 7 8  metadata:annotations:deployment.kubernetes.io/revision:\u0026#34;1\u0026#34;kubectl.kubernetes.io/last-applied-configuration:|{\u0026#34;apiVersion\u0026#34;:\u0026#34;apps/v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Deployment\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{\u0026#34;kubernetes.io/change-cause\u0026#34;:\u0026#34;kubectl apply --filename=deployment1.yaml --record=true\u0026#34;},\u0026#34;labels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;nginx\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;nginx-deployment\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;replicas\u0026#34;:3,\u0026#34;selector\u0026#34;:{\u0026#34;matchLabels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;nginx\u0026#34;}},\u0026#34;template\u0026#34;:{\u0026#34;metadata\u0026#34;:{\u0026#34;labels\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;nginx\u0026#34;}},\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;image\u0026#34;:\u0026#34;nginx:1.7.9\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;nginx\u0026#34;,\u0026#34;ports\u0026#34;:[{\u0026#34;containerPort\u0026#34;:80}]}]}}}}kubernetes.io/change-cause:kubectl apply --filename=deployment1.yaml --record=true  执行如下基本操作，查看deployment资料  1 2 3 4 5 6 7 8 9 10 11  # 查看创建情况 kubectl get deployments kubectl get rs kubectl get pods --show-labels # 查看发布状态 kubectl rollout status deployment/nginx-deployment kubectl rollout status deployment.v1.apps/nginx-deployment   更新Deployment 当且仅当Deployment的Pod Template字段中的内容发生变更时（例如标签、容器的镜像），Deployment的rollout将被触发。\n 修改容器镜像  1 2 3 4 5 6 7  # 这条指令我现在还不理解 kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 # 编辑Deployment，修改image从nginx:1.7.9到nginx:1.9.1 kubectl edit deployment.v1.apps/nginx-deployment   查看发布更新的状态  1 2 3  kubectl rollout status deployment.v1.apps/nginx-deployment   查看各个资源的状态  1 2 3 4 5  kubectl get deployments kubectl get rs kubectl get pods   回滚Deployment 默认情况下，kubernetes将保存Deployment的所有更新历史，可以设定revision history limit来确定保存的历史版本数量。\n 模拟滚动更新操作失误（将1.9.1写成了1.91）：  1 2 3 4 5 6 7 8 9 10  kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 # 查看发布状态 kubectl rollout status deployment.v1.apps/nginx-deployment # 查看各个资源 kubectl get rs kubectl get pods   检查Deployment的更新历史   kubectl rollout history deployment.v1.apps/nginx-deployment 回滚到前一个版本或指定某个版本  1 2 3 4  kubectl rollout undo deployment.v1.apps/nginx-deployment kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2   检查资源状态   kubectl get deployment nginx-deployment kubectl describe deployment nginx-deployment 关于CHANGE-CAUSE：执行kubectl rollout history deployment.v1.apps/nginx-deployment时，返回结果如下：\n deployment.apps/nginx-deployment REVISION CHANGE-CAUSE 2 kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true 4 kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.7.9 --record=true 5 kubectl deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.7.9 --record=true CHANGE-CAUSE列是该revision创建时从Deployment的kubernetes.io/change-cause注解拷贝而来，可以通过如下方式制定CHANGE-CAUSE：\n  为Deployment增加注解：kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=\u0026quot;image updated to 1.9.1\u0026quot;\n  执行 kubectl apply 命令时，增加--record选项\n  手动编辑Deployment的metadata.annotation信息\n  （我为什么要记录CHANGE-CAUSE列呢，因为我不知道生产实践中有没有人利用这个字段记录一些版本信息。）\n伸缩Deployment  执行指令如下：   kubectl scale deployment.v1.apps/nginx-deployment --replicas=10 如果集群启用了HPA（这个还不太熟悉），则执行以下指令可以基于CPU的利用率在一个最大和最小的区间自动伸缩：   kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80 暂停和继续Deployment 可以先暂停Deployment，然后再触发一个或多个更新，最后在恢复该Deployment。这种做法使得您可以在暂停时对Deployment做多次更新，而无需触发不必要的滚动更新。\n执行如下指令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # 暂停Deployment kubectl rollout pause deployment.v1.apps/nginx-deployment # 编辑Deployment kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 # 可以看到尚未生成新的Deployment版本 kubectl rollout history deployment.v1.apps/nginx-deployment # 可以查看到没有新的滚动更新开始执行 kubectl get rs # 再次更新 kubectl set resources deployment.v1.apps/nginx-deployment -c=nginx --limits=cpu=200m,memory=512Mi # 查看Deployment定义，确保Deployment已被修改 kubectl describe deployment nginx-deployment # 恢复Deployment kubectl rollout resume deployment.v1.apps/nginx-deployment   不能回滚一个已暂停的Deployment，除非先恢复这个Deployment。\n","description":"","id":66,"section":"notes","tags":null,"title":"15.Deployment相关的实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/15.deployment%E7%9B%B8%E5%85%B3%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"可以通过下图理解容器组、容器、挂载点、数据卷、存储介质（NFS、PVC、ConfigMap）等几个概念之间的关系：\n 一个容器组可以包含多个数据卷、多个容器 一个容器通过挂载点决定某一个数据卷被挂载到容器中的什么路径 不同类型的数据卷对应不同的存储介质（NFS、PVC、ConfigMap）  ","description":"","id":67,"section":"notes","tags":null,"title":"16.Kubernetes存储中的一些概念","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/16.kubernetes%E5%AD%98%E5%82%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/"},{"content":"Kubernetes明确的区分了UserAccount（我没有看到一个叫做UserAccount的资源）和ServiceAccount的概念，原因如下：\n  UserAccount的使用者是用户，ServiceAccount的使用者是运行在Pod中的进程。\n  UserAccount应该是全局的，用户名在集群范围内（跨名称空间）必须唯一。ServiceAccount的名称在名称空间内唯一即可\n  通常，集群的UserAccount可能是从企业的数据库同步过来（如何操作？想尝试去找一款UserAccount管理工具），在那里，创建新的UserAccount需要特殊的权限，并且受复杂的业务流程管控。ServiceAccount的创建则更加轻量级，允许集群的用户为特定的任务创建ServiceAccount（最小权限的原则）。\n  对用户和ServiceAccount的审计过程可能会不一样（这儿指的是准入控制么）\n  一个复杂系统中，可能为不同的组件配置不同的ServiceAccount。由于ServiceAccount可以临时创建，并且在名称空间内唯一，这种配置信息是可以移植的\n  Service Account Admission Controller Admission Controller是ApiServer的一部分，它在Pod创建或者更新时，对Pod执行一些修改。此控制器激活时（默认处于激活状态），当Pod被创建或修改时，该控制器将执行如下动作：\n 如果Pod未设置ServiceAccount，将ServiceAccount设置为default 如果Pod设置了ServiceAccount，确保Pod引用的ServiceAccount存在，否则拒绝创建或者修改Pod 如果Pod不包含任何ImagePullSecrets，则ServiceAccount中的ImagePullSecrets将被添加到Pod上（不是很熟悉） 为Pod添加一个Volume（其中包含了访问APIServer的token）（由TokenController自动创建的） 为Pod中的每一个容器添加一个VolumeSource，并挂载到路径/var/run/secrets/kubernetes.io/serviceaccount（不是很熟悉）  Token Controller TokenController作为controller-manager的一部分运行。以异步的方式执行如下动作：\n  监听ServiceAccount的创建，并创建一个对应的Secret以允许访问APIServer\n  监听ServiceAccount的删除，并删除所有对应的ServiceAccountToken Secrets\n  监听Secret的添加，确保其引用的ServiceAccount以存在，并在需要时向Secret添加Token（两者的关系我还不太熟悉呀）\n  监听Secret的删除，并在需要的情况下将对应ServiceAccount中对Secret的引用也删除掉\n  启动controller-manager时，必须通过--service-account-private-key-file参数，向TokenController传递一个ServiceAccount Privatekey文件。该PrivateKey将用来为生成的ServiceAccount Token签名。类似的，也必须为通过--service-account-key-file将其对应的PublicKey传递给kube-apiserver。该PublicKey将被用来在认证时验证Token。（这个道理很好理解）\nService Account Controller Service Account Controller管理了名称空间中的ServiceAccount，并确保每一个当前有效的名称空间中都存在一个名为default的ServiceAccount。\n其他知识：创建额外的API Token 目前这部分知识还没有系统化，所以我只是先记录一下，然后等相关知识形成知识面。\n控制器确保每个ServiceAccount都有一个包含ApiToken的Secret。如需为ServiceAccount创建额外的ApiToken，可以创建一个类型为ServiceAccountToken的Secret，并在注解中引用对应的ServiceAccount，此时，控制器将为其创建一个新的Token：\n1 2 3 4 5 6 7 8 9 10 11 12 13  { \u0026#34;kind\u0026#34;: \u0026#34;Secret\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysecretname\u0026#34;, \u0026#34;annotations\u0026#34;: { \u0026#34;kubernetes.io/service-account.name\u0026#34;: \u0026#34;myserviceaccount\u0026#34; } }, \u0026#34;type\u0026#34;: \u0026#34;kubernetes.io/service-account-token\u0026#34; }   相关指令如下：\n1 2 3 4 5 6 7  kubectl create -f ./secret.json kubectl delete -f ./secret.json kubectl delete secret mysecretname kubectl describe secret mysecretname   研究一下创建命名空间时自动创建的ServiceAccount及Secret。创建命名空间时会自动创建一个名为default的ServiceAccount，按照前面所说的，控制器还会确保每个ServiceAccount都包含一个ApiToken的Secret。可以使用如下指令查看这些资源：\n kubectl get sa -n nfs kubectl get secrets -n nfs ","description":"","id":68,"section":"notes","tags":null,"title":"17.User Account和Service Account","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/17.user-account%E5%92%8Cservice-account/"},{"content":"在Kubernetes里，Volume存在明确的生命周期（与包含该数据卷的容器组相同）。因此，Volume的生命周期比同一容器组中任意容器的生命周期要更长，不管容器重启了多少次，数据都能被保留下来。当然，如果容器组退出了，数据卷也就自然退出了。此时，根据容器组所使用的Volume型不同，数据可能随数据卷的退出而删除，也可能被真正持久化，并在下次容器组重启时仍然可以使用。\n从根本上来说，一个Volume仅仅是一个可被容器组中的容器访问的文件目录（也许其中包含一些数据文件）。这个目录是怎么来的，取决于该数据卷的类型（不同类型的数据卷使用不同的存储介质）。\n容器中的一个进程所看到（可访问）的文件系统是由容器的Docker镜像和容器所挂载的数据卷共同组成的。Docker镜像将被首先加载到该容器的文件系统，任何数据卷都被在此之后挂载到指定的路径上。Volume不能被挂载到其他数据卷上，或者通过引用其他数据卷。同一个容器组的不同容器各自独立地挂载数据卷，即同一个容器组中的两个容器可以将同一个数据卷挂载到各自不同的路径上（我好像对这个挂载原理还是不太理解）。\n（我之前没有从这些角度看过Volume）\n","description":"","id":69,"section":"notes","tags":null,"title":"18.Volume的生命周期","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/18.volume%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"content":"StorageClass存储类用于描述集群中可以提供的存储的类型。不同的存储类可能对应着不同的：\n 服务等级 备份策略 集群管理员自定义的策略  Kubernetes自身对存储类所代表的含义并无感知，由集群管理员自行约定。\n这儿展示一个我自己定义的StorageClass：\n1 2 3 4 5 6 7 8 9 10  apiVersion:storage.k8s.io/v1kind:StorageClassmetadata:name:nfs-client-provisionernamespace:nfsprovisioner:fuseim.pri/ifsparameters:archiveOnDelete:\u0026#34;false\u0026#34;  存储类的种类 Kubernetes提供19种存储类Provisioner，但是绝大多数与具体的云环境相关，如AWSElasticBlockStore/AzureFile/AzureDisk/GCEPersistentDisk等（这部分知识可以拓展视野）。\n回收策略 由StorageClass动态创建的PersistentVolume将使用StorageClass中定义的回收策略。可选项有：\n 回收后删除Delete 回收后保留Retain  同一StorageClass中，手动创建的PersistentVolume，将使用创建时手动指定的回收策略。\n存储卷绑定模式 StorageClass根据存储卷绑定模式的选项，确定何时执行存储卷和存储卷声明的绑定，何时执行动态存储卷提供（动态创建存储卷）（这个翻译的好奇怪啊）。可选项有：\n  即刻绑定Immediate\n存储卷声明创建后，立刻动态创建存储卷并将其绑定到存储卷声明。\n  首次使用时绑定 WaitForFirstConsumer\n直到存储卷声明第一次被容器组使用时，才创建存储卷，并将其绑定到存储卷声明。\n  ","description":"","id":70,"section":"notes","tags":null,"title":"19.StorageClass","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/19.storageclass/"},{"content":"使用篇分为两个部分：  在本机准备需要更新到线上源码 在线上环境中使用syncd完成部署  在本机准备源码：   前提：你已经建立好了gitlab仓库，而且你的仓库已经完成了初始化\n  前提：你已经拥有一个gitlab的账号，且你的账号是可以操作目标项目的\n  前提：你的电脑中已经安装了git工具，且你的ssh秘钥已经添加到了gitlab仓库中（这一步不是必须的，你可以使用http协议推送代码，但是每次都需要输入账号密码）\n  git commit -am\u0026quot;描述信息，描述你这次更新做了啥\u0026quot;：该操作会将你的改动推送到本地仓库\n  git push：该操作会将你本地仓库的改动推送到远程仓库\n  git tag \u0026ldquo;Tag 名字\u0026rdquo;：该操作会为当前的版本打上一个tag\n  git push \u0026ndash;tags：该操作会将你创建的tag推送到远程仓库\n  svn commit：提交一下代码（这一步不是必须的，但是即使操作，可以避免svn版本管理工具的脏数据）\n   建议：4-8步操作，建议使用始终由一个人操作，因为我们的项目同时使用了git和svn，且svn管理了git的本地仓库的一些信息。如果两个人操作的话，会造成git本地仓库中信息的冲突，这些冲突时很难解决的，貌似都是二进制的数据\n 在线上环境完成部署：   前提：你需要一个链接到公司内网的vpn账号\n  ssh 10.82.34.134机器，使用下面指令完成vpn链接，链接的过程中需要输入账号和密码（该步是为了解决我们在线上环境中搭的gitlab无法在本地推送代码带来的问题）：\n  1  sudo openconnect --proxy=http://10.82.32.147:8080 ssl-vpn.pc.com.cn:31041 --servercert sha256:9bd4309d7f40392bbb8a7773b037587f21b0e9076b93f8fee325ef01ae3d023f   用堡垒机上的浏览器登录：10.82.34.134:8878，进入syncd的部署页面，如图选择你要部署的项目，点击“填写上线单”  如图填写上线单，其中最重要的是tag名称，该处必须为你用git工具打的tag，且该tag必须推送到远程仓库。完成后添加确定  完成后会自动跳转到如下页面，点击右侧的操作，在下拉框中选择上线  点击构建，构建完成后，点击部署。该过程请注意观察日志消息，可以方便你定位各种问题   不要忘了关闭10.82.34.134上的vpn，也不要在任何地方记录你vpn的账号密码！！！\n  不要忘了关闭10.82.34.134上的vpn，也不要在任何地方记录你vpn的账号密码！！！\n  不要忘了关闭10.82.34.134上的vpn，也不要在任何地方记录你vpn的账号密码！！！\n  总结：  git工具对不常用的人来说会比较陌生，但是我们实际上只使用了其远程仓库和tag的功能，还是比较简单的 上线操作最好始终由一个人操作，我指的是多次上线都是一个人操作，因为双版本管理工具，的确会弄的人很头疼 部署时需要挂vpn，主要还是为了syncd从我们公司内部的gitlab上拉取代码 一定要注意vpn的使用安全！！！一定要注意vpn的使用安全！！！一定要注意vpn的使用安全！！！  ","description":"","id":71,"section":"notes","tags":null,"title":"2.syncd使用篇","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/syncd/2.syncd%E4%BD%BF%E7%94%A8%E7%AF%87/"},{"content":"数据源列表页 页面功能  添加数据源：打开表单设计器页，设计一张新的表单 按数据源名称+语言进行搜索：语言默认为当前页面语言，用户可以指定其他语言。  记录功能  编辑：打开数据源编辑页，对数据源进行修改。 测试：打开数据源测试也，对数据源进行测试。 查看文档：打开数据源文档页，查看数据源的文档  记录字段 datasourceId、datasourceName、type、url、returnType、requestParams、requestBody、useCount\n数据源创建、编辑页 页面功能  创建 数据源名称 数据源类型 数据源返回类型 数据源请求地址 数据源请求参数 数据源请求体  数据源测试页 页面功能  数据源各个参数填写框：这个地方会显示数据源配置了的所有参数，用户填写参数，即可以发送请求 测试按钮：点击测试按钮后，页面会按照数据源的设置发送一个请求。 测试结果显示区域：用于显示发送的请求的返回结果。  数据源文档页 查看数据源的describe字段，使用markdown进行渲染。\n","description":"","id":74,"section":"notes","tags":null,"title":"2.数据源管理页设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E9%A1%B5%E9%9D%A2%E8%AE%BE%E8%AE%A1/2.%E6%95%B0%E6%8D%AE%E6%BA%90%E7%AE%A1%E7%90%86%E9%A1%B5%E8%AE%BE%E8%AE%A1/"},{"content":" id wordId # 关联到名次表中的wordId，用来做国际化的 requestUrl # 数据源请求的Url requestBody # 请求体 returnType # 目前仅支持StringList、IntegerList、BooleanList、CombinedList，StringListMap、IntegerListMap、BooleanListMap、CombinedListMap、Custom describe # 该字段使用markdown语法，主要是开发人员用于为returnType为Custom的数据源编写文档（数据源管理页面会呈现出来） requestBody的格式是怎样的 requestBody原本是设计在requestParams字段中的，因为不想同时支持Get请求和Post请求，故要求所有的请求都为Post。于是废除了requestParams字段。既然废除了这个字段，requestBody应该代替其存在，并只需要实现其功能（我知道requestBody可以很复杂，但是我不想这么设计）\n故requestBody有如下结构：\n { \u0026quot;\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;\u0026quot;: \u0026quot;Boolean\u0026quot;, \u0026quot;\u0026quot;: \u0026quot;Integer\u0026quot; } 对数组、对象的支持，我暂时不不考虑的，但是我很清楚的知道，我们的这套系统是可以非常简单的实现这个的。 wordId字段如何理解 我们不确定表单设计器、数据源管理是否只是国内用户使用。所以我们必须考虑国际化的问题。我解决国际化的问题还是通过名词表（我们在游戏行业中就是使用的这种方案，感觉很简单，但是很强大）。所以，我没有在数据库中直接存在datasourceName字段，而是存储了worldId。但是我可以很明确的告诉你，用户在添加一个表单的时候，是有数据源名称这个字段的，且这个字段就是存在datasourceName字段里的。\n我会直接往名词表查一条记录。 下面展示的是名词表的设计，及相关记录的样式，具体的查询SQL我就不呈现了： ![2021-05-16-10-51-20](https://junjie2018sz.oss-cn-shenzhen.aliyuncs.com/images/2021-05-16-10-51-20.png) id:1000\nlanguage:\n{\n\u0026ldquo;cn\u0026rdquo;: \u0026ldquo;中国\u0026rdquo;,\n\u0026ldquo;us\u0026rdquo;: \u0026ldquo;美国\u0026rdquo;\n}\n ~~~名词表很简单，我不会开文档单独说明了，~~~值得一提的是每增加对一个国家的支持，我们就需要为所有记录的language字段中增加一个国家。 思路已经清晰了，那我们的接口如何出数据了？先想清楚我们会在哪里出数据： 1. 数据源管理页的list接口 2. 表单设计器页为组件绑定数据源时的list接口（其实就是和上面一个接口） 3. 数据源编辑页 这个地方我也不想讲的太细了，需要记住的是，这一套动态表单的所有接口我们都要求用户传递language值，有了这个值，我们完全可以在返回的数据源接口中，完成worldId到datasourceName的转换。 ## returnType为何要设计的这么复杂 为什么returnType要设计的这么复杂呢？因为我想在表单设计器中实现一些静态检查。 如何理解这个静态检查呢？我先举一个例子，组件需要一个返回值类型为BooleanList的数据源，拿到这个数据源后，组件不会去判断是否为BooleanList，它会直接遍历每个值，然后进行if判断。 如果我们不支持BooleanList、不支持在表单设计时进行的静态检查，用户在设计表单的时候，就可以将任意一个返回值为List的数据源绑定到该组件上。那么当这个组件运行的时候，它还是会假设自己获取的是一个BooleanList，如果这个时候进行了if判断，那么组件的行为完全可能是错误的。即使我们的组件检查了数据源返回的List是不是一个BooleanList，结果发现不是，又该怎么办，终止提供服务么（实际上我个人是比较推崇在拥有静态检查后，仍然检查是否为BooleanList，防止开发人员直接改库，造成组件行为错误问题）。这样做，其实就是典型的将静态检查挪到了运行时检查，只是在我们的场景中没有测试的高覆盖率测试，而是真正的表单用户来帮我们检查。 ## ReturnType中Custome需要注意的问题 为什么会有这种类型的存在，显然是为了支持高级组件的数据源需求。有的组件可能想一次性扒拉下来所有的数据，然后自己缓存起来，进行处理，比如在一个组件内实现三级联动，我们就是使用Custom类型实现对这种需求的支撑。 有个问题提前讨论一下，数据源这个东西的RequestBody一定需要指定么？显然是不需要的啊，如果一个组件高度定制，就是那种前后端手拉手开发出来的组件，他们也没打算让其他人用。前端要的就是数据源提供一个url，甚至数据源都不需要，直接写死在组件的代码中，这个时候数据源有意义么，数据源的参数有意义么，没有意义的。 但是，有些问题必须要搞明白，一旦你的代码组件化了，放入到了组件库中，我们就没有办法控制用户在哪块使用你的组件。我是不会做任何设计来提供这种限制效果的（我未来最多做一个租户间的限制），我觉得违背了我的初心，没有任何意义。用户今天可能在一个表单中使用了你的组件，明天又到另一个组件中去使用你的组件。你的组件需要确保对表单的上下文没有任何依赖，你不能从表单上下文中获取任何值。当然，如果你有需求的化，可以考虑在组件的params区域声明你的需求，让用户给你绑定一个context中的数据。 ## 能不能不过度设计，而是依靠高覆盖的测试 动态表单是产品、运营人员实时使用的，使用后将直接在用户端生效，测试无法及时接入。所以，表单设计器进行的必要的静态检查是一定需要的。 ","description":"","id":75,"section":"notes","tags":null,"title":"2.数据源表设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1/2.%E6%95%B0%E6%8D%AE%E6%BA%90%E8%A1%A8%E8%AE%BE%E8%AE%A1/"},{"content":" 支持单人、多人一起玩 支持游戏记录查看  ","description":"","id":76,"section":"notes","tags":null,"title":"2.游戏大厅","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E8%BF%9E%E8%BF%9E%E7%9C%8B%E8%81%94%E6%9C%BA%E7%89%88/2.%E6%B8%B8%E6%88%8F%E5%A4%A7%E5%8E%85/"},{"content":"PersistentVolume和PersistentVolumeClaim如何实现关注点分离 这个只是用一个和传统场景进行对比的场景来讨论PV和PVC如何实现关注点分离的。并非讨论其原理。\n我们可以导出名称空间中应用程序的配置到一个YAML文件，然后在新的名称空间导入该YAML文件。如果应用程序直接使用nfs类型的数据卷，则该nfs的server和path配置随应用程序一起导出到YAML文件中（我还没有使用过nfs类型的存储卷），到新的名称空间导入的应用程序还是对应原来的nfs配置（除非导入后手工修改nfs数据卷的server/path参数）（不排除有人就是有这个需求）。\n如果应用程序使用PersistentVolumeClaim声明该应用需要使用一个存储卷，导出成YAML后，可以等到在新的名称空间再导入该YAML时，再决定应该使用什么类型的PersistentVolume以及对应的参数。（新的名称空间中，可能使用cephfs或glusterfs，而不是nfs）（从这个角度看，PV是命名空间资源，但是PV其实是集群资源，这样，这个案例其实不能很好的说明PV和PVC如何实现关注点分离的）\n通过PersistentVolume和PersistentVolumeClaim，Kubernetes分离了提供存储和使用存储着两个关注点：\n  PersistentVolumeClaim必须定义在与应用程序相同的名称空间中，关注应用程序如何使用存储，通常由应用程序管理员或开发人员负责\n  PersistentVolume只能定义在集群层面，关注集群如何提供存储，通常由集群管理员或者运维人员负责\n  理解PV和PVC PersistentVolume是集群中的一块存储空间，由集群管理员管理、或者由StorageClass自动管理。PV和Node一样，是集群中的资源（Kubernetes集群由存储资源和计算资源组成）。\nPersistentVolumeClaim是一种类型的Volume（这一句有点难以理解），PersistentVolumeClaim引用的PersistentVolume有自己的生命周期，该生命周期独立于任何使用它的容器组。PersistentVolume描述了如何提供存储的细节信息（NFS、cephfs等存储的具体参数）。\nPersistentVolumeClaim代表用户使用存储的请求。Pod容器组消耗Node计算资源，PVC存储卷声明消耗 PersistentVolume存储资源。Pod容器组可以请求特定数量的计算资源（CPU / 内存）；PVC可以请求特定大小/特定访问模式（只能被单节点读写/可被多节点只读/可被多节点读写）的存储资源。\n根据应用程序的特点不同，其所需要的存储资源也存在不同的要求，例如读写性能等。集群管理员必须能够提供关于 PersistentVolume的更多选择，无需用户关心存储卷背后的实现细节。为了解决这个问题，Kubernetes引入了 StorageClass的概念\n理解PV与PVC之间的关系   PersistentVolume是集群中的存储资源，通常由集群管理员创建和管理\n  StorageClass用于对PersistentVolume进行分类，如果正确配置，StorageClass也可以根据PersistentVolumeClaim的请求动态创建PersistentVolume（所以我们可以设置声明时是立即创建还是延迟创建）\n  PersistentVolumeClaim是使用该资源的请求，通常由应用程序提出请求，并指定对应的StorageClass和需求的空间大小\n  PersistentVolumeClaim可以做为数据卷的一种，被挂载到容器组/容器中使用（这个我是第一次听说）\n  ","description":"","id":77,"section":"notes","tags":null,"title":"20.PersistentVolume","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/20.persistentvolume/"},{"content":"有时候我们需要在同一个 Pod 的不同容器间共享数据卷。使用volumeMounts.subPath属性，可以使容器在挂载数据卷时指向数据卷内部的一个子路径，而不是直接指向数据卷的根路径。\n如下是一个subPath字段应用和持久卷声明应用非常好的案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  apiVersion:v1kind:Podmetadata:name:my-lamp-sitespec:containers:- name:mysqlimage:mysqlenv:- name:MYSQL_ROOT_PASSWORDvalue:\u0026#34;rootpasswd\u0026#34;volumeMounts:- mountPath:/var/lib/mysqlname:site-datasubPath:mysqlreadOnly:false- name:phpimage:php:7.0-apachevolumeMounts:- mountPath:/var/www/htmlname:site-datasubPath:htmlreadOnly:falsevolumes:- name:site-datapersistentVolumeClaim:claimName:my-lamp-site-data  通过环境变量指定数据卷内子路径 为什么需要该技术呢？因为我们有时想让subPath的文件夹名为Pod的名称，而Pod又是由RS管理的，所以在创建资源时我们并不知道其名称。\n给一份参考代码吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  apiVersion:v1kind:Podmetadata:name:pod1spec:containers:- name:container1env:- name:POD_NAMEvalueFrom:fieldRef:apiVersion:v1fieldPath:metadata.nameimage:busyboxcommand:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while [ true ]; do echo \u0026#39;Hello\u0026#39;; sleep 10; done | tee -a /logs/hello.txt\u0026#34;]volumeMounts:- name:workdir1mountPath:/logssubPathExpr:$(POD_NAME)readOnly:falserestartPolicy:Nevervolumes:- name:workdir1hostPath:path:/var/log/pods  注意：subPath和subPathExpr字段不能同时使用。\n","description":"","id":78,"section":"notes","tags":null,"title":"21.数据卷的挂载","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/21.%E6%95%B0%E6%8D%AE%E5%8D%B7%E7%9A%84%E6%8C%82%E8%BD%BD/"},{"content":"StatefulSet中得Pod具备一个唯一标识，该标识由如下部分组成：\n 序号 稳定的网络标识 稳定的存储  序号 假设一个StatefulSet的副本数为N，其中的每一个Pod都会被分配一个序号，序号的取值范围从0到N - 1，并且该序号在StatefulSet内部是唯一的。\n稳定的网络ID   StatefulSet中Pod的hostname格式为$(StatefulSet name)-$(Pod 序号)。上面的例子将要创建三个 Pod，其名称分别为： web-0，web-1，web-2。\n  StatefulSet可以使用Headless Service来控制其Pod所在的域。该域的格式为`$(service name).$(namespace).svc.cluster.local ，其中“cluster.local”是集群的域。（什么叫做控制pod所在的域啊？）\n  StatefulSet中每一个Pod将被分配一个dnsName，格式为：$(podName).$(所在域名)\n  稳定的存储 Kubernetes为每一个VolumeClaimTemplate创建一份PersistentVolume。在上面的例子中，每一个 Pod都将由StorageClass——my-storage-class为其创建一个1Gib大小的PersistentVolume。当Pod被调度（或重新调度）到一个节点上，其挂载点将挂载该存储卷声明（关联到该 PersistentVolume）。\n","description":"","id":79,"section":"notes","tags":null,"title":"22.StatefulSet中Pod的标识","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/22.statefulset%E4%B8%ADpod%E7%9A%84%E6%A0%87%E8%AF%86/"},{"content":"关于Service需要了解的知识：\n  Kubernetes将为Service分配一个IP地址，供Service Proxy使用（这个我不了解）\n  Kubernetes将不断扫描符合该Selector的Pod，并将最新的结果更新到与Service同名my-servie的Endpoint对象中（对Endpoint还不是太熟悉）\n  Pod的另一种，Port可能被赋予了一个名字，您可以在Service的targetPort 字段引用这些名字，而不是直接写端口号。这种做法可以使得您在将来修改后端程序监听的端口号，而无需影响到前端程序（因为不需要修改Service，而拥有不同name的Pod应该都可以正确接受转发的流量）。\n  Service的默认传输协议是TCP，您也可以使用其他支持的传输协议。\n  Kubernetes Service中，可以定义多个端口，不同的端口可以使用相同或不同的传输协议。\n  其他知识：\nService从自己的IP地址和port端口接受请求，并将请求映射到符合条件的Pod的targetPort。为了方便，默认targetPort的取值与port字段相同。（实际上就是一条lvs转发记录）\n高级的应用 Service通常用于提供对Kubernetes Pod的访问，但是您也可以将其用于任何其他形式的后端。例如：\n 想要在生产环境中使用一个Kubernetes外部的数据库集群，在测试环境中使用Kubernetes内部的数据库 想要将Service指向另一个名称空间中的Service，或者另一个Kubernetes集群中的Service 正在将程序迁移到Kubernetes，但是根据迁移路径，只将一部分后端程序运行在Kubernetes中  在上述这些情况下，可以定义一个没有Pod Selector的Service：\n1 2 3 4 5 6 7 8 9 10 11  apiVersion:v1kind:Servicemetadata:name:my-servicespec:ports:- protocol:TCPport:80targetPort:9376  因为该Service没有selector，相应的Endpoint对象就无法自动创建。可以手动创建一个Endpoint，以便该Service映射到后端服务真实的IP地址和端口：\n1 2 3 4 5 6 7 8 9 10 11  apiVersion:v1kind:Endpointsmetadata:name:my-servicesubsets:- addresses:- ip:192.0.2.42ports:- port:9376  对于Service的访问者来说，Service是否有label selector都是一样的。\n注意事项：\n  Endpoint中的IP地址不可以是loopback（127.0.0.0/8 IPv4 或 ::1/128 IPv6），或link-local（169.254.0.0/16 IPv4、224.0.0.0/24 IPv4 或 fe80::/64 IPv6）\n  Endpoint中的IP地址不可以是集群中其他Service的ClusterIP\n  Service原理 Kubernetes集群中每个节点都运行了一个kube-proxy，负责为Service提供虚拟IP访问。\nIptables代理模式：\n  kube-proxy监听kubernetes master以获得添加和移除Service/Endpoint的事件\n  kube-proxy在其所在的节点上为每一个Service安装iptable规则\n  iptables将发送到Service的ClusterIP/Port的请求重定向到Service的后端Pod上\n 对于Service中的每一个Endpoint，kube-proxy安装一个iptable规则 默认情况下，kube-proxy随机选择一个Service的后端Pod    IPVS代码模式：\n  kube-proxy监听kubernetes master以获得添加和移除Service/Endpoint的事件\n  kube-proxy根据监听到的事件，调用netlink接口，创建LPVS规则，并且将Service/Endpoint的变化同步到IPVS规则中\n  当访问一个Service时，IPVS将请求重定向到后端POD\n  多端口的Service Service对象中定义多个端口时，必须为每个端口定义一个名字：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  apiVersion:v1kind:Servicemetadata:name:my-servicespec:selector:app:MyAppports:- name:httpprotocol:TCPport:80targetPort:9376- name:httpsprotocol:TCPport:443targetPort:9377  使用自定义的IP地址 创建Service时，如果指定spec.cluserIp字段，可以使用自定义的ClusterIP地址。使用到自定义IP地址的场景：\n 想要重用某个已经存在的DNS条目（不理解） 遗留系统是通过IP地址寻址，且很难改造（不存在说K8S中的项目还有写死IP地址的情况吧）  服务发现 K8S支持两种主要的服务发现模式：\n 环境变量 DNS  环境变量 kubelet查找有效的Service，并针对每一个Service，向其所在节点的Pod注入一组环境变量。支持的环境变量有：\n Docker links兼容的环境变量（不理解这个） {SERVICE}_SERVICE_HOST和{SVCNAME}_SERVICE_PROT  ServiceName被转换成大写 小数点被转换成下滑线    案例：\n REDIS_MASTER_SERVICE_HOST=10.0.0.11 REDIS_MASTER_SERVICE_PORT=6379 REDIS_MASTER_PORT=tcp://10.0.0.11:6379 REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379 REDIS_MASTER_PORT_6379_TCP_PROTO=tcp REDIS_MASTER_PORT_6379_TCP_PORT=6379 REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11 我无法理解这种基于环境变量的服务发现方式，这样不会导致后加入的服务不会被发现么？\nDNS CoreDNS监听Kubernetes API上创建和删除Service的事件，并为每一个Service创建一条DNS记录。\n 需要结合CoreDNS、LVPS理解一波了，不然容易混乱：CoreDNS完成的是ServiceName到ServiceIp的转换，待完成了这个转换过程后，Pod就知道往哪个IP发送消息了。LVPS完成的是ServiceIp到PodId的转换，本质上，这个请求从宿主机发出时，就被路由到了目标机器上。\n Kubernetes同样支持DNS SRV记录，用于查找一个命名的端口。假如my-service.my-ns有一个TCP名为http的端口，则可以使用nslookup _http._tcp.my-service.my-ns发现该Service的IP地址及端口。（有点意思，第一次听说，哈哈。）\n对于ExternalName类型的Service，只能通过DNS的方式进行服务发现（我对ExternalName类型的Service的理解为：就是手动指定Endpoint的Service）。\nHeadless Services HeadlessService不提供负载均衡的特性，也没有自己的IP地址，创建HeadlessService时，只需要指定spec.clusterIP为None。\nHeadlessService可以用于对接其他形式的服务发现机制，无需与Kubernetes的实现绑定。对于HeadlessService而言：\n 没有ClusterIP kube-proxy不处理这类Service kubernetes不提供负载均衡或代理支持  DNS的配置方式取决于该Service是否配置了Selector：\n  配置了Selector\nEndpointController创建Endpoints记录，并修改DNS配置，使其直接返回指定Selector选取的Pod的IP地址（为什么要这样设计了，有什么目的么）。\n  没有配置Selector\nEndpoints Controller不创建Endpoints记录。DNS服务器返回如下结果中得一种：\n 对ExternalName类型的Service，返回CNAMNE记录 对于其他类型的Service，返回与Service同名的EndPoints的A记录     我好想理解错ExternalName类型，我以为不设置Selector，然后手动创建一个Endpoints就是ExternalName，看样子不是这样的。\n 虚拟IP的实现 Iptables方案 假设Service的ClusterIp为10.0.0.1，port为1234，targetPort为4567\nService创建后，kube-proxy设定了一系列的iptables规则，这些规则是可以将虚拟IP映射到per-Service的规则。per-Service规则进一步链接到per-Endpoint规则，并最终将网络请求重定向到后端Pod（使用destination-NAT）。\n当一个客户端连接到该Service的虚拟Ip地址时，iptables的规则被触发。一个后端Pod将被选中（基于session affinity或者随机选择），且网络报文被重定向到该后端Pod。\n使用node-port或load-balancer类型的Service时，以上的代理处理过程是相同的。\nIPVS IPVS的设计是基于in-kernel hash table执行负载均衡，因此，使用LPVS的kube-proxy在Service数量较多的情况仍然能保持好的性能。同时，基于LPVS的kube-proxy可以使用更复杂的负载均衡算法（最少连接数、基于地址的，基于权重的等）\n","description":"","id":80,"section":"notes","tags":null,"title":"23.Service","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/23.service/"},{"content":"ExternalName类型的Service映射到一个外部的DNSName，而不是一个pod label selector。可通过spec.externalName字段指定外部DNSName。\n1 2 3 4 5 6 7 8 9 10  apiVersion:v1kind:Servicemetadata:name:my-servicenamespace:prodspec:type:ExternalNameexternalName:my.database.example.com  执行nslookup my-service.prod.svc.cluster.local指令时，集群的DNS服务将返回一个CNAME记录，其对应的值为my.database.example.com。\n访问my-service与访问其他类型的Service相比，网络请求的转发发生在DNSLevel，而不是使用proxy（理解为各个服务再次请求一次DNS么）。\nExternal Ip （我对这部分的应用不是很理解，所以暂时不处理了）\n区分ExternalName、HeadlessService、无SelectorLabel 再不区分，会将这些概念混在一起的。\nExternalName是Service中的一种类型，其特点在于从CoreDNS请求该Service时，返回的是一个CNAME记录，且这个记录的值就是externalName字段记录的。我觉得一个应用点是，搞个ExternalName，然后将这个ExternalName设置成一些第三方的API接口地址，这样，我们代码里就可以使用ServiceName了，但是感觉这种应用根本就不是痛点。\nHeadlessService就是将ClusterIp字段设置为空。\n无SelectorLabel就是不选择目标的Pod，由用户手动创建Endpoint。\n","description":"","id":81,"section":"notes","tags":null,"title":"24.ExternalName","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/24.externalname/"},{"content":"我印象中我有擦尝试修改容器的/etc/hosts文件，从而到到某个目标，但是失败了。现在才知道，原来容器的/etc/hosts文件是被kubelet管理起来了。\n配置Pod的 /etc/hosts\n","description":"","id":82,"section":"notes","tags":null,"title":"25.配置Pod的hosts文件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/25.%E9%85%8D%E7%BD%AEpod%E7%9A%84hosts%E6%96%87%E4%BB%B6/"},{"content":"CNI意为容器网络接口，它是一种标准的设计，为了让用户在容器创建或销毁时都能够更容易地配置容器网络。目前主要有几款流行的CNI插件：Flannel、Calico、Weave和Canal（技术上是多个插件的组合），这些插件既可以确保满足Kubernetes的网络要求，又能为Kubernetes集群管理员提供他们所需的某些特定的网络功能（我们会需要什么样的特定网络功能呢？）。\n背景 容器网络是容器选择连接到其他容器、主机和外部网络（如Internet）的机制。容器的Runtime提供了各种网络模式，每种模式都会产生不同的体验。\n例如，Docker默认情况下可以为容器配置以下网络：\n none：将容器添加到一个容器专门的网络堆栈中，没有对外连接。 host：将容器添加到主机的网络堆栈中，没有隔离。 default bridge：默认网络模式。每个容器可以通过IP地址相互连接。 自定义网桥：用户定义的网桥，具有更多的灵活性、隔离性和其他便利功能。  Docker还可以让用户通过其他驱动程序和插件，来配置更高级的网络（包括多主机覆盖网络）（不懂）\nCNI的初衷是创建一个框架，用于在配置或销毁容器时动态配置适当的网络配置和资源。\n插件负责为接口配置和管理IP地址，并且通常提供与IP管理、每个容器的IP分配、以及多主机连接相关的功能。容器运行时会调用网络插件，从而在容器启动时分配IP地址并配置网络，并在删除容器时再次调用它以清理这些资源。\n运行时或协调器决定了容器应该加入哪个网络以及它需要调用哪个插件。然后，插件会将接口添加到容器网络命名空间中，作为一个veth对的一侧。接着，它会在主机上进行更改，包括将veth的其他部分连接到网桥。再之后，它会通过调用单独的IPAM（IP地址管理）插件来分配IP地址并设置路由。\n在Kubernetes中，kubelet可以在适当的时间调用它找到的插件，来为通过kubelet启动的pod进行自动的网络配置。\n","description":"","id":83,"section":"notes","tags":null,"title":"26.网络插件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%AC%94%E8%AE%B0/kubernetes%E6%95%99%E7%A8%8B/26.%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/"},{"content":"项目管理脚本请参考线上脚本，线上新增了一些内容以适应更多的部署场景：  新增内容以实现单机多实例部署，且单机多实例时确保日志文件不会相互印象 新增内容以实现同步文件时，完成旧目录中，在新目录中不存在的文件（保证正在使用的目录与最新的发布目录完全同步） 新增内容保证二次部署时不会洗掉第一次部署时产生的日志文件  项目管理篇主要分为三部分：  将现有的项目添加到syncd中 syncd部署项目的底层细节 该脚本的一些思路  将现有的项目添加到syncd中：   前提：你的有一个gitlab仓库，且在部署syncd的机器上，是可以通过git ssh访问到你的仓库的\n  前提：你需要建立部署syncd的机器，与部署各个项目的机器之间的ssh免密登录（单向的，只需要master机器，能免密ssh到各个slave机器）\n  先添加集群，这一步很简单，就只是随便设计一个名字而已\n  为集群添加机器，这一步也很简单，看图就会  添加项目，这一步很简单，操作一下就会了（项目空间不是百分百要创建的，有现成的就用现成的就好）  新增项目，该步比较简单   填写项目信息，这儿有很多细节处需要注意：\n 仓库地址，就填写你gitlab上的仓库 上线模式选择Tag上线，切记！！！ 线上集群选择你中意的集群 用户填写分配的机器的用户（这儿有点坑，我们拿到的机子是有两个用户的，所以在设计集群的时候一定要规避这个问题） 目录及之后的部署前执行的命令、部署后执行的命令是有一定的关联的，所以我单写一步，详细说明这个    目录、部署前、部署后的运行命令如何填写（想知道原理，请看原理部分）：   目录（该处的值一定要与下一步的syncd_deploy_path的值是相同的）：  1  /home/zdmprd/deploy    部署前（一定要注意zdmprd，我这儿其实设计的有问题，不应该放在某个用户的家目录下，导致用户不一样的时候这个地方还要相应的修改）：  1 2 3  syncd_deploy_path=\u0026#34;/home/zdmprd/deploy\u0026#34; \\  \u0026amp;\u0026amp; rm -rf $syncd_deploy_path \\  \u0026amp;\u0026amp; mkdir $syncd_deploy_path    部署后（注意syncd_deploy_path的值与module_name的值，在我们目前的项目中，就这两个值会发生变化）：  1 2 3 4 5 6 7 8 9  syncd_deploy_path=\u0026#34;/home/zdmprd/deploy\u0026#34; \\  \u0026amp;\u0026amp; module_name=\u0026#34;hwb-ranking-cron\u0026#34; \\  \u0026amp;\u0026amp; version=\u0026#34;1.0-SNAPSHOT\u0026#34; \\  \u0026amp;\u0026amp; platform_base=\u0026#34;/home/zdmprd/deploy_true\u0026#34; \\  \u0026amp;\u0026amp; platform_home=$platform_base/$module_name \\  \u0026amp;\u0026amp; mkdir -p $platform_home \\  \u0026amp;\u0026amp; rsync -avz $syncd_deploy_path/ $platform_home \\  \u0026amp;\u0026amp; cd $platform_home \\  \u0026amp;\u0026amp; sudo sh/start_service.sh $module_name $version $platform_home   完成这些信息的填写后，点击确定，还有最后一步我们需要填写如何构建的脚本，构建脚本如何写，如何改请看第10步：  构建设置如何填写：   构建脚本（注意module_name及package_base中的用户名，这些都是可能会发生改变的点，切记切记切记）：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  module_name=\u0026#34;hwb-ranking-cron\u0026#34; package_base=\u0026#34;/home/zdmprd/DeployTools/package\u0026#34; package_path=$package_base/$module_name cd ${env_workspace} mvn package -Dmaven.test.skip=true # 如果master上存放的构建后项目目录结构的文件夹不存在则创建它 if [ ! -d $package_path ];then cp -r $package_base/template/ $package_path fi rsync -avz $module_name/target/lib $package_path rsync -avz $module_name/target/config $package_path rsync -avx $module_name/target/*.jar $package_path cd $package_path tar -zcvf ${env_pack_file} *   完成这些，就将一个项目添加到了syncd中，具体如何使用，请参考：使用篇 ==\u0026gt;Go  ","description":"","id":84,"section":"notes","tags":null,"title":"3.syncd项目管理篇","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/syncd/3.syncd%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E7%AF%87/"},{"content":" id: wordId # 组件名称，国际化后得到componentName outputs jsonb # 当前组件有哪些输出，基本上一个文本框就算一个输出 params jsonb # 当前组件自己决定怎么使用这些参数，支持传递常量值、context中的值 datasources josnb # 当前组件需要哪些数据源 helpInfoWordId # 组件级别的帮助信息 describe # 该字段使用markdown语法，主要用于表述该组件的文档 outputs字段如何设计的 我目前设计的是，组件中一个文本框就代表一个outputs，在表单设计器中，outputs必须绑定到属性上，后端存储表单设计数据时也会进行该项检查。我组件设计时参考了一些金数据，我也想提供组件级和字段级别的帮助信息，所以output的结构如下：\n { outputs: [{ \u0026quot;outputName\u0026quot;:\u0026quot;output1\u0026quot;, \u0026quot;outputType\u0026quot;:\u0026quot;\u0026quot;, # 支持String、Integer、Boolean \u0026quot;helpWordId\u0026quot;:\u0026quot;xxxId\u0026quot; }] } outputName是参数级别的东西，我不考虑其国际化了，但是帮助信息还是需要支持国际化的，所以我使用了helpWordId，这些都是我存储的结构，我返回给前端的时候，还是会根据language替换成相应的提示信息。 我考虑了一段时间后，决定增加outputType类型字段，output是组件当前上下文中重要的数据，当output绑定了属性后，属性会成为表单上下文中重要的数据，这些上下文中的数据会应用到自己即其他组件的params、datasouce parms区域。这些区域都要求都要求进行数据类型检查。 params字段怎么用 我在调研金数据的时候，我发现金数据的部分组件的右侧设计底部都有一排小小的checkBox来配置一些组件的细微行为，如下图所示：\n我觉得这个是有意义的，所以我也提供了params，我们暂时不会提供金数据那种非常友好的操作小界面，而且说明部分一般都是通过组件库中的文档进行说明的。\n另外，这个params更有意义的地方在于：它可以绑定context中的值，组件从而可以通过它实现组件间的联动。\nparams应该是尽量提供默认值的，如果组件强烈需要将context中的值绑定到自己的params中，从而减少组件对表单上下文环境的猜测，我们应该需要强制用户填写这个参数的。故params的配置如下：\n { params:[{ \u0026quot;paramName\u0026quot;:\u0026quot;param1\u0026quot;, \u0026quot;defaultValue\u0026quot;:\u0026quot;13\u0026quot;, \u0026quot;type\u0026quot;:\u0026quot;integer\u0026quot;, # 目前这个地方支持的值有：Integer、String、Boolean（表单设计器需要支持对此的检查） \u0026quot;require\u0026quot;:\u0026quot;true\u0026quot; # 是否必填项（表单设计器需要支持对此的检查） \u0026quot;tips\u0026quot;:\u0026quot;wordId\u0026quot; # 提示信息（未来我们也想实现金数据的那种效果） \u0026quot;exploreLocation\u0026quot;:\u0026quot;params\u0026quot; # 暴露在哪个区域，这个也是为了实现金数据而设计的字段，值可以为params（参数区）、config（配置区），目前组件设计中，右侧还没有配置区，配置区就是类似金数据的右下角 }] } params字段在填值的时候，是支持通过下拉框从表单上下文、组件上下文中选取值的，但是它又同时支持用户直接填一些常量值，我没有想好这块输入框怎么设计，可以交给产品，这个属于体验级别的东西了。\ndatasources字段设计  { datasources:[{ \u0026quot;datasourceName\u0026quot;:\u0026quot;xxx数据源\u0026quot;, \u0026quot;returnType\u0026quot;:\u0026quot;StringList\u0026quot;, }] } 看到这块的结构，我自己也在怀疑组件声明数据源就这么简单，能满足高级的需求吗？先看看我自己的左右互搏吧。\n\u0026raquo;\u0026gt;以下内容仅做讨论，不推荐该方案\u0026laquo;\u0026lt;\n假如啊，我不要用户去给我搞什么绑定，假如啊，组件在调用数据源的时候，一定是按照组件喜欢的方式去调用的，行不行。我先告诉你，肯定是可以的，我动态表单的第一套设计就是这个方案。我给你构思下完整的场景，组件直接通过如下的伪代码的方式声明自己要的数据源具备的特点：\n datasources: datasource1: param1 String param2 Boolean param3 Integer datasource2: param1 String param2 Boolean param3 Integer 当在表单设计器中，选择数据源的时候，小小的选择框就会通过这些条件去我们的数据源库查找所有符合条件的数据源，然后用户选择一个添加进组件编辑区域。置于要用到的context参数，我们在params区域完成绑定。置于绑定的这些context如何被传递到了数据源，完全是由组件自己决定的。\n为什么我放弃了这个方案了？~~~你们感觉这个像什么，像不像方法的覆盖，组件中定义的是一个抽象方法，组件中绑定的是一个具体的实现。既然像方法的覆盖，那么它们的问题就是（我不从技术上讨论了，意义不大）~~~因为组件本身还是高度定制的啊，用这种方案实现的一个下拉框组件，怎么去实现组件间的联动呢。难道我很还需要去开发一个下拉框组件（二级）、下拉框组件（三级），这让用户怎么去理解啊？核心的原因就是调用数据源的方式，被组件给自己控制了，那数据源本身就没有高复用的可能性了。\n\u0026raquo;\u0026gt;讨论完毕\u0026laquo;\u0026lt;\n在新设计中，我就只想简单点，主要数据源的返回值都是一致的，我就可以为这个组件提供数据。在这种场景下，我还考虑了两个问题：\n 数据源很清晰的知道我自己需要哪些参数，能够返回那种类型的数据结构给到用户。而且你要你提供了这些参数，那么就一定可以拿到相应的数据。 组件很清晰的知道数据源该怎么使用，它根本就不需要数据源的概念，它只需要一个url而已。  这个我在数据源设计中也讨论过，这个就是高通用的组件和高度定制的组件。我其实建议就走两个极端，我们要么开发高通用的，要么开发高定制的。更极端一点，开发高定制的时候，我们甚至不需要声明数据源，前后端开发直接将url写在在组件里好了。如果组件需要表单上下文的参数，就通过params区域获取。\n如果，未来我们有需求，将某个组件给通用化，我们可以一步一步的做，我们可以先将url写到数据源中，从而实现替换不同的数据源，使这个组件出不同的数据。然后将params区域，原本用来获取context中的数据的param放到数据源的reqeustBody中，这样更优雅一些。接下拉，我们将检查源也从硬编码的组件中给剔除来。其实要做的工作真的没有多少。\n我是建议这部分在整个系统使用中慢慢总结，慢慢优化的。\n","description":"","id":88,"section":"notes","tags":null,"title":"3.组件表设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1/3.%E7%BB%84%E4%BB%B6%E8%A1%A8%E8%AE%BE%E8%AE%A1/"},{"content":"组件：\n组件输出声明：\noutput\n组件参数声明： parm1: pram2: pram3: 数据源声明：  组件声明数据源部分：\nJList abc\nJList abc(queryA, queryB, queryC)\n如何解释这两种不同的声明方法：\n  组件声明数据源时，未向数据源传递参数，那么就意味着它只会调用数据源的get方法，所以用户需要确保该数据源是支持不传递参数就可以获取到数据的。如果数据源需要传递参数，那么就必须由用户完成参数的绑定工作。\n  组件在声明的时候，意味着数据源内部调用时该数据源时，会传递queryA=xxx，queryB=xxx，queryC=xxx到数据源。如果用户提供的数据源正好包含这三个参数，那么会自动完成绑定。如果用户提供的数据源参数名并不为这三个，则需要由用户完成数据源中参数到组件声明的参数的绑定。不允许数据源的参数多余或者少于声明的参数数。（这部分已经属于高度定制的内容了，本质上不是服务于普通用户的）\n    要求数据源具备queryA参数、queryB参数、queryC参数。且参数名也需要一致。如果数据源的正好有这三个参数，则可以正确的完成\n  Base组件声明自己需要数据源，并不会给数据源传递任何参数，需要有\n组件数据源声明部分：组件声明自己需要什么数据源，\n就拿一个三级联动组件来说。我们该如何给他绑定数据源？是绑定三个数据源么，\n这个问题的答案是，你想将这个三级联动组件作为基础组件，还是作为高度定制的组件。如果是高级定制组件的话，数据源的设计本身就应该和组件的需求契合度非常高，所以我们没有必要去讨论数据源是怎么样的，这个完全是看组件的设计者。\n为定制组件配置数据源是怎么一个场景。\n","description":"","id":89,"section":"notes","tags":null,"title":"3.组件配置项详细说明","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1%E8%AF%B4%E6%98%8E/3.%E7%BB%84%E4%BB%B6%E9%85%8D%E7%BD%AE%E9%A1%B9%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E/"},{"content":" 部署前指令（直接copy过去，改username参数的值）：  1 2 3 4  username=zdmprd \\  \u0026amp;\u0026amp; syncd_deploy_path=\u0026#34;/home/$username/deploy\u0026#34; \\  \u0026amp;\u0026amp; rm -rf $syncd_deploy_path \\  \u0026amp;\u0026amp; mkdir $syncd_deploy_path   部署后执行（直接copy，改username、module_name、action_profile、version的值）  1 2 3 4 5 6 7 8 9 10 11  username=zdmprd \\  \u0026amp;\u0026amp; module_name=\u0026#34;trial-bottal-activity\u0026#34; \\  \u0026amp;\u0026amp; active_profile=prod1 \\  \u0026amp;\u0026amp; version=\u0026#34;1.0-SNAPSHOT\u0026#34; \\  \u0026amp;\u0026amp; syncd_deploy_path=\u0026#34;/home/$username/deploy\u0026#34; \\  \u0026amp;\u0026amp; platform_base=\u0026#34;/home/$username/deploy_$active_profile\u0026#34; \\  \u0026amp;\u0026amp; platform_home=$platform_base/$module_name \\  \u0026amp;\u0026amp; mkdir -p $platform_home \\  \u0026amp;\u0026amp; sudo rsync -avz --delete --exclude \u0026#34;logs/\u0026#34; $syncd_deploy_path/ $platform_home \\  \u0026amp;\u0026amp; cd $platform_home \\  \u0026amp;\u0026amp; sudo sh/start_service.sh $module_name $version $platform_home $active_profile   构建脚本（直接copy过去，改module_name参数的值）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  module_name=\u0026#34;promotion-api\u0026#34; package_base=\u0026#34;/home/zdmprd/DeployTools/package\u0026#34; package_path=$package_base/$module_name cd ${env_workspace} mvn package -Dmaven.test.skip=true # 如果master上存放的构建后项目目录结构的文件夹不存在则创建它 if [ ! -d $package_path ];then cp -r $package_base/template/ $package_path fi rsync -avz $module_name/target/lib $package_path rsync -avz $module_name/target/classes/config $package_path rsync -avx $module_name/target/*.jar $package_path cd $package_path tar -zcvf ${env_pack_file} *   ","description":"","id":92,"section":"notes","tags":null,"title":"4.syncd项目管理篇2","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/syncd/4.syncd%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E7%AF%872/"},{"content":" id wordId # 关联到名次表中的wordId，用来做国际化的，国际化后得到的字段名为checkerName requestUrl # 数据源请求的Url requestBody # 请求体 describe # 该字段使用markdown语法，主要用于表述该检查器的文档 检查器是比较简单的，只需要发送请求，传递参数，就可以判断当前填写的值是否正确。\n","description":"","id":94,"section":"notes","tags":null,"title":"4.检查器表设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1/4.%E6%A3%80%E6%9F%A5%E5%99%A8%E8%A1%A8%E8%AE%BE%E8%AE%A1/"},{"content":" ","description":"","id":95,"section":"notes","tags":null,"title":"4.表单设计器详细设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1%E8%AF%B4%E6%98%8E/4.%E8%A1%A8%E5%8D%95%E8%AE%BE%E8%AE%A1%E5%99%A8%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1/"},{"content":" confluence上传文件要求小于100mb，所以无法上传，需要使用的请直接问我要  使用方法：  如图，进入该目录层次，在你的数据库中执行syncd_v2.0.0.sql。  如图，进入该目录层次，打开init.sh脚本，修改如下字段的值。该五个字段的值，分别对应着数据库的连接信息  完成第2步后，运行init.sh脚本，即可以完成安装。脚本运行完成后，将在后台启动syncd，你已经可以进行测试  已知问题：   如果你的电脑上已经安装了go，且版本比较低，可能无法通过编译，解决方法是：\n 卸载低版本的go，使用脚本里安装的go 手动修改path，是执行software/go目录下的go优先级更高    该脚本没有考虑开关机重启的问题，相关教程可以自行百度；syncd的启动执行，可以在syncd目录下的init.sh脚本中找到\n  ","description":"","id":96,"section":"notes","tags":null,"title":"5.syncd部署篇","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/syncd/5.syncd%E9%83%A8%E7%BD%B2%E7%AF%87/"},{"content":" id wordId # 关联到名次表中的wordId，用来做国际化的，国际化后得到的字段名为formName formDesignData # 表单设计数据，设计器提交后，前端自动生成该文件（需要相应的流程图） formValidateData # 表单校验数据，设计器提交后，前端自动生成改文件（需要相应的流程图） describe # 该字段使用markdown语法，文档。 表单表整体也是比较简单的。这儿稍微复杂的是表单设计器如何生成formDesignData和formValidateData，这部分设计需要呈现在表单设计器的详细设计中。\n","description":"","id":98,"section":"notes","tags":null,"title":"5.表单表设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%AE%BE%E8%AE%A1/5.%E8%A1%A8%E5%8D%95%E8%A1%A8%E8%AE%BE%E8%AE%A1/"},{"content":"如下为一个表单设计器的草图（不是最新版）\n区域有：\n 组件库区域 表单  目前收集的区域  ","description":"","id":100,"section":"notes","tags":null,"title":"7.表单设计器页设计（非常重要）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E9%A1%B5%E9%9D%A2%E8%AE%BE%E8%AE%A1/7.%E8%A1%A8%E5%8D%95%E8%AE%BE%E8%AE%A1%E5%99%A8%E9%A1%B5%E8%AE%BE%E8%AE%A1%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81/"},{"content":"对表单的统计 表单总校验次数：xxx次\n表单校验成功次数：xxx次\n具体某个表单的检验次数：\nformId、formName、validateCount、validateSuccessfulCount\n对属性的统计 propertyId、propertyName、formId、formName、validateCount、validateSuccessfulCount\n对数据源的统计 datasourceId、datasourceName、useCount\n对检查器的统计 checkerId、checkerName、checkCount\n说明 统计属性字段的使用情况是产品明确提到过的一个需求（我还需要和他确认，这样的统计数据设计是否符合他的需求）。\n我个人认为对数据源、检查源的统计也是有意义的，我们可能对高频率使用的数据源、检查器有针对的进行优化。\n具体实现上，我可能会选择插入表，我认为创建表单并非一个高频率、大数据量的操作，没有必要动用专用的统计工具。\n","description":"","id":101,"section":"notes","tags":null,"title":"8.统计数据页设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E9%A1%B5%E9%9D%A2%E8%AE%BE%E8%AE%A1/8.%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E9%A1%B5%E8%AE%BE%E8%AE%A1/"},{"content":"AutoConfigurationPackage注解代码如下：\n1 2 3 4  @Import(AutoConfigurationPackages.Registrar.class) public @interface AutoConfigurationPackage {}   这个注解的功能是：\n 利用Register给容器导入一系列组件 将指定的包下的所有组件导入进来（MainApplication所在的包下）  这个注解存在的意义是，一个一个的导入组件，代码量太大了，而且不太优雅。\n@Import(AutoConfigurationImportSelector.class)这行代码做了什么？\n  利用getAutoConfigurationEntry(annotationMetadata)给容器中批量导入一些组件\n  调用List\u0026lt;String\u0026gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类\n  利用工厂加载Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; loadSpringFactories(@Nullable ClassLoader classLoader)得到所有的组件\n  从META-INF/spring.factories位置来加载一个文件。\n 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories    ","description":"","id":102,"section":"notes","tags":null,"title":"@AutoConfigurationPackage注解的意义","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/autoconfigurationpackage%E6%B3%A8%E8%A7%A3%E7%9A%84%E6%84%8F%E4%B9%89/"},{"content":"如下代码：\n1 2 3 4 5 6 7 8  @Bean @ConditionalOnBean(MultipartResolver.class) @ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) public MultipartResolver multipartResolver(MultipartResolver resolver) { return resolver; }   这段配置的含义是这样的，如果容器中有dispatcherServlet的bean，容器中有MultipartResolver.class的bean，那么我们将创造一个名为multipartResolver的Bean。具体的操作是从容器中注入的MultipartResolver.class的Bean，返回一个名为multipartResolver的Bean。\n","description":"","id":103,"section":"notes","tags":null,"title":"@Bean配置时一段经典的源码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/bean%E9%85%8D%E7%BD%AE%E6%97%B6%E4%B8%80%E6%AE%B5%E7%BB%8F%E5%85%B8%E7%9A%84%E6%BA%90%E7%A0%81/"},{"content":"我之所以多这个注解感兴趣，是因为最近开到SpringBootApplication这个注解继承的注解就配置了Filter。\n我认为相关的知识我使用的频率非常的低。\nexcludeFilters 代码如下：\n1 2 3 4 5  @ComponentScan(value = \u0026#34;fun.junjie.demo\u0026#34;, excludeFilters = { @Filter(type = FilterType.ANNOTATION, classes = {Controller.class}) })   @ComponentScan的value参数指明了需要扫描的包，excludeFilters指明了扫描的时候排除哪些类。\n@Filter的type指明了类中带有某个注解则不进行注入，classes指明了具体时哪个注解。\nincludeFilters 这个注解说明了扫描的时候，只包含哪些类。\n常用的规则 ANNOTATION：注解\nASSIGNABLE_TYPE：指定的类型\nASPECT：使用aspect的表达式（不理解，也从来没用过）\nREGEX：使用正则的表达式\nCUSTOM：使用自定义规则\n开发自己的TypeFilter 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class MyTypeFilter implements TypeFilter { @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { /* matadataReader：读取到的当前正在扫描的类的信息 metadataReaderFactory：可以获取到其他任何类的信息 */ // 获取当前类注解的信息  metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的信息  metadataReader.getClassMetadata(); // 获取当前类资源（类的路径）  metadataReader.getResource(); return false; } }   其他知识  如果是jdk8，@ComponentScan组件可以在一个类中重复使用多次  在实践中，我发现因为SpringBootApplication中使用了该注解，所以DemoApplication不能再使用该注解了。看样子继承会影响到重复性。\n如果不是jdk8，可以使用@ComponentScans策略来实现相同的效果  1 2 3 4 5 6 7 8  @ComponentScans( value={ @ComponentScan(value=\u0026#34;fun.junjie1\u0026#34;, includeFilters = {}), @ComponentScan(value=\u0026#34;fun.junjie2\u0026#34;, includeFilters = {}) } )   ","description":"","id":104,"section":"notes","tags":null,"title":"@ComponentScan中使用filter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/componentscan%E4%B8%AD%E4%BD%BF%E7%94%A8filter/"},{"content":"SpringBoot中，更多的是使用已经高度开发的一系列条件注解，第一次接触Spring的条件注解，没想到还需要写实现类。\n1 2 3 4 5 6 7 8 9  @Conditional({ WindowCondition.class }) @Bean public XXX xxx(){ return new XXX(); }   Condition的实现类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public class WindowCondition implements Condition { @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) { /* conditionContext：判断条件能使用的上下文（环境） annotatedTypeMetadata：注释信息 */ // 获取到ioc使用的beanFactory  ConfigurableListableBeanFactory beanFactory = conditionContext.getBeanFactory(); // 获取类加载器  ClassLoader classLoader = conditionContext.getClassLoader(); // 获取当前环境信息  Environment environment = conditionContext.getEnvironment(); // 获取到bean定义的注册类（我以为会通过这个类注入Bean，看样子是我想多了）  // 支持定义一个Bean  // 支持移除一个bean  BeanDefinitionRegistry registry = conditionContext.getRegistry(); return false; } }   我们也可以手动指定os.name：\n -Dos.name=linux ","description":"","id":105,"section":"notes","tags":null,"title":"@Conditional注解实现条件注入","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/conditional%E6%B3%A8%E8%A7%A3%E5%AE%9E%E7%8E%B0%E6%9D%A1%E4%BB%B6%E6%B3%A8%E5%85%A5/"},{"content":"我整理这部分资料，仅仅是查漏补缺，补充一些我不太熟悉的知识。\nSpirng的宽松绑定规则 实体中的hostName可以绑定如下配置：\n mail.hostName mail.hostname mail.host_name mail.host-name mail.HOSTNAME 三种方式将一个Bean注入到Spring Context中   使用@Component注解（前提能够被@ComponentScan扫描）\n  通过Java Configuration实现相同的效果（要求PropertiesConfig可以被扫描到）\n  1 2 3 4 5 6 7 8 9  @Configuration class PropertiesConfig() { @Bean public MailModuleProperties mailModuleProperties() { return new MailModuleProperties(); } }   在@EnableConfigurationProperties注解中指定参数（这种方法我用的非常少）  1 2 3 4 5 6 7  @Configuration @EnableConfigurationProperties(MailModuleProperties.class) class PropertiesConfig() { }   至于如何选择这些方法，网上文章的有一些建议，但是我目前不计划采纳这些建议。\nignoreInvalidFields、ignoreUnknownFields配置 这两个属性配置@ConfigurationProperties中，我觉得是有一定价值的，毕竟开发该属性配置信息的人最清楚如果配置文件中的配置值非法或者未知，该如何处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Data @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreInvalidFields=true) public class MailModuleProperties{ private Boolean enabled = Boolean.TRUE; } @Data @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreUnknownFields=false) public class MailModuleProperties{ private Boolean enabled = Boolean.TRUE; }   备注：ignoreUnknownFields未来可能会被删除，存在两个Properties绑定到一个命名空间上，其中一个类知道某个属性，而另一个不知道。（额，好吧）\n支持@Validate 1 2 3 4 5 6 7 8 9  @Data @Validate @ConfigurationProperties(prefix = \u0026#34;myapp.mail\u0026#34;, ignoreUnknownFields=false) public class MailModuleProperties{ @NotNull private Boolean enabled; }   Duration与DataSize SpringBoot内置支持从配置参数中解析durations和data size。duration和data size单位如下：\n ns: 纳秒 us：微秒 ms：毫秒 s ：秒 m ：分 h ：时 d ：天 B KB MB GB TB 配置案例如下：\nmyapp.mail.pause-between-mails = 5s myapp.mail.max-attachment-size = 1MB 对应的Java代码如下：\n1 2 3 4 5 6 7 8 9 10  import org.springframework.util.unit.DataSize; import java.time.Duration; @DurationUnit(ChronoUnit.SECONDS) private Duration pauseBetweenMails; @DataSizeUnit(DataUnit.MEGABYES) private DataSize maxAttachmentSize = DataSize.ofMegabytes(2);   Duration和DataSize这些类我几乎没有用过，这也说明我开发的复杂业务逻辑还是太少了，对JAVA了解的还仅仅只是一个皮毛。\n使用Spring Boot Configuration Processor完成自动补全 添加依赖如下：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   需要重新Build一下（对应到Idea中就是重新启动一下），这时我们在编辑application.yml时就会有自动提示了。\nBuild后会生成一份json文件，相关的提示信息就存储在这份json文件中：\n我一直在用这个依赖，但是从来不知道我们的自动提示功能是有这个依赖提供的，而且这个依赖还可以对我们自己开发的配置进行自动提示。\n编辑配置属性为Deprecated 案例代码如下：\n1 2 3 4 5 6  @DeprecatedConfigurationProperty(reason = \u0026#34;No Need Now\u0026#34;, replacement = \u0026#34;none\u0026#34;) public String getDefaultSubjects() { }   比较糟心的是，这个注解只能注册到方法上，为了使用这个注解我们还需要开发一个Getter方法，使用lombok时非常的不爽。\n@ConfigurationProperties注解不支持SpEL表达式 我目前对SpEL表达式的需求还比较少，先持续关注一些这个问题。\n@ConfigurationProperties、@PropertySource @ConfigurationProperties支持和@PropertySource结合，读取指定文件，博客上说只能用于properties文件，但是我记得在我的实验中，貌似也是支持yaml文件的。\n我目前对该技术没有太大的需求，所以暂时不研究。\n@ConfigurationProperties与@Value的对比 @Value与@ConfigurationProperties涉及到的源码 1 2 3 4 5 6 7 8 9  @Value org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor @ConfigurationProperties org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor   这是好东西，深入学习SpringBoot是没有办法避免研究这些的。\n参考资料   @ConfigurationProperties 注解使用姿势，这一篇就够了\n  SpringBoot配置中@ConfigurationProperties和@Value的区别\n  ","description":"","id":106,"section":"notes","tags":null,"title":"@ConfigurationProperties注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/configurationproperties%E6%B3%A8%E8%A7%A3/"},{"content":"如下代码：\n1 2 3 4 5 6 7 8 9  @Bean @ConfigurationProperties(\u0026#34;spring.datasource\u0026#34;) public DataSource dataSource(){ return new DruidDataSource(); }   这种写法会让返回的DataSource Bean与spring.datasource下的配置一一绑定。这是我学习尚硅谷的SpringBoot课程进行查漏补缺时学到的一种写法。实际上让@Configuration注解在方法上，在我看到这个课程前我自己就探索出来了，如下代码所示，但是我当时以为@ConfigurationProperties影响的是参数，而且我在断点中也曾发现过templates是一个长度为零的List。\n1 2 3 4 5 6 7 8 9 10 11 12  @Configuration public static class TemplatesPropertiesInternalConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;templates\u0026#34;) public List\u0026lt;Template\u0026gt; templates(List\u0026lt;Template\u0026gt; templates) { return templates; } }   所以我这次决定验证一下该知识点，我实验代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  @Configuration public static class TemplatesPropertiesInternalConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;templates\u0026#34;) public List\u0026lt;Template\u0026gt; templates() { return null; } } @Configuration public static class TemplatesPropertiesInternalConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;templates\u0026#34;) public List\u0026lt;Template\u0026gt; templates() { return new ArrayList(); } }   我期待这两个方法都能够返回我在配置文件中配置的List\u0026lt;Template\u0026gt;。额，好尴尬，其实我不用实验的，因为我代码中已经在使用这个知识点了，只是这个知识点是我自己摸索出来的：\n","description":"","id":107,"section":"notes","tags":null,"title":"@ConfigurationProperties的一种写法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/configurationproperties%E7%9A%84%E4%B8%80%E7%A7%8D%E5%86%99%E6%B3%95/"},{"content":"我的客户端放在com.sdstc.auth.client下，我代码的包结构如下：\n默认情况下，我需要将我的启动类放在com.sdstc下才能够正常的扫描到我Feign Client。即使我在@SpringBootApplication中配置了com.sdstc.auth.client，也无法扫描到该客户端。\n最后我尝试出了如下写法，即为@EnableFeignClients配置扫描地址：\n1 2 3 4 5 6 7 8 9  @EnableFeignClients({\u0026#34;com.sdstc\u0026#34;}) @SpringBootApplication(scanBasePackages = {\u0026#34;com.sdstc\u0026#34;}) public class SRMApplication { public static void main(String[] args) { SpringApplication.run(SRMApplication.class, args); } }   ","description":"","id":108,"section":"notes","tags":null,"title":"@EnableFeignClients中没有配置backPackages，导致找不到客户端","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/enablefeignclients%E4%B8%AD%E6%B2%A1%E6%9C%89%E9%85%8D%E7%BD%AEbackpackages%E5%AF%BC%E8%87%B4%E6%89%BE%E4%B8%8D%E5%88%B0%E5%AE%A2%E6%88%B7%E7%AB%AF/"},{"content":"@ImportResource多用在项目中存在老旧的Spring项目（我目前基本上没有遇到过这种情况）\n1 2 3  @ImportResource(\u0026#34;classpath:beans.xml\u0026#34;)   我使用这两个注解的次数非常的少。\n","description":"","id":109,"section":"notes","tags":null,"title":"@ImportResource导入一个bean.xml文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/importresource%E5%AF%BC%E5%85%A5%E4%B8%80%E4%B8%AAbean.xml%E6%96%87%E4%BB%B6/"},{"content":"@Import创建出来的组件，组件的名称为其全类名。这个注解可以用在将第三方的Bean注册到Spring Context。这种方式导入相对于Java Config来说更方便。\n1 2 3  @Import({User.class, DBHelper.class})   @Import可以与ImportSelector结合使用。ImportSelector为一个接口，包含一个selectImports方法，该方法返回一个全类名数组，该数组代表的对象将会被注入到容器中。\n1 2 3 4 5 6 7 8 9 10 11 12 13  public class MyImportSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { // importingClassMetadata当前标注@Import注解类的所有注解信息  return new String[]{ \u0026#34;demo.xxx.XXX\u0026#34;, \u0026#34;demo.xxx.YYY\u0026#34;, }; } }   @Import可以与ImportBeanDefinitionRegistrar结合使用，实现ImportBeanDefinitionRegistrar接口，在registerBeanDefinitions方法中直接通过beanDefinitionRegistry完成Bean的注入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry beanDefinitionRegistry) { /* beanDefinitionRegistry：BeanDefinition注册类，把所有需要注入到容器中的bean，调用 beanDefinitionRegistry.registerBeanDefinition收工注册进来 */ if (beanDefinitionRegistry.containsBeanDefinition(\u0026#34;red\u0026#34;)) { beanDefinitionRegistry.registerBeanDefinition(\u0026#34;red\u0026#34;, new RootBeanDefinition(Weight.class)); } } }   ","description":"","id":110,"section":"notes","tags":null,"title":"@Import与ImportSelector与ImportBeanDefinitionRegistar","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/import%E4%B8%8Eimportselector%E4%B8%8Eimportbeandefinitionregistar/"},{"content":"在对MyBatis查漏补缺的时候看到了@MapKey注解，加上这个注解后可以指定一个字段作为返回Map中的key。\n我觉得这个东西挺好的，我有很高的需求，之前的话，我一直是手动查出来，然后再拼接成Map的。\n使用这个技术有一个问题：我们使用的是MyBatis-Plus，MyBatis-Plus不知道支不支持这个注解。\n我计划在通读MyBatis-Plus的文档后再回过头来看这个问题。\n","description":"","id":111,"section":"notes","tags":null,"title":"@MapKey注解的应用（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mapkey%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%BA%94%E7%94%A8%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"@Profile注解类型于@Conditional，但是它仅针对当前运行的环境，我觉得这个东西在生产开发中使用的频率非常的低，几乎没有使用的空间。\n但是我们目前的项目中有一个场景，可能会用到相关的技术，在我们的项目中，dev环境使用的数据源驱动并非PG数据库的的官方驱动，而是p6spy数据源启动，p6spy是一个非常强大的数据源，它可以拦截jdbc的所有SQL请求（我在实验中，并非所有的sql都可以被拦截）。但是上sit环境和prod环境时，我们需要使用正常的pg数据源。\n从某种角度上讲，此时我们可以需要使用@Profile技术了。但是SpringBoot非常的强大，我们使用了两个application.yml文件，一个application-sit.yml、一个application-dev.yml文件，在每个文件中配置了不同的driverClass，从而就实现了在不同的环境中使用不同的数据源，感觉非常的方便。\n如果该需求使用@Profile实现，我们会在代码中直接定义两个数据源，并直接硬编码给配置好，然后通过@Profile设置在不同的环境中装配不同的数据源。这么说来@Profile适用的场景是：组件的配置无法配置文件化（或者说没有精力去将一个组件的配置配置文件化，我们选择了在代码里通过JavaConfig进行配置）。\n对@Profile的小结 经过上面的分析，我对@Profile的使用场景总结如下：当我们在进行bean的配置时，如果我们没有精力将组件的配置进行配置文件化，或者组件的配置本身也不是很好的支持配置文件化，我们可以考虑使用@Profile技术。\n使用@Profile文件，我们需要公司级别的常量，用来表示各个公司中尝尝使用的各个环境，然后各个项目都需要遵守这个规范，使用已定义的Profile。\n","description":"","id":112,"section":"notes","tags":null,"title":"@Profile注解的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/profile%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"@PropertySource有如下注意事项：\n  @PropertySource目前也是支持yml文件的，我看网上说只支持properties文件，估计是Spring版本比较旧吧。\n  @PropertySource注入的文件，可以在代码中通过环境变量获取到，代码如下：\n  1 2 3 4 5 6  SpringApplication .run(DemoApplication.class, args) .getEnvironment() .getProperty(\u0026#34;tmp\u0026#34;)    PropertySource是可以在一个类上注解多次的，相同功能也可以使用PropertySources实现。\n  PropertySource这个注解想到于在Spring项目的配置文件中做了如下配置（没有打算使用Spring的xml配置方式，记录这个东西仅仅是为了方便学习和理解）：\n  1 2 3  \u0026lt;context:property-placeholder location=\u0026#34;classpath:tmp.properties\u0026#34;\u0026gt;   ","description":"","id":113,"section":"notes","tags":null,"title":"@PropertySouce注解需要注意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/propertysouce%E6%B3%A8%E8%A7%A3%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"我尝试使用@Repository代替@Mapper，结果发现应用根本就无法启动起来。这个问题我之前实验中貌似不存在，在我SpringBoot升到2.5.2时第一次发现该问题。\n（先记录一下吧，以后有精力再深入研究）\n","description":"","id":114,"section":"notes","tags":null,"title":"@Repository和@Mapper的差别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/repository%E5%92%8Cmapper%E7%9A%84%E5%B7%AE%E5%88%AB/"},{"content":"Scope可配置的值如下：\n1 2 3 4 5 6 7  ConfigurableBeanFactory#SCOPE_PROTOTYPE：多实例 ConfigurableBeanFactory#SCOPE_SINGLETON：单实例（默认） WebApplicationContext#SCOPE_REQUEST（一个请求创建一个实例） WebApplicationContext#SCOPE_SESSION（一个Session创建一个实例）   当为单实例时，可以通过@Lazy进行懒加载。这些知识很好理解，不整理代码了。\n","description":"","id":115,"section":"notes","tags":null,"title":"@Scope与@Lazy注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/scope%E4%B8%8Elazy%E6%B3%A8%E8%A7%A3/"},{"content":"正确的写法如下：\n1 2 3 4 5 6 7 8 9  @Mapper public interface CommonMaterialMapper extends BaseMapper\u0026lt;CommonMaterial\u0026gt; { @Select(\u0026#34;\u0026lt;script\u0026gt;select * from t_common_material where id in \u0026lt;foreach collection=\u0026#39;ids\u0026#39; item=\u0026#39;id\u0026#39; open=\u0026#39;(\u0026#39; separator=\u0026#39;,\u0026#39; close=\u0026#39;)\u0026#39;\u0026gt; #{id} \u0026lt;/foreach\u0026gt;\u0026lt;/script\u0026gt;\u0026#34;) List\u0026lt;CommonMaterial\u0026gt; selectListWithDelete(@Param(\u0026#34;ids\u0026#34;) List\u0026lt;String\u0026gt; ids); }   忘记使用\u0026lt;script\u0026gt;会导致错误。\n","description":"","id":116,"section":"notes","tags":null,"title":"@Select中忘记使用Script标签了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/select%E4%B8%AD%E5%BF%98%E8%AE%B0%E4%BD%BF%E7%94%A8script%E6%A0%87%E7%AD%BE%E4%BA%86/"},{"content":"该问题由同事定位并修复，我在一旁参观了整个过程。我们的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Select(\u0026#34;\u0026lt;script\u0026gt;\u0026#34; + \u0026#34; SELECT * FROM t_user where is_delete = 0\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.account != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND account like #{request.account} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.registStatus != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND regist_status = #{request.registStatus} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.name != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND name like #{request.name} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.status != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND status = #{request.status} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.startTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026gt;= #{request.startTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.endTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026gt;= #{request.endTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; order by gmt_create_time\u0026#34; + \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;) IPage\u0026lt;User\u0026gt; getUserListPage(Page\u0026lt;User\u0026gt; objectPage, SearchExperienceAccountRequest request);   结果项目在启动的是否报了如下的错误：\n 2021-06-16 15:11:52.260 WARN AbstractApplicationContext.java:558- Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountController' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\controller\\AccountController.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'accountServiceImpl' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\service\\impl\\AccountServiceImpl.class]: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'companyMapper' defined in file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\com\\sdstc\\authcenter\\mapper\\CompanyMapper.class]: Unsatisfied dependency expressed through bean property 'sqlSessionFactory'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'sqlSessionFactory' defined in class path resource [com/baomidou/mybatisplus/autoconfigure/MybatisPlusAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.ibatis.session.SqlSessionFactory]: Factory method 'sqlSessionFactory' threw exception; nested exception is org.springframework.core.NestedIOException: Failed to parse mapping resource: 'file [D:\\Project\\auth-center\\authcenter-server\\target\\classes\\mapper\\UserMapper.xml]'; nested exception is org.apache.ibatis.builder.BuilderException: Could not find value method on SQL annotation. Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance. Cause: org.xml.sax.SAXParseException; lineNumber: 1; columnNumber: 523; 元素内容必须由格式正确的字符数据或标记组成。 问题的原因在于我们的代码中使用了\u0026gt;符号，这是一个特殊的字符，写在xml中需要进行转义。\n改正后的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Select(\u0026#34;\u0026lt;script\u0026gt;\u0026#34; + \u0026#34; SELECT * FROM t_user where is_delete = 0\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.account != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND account like #{request.account} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.registStatus != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND regist_status = #{request.registStatus} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.name != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND name like #{request.name} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.status != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND status = #{request.status} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.startTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026amp;gt;= #{request.startTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; \u0026lt;if test=\u0026#39;request.endTime != null\u0026#39;\u0026gt;\u0026#34; + \u0026#34; AND gmt_create_time \u0026amp;lt;= #{request.endTime} \u0026#34; + \u0026#34; \u0026lt;/if\u0026gt;\u0026#34; + \u0026#34; order by gmt_create_time\u0026#34; + \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;) IPage\u0026lt;User\u0026gt; getUserListPage(Page\u0026lt;User\u0026gt; objectPage, SearchExperienceAccountRequest request);   这个问题我需要小心，原因是我之前在开发一款帮忙优化排版的脚本，我并没有注意到这个问题，其次我从业到现在，接触xml的次数太少了，踩过的坑也很少，我很容易犯相同的错误。\n不过我对这种编码的方式也存在一些疑惑：\n  这个查询可以通过LambdaQueryWrapper实现么\n  这样的脚本是自己手动一行一行的编写的么，那我想测试该sql脚本的时候又该怎么办\n  我觉得使用这种方案，还是需要一些小工具的，让编写代码和检查代码都比较轻松，否则的话一点SQL出现了问题，我觉得没有谁有积极性去排查其中的问题。\n","description":"","id":117,"section":"notes","tags":null,"title":"@Select中特殊字符导致的错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/select%E4%B8%AD%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E5%AF%BC%E8%87%B4%E7%9A%84%E9%94%99%E8%AF%AF/"},{"content":"@Skip注释用在ChannelHandler的实现类的方法上，程序运行的过程中，如果某个handler实现中的方法被@Skip注释了，则此方法不会被ChannelPipeline对象调用。\n（我暂时不想深入研究，因为还没有研究到fireXXX那块）\n参考资料  Netty框架中的@Skip使用说明  ","description":"","id":118,"section":"notes","tags":null,"title":"@Skip注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/skip%E6%B3%A8%E8%A7%A3/"},{"content":"代码如下：\n1 2 3  @TableField(exist = false)   开发一些Demo时用到了这个技术，记录一下。\n参考资料  mybatis怎么忽略映射字段  ","description":"","id":119,"section":"notes","tags":null,"title":"@TableField处理表中不存在的字段","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/tablefield%E5%A4%84%E7%90%86%E8%A1%A8%E4%B8%AD%E4%B8%8D%E5%AD%98%E5%9C%A8%E7%9A%84%E5%AD%97%E6%AE%B5/"},{"content":"默认情况下，RedisTemplate不参与托管的Spring事务。如果希望RedisTemplate在使用@Transactional或TransactionTemplate时使用Redis事务，则需要通过设置setEnableTransactionSupport(true)显式启用对每个 RedisTemplate的事务支持。\n启用事务支持将RedisConnection绑定到由ThreadLocal支持的当前事务。如果事务完成且没有错误，则使用E​​XEC提交Redis事务，否则使用DISCARD回滚。Redis事务是面向批处理的。在正在进行的事务期间发出的命令会排队，并且仅在提交事务时应用。\nSpring Data Redis区分正在进行的事务中的只读和写入命令。只读命令（例如 KEYS）通过管道传输到新的（非线程绑定的）RedisConnection以允许读取。写入命令由RedisTemplate排队并在提交时应用。\n（我暂时没有计划研究RedisTemplate结合@Transaction使用，因为对Spring的事务理解的并不是足够的透彻，出现问题后难以定位）\n","description":"","id":120,"section":"notes","tags":null,"title":"@Transactional注解于Spring Data Redis事务","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/transactional%E6%B3%A8%E8%A7%A3%E4%BA%8Espring-data-redis%E4%BA%8B%E5%8A%A1/"},{"content":"我知道Node SCSS和Dart SCSS有差异，结果没想到差异来的这么快，我按照官方教程录入了如下的代码，结果始终无法运行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @use \u0026#34;sass:math\u0026#34;; .container { display: flex; } article[role=\u0026#34;main\u0026#34;] { width: math.div(600px, 960px) * 100%; } aside[role=\u0026#34;complementary\u0026#34;] { width: math.div(300px, 960px) * 100%; margin-left: auto; }   后来我才发现，是因为我使用了node scss的原因，我将node scss切换成drat scss，该问题修复了。\n升级Node SCSS到Daft SCSS 参考资料   SCSS: @use, @forward: Cannot use modules and access it\u0026rsquo;s members\n在该资料中发现了是因为Node SCSS不支持@use\n  SASS/SCSS 簡介\n在该资料中知道了@import和@use的区别。\n  Node Sass to Dart Sass\n在该资料中知道了Drat SCSS和Node SCSS的区别，并知道了如何升级Node SCSS到Daft SCSS。\n  ","description":"","id":121,"section":"notes","tags":null,"title":"@use指令用不了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/vue/scss/use%E6%8C%87%E4%BB%A4%E7%94%A8%E4%B8%8D%E4%BA%86/"},{"content":"@Valid与@Validation的区别：\n  @Validation支持分组功能，@Valid不支持分组功能\n  @Validated用于类型、方法、方法参数，不能用于成员属性上，@Valid用于方法、构造函数、方法参数、成员属性上。因为@Validated不能用于成员属性，故其不支持嵌套验证功能（在开发中已经遇到过这个问题了）\n  参考资料   @Validated和@Valid区别：Spring validation验证框架对入参实体进行嵌套验证必须在相应属性（字段）加上@Valid而不是@Validated\n还有一部分关于嵌套验证的资料，因为我这部分已经比较熟悉了，就不整理了。\n  ","description":"","id":122,"section":"notes","tags":null,"title":"@Valid与@Validation的区别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/valid%E4%B8%8Evalidation%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"content":"我在看官网的文档时，注意到如下一段配置及讲解，这让我产生了疑惑，故记录下来：\n该讲解翻译如下：在服务端配置中，每个对等点（客户端）将能够将数据包发送到网络接口，其源IP与相应的允许IP列表匹配。例如，当服务器从对等方gN65kIK接收到一个数据包时，经过解密和认证后，如果它的源IP是10.10.10.230，则允许它进入接口，否则它将会被丢弃。\n我的疑惑是这样的：在配置客户端时，AllowedIPs貌似是作为路由项的（体现在手机客户端中，配置了路由后，自动更新该配置），也就是说，我手机中发送到该AllowedIPs的所有流量都通过wg网口。但是在上面的讲解中，似乎是说AllowedIPs类似与iptables限制了源IP。我保持观望吧。\n之后一段的如下：\n从这个角度看，AllowIPs貌似在接收数据包和发送数据包时都起到了一定的作用。\n后面文档其实做了总结：在发送数据包时，允许IP列表表现为一种路由表，而在接收数据包时，允许IP列表表现为一种访问控制列表\n参考资料  wireguard  ","description":"","id":123,"section":"notes","tags":null,"title":"AllowedIPs不理解的地方","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/allowedips%E4%B8%8D%E7%90%86%E8%A7%A3%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"先给条指令，用来查看当前系统的发行版本（这条蛮好用的，目前我的系统都能用这个）：\n cat /etc/issue 添加curl  apk add curl 添加telnet  apk add busybox-extras 参考资料  如何查看LINUX发行版的名称及其版本号 Ryanb58/install.md  ","description":"","id":124,"section":"notes","tags":null,"title":"Alpine Linux 3.11安装常用工具包","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/alpine/alpine-linux-3.11%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%8C%85/"},{"content":"我公司和家里的电脑上同时配置了alt + f快捷键，用来快速打开文件在资源浏览器中的位置。在公司的电脑上我可以在任意打开的文件，或者目录树中任意一个条目中执行该快捷键，但是在家里的电脑上我智能在目录条目上执行该快捷键，很是困扰。\n今天小小研究了一下，发现配置快捷键的时候还可以配置一个条件，我家里的电脑上配置了在非编辑窗口，该快捷键生效，所以一直都有问题，删掉该条件即可。\n","description":"","id":125,"section":"notes","tags":null,"title":"alt+f快捷键不好使了","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/alt+f%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%B8%8D%E5%A5%BD%E4%BD%BF%E4%BA%86/"},{"content":"指令如下：\n conda create --name python38 python=3.8 conda active python38 ","description":"","id":126,"section":"notes","tags":null,"title":"Anaconda创建环境并激活环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/anaconda3/anaconda%E5%88%9B%E5%BB%BA%E7%8E%AF%E5%A2%83%E5%B9%B6%E6%BF%80%E6%B4%BB%E7%8E%AF%E5%A2%83/"},{"content":"我决定采用《奔跑吧，Ansible》这本书中放置目录文件的结构，目前收集的结构如下：\n |-- Playbooks |----- hosts |----- ansible.cfg 我目前ansible.cfg的配置如下：\n1 2 3 4 5 6 7  [defaults] hostfile = hosts remote_user = root remote_port = 22 host_key_checking = False   ","description":"","id":127,"section":"notes","tags":null,"title":"ansible.cfg文件的应用及playbooks目录的结构","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/ansible.cfg%E6%96%87%E4%BB%B6%E7%9A%84%E5%BA%94%E7%94%A8%E5%8F%8Aplaybooks%E7%9B%AE%E5%BD%95%E7%9A%84%E7%BB%93%E6%9E%84/"},{"content":"安装nginx 指令如下：\n1 2 3 4 5 6 7 8 9  ansible test -m yum -a name=nginx # 安装前更新一下软件包 ansible test -m yum -a name=nginx update_cache=yes # 重启nginx ansible test -m service -a name=nginx   playbook中运行nginx的实验 如下playbook，在运行的时候始终无法正常的执行restart nginx，报错内容如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  ---- name:Configure webserver with nginxhosts:webserverssudo:Falsetasks:- name:install nginxyum:name=nginx- name:copy nginx config filecopy:src=files/nginx.conf dest=/etc/nginx/sites-available/default/- name:create folderfile:\u0026gt;path=/etc/nginx/sites-enabled state=directory- name:enable configurationfile:\u0026gt;dest=/etc/nginx/sites-enabled/default src=/etc/nginx/sites-available/default state=link- name:copy index.htmltemplate:src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html mode=0644- name:restart nginxservice:name=nginx state=restarted  报错内容：\n TASK: [restart nginx] ********************************************************* failed: [192.168.23.60] =\u0026gt; {\u0026quot;failed\u0026quot;: true} msg: Job for nginx.service failed because the control process exited with error code. See \u0026quot;systemctl status nginx.service\u0026quot; and \u0026quot;journalctl -xe\u0026quot; for details. FATAL: all hosts have already failed -- aborting PLAY RECAP ******************************************************************** to retry, use: --limit @/home/junjie/web-notls.retry 192.168.23.60 : ok=6 changed=0 unreachable=0 failed=1 之所以发生这个问题是因为我在安装nginx后，启动了该nginx，且在杀死nginx时由于nginx会自动重启，一直没有真正的杀死nginx进程，最后导致ansible无法正常启动nginx服务，杀死nginx后，该问题解决了。\n","description":"","id":128,"section":"notes","tags":null,"title":"Ansible关于nginx的实验","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/ansible%E5%85%B3%E4%BA%8Enginx%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"我在开发代码生成工具时，大量使用了application.yml进行配置，这次看课程的时候，又看到了相关的知识点，发现有一些细节我自己之前也没有意识到，所以这儿整理一下。\n基础知识  单引号和双引号的区别：单引号不会转义，双引号会转义。 list的内内联写法：math: [131,140,148] map的内联写法：chinese: {first: 128,second: 136}  对Map的一些处理 我之前实验的过程中，进行Map相关的操作时，出现了一些奇奇怪怪的问题，但是我在看课程的时候，发现并没有这些问题，所以我这儿重新进行一下实验，定义如下Property\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Data @Component @ConfigurationProperties(prefix = \u0026#34;person\u0026#34;) public class PersonProperties { private Map\u0026lt;String, Pet\u0026gt; pets; private Map\u0026lt;String, Object\u0026gt; petsObj; private Map\u0026lt;String, List\u0026lt;Pet\u0026gt;\u0026gt; petsList; } @Data class Pet { private Integer id; private Integer age; }   准备如下application.yml文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  person:pets:tom:id:1age:3jack:id:2age:3pets-obj:tom:id:1age:3jack:id:2age:3pets-list:zhangsan:- id:1age:3- id:2age:3  总结一下我之前犯的错误，我当时的需求是想用Map\u0026lt;String, Pet\u0026gt;去接受一个配置项，即本实例中的pets字段，但是我错误的写了如下的配置：\n1 2 3 4 5 6 7 8  person:pets:- id:1age:3- id:2age:3  后续：\n针对Map，有个让人头疼的问题，application.yml自动提示在对Map类型效果不是很好。\n","description":"","id":129,"section":"notes","tags":null,"title":"application.yml中的一些语法细节","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/application.yml%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E7%BB%86%E8%8A%82/"},{"content":"我在重构我的代码生成工具，之前有如下代码：\n1 2 3 4 5 6  tools:template-directory:\u0026#39;classpath:templates/\u0026#39;enum-comment-pattern:\u0026#39;^([A-Za-z\\u4e00-\\u9fa5 ]{1,})（(([A-Za-z0-9-]+：[\\u4e00-\\u9fa5A-Za-z0-9-]{1,}，?)+)）$\u0026#39;number-pattern:\u0026#39;^[0-9]*$\u0026#39;  我的Properties类是这样写的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Data public class ToolsProperties { private String templateDirectory; private String numberPattern; public Path getTemplateDirectory(){ // 做一些处理将String转换成Path  } public Pattern getNumberPattern(){ // 做一些处理将String转换成Pattern  } }   我觉得这样的写法非常的不优雅，我无法接受，我想要如下的写法：\n1 2 3 4 5 6 7  @Data public class ToolsProperties { private Path templateDirectory; private Pattern numberPattern; }   在我开始编码前，我以为我会使用Convert完成该工作，但是我发现SpringBoot支持自动将application.yml中的字符串转换成Path和Pattern，于是我就使用了该特性。\nConvert的开发 我还是要写一份我开发Convert（毕竟这份代码没啥用了，我准备删除了）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  public class PathConverter implements Converter\u0026lt;String, Path\u0026gt; { @Override public Path convert(String templateDirectory) { try { Path templateDirectoryPath = templateDirectory.startsWith(\u0026#34;classpath:\u0026#34;) ? ResourceUtils.getFile(templateDirectory).toPath() : Paths.get(templateDirectory); if (!Files.exists(templateDirectoryPath)) { throw new RuntimeException(\u0026#34;TemplateDirectory不存在，请检查配置文件\u0026#34;); } return templateDirectoryPath; } catch (FileNotFoundException e) { throw new RuntimeException(\u0026#34;TemplateDirectory不存在，请检查配置文件\u0026#34;); } } }   这份代码有两个亮点：\n 支持在配置文件中配置classpath:。 使用了ResourceUtils工具处理classpath。  可惜了，Spring默认支持对Path的转换，导致我这个代码没用到。\nSpringBoot对Path的处理 很糟心的是，将ToolsProperties中templateDirectory字段换成Path类型并没有想象中的那么顺利，我一开始将template-directory配置成classpath:templates，结果提示无法找到该文件，我以为是SpringBoot默认的Path转换器不支持classpath，于是我就想替换掉这个转换器，接下来就是漫长的找这个转换器的过程（这个转换器是不存在的）\n具体过程我就不写出来了，总是整个过程我收获了如下技巧：\n  我在ToolsProperties写了一个Setter（手写的，非Lombok），然后断点在这个setter中，最终SpringBoot调到了这个方法，我从而可以查看调用栈，从而快速找到我想观察的方法。（貌似可以直接断点到字段上，我没有试过）\n  我一开始不知道Idea可以断点拉姆达表达式，遇到拉姆达表达式，我就一层一层的去找这个拉姆达表达式是在哪实现的，然后在拉姆达表达式中进行断点。实际上不需要这么做，我可以直接断点在函数式接口的方法上，Idea会自动帮我找到这个方法的定义。（虽然如此，还是一层一层的找更快乐）\n  对Path、Pattern的处理，SpringBoot并没有采用Convert，而是一系列非常复杂的机制，有兴趣的自己去看看吧，我目前还没有完全消化。\n  如果我们用Path接受配置文件中的配置，Path指向一个文件夹的时候配置的值一定要一个反斜杠结尾。\n  分享一些快乐  我是如何知道SpringBoot支持classpath:的，如下，我在断点调试值看到了如下的代码：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  @Override public void setAsText(String text) throws IllegalArgumentException { boolean nioPathCandidate = !text.startsWith(ResourceUtils.CLASSPATH_URL_PREFIX); if (nioPathCandidate \u0026amp;\u0026amp; !text.startsWith(\u0026#34;/\u0026#34;)) { try { URI uri = new URI(text); if (uri.getScheme() != null) { nioPathCandidate = false; // Let\u0026#39;s try NIO file system providers via Paths.get(URI)  setValue(Paths.get(uri).normalize()); return; } } catch (URISyntaxException ex) { // Not a valid URI; potentially a Windows-style path after  // a file prefix (let\u0026#39;s try as Spring resource location)  nioPathCandidate = !text.startsWith(ResourceUtils.FILE_URL_PREFIX); } catch (FileSystemNotFoundException ex) { // URI scheme not registered for NIO (let\u0026#39;s try URL  // protocol handlers via Spring\u0026#39;s resource mechanism).  } } this.resourceEditor.setAsText(text); Resource resource = (Resource) this.resourceEditor.getValue(); if (resource == null) { setValue(null); } else if (nioPathCandidate \u0026amp;\u0026amp; !resource.exists()) { setValue(Paths.get(text).normalize()); } else { try { setValue(resource.getFile().toPath()); } catch (IOException ex) { throw new IllegalArgumentException(\u0026#34;Failed to retrieve file for \u0026#34; + resource, ex); } } }   我最后是如何知道path的值要配置成classpath:templates/，没有分号则SpringBoot会提示没有该文件的？  同样是上面的源码呀，哈哈，里面有一行resource.getFile().toPath()，看到这一行时，我就开始知道是因为我少了一个反斜杠最后导致SpringBoot提示文件夹不存在。\n实际上使用Java原生的API是不存在这个问题的，下面两个输出都为true：\n1 2 3 4  System.out.println(Files.exists(Paths.get(\u0026#34;C:\\\\Users\\\\wujj\\\\Desktop\\\\Tmp5\u0026#34;))); System.out.println(Files.exists(Paths.get(\u0026#34;C:\\\\Users\\\\wujj\\\\Desktop\\\\Tmp5\\\\\u0026#34;)));   后续：\n一顿分析猛如虎，最后发现根本就不是分析的情况，只因为我的templates文件是空的，Idea没有给我拷贝到target目录下，而Spring的Resource类是判断二进制文件的目录是否存在templates文件夹。\n我为什么会分析错呢？？？因为我第一次猜测是Path只能接受文件，所以我在template目录下创建了一个文件，然后进行测试，发现Path确实能正确的接受，所以我认为Path能接受文件。然后我觉得很奇怪，不可能说只能接受文件不能接受目录，所以我分析是因为我少了最后的分号，这个时候我没有删除这个文件就进行了测试，发现确实可以，所以我认为就是因为少了分号。此时我没有再删除这个文件进行二次测试就下结论了。擦\n我找了一圈没有找到很好的方案解决这个问题（我不想再引入一些复杂的东西导致我Maven插件配置的乱七八糟），考虑到这个问题会在启动阶段暴露，所以我们知道有这个问题就好了，尽量不要在resources创建空文件夹，然后在application.yml中配置这个文件夹。\n","description":"","id":130,"section":"notes","tags":null,"title":"application.yml更优雅写法及遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/application.yml%E6%9B%B4%E4%BC%98%E9%9B%85%E5%86%99%E6%B3%95%E5%8F%8A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"打算下次再使用的时候系统整理一下这些知识，目前的话我总是在需要的时候才查找这些资料，查找后又没有整理，所以下次用的时候还需要查，非常的不方便。\n参考资料  Java Array、List、Set互相转化  ","description":"","id":131,"section":"notes","tags":null,"title":"Array、Set、List互转的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/arraysetlist%E4%BA%92%E8%BD%AC%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":" 官网下载最新版BIOS   https://cn.msi.com/Motherboard/support/B450M-MORTAR.html  格式化U盘为FAT32（很关键，已经踩过坑了），然后解压官网下载的压缩包，将压缩包内的2~3个文件拷贝到U盘的根目录。\n  进入Bios系统，选择M-Flash，然后后面的都是傻瓜式操作\n  参考资料  官方提供的视频资料  ","description":"","id":132,"section":"notes","tags":null,"title":"B450M主板升级BIOS","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E5%8D%87%E7%BA%A7bios/"},{"content":"BIOS系统中选择OverClocking（应该是这个吧，忘记了，是个大项），然后选择CPU配置，然后选择Svmmode，选择开启。\n参考资料  请问amd 2600+微星b450m怎么开虚拟化技术？  ","description":"","id":133,"section":"notes","tags":null,"title":"B450M主板开启AMD-V","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E5%BC%80%E5%90%AFamd-v/"},{"content":"参考资料  微星b450m迫击炮主板接线图解  ","description":"","id":134,"section":"notes","tags":null,"title":"B450M主板线如何插","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/physicalmachine/b450m%E4%B8%BB%E6%9D%BF%E7%BA%BF%E5%A6%82%E4%BD%95%E6%8F%92/"},{"content":"我以为这个是一个比较简单的工作，像Linux中调用一下nohup就好了，但是没想到方案中有很多代码我都不太懂：\n1 2 3 4 5 6 7  @echo off if \u0026#34;%1\u0026#34; == \u0026#34;h\u0026#34; goto begin mshta vbscript:createobject(\u0026#34;wscript.shell\u0026#34;).run(\u0026#34;%~nx0h\u0026#34;,0)(window.close)\u0026amp;\u0026amp;exit :begin java -jar -Dspring.profiles.active=local gateway.jar \u0026gt; log.txt   参考教程  bat脚本实现后台运行cmd命令 批处理文件 bat 后台运行  ","description":"","id":135,"section":"notes","tags":null,"title":"bat脚本后台启动程序","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/bat%E8%84%9A%E6%9C%AC%E5%90%8E%E5%8F%B0%E5%90%AF%E5%8A%A8%E7%A8%8B%E5%BA%8F/"},{"content":"最近研究基于注解的参数校验时接触了一些新的概念，整理一下。\nBean Validation Bean Validation是一整套关于数据验证的规范，JSR 303–Bean Validation规范。\nBean Validation定义了一系列元数据模型和API。Hibernate Validator是Bean Validation的参考实现，除了JSR 303规范中内置约束，还额外定义一些常用约束实现。\nBean Validation中的约束 常用：\n @Null @NotNull  少用：\n @Min(value) @Max(value) @Size(max, min) @Pattern(value) @Email @Length @Range @NotEmpty  未用：\n @AssertTrue @AssertFalse @Past @Future @Digits (integer, fraction) @DecimalMin(value) @DecimalMax(value)  在代码中校验 如下代码，其中validator可以从SpringBoot Context中获取，我已经验证过了。\n ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); Validator validator = factory.getValidator(); Set\u0026lt;ConstraintViolation\u0026lt;DemoDTO\u0026gt;\u0026gt; violations = validator.validate(dto); Bean Validation、Hibernate Validation、spring-boot-starter-validation关系 Bean Validation是Java中的一项标准，它通过一些注解表达了对实体的限制规则。通过提出了一些API和扩展性的规范，这个规范是没有提供具体实现的，希望能够Constrain once, validate everywhere。现在它已经发展到了2.0，兼容Java8。\nHibernate Validation实现了Bean Validation标准，里面还增加了一些注解，在程序中引入它我们就可以直接使用。\nSpring MVC也支持Bean Validation，它对Hibernate Validation进行了二次封装，添加了自动校验，并将校验信息封装进了特定的BindingResult类中，org.springframework.boot:spring-boot-starter-validation引入这个库，实现对bean的校验功能。\n参考资料   spring boot 参数校验这么做简洁实用\n  SpringBoot自定义请求参数校验\n讲述了Bean Validation与Hibernate Validation之间的关系，包含一些自定义Validator的代码及一些以编程的方式校验的代码。另外这篇文章的参考文档质量非常高，我有时间想去研究一下。\n  ","description":"","id":136,"section":"notes","tags":null,"title":"Bean Validation","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/bean-validation/"},{"content":"BeanPostProcessor是许多注解、Aware实现的最核心的技术，所以研究它的实现原理是非常有价值的，利于后面其他知识的学习。\n","description":"","id":137,"section":"notes","tags":null,"title":"BeanPostProcessor源码分析（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/beanpostprocessor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"今天在看一个Netty框架的源码时，看到了如下的代码：\n1 2 3 4 5 6  Channel channel = serverBootstrap.bind() .sync() .channel(); ALL_CHANNELS.add(serverChannel);   ALL_CHANNELS变量的作用是收集所有的Channel对象，然后在服务器关闭的时候一一关闭这些对象（这样貌似可以提供一定的扩展性，比如在关闭前一一通知到各个客户端服务器关闭的原因，方便客户端进行日志，但是我没有看到这样的应用）。\n我所担心的是此时的channel并非绑定后的channel，我之所以有这样的担忧是因为我忘记了bind时仍然仅只有NioServerSocketChannel可用，所以此时是绝对不存在另一个可用的channel的；其次在原生的NIO中也是存在先创建channel，再进行绑定的用法的：\n1 2 3 4 5 6  ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(7000)); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);   但是我觉得这种写法还是存在一定的问题，我比较中意下面的这种写法：\n1 2 3 4 5 6 7 8 9 10  // 监听服务器 ChannelFuture bindFuture = serverBootstrap.bind(nettyConfig.getSocketAddress()).sync(); bindFuture.addListener((ChannelFutureListener) future -\u0026gt; { if (future.isSuccess()) { log.info(\u0026#34;Bind Success On {}\u0026#34;, nettyConfig.getPortNumber()); allChannels.add(future.channel()); } });   ","description":"","id":138,"section":"notes","tags":null,"title":"bindFuture中的channel","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/bindfuture%E4%B8%AD%E7%9A%84channel/"},{"content":"为了尽量还原我GitBook的界面风格，我决定使用Hugo Book主题，按照如下代码启动了Hugo，发现整体上还是蛮让人满意的，左侧为目录树，右侧为具体的每个文档内容，而且目录树部分是可以折叠的，所以我决定研究一下hugo和这个主题。\n1 2 3 4 5 6 7 8  hugo new site mydocs; cd mydocs git init git submodule add https://github.com/alex-shpak/hugo-book themes/book cp -R themes/book/exampleSite/content . hugo server --minify --theme book --bind=\u0026#34;0.0.0.0\u0026#34; --baseUrl=\u0026#34;http://192.168.27.121:1313\u0026#34;   我遇到的第一个问题是，我无法控制目录树的显示状态。实验中我让content目录仅包含docs目录，目录树仍然可以呈现出来，这个和我理解的有很大的出入。最后经过观察，我明白了，每个docs目录下都有一个_index.md文件，这个文件决定了目录树的显示（目前的理解）。\n在随后的资料中，我发现我们可以通过content/menu/index.md文件，控制右侧的目录树显示。当然如果相要这份文件生效，还需要在config.toml中进行如下配置：\n [params] BookMenuBundle = '/menu' 这就是我对BookMenuBundle的第一次接触。我原本以为这是一个非常简单的配置，但是我随后发现Bundles似乎是一个很重要的概念，我决定研究一下这个东西。\ngit submodule add https://github.com/zzossig/hugo-theme-zdoc.git themes/zdoc\nhugo server \u0026ndash;minify \u0026ndash;theme zdoc\n","description":"","id":139,"section":"notes","tags":null,"title":"BookMenuBoundle简单配置的实验","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/bookmenuboundle%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"Bootstrap   option方法：设置ChannelOption，其将被应用到每个新创建的Channel的ChannelConfig。这些选项将会通过bind()或者connect()方法设置到Channel，不管哪个先被调用。不管哪个先被调用。这个方法在Channel已经被创建后再调用不会有任何的效果。支持的ChannelOption取决于使用的Channel类型。\n  attr方法：指定新创建的Channel的属性值。这些属性值是通过bind()或者connect()方法设置到Channel的，具体取决于谁最先被调用。这个方法在Channel被创建后将不会有任何效果。\n  ServerBootstrap  option childOption attr childAttr handler childHandler  从Channel中引导客户端 （大致就是服务端的ChannelHandler需要建立一个建立一个Bootstra与另一个服务器链接）\n假设服务器正在处理一个客户端的请求，这个请求需要服务器充当第三方系统的客户端。当一个应用程序（如一个代理服务器）必须要和组织现有的系统（如Web服务或者数据库）集成时，就可能发生这种情况。在这种情况下，将需要从已经被接受的子Channel中引导一个客户端Channel。\n可以创建新的Bootstrap实例，但是这不是最高效的解决方案，因为它要求你为每个新创建的客户端Channel定义另一个EventLoop。这会产生额外的线程，以及在已被接受的子Channel和护短端Channel之间交换数据时不可避免的上下文切换（可以理解这部分）。\n一个更好的解决方法是：通过将已被接受的子Channel的EventLoop传递给Bootstrap的group()方法来共享该EventLoop。因为分配给EventLoop的所有Channel都使用同一个线程，所以这避免了额外的线程创建，以及上下文切换。\n（可以，比较容易理解）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  BootstrapUtils.runServer(new SimpleChannelInboundHandler\u0026lt;ByteBuf\u0026gt;() { ChannelFuture connectChannel; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { Bootstrap bootstrap = new Bootstrap() .group(ctx.channel().eventLoop()) .channel(NioSocketChannel.class) .handler(new SimpleChannelInboundHandler\u0026lt;ByteBuf\u0026gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception { System.out.println(\u0026#34;Received data\u0026#34;); } }); bootstrap.connect(new InetSocketAddress(\u0026#34;www.baidu.com\u0026#34;, 80)); } @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception { if (connectChannel.isDone()) { // do something with the data  } } });   编写Netty应用程序的一个一般准则：尽可能地重用EventLoop，以减少线程创建所带来的开销。\nChannelOption与Attribute 可用的ChannelOption包括了底层连接的详细信息，如keep-alive、超时属性、缓冲设置。\nNetty应用程序通常与组织的专有软件集成在一起，而像Channel这样的组件可能甚至会在正常的Netty生命周期之外被使用。在某些常用的属性和数据不可用时，Netty提供了属性抽象（一个由Channel和引导类提供的集合）以及属性Key抽象（一个用于插入和获取属性值的泛型类）。使用这些工具，便可以安全地将任何类型的数据项与客户端和服务端Channel（包含ServerChannel的子Channel）相关联了。\n（不太理解）\n考虑一个用户跟踪用户和Channel质检的关系的服务器应用程序。这可以通过将用户id存储为Channel的一个属性来完成。类似的技术可以被用来基于用户的id将消息路由给用户，或者关闭活动较少的Channel。\n（不是太理解，我为什么不用userId到Channel的Map呢？）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  final AttributeKey\u0026lt;Integer\u0026gt; id = AttributeKey.valueOf(\u0026#34;ID\u0026#34;); Bootstrap bootstrap = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new SimpleChannelInboundHandler\u0026lt;ByteBuf\u0026gt;() { @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception { Integer integer = ctx.channel().attr(id).get(); // do something  } @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception { System.out.println(\u0026#34;Received data\u0026#34;); } }) .option(ChannelOption.SO_KEEPALIVE, true) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000) .attr(id, 123456); bootstrap.connect().syncUninterruptibly();   引导数据报 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  Bootstrap bootstrap = new Bootstrap() .group(new OioEventLoopGroup()) .channel(OioDatagramChannel.class) .handler(new SimpleChannelInboundHandler\u0026lt;DatagramPacket\u0026gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) throws Exception { // do something  } }); bootstrap.bind().addListener((ChannelFutureListener) future -\u0026gt; { });   ","description":"","id":140,"section":"notes","tags":null,"title":"Boostrap","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/boostrap/"},{"content":"理解同步不阻塞模型 Java NIO（同步不阻塞）：服务器实现模式为一个线程处理多个请求（链接），即客户端发送的连接请求会注册到多路复用器上，多路复用器轮询连接有IO请求就进行处理。\n应该就是c++的epoll模式的java实现吧。\nNIO有如下知识点：\n  NIO相关类都被放在了java.nio包及子包下，并且对原java.io包中的很多类进行改写。\n  NIO有三大核心部分：Channel、Buffer、Selector\n  NIO是面向缓冲区的，或者面向块编程的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩网络。\n  Java NIO的非阻塞模式，是一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等它完全写入（写到了Buffer里），这个线程同时可以去做别的事情。\n  通俗理解：NIO是可以做到用一个线程来处理多个操作。假设有10000个请求过来，根据实际情况，可以分配50或者100个线程来处理。不像BIO那样，非得分配10000个。\n  HTTP2.0使用了多路复用的技术，做到同一个链接并发处理多个请求，并且并发请求的数量比HTTP1.1大了好几个数量级。\n  NIO与BIO的比较   BIO以流的方式处理数据，而NIO以块的方式处理数据块，块IO的效率比流IO高很多\n  BIO是阻塞的，NIO是非阻塞的\n  BIO基于字节流和字符流进行操作，而NIO基于Channel和Buffer进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector用于监听多个通道的事件（比如链接请求、数据到达等），因此使用单个线程就可以监听多个客户端通道。\n  Select、Channel、Buffer关系 三者关系如下：\n  每个Channel都会对应一个Buffer\n  Selector对应一个线程，一个线程对应多个Channel\n  可以多个Channel注册到同一个Selector中\n  程序切换到哪个Channel是由事件决定的，Event就是一个重要的概念\n  Selector会根据不同的事件，在各个通道上切换\n  Buffer就是一个内存块，底层是有一个数组\n  数据的读取写入是通过Buffer，这个和BIO不一样，BIO中要么是数据流要么是输出流，不能双向，但是NIO的Buffer是可以读也可以写的，需要通过flip方法切换。\n  Channel是双向的，可以返回底层操作系统的情况，比如Linux底层的操作系统通道就是双向的\n  缓冲区 缓冲区（Buffer）：缓冲区本质上是一个可以读写数据的内存块，可以理解成一个容器对象（含数组），该对象提供了一组方法，可以轻松地使用内存块。缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态的变化情况。Channel提供从文件、网络读取数据的渠道，但是读取和写入的数据都必须经由Buffer。\nBuffer类及其子类   在NIO中，Buffer是一个顶层父类，它是一个抽象类，常用的Buffer子类如下：\n ByteBuffer ShortBuffer CharBuffer IntBuffer LongBuffer DoubleBuffer FloatBuffer    IntBuffer的一个简单的案例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class Main { public static void main(String[] args) { IntBuffer intBuffer = IntBuffer.allocate(5); for (int i = 0; i \u0026lt; intBuffer.capacity(); i++) { intBuffer.put(i); } intBuffer.flip(); while (intBuffer.hasRemaining()) { System.out.println(intBuffer.get()); } } }   Buffer类定义了所有的缓冲区都具有的四个属性来提供关于其所包含的数据元素的信息。  属性的含义如下：\n Capacity：可以容纳的最大数据量，在缓冲区创建时被设定并且不能改变 Limit：表示缓冲区的当前终点，不能会缓冲区超过Limit的位置进行读写操作，且Limit可以被修改 Position：下一个要被读或写的元素的索引，每次读写缓冲区数据都会改变此值，为下次读写做准备 Mark：标记  Buffer中常用的方法  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // capacity、position、limit的设置与获取 public final int capacity(); public final int position(); public final Buffer position(int newPosition); public final int limit(); public final Buffer limit(int newLimit); // 在当前的位置设置标记 public final Buffer mark(); // 将当前的位置设置为标记的位置 public final Buffer reset(); // 清除当前Buffer，即将各个标记恢复到初始状态，但是数据并没有真正擦除 public final Buffer clear(); // 翻转当前Buffer public final Buffer flip(); // 将position设置为0并丢弃mark public final Buffer rewind(); // 返回当前Buffer当前还有多少元素可读 public final int remaining(); // 判断当前Buffer是否有元素可读 public final boolean hasRemaining(); // 判断当前Buffer是否为只读缓冲区 public abstract boolean isReadOnly(); // 判断当前Buffer是否具有可访问的底层实现数组 public abstract boolean hasArray(); // 返回当前Buffer的底层实现数组 public abstract Object array(); // 返回当前Buffer的底层实现数组中第一个缓冲区元素的偏移量 public abstract int arrayOffset(); // 判断是否为直接缓冲区 public abstract boolean isDirect();   ByteBuffer中最常用的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 创建直接缓冲区 public static ByteBuffer allocateDirect(int capacity); // 设置缓冲区的初始容量 public static ByteBuffer allocate(int capacity); // 把一个数组放到缓冲区中使用 public static ByteBuffer wrap(byte[] array, int offset, int length); // 构造初始化位置offset和上界length的缓冲区 public static ByteBuffer wrap(byte[] array);   Channel相关知识 Channel的基础知识：\n  NIO的Channel类似于流，但是有如下区别：\n Channel可以同时进行读写，而流只能读或者只能写 Channel可以实现异步读写数据 Channel可以从缓冲区读数据，也可以写数据到缓冲区    常用的Channel类有：FileChannel、DatagramChannel、ServerSocketChannel、SockerChannel。\n  FileChannel用于文件的数据读写，DatagramChannel用于UDP的数据读写，ServerSocketChannel和SocketChannel用于TCP的数据读写。\n  理解ServerSocketChannel与SocketChannel 如下：\nFileChannel案例： FileChannel写案例：\n1 2 3 4 5 6 7 8 9  FileOutputStream fos = new FileOutputStream(\u0026#34;tmp.txt\u0026#34;); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put(\u0026#34;Hello, World!\u0026#34;.getBytes(StandardCharsets.UTF_8)); byteBuffer.flip(); fos.getChannel().write(byteBuffer);   FileChannel读案例：\n1 2 3 4 5 6 7 8 9 10  File file = new File(\u0026#34;tmp.txt\u0026#34;); FileInputStream fis = new FileInputStream(file); ByteBuffer byteBuffer = ByteBuffer.allocate((int) file.length()); fis.getChannel().read(byteBuffer); System.out.println(new String(byteBuffer.array()));   FileChannel复制文件的案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  File file = new File(\u0026#34;tmp.txt\u0026#34;); FileInputStream fis = new FileInputStream(file); FileOutputStream fos = new FileOutputStream(\u0026#34;tmp_copy.txt\u0026#34;); // 方案一 // ByteBuffer byteBuffer = ByteBuffer.allocate((int) file.length()); // fis.getChannel().read(byteBuffer); // byteBuffer.flip();  // fos.getChannel().write(byteBuffer);  // 方案二 ByteBuffer byteBuffer = ByteBuffer.allocate(4096); while (true) { byteBuffer.clear(); int read = fis.getChannel().read(byteBuffer); if (read == -1) { break; } byteBuffer.flip(); fos.getChannel().write(byteBuffer); }   FileChannel使用transformTo、transformFrom进行复制：\n1 2 3 4 5 6 7 8  File file = new File(\u0026#34;tmp.txt\u0026#34;); FileInputStream fis = new FileInputStream(file); FileOutputStream fos = new FileOutputStream(\u0026#34;tmp_copy3.txt\u0026#34;); // fis.getChannel().transferTo(0, file.length(), fos.getChannel()); fos.getChannel().transferFrom(fis.getChannel(), 0, file.length());   Buffer和Channel的注意事项和细节  ByteBuffer支持类型化的put和get，put放入什么类型，get就应该使用相应的数据类型来取出，否则可能有BufferUnderflowException异常  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ByteBuffer buffer = ByteBuffer.allocate(64); buffer.putInt(100); buffer.putLong(100); buffer.putChar(\u0026#39;你\u0026#39;); buffer.putShort((short) 100); buffer.flip(); System.out.println(buffer.getInt()); System.out.println(buffer.getLong()); System.out.println(buffer.getChar()); System.out.println(buffer.getShort());   可以将一个普通的Buffer转成只读的Buffer  1 2 3 4 5 6 7 8 9 10 11 12  ByteBuffer buffer = ByteBuffer.allocate(64); for (int i = 0; i \u0026lt; 64; i++) { buffer.put((byte) i); } buffer.flip(); ByteBuffer byteBuffer = buffer.asReadOnlyBuffer(); System.out.println(byteBuffer.getClass());    NIO还提供了MappedByteBuffer，可以让文件直接在内存（堆外的内存中进行修改），而如何同步到文件由NIO来完成。（实验中需要避免Idea的缓存对时间结果的观察）  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  RandomAccessFile raf = new RandomAccessFile(\u0026#34;tmp.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = raf.getChannel(); /* 参数一：FileChannel.MapMode.READ_WRITE，使用读写模式 参数二：0：可以直接修改的起始位置 参数三：5：映射到内存的大小（单位字节） */ MappedByteBuffer mbf = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5); mbf.put(0, (byte) \u0026#39;H\u0026#39;); mbf.put(1, (byte) \u0026#39;H\u0026#39;); mbf.put(2, (byte) \u0026#39;H\u0026#39;); mbf.put(3, (byte) \u0026#39;H\u0026#39;); mbf.put(4, (byte) \u0026#39;H\u0026#39;); channel.close(); raf.close();    NIO还支持通过多个Buffer（即Buffer数组）完成读写操作，即Scattering和Gatering（实验的过程中，因为Telnet配置的问题，体验并不是太好）   Scattering：将数据写入到buffer时，可以采用buffer数组，依次写入 Gathering：从buffer读取数据时，可以采用buffer数组，依次读取  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  InetSocketAddress inetSocketAddress = new InetSocketAddress(7000); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(inetSocketAddress); ByteBuffer[] byteBuffers = new ByteBuffer[]{ ByteBuffer.allocate(5), ByteBuffer.allocate(3)}; SocketChannel socketChannel = serverSocketChannel.accept(); // 客户端只发行8个字节（协商） int messageLength = 8; while (true) { // 读取数据  int byteRead = 0; while (byteRead \u0026lt; messageLength) { long bytes = socketChannel.read(byteBuffers); byteRead += bytes; Arrays.asList(byteBuffers).forEach(buffer -\u0026gt; { System.out.printf(\u0026#34;position=%4d, limit=%4d%n\u0026#34;, buffer.position(), buffer.limit()); }); } Arrays.asList(byteBuffers).forEach(Buffer::flip); // 回显数据  long byteWrite = 0; while (byteWrite \u0026lt; messageLength) { long bytes = socketChannel.write(byteBuffers); byteWrite += bytes; } Arrays.asList(byteBuffers).forEach(Buffer::clear); }   Selector   Netty的IO线程NioEventLoop聚合了Selector，可以同时并发处理成百上千个客户端连接。\n  Selector中的方法：\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 得到一个选择器对象 public static Selector open(); public abstract int selectNow() throws IOException; // 监控所有注册的通道，当其中有IO操作可以进行时，将对应的SelectionKey加入到内部集合中并返回 // 参数用来设置超时时间 public abstract int select() throws IOException; public abstract int select(long timeout) throws IOException; // 从内部集合中得到所有的SelectionKey public abstract Set\u0026lt;SelectionKey\u0026gt; selectedKeys(); // 唤醒Selector（不知道用于什么场景） public abstract Selector wakeup();   SelectionKey中的方法：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // 得到与之关联的Selector public abstract Selector selector(); // 得到与之关联的Channel public abstract SelectableChannel channel(); // 设置或改变监听事件 public abstract int interestOps(); public abstract SelectionKey interestOps(int ops); // 是否可以accept、read、write public final boolean isAcceptable(); public final boolean isReadable(); public final boolean isWritable();   ServerSocketChannel中的方法：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // 得到一个ServerSocketChannel通道 public static ServerSocketChannel open(); // 设置服务器端口号 public final ServerSocketChannel bind(SocketAddress local); public abstract ServerSocketChannel bind(SocketAddress local, int backlog); // 接受一个链接，返回达标这个链接的通道对象 public abstract SocketChannel accept(); // 设置阻塞或非阻塞模式，取值false表示采用非阻塞模式 public final SelectableChannel configureBlocking(boolean block); // 注册一个选择器并设置监听事件 public final SelectionKey register(Selector sel, int ops, Object att);   SocketChannel中的方法：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // 链接服务器 public abstract boolean connect(SocketAddress remote); // 如果connect方法链接失败，接下来就要通过该方法完成链接操作（不明所以） public abstract boolean finishConnect(); // 从通道读数据 public abstract int read(ByteBuffer dst); public final long read(ByteBuffer[] dsts); public abstract long read(ByteBuffer[] dsts, int offset, int length); // 往通道写数据 public abstract int write(ByteBuffer src); public final long write(ByteBuffer[] srcs); public abstract long write(ByteBuffer[] srcs, int offset, int length);    Selector、SelectionKey、ServerSocketChannel、SocketChannel关系梳理：\n  当客户端连接时，会通过ServerSocketChannel得到SocketChannel\n  将socketChannel注册到Selector上，register(Selector selector,int ops)，一个selector上可以注册多个SocketChannel\n  注册后返回一个SelectionKey，会和该Selector关联（集合）\n  Selector进行监听select方法，返回有事件发生的通道的个数\n  进一步得到个SelectionKey（有事件发生）\n  在通过SelectionKey反向获取SocketChannel（channel方法）\n  可以通过得到的channel，完成业务处理\n    AIO简介   在IO编程中，常用的两种模式：Reactor和Proactor，Java的NIO就是Reactor，当有事件触发时，服务端得到通知，进行相应的处理。\n  AIO引入异步通道的概念，采用了Proactor模式，简化了程序编写，有效的请求才启动线程，它的特点是先有操作系统完成后才通知服务端程序启动线程去处理，一般适用于链接数较多且连接时间较长的应用。\n  AIO还没有广泛的应用，Netty也是基于NIO而不是AIO。\n  零拷贝 （暂时不整理了，核心在于transformTo、transformFrom就是零拷贝方法）\n","description":"","id":141,"section":"notes","tags":null,"title":"Buffer、Channel与Selector","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/bufferchannel%E4%B8%8Eselector/"},{"content":"找不到就开发咯，相同类目下可以找到开发Converter的笔记。\n参考资料   EasyExcel ExcelDataConvertException:Can not find ‘Converter‘ support class ArrayList问题解决\n记录了一些EasyExcel默认支持的类型，我还没仔细看着。\n  ","description":"","id":142,"section":"notes","tags":null,"title":"Can Nof Find Converter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/can-nof-find-converter/"},{"content":" 官网  ","description":"","id":143,"section":"notes","tags":null,"title":"CAS相关资料整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/cas/cas%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"上一次实验中，让我最难以忘怀的每次重新搭建Kubernetes集群时都需要漫长的等待，即使我用了国内的仓库，也需要不停的等待。单纯的搭建K8s，使用阿里的仓库，时间是可以接受的。但是因为后面的装Flannel插件和Istio时及一些杂七杂八的东西时，时间真的受不了。使用国内的仓库，遇到最多的问题就是某个镜像的某些层拉取非常快，而其他的层就拉的非常的慢，我完全无法理解这个现象。\n我当时解决该问题的主要方案是，在一台机器上拉取镜像，然后推到我自己的Harbor仓库，然后在其他结点上拉取我Harbor中的镜像，重新打上Tag。这个方案工作量比较大，而且当时我的Harbor也并非处于一个稳定的环境，经常连带虚拟机一起都被我销毁了，所以体验非常的糟糕。\n重建Kubernetes集群，对我来说是一件非常频繁的事情，当集群出现了我意料之外的状况时，相比慢慢的排错，不如直接重建（主要是排错需要的知识储备不够）。所以我这次必须解决重建速度慢的问题。\n我这次准备了两个方案解决速度慢的问题，一个是透明代理，一个是高质量的使用Harbor。实践中透明代理的速度并不理想，只能达到200~600kb，而且使用透明代理时，依旧存在镜像部分层下载速度巨慢的情况（我不确定是不是我电脑或者我的网络环境造成的）。Harbor提供了类似与Nexus的代理仓库的东西，但是目前的版本只支持Docker Hub和镜像源本身也是使用Harbor的两种场景，非常巧合，K8s搭建时，使用的镜像源是gcr.io，无法被代理（貌似说最新的2.2.1增加了对部分镜像源的支持）。\n所以我最终选择的方案是：宿主机挂透明代理，一台虚拟机上拉取所有的镜像，然后push到我的Harbor。使用Kubedam初始化时指定仓库为我自己的Harbor仓库，这个方案有我之前方案的影子，只是细节处有些不同。我计划未来将这个方案脚本化，总之，我的目标还是能够快速的重建K8s、Istio集群。\n搭建Harbor   官网下载离线安装包，解压该离线包。\n  从harbor.yml.tmp复制一份harbor.yml文件，修改hostname、数据存储目录、日志存储目录，注释掉https相关的配置\n  执行./prepare，得到一份docker-compose.yml文件\n  执行./install.sh，完成镜像的加载，容器的启动。\n  遇到的问题：\n我在安装Harbor遇到的问题，绝大多数人应该都不会遇到。因为我考虑让Harbor的数据更安全，我通过Vagrant的同步目录同步到了主机上。在配置harbor.yml文件时，我将数据和日志文件指向了这个同步目录。结果就导致了harbor-db这个容器没有权限操作这个同步目录。\n对这个问题深入研究后发现一些有意思的东西：harbor-db会创建一个progress用户和一个input用户组，来操作数据目录，同时它会把数据目录的所有者修改为progress:input。但是，Vagrant的同步目录是不支持修改用户和用户组的（执行了chown指令后没有任何效果），这最终到时harbor-db容器一直报无权限。\n实际上对这个问题更深入研究，也会发现一些无法解释的问题。我将同步目录的权限全部设置为了777，并将所有者设置为root:root，而非默认的vagrant:vagrant。理论上讲，harbor-db容器的任何用户都可以操作这个目录了呀，但是它依旧会报错。我觉得这个报错可能不是系统报的，而是harbor-db的程序无法找到自己需要的用户和用户组为progress:input的数据目录，而报的错误。\n我最后决定不使用同步目录了，以后对Harbor所在的虚拟机操作谨慎些，定时同步下吧。又或者，未来有时间将Harbor迁移到J4125那台机器上也行。\n搭建Kubernetes 主节点  关闭防火墙  1 2 3 4  systemctl disable firewalld systemctl stop firewalld   关闭selinux  1 2 3 4 5 6 7 8  # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config   关闭交换分区  1 2 3 4 5 6 7  # 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab   修改内核参数  1 2 3 4 5 6 7  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system   重启后检查各台机器的状态   reboot sestatus swapon -s master节点  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubectl kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   初始化K8s（我执行的是如下指令，如果你没有自己的Harbor，建议参考参考资料部分提供的教程）   # 初次执行，需要将如下镜像拉取下来推送到自己的Harbor仓库 kubeadm config images list kubeadm config images pull docker tag k8s.gcr.io/kube-apiserver:v1.21.0 172.16.100.100:80/library/kube-apiserver:v1.21.0 docker tag k8s.gcr.io/kube-controller-manager:v1.21.0 172.16.100.100:80/library/kube-controller-manager:v1.21.0 docker tag k8s.gcr.io/kube-scheduler:v1.21.0 172.16.100.100:80/library/kube-scheduler:v1.21.0 docker tag k8s.gcr.io/kube-proxy:v1.21.0 172.16.100.100:80/library/kube-proxy:v1.21.0 docker tag k8s.gcr.io/pause:3.4.1 172.16.100.100:80/library/pause:3.4.1 docker tag k8s.gcr.io/etcd:3.4.13-0 172.16.100.100:80/library/etcd:3.4.13-0 docker tag k8s.gcr.io/coredns/coredns:v1.8.0 172.16.100.100:80/library/coredns/coredns:v1.8.0 docker push 172.16.100.100:80/library/kube-apiserver:v1.21.0 docker push 172.16.100.100:80/library/kube-controller-manager:v1.21.0 docker push 172.16.100.100:80/library/kube-scheduler:v1.21.0 docker push 172.16.100.100:80/library/kube-proxy:v1.21.0 docker push 172.16.100.100:80/library/pause:3.4.1 docker push 172.16.100.100:80/library/etcd:3.4.13-0 docker push 172.16.100.100:80/library/coredns/coredns:v1.8.0 kubeadm init \\ --image-repository 172.16.100.100:80/library \\ --kubernetes-version v1.21.0 \\ --pod-network-cidr=10.244.0.0/16 \\ --apiserver-advertise-address=172.16.100.101  配置kubectl工具   mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 获取加入集群的指令   kubeadm token create --print-join-command 从节点  安装kubeadm、kubelet  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   执行加入集群的指令（我直接从教程里Copy过来的）   kubeadm join 192.168.99.104:6443 --token ncfrid.7ap0xiseuf97gikl --discovery-token-ca-cert-hash sha256:47783e9851a1a517647f1986225f104e81dbfd8fb256ae55ef6d68ce9334c6a2 安装网络插件  翻墙下载配置文件（我计划将kube-flannel.yml文件中的image改为我本地harbor中的镜像），该操作每台机器都需要执行：   https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml 参考资料   CentOS 搭建 K8S，一次性成功，收藏了！\n核心参考了该教程。\n  Harbor下载地址\n  centos 7.0 查看selinux状态|关闭|开启\n  Linux开启与关闭Swap交换分区以及Putty命令行的基本操作\n  ","description":"","id":144,"section":"notes","tags":null,"title":"CentOS 7搭建Kubernetes（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/centos-7%E6%90%AD%E5%BB%BAkubernetes%E5%BA%9F%E5%BC%83/"},{"content":"我已经转到了PVE，VirtualBox和Vagrant相关的笔记已没有意义，故不再维护该笔记\n安装VirtualBox和Vagrant VirutalBox和Vagrant安装方式有很多，我比较推荐的是下载rpm包的方式安装。这样的VirtualBox和Vagrant的安装方式能够统一，如果对其他方案感兴趣，可以在我的废弃资料中找找，我之前有尝试过其他的方案。\n 使用如下地址下载资源（可以尝试去官网找下最新的资源）：   https://download.virtualbox.org/virtualbox/6.1.18/VirtualBox-6.1-6.1.18_142142_el8-1.x86_64.rpm https://releases.hashicorp.com/vagrant/2.2.15/vagrant_2.2.15_x86_64.rpm 资源下载好后，拖到服务器中，运行如下指令安装：   dnf -y install VirtualBox-6.1-6.1.18_142142_el8-1.x86_64.rpm dnf -y install vagrant_2.2.15_x86_64.rpm 官网下载Vagrant的CentOS 8的Box（Vagrant Box下载是有技巧的，使用官网提供的简单下载按钮，容易断流），注意要选择平台为VirtualBox。Vagrant的Box可以理解为Vagrant封装的系统镜像。下载完成后拖到服务器中，用如下指令将Box加载到Vagrant中，我下载了CentOS 7和CentOS 8，因为有时候新系统可能会出些奇怪的问题，且资料还不好找，所以就换着来。   # 参考下载地址，下载后将文件名改为centos7、centos8 https://app.vagrantup.com/generic/boxes/centos7/versions/3.2.14/providers/virtualbox.box https://app.vagrantup.com/generic/boxes/centos8/versions/3.2.14/providers/virtualbox.box vagrant box add --name centos7 7a1ba0be-378a-4d19-bc12-fbb8a21a27f0 vagrant box add --name centos8 c7a9dc13-f8f4-43ac-86fd-7155a2ac7a4c vagrant box list  启动一个虚拟机完成VirtualBox和Vagrant测试。这个过程中可能会遇到VirtualBox无法启动的问题，可以参考我另一篇文章。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  mkdir Test cd Test vagrant init tee Vagrant \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;centos7\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.name = \u0026#39;node\u0026#39; vb.memory = \u0026#34;1024\u0026#34; vb.cpus = 1 end end EOF vagrant up   接下来你会看到如下日志：   Bringing machine 'default' up with 'virtualbox' provider... ==\u0026gt; default: Clearing any previously set forwarded ports... ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running 'pre-boot' VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.2.44 default: VirtualBox Version: 6.1 ==\u0026gt; default: Machine already provisioned. Run `vagrant provision` or use the `--provision` ==\u0026gt; default: flag to force provisioning. Provisioners marked to run always will still run. 使用Vagrant集群脚本 这个脚本是我之前学习一些集群工具时开发的，它的优点是可以轻松改几行代码就启动一个小集群，因为我目前比较清晰的了解我们目前的需求，所以有针对的对这个脚本进行了一些改造。\n","description":"","id":145,"section":"notes","tags":null,"title":"CentOS 8安装VirtualBox和Vagrant，并配置Vagrant","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/centos-8%E5%AE%89%E8%A3%85virtualbox%E5%92%8Cvagrant%E5%B9%B6%E9%85%8D%E7%BD%AEvagrant/"},{"content":"关于代理的问题，现在已经让我非常的头疼了，我计划还是研究一下软路由，尽量让我的工具机流量全部走外网。另外，我可能还需要升级一下我搭梯子的能力，我感觉我现在的梯子没有跑满我的带宽，速度还是有点慢。\n20210218后续：\n即使有了软路由，有了透明代理，该需求仍然常见。\ndnf代理设置 打开/etc/dnf/dnf.conf，在[main]后添加：\n1 2 3 4 5 6 7 8 9 10 11 12  proxy=http://192.168.31.154:1080 proxy_username= proxy_password= tee -a /etc/dnf/dnf.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; proxy=http://192.168.31.154:1080 proxy_username= proxy_password= EOF    20200416补充：\n我习惯性的写https_proxy = http://192.168.31.154:1080/，结果遭遇了网络管制，我百思不得解，最后终于尝试发现是将proxy写成了http_proxy，但是dnf本身却没有报任何错误。这个很好理解，默认情况下是有网络管制的，我的配置项写错了，所以代理根本就没有起到作用，所以就走了默认情况。\n yum代理设置 vim /etc/yum.conf\n proxy=http://192.168.31.154:1080 wget代理设置 wget完整的配置文件位于/etc/wgetrc，不建议改这个文件，可以拷贝一份放在自己的家目录下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  tee ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = http://192.168.13.59:1080/ http_proxy = http://192.168.13.59:1080/ ftp_proxy = http://192.168.13.59:1080/ EOF # 这种写法不允许，需要研究下 tee -a ~/.wgetrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https_proxy = socks://127.0.0.1:1080/ http_proxy = socks://127.0.0.1:1080/ ftp_proxy = socks://127.0.0.1:1080/ EOF   git代理设置  git config --global http.proxy 'http://192.168.31.154:1080' git config --global https.proxy 'http://192.168.31.154:1080' 参考文档  为 dnf 设置代理 为wget命令设置代理  ","description":"","id":146,"section":"notes","tags":null,"title":"CentOS 8常用软件代理设置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos-8%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"},{"content":"CentOs拨号上网的需求并不常见，故不在维护该笔记\n操作步骤  指令如下   nmcli conn add con-name pppoe-home type pppoe ifname enp2s0 username 13022052202D396 password 123456 nmcli conn up pppoe-home nmcli conn modify pppoe-home con-name pppoe nmcli conn add con-name enp5s0 ifname enp4s0 type ethernet 我以前一直没有注意到，使用拨号上网的时候，竟然会多出来个这么个东西。\n遇到的问题  遇到如下问题：   -- Logs begin at Sat 2021-05-01 03:10:09 EDT, end at Sat 2021-05-01 04:00:09 EDT. -- May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.1813] manager: (enp2s0): new Ethernet device (/org/freedesktop/NetworkManager/Devices/3) May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.1829] device (enp2s0): state change: unmanaged -\u0026gt; unavailable (reason 'managed', sys-iface-state: 'external') May 01 03:10:14 localhost.localdomain NetworkManager[809]: \u0026lt;info\u0026gt; [1619853014.9689] device (enp2s0): state change: unavailable -\u0026gt; disconnected (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6788] device (enp2s0): carrier: link connected May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6798] device (enp2s0): Activation: starting connection 'pppoe-home' (d1402583-37ea-4cbd-890d-4061e6e66d1f) May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6800] device (enp2s0): state change: disconnected -\u0026gt; prepare (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6806] device (enp2s0): state change: prepare -\u0026gt; config (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;info\u0026gt; [1619855983.6813] device (enp2s0): state change: config -\u0026gt; ip-config (reason 'none', sys-iface-state: 'managed') May 01 03:59:43 MiWiFi-R4CM-srv NetworkManager[809]: \u0026lt;warn\u0026gt; [1619855983.6816] device (enp2s0): PPPoE failed to start: the PPP plugin /usr/lib64/NetworkManager/1.26.0-12.el8_3/libnm-ppp-plugin.so is not installed 解决方法从如下页面下载相应的dpm包，并进行安装。\n http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/ dnf -y install NetworkManager-ppp-1.26.0-12.el8_3.x86_64.rpm 我感觉我解决VirtualBox的问题时，给我自己留下了不少的技术资产，我已经用相关的知识定位解决了好几个问题了。\n复杂的问题 拨号成功后，我可以ping通8.8.8.8，也可以curl到www.baidu.com。目前我的网络拓补如下：\n这个时候发生了一些怪异的事情，我笔记本能ping通192.168.31.217，也能通过telnetl与其22端口建立连接，但是无法通过xshll建立ssh连接。这种现象我是第一次见，我很难在我的知识范围内找到一个合理的解释。\n不过不的不说，我J4125那台机器上是多网卡的，而且现在enp2s0作为了上网卡，在很多单网卡的机器中，流量都会默认从这个网卡出去。我觉得抓包分析，可能会看到这样的现象，但是J4125上的usb网卡，本来就是临时挂载一下，所以我懒得花精力去修复这个问题。\n参考资料   linux配置网络，nmcli配置法及直接修改配置文件法\n里面简单提了下nmcli支持拨号上网。\n  ","description":"","id":147,"section":"notes","tags":null,"title":"CentOS 8拨号上网","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos-8%E6%8B%A8%E5%8F%B7%E4%B8%8A%E7%BD%91/"},{"content":"我现在很少在不使用透明代理的情况下安装软件，故作废该笔记\n我一直以为CentOS在下载软件是会就近选择软件源，但是我今天更新软件时发现速度很慢，所以干脆一不做二不休，直接将软件源替换为国内的。\n操作步骤  备份/etc/yum.repos.d文件夹（备份是推荐带上年月日，最好再带上操作人）  1 2 3  cp -r /etc/yum.repos.d /etc/yum.repos.bck20210410   执行如下指令，更换配置文件中的属性：  1 2 3 4 5 6  sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\  -e \u0026#39;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g\u0026#39; \\  -i.bak \\  /etc/yum.repos.d/CentOS-*.repo    更新缓存  1 2 3  dnf makecache   最后更新一下系统软件   dnf update 参考资料  CentOS 镜像使用帮助 CentOS 8 设置国内安装源  ","description":"","id":148,"section":"notes","tags":null,"title":"CentOS 8配置软件源","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos-8%E9%85%8D%E7%BD%AE%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"content":"其实就是因为我将python的软连接换成了python3.6，改回来就好了。\n参考资料  解决 CentOS 7 使用 yum 命令提示语法错误  ","description":"","id":149,"section":"notes","tags":null,"title":"Centos7 YUM提示语法错误","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos7-yum%E6%8F%90%E7%A4%BA%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF/"},{"content":"使用yum install python-pip安装的pip甚至没有办法执行pip install --upgrade pip，这就导致这个版本的pip没有办法做任何事。最终找到下面的方案安装比较新的pip：\n sudo yum remove python-pip wget https://bootstrap.pypa.io/pip/2.7/get-pip.py sudo python get-pip.py Ansible文档中的一个放哪 和我目前的查不多\n curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py --user 废弃方案（版本过旧，无法使用） 指令如下：\n yum -y install epel-release yum install python-pip pip install --upgrade pip 参考资料   [Command \u0026ldquo;python setup.py egg_info\u0026rdquo; failed with error code 1 in /tmp/pip-build-*)[https://www.mlzhilu.com/archives/commandpythonsetuppyegginfofailedwitherrorcode1intmppip-build-]\n这个教程有两个方案，因为第一个方案已经解决我的问题了，所以第二个方案我就没有尝试。\n  centos 7 安装 pip\n  ","description":"","id":150,"section":"notes","tags":null,"title":"CentOS7中安装pip","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/centos7%E4%B8%AD%E5%AE%89%E8%A3%85pip/"},{"content":"我主要参考如下教程，该教程非常优秀，按照教程做，没有出现任何问题：\n[Linux]CentOS7.6更新内核\n在使用该教程时有一些注意事项：\n 移除旧内核时，可以使用rpm -qa | grep kernel查看系统已经按照了那些内核（教程有该指令） 如果在重启前移除旧内核，这时候时移除不掉的，会提示忽略正在运行内核 安装内核源时，我在http://elrepo.org/tiki/HomePage找到了指令  ","description":"","id":151,"section":"notes","tags":null,"title":"CentOS7升级内核到5.4","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B05.4/"},{"content":"我对这块算不上熟悉，只是因为需要高频率的在Linux系统和Windows系统之间交换文件，所以我想将Linux上的一个目录挂载到我本地。我尝试了NFS的方案，但是有一些问题不很好找到资料，所以我又尝试了smb的方案，smb的方案已经能满足我的需求了，具体操作如下：\n 安装samba，并设置开启启动   yum install samba systemctl enable smb systemctl start smb 将root用户添加到samba用户列表中   smbpasswd -a root 只有root用户运行smbpasswd程序时才可以使用-a选项，通过这个选项后跟上用户名可以往本地smbpasswd文件中添加用户，并且为该用户设置口令。如果smbpasswd文件中已经存在了该用户，则该指令可以为这个用户修改口令。所有加入到smb用户必须是在系统口令文件中（/etc/passwd）已经存在的，否则该操作将会失败。\n修改配置文件/etc/samba/smb.conf，追加如下配置：  1 2 3 4 5 6 7 8 9 10 11 12  [Kubernetes] comment = Kubernetes path = /root/Kubernetes valid users = root available = yes browseable = yes public = yes writable = yes printale = no write list = +staff   重启smb服务   systemctl restart smb 配置Windows客户端  （截图中出错了，应该是Kubernetes，截图截成了Kubenetes）\n遇到的问题   之前考虑的是NFS方案（实际上我没怎么考虑，就搜到的第一篇资料是NFS），但是这个方案在Win10客户端连接服务端的时候出了问题，还不好找资料解决，所以我就放弃了。\n  映射网络驱动器的时候，明明已经完成映射了（在我的电脑里可以看到），但是映射界面始终显示连接中，我最后果断关闭了，我觉得这个可能是个例。\n  小结 我对smb其实也是一知半解，但是现在这套方案能用就行啦，我暂时不想花费自己的时间去深入研究SMB，感觉太良妃自己的时间了。\n参考资料   Centos7配置smb服务root访问\n我主要参考的就是这一份资料。\n  CentOS 7下Samba服务器的安装与配置 \n这篇教程讲解了很多技术细节的东西，但是我暂时没有精力查看。\n  ","description":"","id":152,"section":"notes","tags":null,"title":"Centos7简单配置samba","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos7%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AEsamba/"},{"content":"这篇笔记不是针对CentOS7的\n操作步骤  常用指令   uanme -a # 查看当前内核版本 cat /etc/redhat-release # 查看当前系统版本 rpm -qa | grep kernel # 查看已安装的内核 yum repolist # 查看yum当前配置了哪些源 安装elrepo仓库，并查看仓库配置信息   rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm cat /etc/yum.repos.d/elrepo.repo 这一步中，我将elrepo仓库全部配置成enable了，按照教程，如果不配置的话需要在yum的搜索、查询、安装指令上加上--enablerepo=elrepo-kernel。额，实际上我执行这些指令的时候也加上了这行配置。\n查看新的内核包，及查看kernel-lt和kernel-ml的信息。   yum search --enablerepo=elrepo-kernel lt # 这条指令没有给到我有用的信息，返回的内容太多了 yum info --enablerepo=elrepo-kernel kernel-lt kernel-ml 删除旧版本的内核开发工具，并安装新版本的内核，及内核开发工具   yum remove kernel-tools kernel-tools-libs kernel-headers kernel-devel yum install --enablerepo=elrepo-kernel -y kernel-ml kernel-ml-headers kernel-ml-devel kernel-ml-tools kernel-ml-tools-libs kernel-devel-ml yum install --enablerepo=elrepo-kernel -y kernel-lt kernel-lt-headers kernel-lt-devel kernel-lt-tools kernel-lt-tools-libs kernel-devel 因为我那个折腾人的螃蟹2.5G网卡的驱动，必须要求内核在5.6以上，所以我选择了ml内核。\n设置grub（这部分我按教程瞎操作的，我对grub、grub2还不太熟悉）   grub2-set-default 0 grub2-mkconfig -o /boot/grub2/grub.cfg reboot 移除旧版内核（如果能指定版本更好，否则可能有清除到一些有用的工具包）   yum remove kernel-core-4.18.0 kernel-devel-4.18.0 kernel-tools-libs-4.18.0 kernel-headers-4.18.0 yum remove kernel-lt kernel-lt-devel kernel-lt-tools-libs kernel-lt-headers yum remove kernel-ml kernel-ml-devel kernel-ml-tools-libs kernel-ml-headers 踩过的坑  kernel-ml输入成kernel-mt，导致搜索不到相关的开发包  参考资料   Welcome to the ELRepo Project\n我在这个网站学习了设置CentOS 8的ElRepo仓库。\n  CentOS7.6更新内核\n在该教程中学习了很多知识，比如：\n 查看当前安装的内核版本指令 elrepo是一个企业级Linux的仓库 lt表示longterm（长时间支持版本），ml表示mainline（主线版本）    Centos 8升级内核版本\n我一开始使用的是这个教程，但是这个教程只给了内核的安装，没有讲到内核工具包，所以我又上其他教程中补充了一些资料。\n  ","description":"","id":153,"section":"notes","tags":null,"title":"CentOS8升级内核到5.12","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos8%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B05.12/"},{"content":"这个是我目前找到的最优雅的方式了，需要重启后生效（重启后命令提示符前的主机名也会改变）：\n hostnamectl set-hostname kerrydb 参考资料  Centos 7修改hostname浅析  ","description":"","id":154,"section":"notes","tags":null,"title":"CentOS修改主机名称","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0/"},{"content":"这是一个非常简单的指令，但是我总是拼不对，干脆记下来算了。\n systemctl stop firewalld systemctl disable firewalld 20210502后续：\n我今天才知道firewalld和iptables不是同一个东西，虽然他们都是基于Netfilter的内核数据包管理工具。\n因为firewalld默认是拒绝所有进入的流量（除了22号端口），而iptables默认是允许所有的流量的，所以我在进行实验的时候，经常需要关闭firewalld。（其实我还是有点疑惑，我看结构图，firewalld最终也是调回了iptables的命令，可以真正使用iptables -L去查看的时候，又看不到任何的规则）\n在搭建OpenVPN时，很有趣，配置完iptables后，往往会关闭防火墙，我一直好奇，防火墙都被关闭了，那数据包又该如何如何按照规则分配呢，现在这个问题明晰了。\n还有一个有趣的问题：我之前一直搜索的是如何关闭防火墙，所以搜索到了上面的指令，如果我搜索如何关闭iptables的话，可以得到下面的指令：\n service iptables stop 参考资料  Linux CentOS7关闭防火墙 CentOS6关闭开启防火墙 CentOS打开关闭防火墙  ","description":"","id":155,"section":"notes","tags":null,"title":"CentOS关闭防火墙","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99/"},{"content":"需求极少，不在维护\nWindows Linux 参考参考资料。\n参考资料  Linux查看网卡是千兆还是万兆网卡 查看网卡是百兆还是千兆  ","description":"","id":156,"section":"notes","tags":null,"title":"CentOS和Window查看网卡是百兆还是千兆","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos%E5%92%8Cwindow%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1%E6%98%AF%E7%99%BE%E5%85%86%E8%BF%98%E6%98%AF%E5%8D%83%E5%85%86/"},{"content":"CentOS安装Python实际上有更简单的方法，就是通过yum安装，但是这种方法安装的版本和我win机器的版本不一致，所以我选择了用源码安装。\n操作步骤  安装编译环境  1 2 3 4 5  yum -y groupinstall development yum install -y zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel yum install libffi-devel -y   去官网下载源码，我下载的是GZipped source tarball：   https://www.python.org/downloads/release/python-389/ # 3.8.9版本的 wget https://www.python.org/ftp/python/3.8.9/Python-3.8.9.tgz 解压源码，进行配置，然后编译：   tar xf Python-3.8.9.tgz \u0026amp;\u0026amp; cd Python-3.8.9 ./configure --prefix=/usr/local/python3 make \u0026amp;\u0026amp; make install 添加Python到环境变量中：   cd /etc/profile.d echo 'export PATH=$PATH:/usr/local/python3/bin/' \u0026gt; python3.sh source /etc/profile 其他知识   添加环境变量的时候是单独为该程序在/etc/profile.d目录创建一个文件去修改环境变量，这样是方便以后查找和取消添加的环境变量。我之前是直接去更改/etc/profile文件，博文提到的这种方式更便于管理。\n  某些场景下可能需要重装，比如我在安装后通过pip拉取工具的时候，报了ModuleNotFoundError: No module named '_ctypes'错误（相关笔记整理在Python分类下的其他文章中），我需要按照教程下载一些CentOS包，然后重新编译安装，指令如下：\n   make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 参考资料   CentOS 7安装Python教程\n  CentOS 7安装Python3 笔记\n这是我很久前收藏的一篇博文，我应该没有按照这个方案去做。\n  ","description":"","id":157,"section":"notes","tags":null,"title":"CentOS安装Python 3.x","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/centos%E5%AE%89%E8%A3%85python-3.x/"},{"content":"指令如下，这是我目前找到的最优雅，最快速的方法：\n nmcli connection modify eth0 \\ ipv4.dns 192.168.31.199 \\ ipv4.method manual \\ ipv4.gateway 192.168.31.199 \\ connection.autoconnect yes nmcli c up eth0 nmcli connection modify eth0 \\ ipv4.addresses 192.168.23.60/24 \\ ipv4.dns 192.168.23.65 \\ ipv4.method manual \\ ipv4.gateway 192.168.23.65 \\ connection.autoconnect yes nmcli c up eth0 # 访问外网（下载软件） nmcli connection modify eth0 \\ ipv4.addresses 192.168.23.69/24 \\ ipv4.dns 192.168.23.65 \\ ipv4.method manual \\ ipv4.gateway 192.168.23.65 \\ connection.autoconnect yes nmcli c up eth0 # 访问内网 nmcli connection modify eth0 \\ ipv4.addresses 192.168.23.69/24 \\ ipv4.dns 192.168.20.21 \\ ipv4.method manual \\ ipv4.gateway 192.168.23.1 \\ connection.autoconnect yes nmcli c up eth0 nmcli connection modify eth0 \\ ipv4.addresses 172.20.11.206/24 \\ ipv4.dns 172.20.11.210 \\ ipv4.method manual \\ ipv4.gateway 172.20.11.210 \\ connection.autoconnect yes nmcli c up eth0 后续：\n一次巧合的机会，我发现我的一台服务器的/etc/resolv.conf文件中的nameserver会自动更新为默认的ip，我注意到这台机器的/etc/resolv.conf是由一个脚本管理的（并非NetworkManager），我猜想可能是我的失误操作，导致了这个问题（我记得我曾在一台机器上安装过NetPlan）。所以我又手动执行了一次上面的代码。\n20220115后续：\n今天需要再用一下虚拟机，因为之前网络升级，所以修改了网段，所有虚拟机网络都需要重新配置一下。结果我虚拟机网络配好了后，死活连不上，且自己ping自己都无法ping通。我翻看了上一个后续，我以为是该问题导致的。所以我想办法关闭了NetworkManager，关闭NetworkManager后，是无法使用nmcli指令的，所以我分析不是这个问题导致的。\n最后几经调试，我发现我把192.168.31.151写成了191.168.31.151，我也不知道这是一个什么神奇而又愚蠢的错误。\n nmcli c m eth0 \\ ipv4.addresses 191.168.31.151/24 \\ ipv4.gateway 192.168.31.199 \\ 参考资料  Centos8 配置静态IP  ","description":"","id":158,"section":"notes","tags":null,"title":"CentOS快速配置多台机器为静态地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8%E4%B8%BA%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80/"},{"content":"需求极少，不在维护\n事情的起因是这样的，我发现我Vagrant的虚拟机都会有两张网卡，经过分析我发现第一张网卡是用于nat，第二张网卡是用于我设置的host_only。但是我目前只需要使用host_only，我尝试去删除eth0，结果导致了我虚拟机无法访问，这个是很好理解的：VirtualBox使用host_only模式的时候，主机无法与虚拟机通信。\n为了正常进行实验，我决定设置路由，让我的请求走eth1，我执行的代码如下：\n route add -net 192.168.56.0/24 dev eth1 route add -net 192.168.41.0/24 dev eth1 route add -net 192.168.31.0/24 dev eth1 实验结果是怎样的，192.168.56.1、192.168.41.1都可以正常的ping通，192.168.31.1无法正常的ping通。\n我没有进行抓包分析，但是host_only模式真的是霸道啊，我其实已经在3400G上设置了ip转发，我还检查了3400G的路由信息，这样都没办法ping通。我以前一直以为，host_only模式就是一台虚拟机连接上了虚拟出来的网卡，这个虚拟网卡和普通的物理网卡是相似的，是可以进行ip转发的，现在看来不是这样的。\n我目前的方案是vagrant使用了public_network模式，并指定ip地址，这样非常省事，我可以在我的笔记本上直接ping到我的虚拟机。\n","description":"","id":159,"section":"notes","tags":null,"title":"CentOS添加默认路由","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E6%B7%BB%E5%8A%A0%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1/"},{"content":"需求极少，不在维护\n我使用的是ip link set enp0s3 up，效果非常好。另外ifdown enp0s8指令不好使，文档里也说了，ifdown不支持以enp打头的网卡，这个坑被我踩了。\nnmcli c down enp0s3是我之后要尝试的方式，我比较喜欢nmcli系列的指令。\n参考资料  Linux 中如何启用和禁用网卡？  ","description":"","id":160,"section":"notes","tags":null,"title":"CentOS禁用网卡","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos%E7%A6%81%E7%94%A8%E7%BD%91%E5%8D%A1/"},{"content":"相关需求非常的冷门，即使是我自己，也不常用，所以不在维护该笔记\n我现在最后悔的事情就是买软路由的时候选了R8125 2.5G网卡，这个网卡是在是太折腾人了。CentOS、PVE上都需要手动的编译安装驱动，ESXI上表现的总是有问题（ESXI 6.7本身也有很多Bug）。不过在折腾这张网卡的时候，也接触了一些较高级的知识，算因祸得福吧。\n操作步骤  准备相关工具：   dnf group install \u0026quot;Development Tools\u0026quot; 官网下载驱动，拖到机器中执行如下指令，我选择的是   tar -jxvf r8125-9.005.01.tar.bz2 cd r8125-9.005.01 ./autorun.sh 编译完成后（解决完各种问题后），执行如下指令，完成驱动安装和检查：   modprode r8125 lsmod | grep r8125 modinfo r8125 reboot 解决的各种问题 我按照时间顺序记录，建议倒序阅读，因为后面的方案可以解决前面的所有问题！！！\n 第一个问题   [root@MiWiFi-R4CM-srv r8125-9.005.01]# ./autorun.sh Check old driver and unload it. Build the module and install make[2]: *** /lib/modules/4.18.0-240.el8.x86_64/build: No such file or directory. Stop. make[1]: *** [Makefile:171: clean] Error 2 make: *** [Makefile:48: clean] Error 2 果断定位是kernel-devel工具没装，按照解决VirtualBox相关问题时的方法安装后，发现该报错消失。\n第二个问题   /root/r8125-9.005.01/src/r8125_n.c:62:10: fatal error: linux/pci-aspm.h: No such file or directory #include \u0026lt;linux/pci-aspm.h\u0026gt; ^~~~~~~~~~~~~~~~~~ compilation terminated. make[3]: *** [scripts/Makefile.build:316: /root/r8125-9.005.01/src/r8125_n.o] Error 1 make[2]: *** [Makefile:1544: _module_/root/r8125-9.005.01/src] Error 2 make[1]: *** [Makefile:163: modules] Error 2 make: *** [Makefile:41: modules] Error 2 查了一些资料后意识到是内核版本的问题，果断升级（花了很长时间），参考我相关的资料进行内核升级。\n参考资料   给PVE6添加Realtek 8125 2.5G网卡驱动\n学习了modprode指令的使用，其实我现在也不知道是不是这个指令起的作用，但是原教程给的load module指令，不可用，而且几乎查不到相关的资料。\n  CentOS8 手工编译安装 Realtek 8125 2.5G网卡驱动\n我遇到的问题，这篇教程一个都没有提，糟心。我只学到了大概了流程。\n  ","description":"","id":161,"section":"notes","tags":null,"title":"CentOS编译R8125网卡驱动","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos%E7%BC%96%E8%AF%91r8125%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"content":"我开发的点外卖提醒机器人，在半夜提醒点外卖了，我的定时脚本如下：\n 30,32,35 11 * * 1-6 /root/Software/launch/dist/launch 45,50 17 * * 1-6 /root/Software/launch/dist/launch 我定时任务肯定是没有任何问题的，所以感觉是服务器时间出问题了，所以打算修复一下这个问题：\n # 检查当前时区 timedatectl status | grep 'Time zone' # 输出为： Time zone: America/New_York (EDT, -0400) # 设置硬件时钟调整为本地时钟一致 timedatectl set-local-rtc 1 # 设置时区为上海 timedatectl set-timezone Asia/Shanghai # 查看时间和时区 date \u0026amp; timedatectl status | grep 'Time zone' # 输出为： Tue Jun 29 09:27:36 CST 2021 Time zone: Asia/Shanghai (CST, +0800) 参考资料  CentOS 7同步时间的2种方法  ","description":"","id":162,"section":"notes","tags":null,"title":"CentOS设置时区","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA/"},{"content":"有了更优雅，更便利的方案\nCentOS 8版本  在/etc/sysconfig/network-scripts下，找到你需要配置的网卡配置文件，打开编辑：   TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static #修改：将dhcp修改为stati表示使用静态ip DEFROUTE=yes IPADDR=192.168.128.129 #新增：设置IP地址 NETMASK=255.255.255.0 #新增：设置子网掩码 GATEWAY=192.168.128.1 #新增：设置网关 DNS1=114.114.114.114 #新增：设置dns IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens33 UUID=e4987998-a4ce-4cef-96f5-a3106a97f5bf DEVICE=ens33  IPADDR=192.168.56.101 NETMASK=255.255.255.0 DNS1=114.114.114.114 GATEWAY=192.168.56.100  使用nmcli c reload命令重启网络  CentOS 7版本 同上，修改/etc/sysconfig/network-scripts下的问题，然后执行：\n service network restart； 我没有尝试使用nmcli c reload，以后有机会尝试一下。\n参考教程  centos8 网络配置 centos7设置静态IP地址  ","description":"","id":163,"section":"notes","tags":null,"title":"CentOS设置静态ip（已废弃）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip%E5%B7%B2%E5%BA%9F%E5%BC%83/"},{"content":"这个不整理了，照着教程做，什么问题都没有遇到。\n参考资料  CentOS 8.x 和 RHEL 8.x 更改默认启动项  ","description":"","id":164,"section":"notes","tags":null,"title":"CentOS设置默认启动项（引导项）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%90%AF%E5%8A%A8%E9%A1%B9%E5%BC%95%E5%AF%BC%E9%A1%B9/"},{"content":"需求极少，不在维护\n我之前管理VPS时也遇到这样的需求了，整理一下：\n pkill -kill -t pts/0 参考资料  linux下踢掉一个用户（心跳包解决ssh断开连接）  ","description":"","id":165,"section":"notes","tags":null,"title":"CentOS踢掉一个用户","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/centos%E8%B8%A2%E6%8E%89%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7/"},{"content":"该技术是学习Kubernetes的存储卷时要用到的。\n服务端配置 参考资料 ","description":"","id":166,"section":"notes","tags":null,"title":"CentOS部署NFS","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/centos%E9%83%A8%E7%BD%B2nfs/"},{"content":"Sharable的应用案例 先直观感受一下该注解的影响：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public static class Handler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception { System.out.println(msg); } } public static void main(String[] args) { Handler handler = new Handler(); BootstrapUtils.runServer(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(handler); } }); }   如上代码，在第二个客户端连接的时候，会报如下错误：\n io.netty.channel.ChannelPipelineException: shareable.Server$Handler is not a @Sharable handler, so can't be added or removed multiple times. at io.netty.channel.DefaultChannelPipeline.checkMultiplicity(DefaultChannelPipeline.java:600) at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:202) at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:381) at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:370) at shareable.Server$1.initChannel(Server.java:27) at shareable.Server$1.initChannel(Server.java:24) at io.netty.channel.ChannelInitializer.initChannel(ChannelInitializer.java:129) at io.netty.channel.ChannelInitializer.handlerAdded(ChannelInitializer.java:112) at io.netty.channel.AbstractChannelHandlerContext.callHandlerAdded(AbstractChannelHandlerContext.java:938) at io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:609) at io.netty.channel.DefaultChannelPipeline.access$100(DefaultChannelPipeline.java:46) at io.netty.channel.DefaultChannelPipeline$PendingHandlerAddedTask.execute(DefaultChannelPipeline.java:1463) at io.netty.channel.DefaultChannelPipeline.callHandlerAddedForAllHandlers(DefaultChannelPipeline.java:1115) at io.netty.channel.DefaultChannelPipeline.invokeHandlerAddedIfNeeded(DefaultChannelPipeline.java:650) at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:514) at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429) at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute$$$capture(AbstractEventExecutor.java:164) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469) at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) 如果在Handler上增加@Shareable注解，就不会存在这个问题。\nChannelHandlerAdapter对其的支持 ChannelHandlerAdapter仅包含如下两个有价值的实现：\n1 2 3 4 5  protected void ensureNotSharable() { } public boolean isSharable() { }   这两个方法在什么时候会用到呢？在pipeline的addLast方法中有如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) { final AbstractChannelHandlerContext newCtx; synchronized (this) { checkMultiplicity(handler); // other code  } } private static void checkMultiplicity(ChannelHandler handler) { if (handler instanceof ChannelHandlerAdapter) { ChannelHandlerAdapter h = (ChannelHandlerAdapter) handler; if (!h.isSharable() \u0026amp;\u0026amp; h.added) { throw new ChannelPipelineException( h.getClass().getName() + \u0026#34; is not a @Sharable handler, so can\u0026#39;t be added or removed multiple times.\u0026#34;); } h.added = true; } }   isSharable的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12  public boolean isSharable() { Class\u0026lt;?\u0026gt; clazz = getClass(); Map\u0026lt;Class\u0026lt;?\u0026gt;, Boolean\u0026gt; cache = InternalThreadLocalMap.get().handlerSharableCache(); Boolean sharable = cache.get(clazz); if (sharable == null) { sharable = clazz.isAnnotationPresent(Sharable.class); cache.put(clazz, sharable); } return sharable; }   InternalThreadLocalMap.get().handlerSharableCache()为一个空Map，其资源是在cache.put(clazz, sharable)中放置进去的。搞SpringBoot多了，总感觉有些东西是在启动时通过反射之类的方法加载的，我还在找@Sharable的实现类，没想到用了这么简单的一个方案处理。\nChannelHandlerAdapter中其他实现 1 2 3 4 5 6 7 8  @Skip @Override @Deprecated public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.fireExceptionCaught(cause); }   已经废除了，研究价值不是很大，@Skip比较新颖，有点意思。\n参考资料  Netty 之 @Sharable  ","description":"","id":167,"section":"notes","tags":null,"title":"ChannelHandlerAdapter与@Sharable","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/channelhandleradapter%E4%B8%8Esharable/"},{"content":"每个Channel都拥有一个与之相关联的ChannelPipeline，其持有一个channelHandler的实例链。在默认的情况下，ChannelHandler会把对它的方法的调用转发给链中的下一个channelHandler。\n因此，如果exceptionCaught()方法没有被该链中的某处实现，那么所接收的异常将会被传递到ChannelPipeline的尾端并被记录。为此，你的应用程序应该提供至少有一个实现了exceptionCaught()方法的ChannelHandler。\n","description":"","id":168,"section":"notes","tags":null,"title":"ChannelHandler中不处理异常会发生什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/channelhandler%E4%B8%AD%E4%B8%8D%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88/"},{"content":"我在阅读Netty实战的时候有这样一段描述：\n我觉得这段话和这张图描述的并不够严谨，因为在我的实验中，前后是要看是入站还是出站数据的，如果是入站数据，下一个ChannelHandler在当前ChannelHandler的右侧，如果是出站数据，下一个ChannelHandler在当前ChannelHandler的左侧。我实验代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  ch.pipeline() .addLast(new ChannelInboundHandlerAdapter() { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;Running 1\u0026#34;); ctx.fireChannelRead(msg); } }) .addLast(new ChannelOutboundHandlerAdapter() { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\u0026#34;Running 2\u0026#34;); } }) .addLast(new ChannelInboundHandlerAdapter() { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;Running 3\u0026#34;); ctx.write(msg); } }) .addLast(new ChannelOutboundHandlerAdapter() { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\u0026#34;Running 4\u0026#34;); } });   ","description":"","id":169,"section":"notes","tags":null,"title":"ChannelHanlerContext调用写方法消息的走向","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/channelhanlercontext%E8%B0%83%E7%94%A8%E5%86%99%E6%96%B9%E6%B3%95%E6%B6%88%E6%81%AF%E7%9A%84%E8%B5%B0%E5%90%91/"},{"content":"Channel的声明周期 Channel的生命周期分为如下状态：\n ChannelUnregistered：Channel被创建还未注册到EventLoop。 ChannelRegisterted：Channel已经注册到EventLoop。 ChannelActive：Channel处于活动状态（已经连接到它的远程节点），可以接收和发送数据了。 ChannelInActive：Channel没有连接到远程节点。  当这些状态发生变化时，将会产生对应的事件。这些事件会被转发给ChannelHandler。\nChannelHandler的生命周期 如下为ChannelHandler定义的生命周期操作，当ChannelHandler被添加到ChannelPipeline或者从ChannelPipeline中移除时会调用这些操作：\n handlerAdded：当把ChannelHandler添加ChannelPipeline时调用 handlerRemoved：当把ChannelHandler移除ChannelPipeline时调用 exceptionCaught：处理中有异常时调用  ChannelInboundHandler ChannelInboundHandler的生命周期方法：\n channelRegistered channelUnregistered channelActive channelInactive channelReadComplete：当Channel上的一个读操作完成时被调用（如何理解） channelRead：当从Channel读取数据时被调用 channelWritabilityChanged（如何理解） userEventTriggered（如何理解）  对channelReadComplete的理解：当所有可读的字节都已经从Channel中读取之后，将会调用该回调方法。所以在channelReadComplete被调用之前能看到多次channelRead的调用。\n理解channelWritabilityChanged 当Channel的可写状态发生改变时被调用。用户可以确保写操作不会完成得太快（以避免发生OutOfMemoryError）或者可以在Channel变为再次可写时恢复写入。可以通过调用Channel的isWritable方法来检测Channel的可写性。与可写性相关的阈值可以通过Channel.config().setWriteHighWaterMark()和Channel.config().setWriteLowWaterMark()方法来设置。\n（需要结合案例理解）\n理解userEventTriggered 当ChannelInboundHandler.fireUserEventTriggered()方法被调用时调用，因为一个POJO被传经了ChannelPipeLine。\n（需要结合案例理解）\n显示释放和池化 当实现ChannelInBoundHandler时并重写channelRead方法时，需要在方法中显示释放并池化ByteBuf实例相关的内容：\n1 2 3 4 5  public void channelRead(ChannelHandlerContext ctx, Object msg) { ReferenceCountUtil.release(msg); }   Netty使用WARN级别的日志记录未释放的资源。\nChannelOutboundHandler ChannelOutboundHandler的一个强大的功能是可以按需推迟操作或者事件，这使得可以通过一些复杂的方法类处理请求。例如，如果到远程节点的写入被暂停了，可以推迟冲刷操作并在稍后继续。\n bind： connect： disconnect： close： deregister： read： flush： write：  在书中找到的ChannelOutboundHandler案例：\n1 2 3 4 5 6 7 8 9  public class DiscardOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { ReferenceCountUtils.release(msg); promise.setSuccess(); } }   ChannelPromise与ChannelFuture ChannelOutboundHandler中的大部分方法都需要一个ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个子类，其定义了一些可写的方法，如setSuccess和setFailure，从而是ChannelFuture不可变。\nChannelHandler适配器 在ChannelInboundHandlerAdapter和ChannelOutboundHandlerAdapter中所提供的方法体现了其相关联的ChannelHandlerContext上的等效方法，从而将事件转发到ChannelPipeline中的下一个ChannelHandler中\n（什么意思呀）\n资源管理 Netty挺了ResourceLeakDetector来诊断潜在的资源泄漏问题。\n（目前没有接触过）\n1 2 3 4 5 6 7 8 9  public class DiscardOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { ReferenceCountUtils.release(msg); promise.setSuccess(); } }   重要的是不仅要释放资源，还要通知ChannelPromise，否则可能会出现ChannelFutureListener收不到某个消息已经被处理了的通知的情况。\n总之，如果一个消息被消费了或者丢弃了，并且没有传递给ChannelPipeline中的下一个ChannelOutboundHandler，那么用户就有责任调用ReferenceCountutils.release()。如果消息到达了实际的传输层，那么当它被写入时或者Channel关闭时，都将被自动释放。\nChannelPipeline 每个新创建的Channel都会被分配一个新的ChannelPipeline。这项关联时永久性的，Channel既不能附加另外一个ChannelPipeline也不能分离器当前的。在Netty组件中的生命周期中，这是一项固定的操作，不需要开发人员的任何干预。\n根据事件的起源，事件将会被ChannelInboundHandler或者ChannelOutboundHandler处理。随后通过调用ChannelHandlerContext实现，它将被转发给统一超类型的下一个ChannelHandler。\nChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler交互。ChannelHandler可以通知其所属的ChannelPipeline中的下一个ChannelHandler，甚至可以动态的修改所属的ChannelPipeline。ChannelHandlerContext具有丰富的处理事件和执行IO操作的API。\nChannelPipeline提供了通过ChannelPipeline本身传播事件的方法，如果一个入站事件被触发，它将被从ChannelPipelien的头部一直被传播到ChannelPipeline的尾端。（怎么通过ChannelPipeline制造一个入站事件？）\nChannelPipeline传播事件时，它会测试ChannelPipeline中的下一个ChannelHandler的类型是否和事件的传播方向相匹配。如果不匹配，ChannelPipeline将跳过该ChannelHandler并前进到下一个（这个测试怎怎么进行的呢），直到它找到和该事件所期望的方向相匹配的为止。如果我直接实现ChannelHandler接口，这个判断工作又是怎么进行的呢？\nChannelHandler可以通过添加、删除或者替换其他的ChannelHandler来实时地修改ChannelPipeline的布局（它也可以将它自己从ChannelPipeline中移除）。这是ChannelHandler最重要的能力之一。\n addFirst addLast addBefore addAfter remove replace  重组ChannelHandler的这种能力使我们可以用它来轻松地实现及其灵活的逻辑。\nChannelPipeline用于方法ChannelHandler的操作：\n get：通过类型或者名称返回ChannelHandler context：返回和ChannelHandler绑定的ChannelHandlerContext names：返回ChannelPipeline中所有的ChannelHandler的名称  （能不能通过上面的技术实现跳channelHandler发送消息，感觉应该不行）\nChannelHandler的执行与阻塞 通常ChannelPipeline中的每一个ChannelHandler都是通过它的EventLoop来处理传递给它的事件，所以至关重要的是不要阻塞这个线程，因为这会对整体的IO处理产生负面的影响。\n但是有时候需要与那些使用阻塞API的遗留代码进行交互，对于这种情况，ChannelPiepline有一些接受EventExecutorGroup的add方法。如果一个时间被传递给一个自定义的EventExecutorGroup，它将被包含在这个EventExecutorGroup中的某个EventExecutor所处理，从而被从该Channel本生的EventLoop中移除。\n（需要看一下案例代码）\n触发事件 入站操作，同于通知ChannelInboundHandler在ChannelPipeline中所发生的事件：\nfireChannelRegistered\nfireChannelUnregistered\nfireChannelActive\nfireChannelInactive\nfireChannelExceptionCaught\nfireChannelEventTriggered\nfireChannelChannelRead\nfireChannelChannelReadComplete\nfireChannelChannelWritabilityChanged\n出站发生的事件：\n bind connect disconnect close deregister flush wirte writeAndFlush read  我为什么对出站事件这么陌生，很正常，目前这方面接触的还非常的少。\nChannelHandlerContext 每当有ChannelHandlr添加到ChannelPipeline，就会创建一个ChannelHandlerContext。ChannelContextHandler的主要功能是管理它所关联的ChannelHandler和在同一个ChannelPipeline中的其他ChannelHandler交互。\nChannelHandlerContext有很多方法，其中有一些方法也存在于Channel和ChannelPipeline本身上，但是有一点重要的不同。如果调用Channel或者ChannelPipeline上的这些方法，它们将沿着整个ChannelPipeline进行传播，而调用位于ChannelHandlerContext上相同的方法，则将从所关联的ChannelHandler开始，并且只会传播给位于该ChannelPipeline中的下一个能够处理该事件的ChannelHandler。\nbind：绑定到给定的SocketAddress，并返回ChannelFuture（为什么能在ChannelHandler中进行绑定，很奇怪）\nconnect：同样的，不是很好理解这个API\n从某个特定的ChannelHandler开始处理 为什么要从ChannelPipeline中的某个特定点开始传播事件？\n 为了减少将事件传经对它不感兴趣的ChannelHandler所带来的开销 为了避免将事件传经那些可能会对它感兴趣的ChannelHandler  要想调用从某个特定的ChannelHandler开始的处理过程，必须获取到在该ChannelHandler之前的ChannelHandler所关联的ChannelHandlerContext。这个ChannelHandlerContext将调用和它关联的ChannelHandler之后的ChannelHandler。\n（貌似有点复杂哦，不知道能玩出怎样的花）\n一些奇怪的理解 1 2 3 4  ChannelHandlerContext ctx = ...; ctx.write(Unpooled.copiedBuffer(\u0026#34;Netty In Action\u0026#34;, CharsetUtil.UTF_8))   从图中可以看到，第二个ChannelHandler调用了write后，消息并不是往左走，而是往右走，这个和我的理解是有冲突的。\n（这部分书中的内容有问题，在当前分类下可以找到我实验的代码）\n高级用法 可以缓存ChannelHandlerContext的引用以供稍后使用，这可能会发生在任何的ChannelHandler方法之外，甚至来自不同的线程。\n一个ChannelHandler可以属于多个ChannelPipeline，所以它们可以绑定到多个ChannelHandlerContext实例。用于这种用法的ChannelHandlr必须要使用@Shareable注解，否则，试图将它添加到多个ChannelPipeline时将会触发异常。\n在多个ChannelPipeline中安装同一个ChannleHandler的一个常见的原因是用于收集跨越多个Channel的统计信息。\n异常处理 处理出站异常 用于处理出站操作中的正常完成以及异常的选项，都基于以下的通知机制：\n  每个出站操作都将返回一个ChannelFuture。注册到ChannelFuture的ChannelFutureListener将在操作完成时被通知该操作是成功了还是出错了。\n  几乎所有的ChannelOutboundHandler上的方法都会传入一个ChannelPromise的实例，作为ChannelFuture的子类，ChannelPromise也可以被分配用于异步通知的监听器。但是ChannelPromise还具有立即通知的可写方法：\n  1 2 3 4  ChannelPromise setSuccess(); ChannelPromise setFailure(Throwable cause);   如下代码使用这种方式来添加ChannelFutureListener：\n1 2 3 4 5 6 7 8 9 10 11 12  ChannelFuture future = channel.write(someMessage); future.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture f){ if(!f.isSuccess()){ f.cause().printStackTrace(); f.channel().close(); } } })   第二种方式是将ChannelFutureListener添加到即将作为参数传递给ChannelOutboundHandler的方法的ChannelPromise（这是说ChannelPromise即将作为参数传递给ChannelOutboundHandler）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class OutboundExceptionHandler extends ChannelOutboundHandlerAdatapter { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { promise.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture f) { if(!f.isSuccess()) { f.cause().printStackTrace(); f.channel().close(); } } }) } }   谈谈我自己的理解 wirte继承方法中的promise和write中返回的ChannelFuture A(ChannelOutboundHandler) -\u0026gt; B(ChannelInboundHandler)\n如图所示的pipeline，如果我在B的中调用write，得到一个ChannelFuture，我认为这个ChannelFuture和我在A的write方法中得到的ChannelPromise是同一个对象，我的验证代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ch.pipeline() .addLast(new ChannelOutboundHandlerAdapter() { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\u0026#34;Running 1\u0026#34;); System.out.println(promise); } }) .addLast(new ChannelInboundHandlerAdapter() { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;Running 2\u0026#34;); ChannelFuture writeChannelFuture = ctx.write(msg); System.out.println(writeChannelFuture); } });   输出的结果如下，和我假设的一致：\n Running 2 Running 1 DefaultChannelPromise@7c903a86(incomplete) DefaultChannelPromise@7c903a86(incomplete) 什么时候用ChannelFuture什么时候用ChannelPromise 从目前学习到的知识总结出这样的结论，如果在ChannelInboundHandler之类的Handler中直接写数据，此时要回调则使用ChannelFuture，如果在ChannelOutboundHandler之类的Handler中实现write之类的方法，则使用ChannelPromise。\n","description":"","id":170,"section":"notes","tags":null,"title":"Channel和ChannelPipeline","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/channel%E5%92%8Cchannelpipeline/"},{"content":"这个标签我用的比较少，所以收集几个案例先，等未来有需求了再深入研究：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;select id=\u0026#34;getUserList_choose\u0026#34; resultMap=\u0026#34;resultMap_user\u0026#34; parameterType=\u0026#34;com.yiibai.pojo.User\u0026#34;\u0026gt; SELECT * FROM User u \u0026lt;where\u0026gt; \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;username !=null \u0026#34;\u0026gt; u.username LIKE CONCAT(CONCAT(\u0026#39;%\u0026#39;, #{username, jdbcType=VARCHAR}),\u0026#39;%\u0026#39;) \u0026lt;/when \u0026gt; \u0026lt;when test=\u0026#34;sex != null and sex != \u0026#39;\u0026#39; \u0026#34;\u0026gt; AND u.sex = #{sex, jdbcType=INTEGER} \u0026lt;/when \u0026gt; \u0026lt;when test=\u0026#34;birthday != null \u0026#34;\u0026gt; AND u.birthday = #{birthday, jdbcType=DATE} \u0026lt;/when \u0026gt; \u0026lt;otherwise\u0026gt; \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/select\u0026gt;   ","description":"","id":171,"section":"notes","tags":null,"title":"CHOOSE标签","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/choose%E6%A0%87%E7%AD%BE/"},{"content":"这个功能和Postman的导入功能结合在一起使用，前端、后端、测试联调时，非常的方便，过程如截图：\nCopy All As Curl，会将当前Network中的所有请求都copy成Curl，实际使用中用的比较少。\n没有找到相应的快捷键，有点失望。\n","description":"","id":172,"section":"notes","tags":null,"title":"Chrome导出Curl指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/chrome%E5%AF%BC%E5%87%BAcurl%E6%8C%87%E4%BB%A4/"},{"content":"这个技巧不是在任何时间都好用的，相比于在密码管理器中查看密码，该方式最大的好处比较简单。\n方法如下：\n 使用密码填充工具填充密码后，对这密码框右键，选择inspect 将input标签的type从password改为text  ","description":"","id":173,"section":"notes","tags":null,"title":"Chrome查看密码的技巧","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/chrome%E6%9F%A5%E7%9C%8B%E5%AF%86%E7%A0%81%E7%9A%84%E6%8A%80%E5%B7%A7/"},{"content":"在看Netty源码时，遇到如下一段代码：\n1 2 3 4  private final Set\u0026lt;ChannelHandlerContext\u0026gt; initMap = Collections.newSetFromMap( new ConcurrentHashMap\u0026lt;ChannelHandlerContext, Boolean\u0026gt;());   扒了一下该方法底层源码看了一下，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  public static \u0026lt;E\u0026gt; Set\u0026lt;E\u0026gt; newSetFromMap(Map\u0026lt;E, Boolean\u0026gt; map) { return new SetFromMap\u0026lt;\u0026gt;(map); } private static class SetFromMap\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Serializable { private final Map\u0026lt;E, Boolean\u0026gt; m; // The backing map  private transient Set\u0026lt;E\u0026gt; s; // Its keySet  SetFromMap(Map\u0026lt;E, Boolean\u0026gt; map) { if (!map.isEmpty()) throw new IllegalArgumentException(\u0026#34;Map is non-empty\u0026#34;); m = map; s = map.keySet(); } public void clear() { m.clear(); } public int size() { return m.size(); } public boolean isEmpty() { return m.isEmpty(); } public boolean contains(Object o) { return m.containsKey(o); } public boolean remove(Object o) { return m.remove(o) != null; } public boolean add(E e) { return m.put(e, Boolean.TRUE) == null; } public Iterator\u0026lt;E\u0026gt; iterator() { return s.iterator(); } public Object[] toArray() { return s.toArray(); } public \u0026lt;T\u0026gt; T[] toArray(T[] a) { return s.toArray(a); } public String toString() { return s.toString(); } public int hashCode() { return s.hashCode(); } public boolean equals(Object o) { return o == this || s.equals(o); } public boolean containsAll(Collection\u0026lt;?\u0026gt; c) {return s.containsAll(c);} public boolean removeAll(Collection\u0026lt;?\u0026gt; c) {return s.removeAll(c);} public boolean retainAll(Collection\u0026lt;?\u0026gt; c) {return s.retainAll(c);} // addAll is the only inherited implementation  // Override default methods in Collection  @Override public void forEach(Consumer\u0026lt;? super E\u0026gt; action) { s.forEach(action); } @Override public boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter) { return s.removeIf(filter); } @Override public Spliterator\u0026lt;E\u0026gt; spliterator() {return s.spliterator();} @Override public Stream\u0026lt;E\u0026gt; stream() {return s.stream();} @Override public Stream\u0026lt;E\u0026gt; parallelStream() {return s.parallelStream();} private static final long serialVersionUID = 2454657854757543876L; private void readObject(java.io.ObjectInputStream stream) throws IOException, ClassNotFoundException { stream.defaultReadObject(); s = m.keySet(); } }   可以看到SetFromMap的实现就仅仅只是对一个Map方法的包装。在netty的源码中主要用到了add方法和remove方法，且用法如下：\n1 2 3 4 5 6 7  if (initMap.add(ctx)) { // do something } initMap.remove(ctx);   摘取SetFromMap的add方法和remove方法的实现如下：\n1 2 3 4 5 6 7 8 9  public boolean add(E e) { return m.put(e, Boolean.TRUE) == null; } public boolean remove(Object o) { return m.remove(o) != null; }   remove很好理解，map中不存在这个元素，就返回false。对于add方法，我从来没有注意到set的add方法会在set中已经存在这个元素时返回false，这次又学习到了新的东西：\n1 2 3 4 5  Set\u0026lt;String\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); System.out.println(set.add(\u0026#34;Hello\u0026#34;)); // true System.out.println(set.add(\u0026#34;Hello\u0026#34;)); // false    ","description":"","id":174,"section":"notes","tags":null,"title":"Collections.newSetFromMap","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/collections.newsetfrommap/"},{"content":"这个算是写法的一种优化，之前的写法不太优雅：\n1 2 3 4 5 6 7 8 9  CollectionUtils.isEmpty(null); // true CollectionUtils.isEmpty(new ArrayList()); // true　CollectionUtils.isEmpty({a,b}); // false  CollectionUtils.isNotEmpty(null); // false CollectionUtils.isNotEmpty(new ArrayList());// false CollectionUtils.isNotEmpty({a,b}); // true    ","description":"","id":175,"section":"notes","tags":null,"title":"CollectionUtils判断集合是否为空","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/collectionutils%E5%88%A4%E6%96%AD%E9%9B%86%E5%90%88%E6%98%AF%E5%90%A6%E4%B8%BA%E7%A9%BA/"},{"content":"可以使用command指令随心所欲的执行命令，当使用这个模块时需要使用-a参数将需要执行的命令传入模块。command模块非常常用，所以ansible命令将其设置为了默认模块。如果我们的命令包含空格，我们需要使用引号将命令括起来，这样shell才会将整个字符串作为单一参数传给Ansible。\n1 2 3 4 5 6 7 8 9 10  ansible test -m command -a uptime ansible test -a uptime ansible test -a \u0026#39;tail /var/log/dmesg\u0026#39; # 如果需要管理员权限，则传入参数-S ansible test -S -m command -a uptime ansible test -S -a uptime ansible test -S -a \u0026#39;tail /var/log/dmesg\u0026#39;   ","description":"","id":176,"section":"notes","tags":null,"title":"command模块的简单使用","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/command%E6%A8%A1%E5%9D%97%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"},{"content":"今天遇到如下需求：我需要将如下application.yml配置读取到相应的Properties配置文件中：\n1 2 3 4 5 6 7 8 9  templates:- template:\u0026#34;${beanClass}.ftl\u0026#34;module:${project.modules.server}packet:${packages.service}packets-to-import:- ${packages.request}- ${packages.response}  这个非常难搞，因为@ConfigurationProperties必须要指定一个前缀，而这个前缀有需要作为Properties的一个字段，几经折腾我开发了如下的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  @Data @Component public class TemplatesProperties implements ApplicationContextAware { private List\u0026lt;Template\u0026gt; templates; @Data public static class Template { /** * 模板文件 */ private String template; /** * 当前模板所属的模块 */ private String module; /** * 当前模板生成的类所属的包 */ private String packet; /** * 当前模板生成的类额外需要导入的包 */ private List\u0026lt;String\u0026gt; packetsToImport; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //noinspection unchecked  templates = (List\u0026lt;Template\u0026gt;) applicationContext.getBean(\u0026#34;templates\u0026#34;); } @Configuration public static class TemplatesPropertiesInternalConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;templates\u0026#34;) public List\u0026lt;Template\u0026gt; templates(List\u0026lt;Template\u0026gt; templates) { return templates; } } }   这个利用了ConfigurationProperties可以放在方法上，为什么说解决这个问题是靠想象力呢，我查了很多资料，没有找到相关需求的解决方案，所以我自己观察@ConfigurationProperties，发现它可以注解到方法上，所以我就大胆尝试并查找了一些资料，解决了这个需求。\n为什么不在application.yml中再加一个字段呢？因为我有强迫症！\n优化与遇到的问题 我想将上面的代码优化成下面的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  @Data @NoArgsConstructor @AllArgsConstructor public class TemplatesProperties { private List\u0026lt;Template\u0026gt; templates; @Data public static class Template { /** * 模板文件 */ private String template; /** * 当前模板所属的模块 */ private String module; /** * 当前模板生成的类所属的包 */ private String packet; /** * 当前模板生成的类额外需要导入的包 */ private List\u0026lt;String\u0026gt; packetsToImport; } @Configuration public static class TemplatesPropertiesInternalConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;templates\u0026#34;) public TemplatesProperties templates(List\u0026lt;Template\u0026gt; templates) { return new TemplatesProperties(templates); } } }   但是我发现此时获取的templates是一个长度为零的数组，同时Idea提示无法注入templates，我对这个问题产生了兴趣，于是还原代码进行测试，我有如下收获：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //noinspection unchecked  tables = (List\u0026lt;Table\u0026gt;) applicationContext.getBean(\u0026#34;tables\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } @Configuration public static class TablePropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;tables\u0026#34;) public List\u0026lt;Table\u0026gt; tables(List\u0026lt;Table\u0026gt; tables) { return tables; } }   上面这段代码的调用时序为：\n tables = (List\u0026lt;Table\u0026gt;) applicationContext.getBean(\u0026quot;tables\u0026quot;); return tables; System.out.println(\u0026quot;\u0026quot;);  （我没有从上面的调用时序收获到任何有意思的东西，只是觉得有趣而已）\n此时return tables;返回的是一个疮毒为0的tables，所以说，我一顿操作猛如虎，最后发现对@ConfigurationProperties用于方法上理解是错误的。加了@ConfigurationProperties并不是说此时方法注入的Bean的属性是从配置文件中获取的，而是说此时@Bean方法返回的东东是从配置文件获取的，所以正确的优化方法只能是下面的这种写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  @Data @Component public class TableProperties implements ApplicationContextAware { private List\u0026lt;Table\u0026gt; tables; @Data public static class Table { /** * 表逻辑名称 */ private String logicName; /** * 对应的实体名称 */ private String entityName; /** * 不需要生成的模板 */ private List\u0026lt;String\u0026gt; templatesExclude; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //noinspection unchecked  tables = (List\u0026lt;Table\u0026gt;) applicationContext.getBean(\u0026#34;tables\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } @Configuration public static class TablePropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;tables\u0026#34;) public List\u0026lt;Table\u0026gt; tables() { return new ArrayList\u0026lt;\u0026gt;(0); } } }   相对一开始的写法，省去了@Bean方法的方法参数，虽然只是小小的一点改动，但代表着对@ConfigurationProperties更正确的理解。\n参考资料  Spring Boot中注解@ConfigurationProperties的三种使用场景  ","description":"","id":177,"section":"notes","tags":null,"title":"ConfigurationProperties注解在方法上","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/configurationproperties%E6%B3%A8%E8%A7%A3%E5%9C%A8%E6%96%B9%E6%B3%95%E4%B8%8A/"},{"content":"我目前的这套方案可以说是以Validation的思想实现我需要的需求。\n已存在的校验技术及我的校验注解需求 搞了大半天的成果，虽然不能很优雅的实现我的需求，但是在研究的过程中增加了我对Validation的了解，所以还是记录一下下吧。\n我听说有一种技术（我已经验证过这个技术），可以在@NotBlank的message中定义占位符，如下所示：\n @NotBlank(message = \u0026quot;{notBlank}不为空\u0026quot;) 然后在一个messages.properties的文件中定义：\n notBlank=\u0026quot;XXX\u0026quot; 当参数校验错误的时候生成的消息为：XXX不为空。更进一步的，我们可以在message.properties中这么定义：\n notBlank=\u0026quot;{0} XXX\u0026quot; 理想情况下，{0}将会被替换为@NotBlank标注的字段的名称，我无法成功实验该技术，但是这个技术的的确确是我想要的。我希望通过这个技术定义自己的@NotNull、@NotBlank等注解，这样我们在使用这些注解时只需要加上这些注解，而不需要写上message消息。\n一种不是太满意的实现方案 这里需要特殊说明一下，其实我可以通过如下的技术实现在ExceptionHandler中拼接字段信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13  @ControllerAdvice public class MyExceptionHandler { @ResponseBody @ExceptionHandler(value = {MethodArgumentNotValidException.class, BindException.class}) public Response exceptionHandler(MethodArgumentNotValidException e) { FieldError fieldError = e.getBindingResult().getFieldError(); return new Response(0, fieldError.getField() + \u0026#34;:\u0026#34; + fieldError.getDefaultMessage()); } }   这种方案很简单也很好理解，但是我放弃这个方案了，其原因是ExceptionHandler是全局的，而@NotNull等注解并不一定应用于Request中的参数校验，这种方式可能会暴露程序内部的一些设计；其次，修改ExceptionHandler是框架层的东西，我对其的任何调整都会影响已经在线上运行的项目，我觉得这样风险很大。最后，我觉得这并不是一种优雅的方式。\n我目前的方案 先分析一下如下代码是如何实现notBlank被替换为我们想要的字符串的。message.properties会被加载到内存中，存在一个叫做messageParams的属性中，当框架发现了message中包含大括号，则其会取到大括号的内容，然后得到该内容在messageParams中映射的值（有兴趣自己读源码吧，我是一点一点断点理解这个问题的）。\n1 2 3  @NotBlank(message = \u0026#34;{notBlank}不为空\u0026#34;)   针对我们的代码，正常情况下参数校验完成后的到的message是：{fieldName}：不能为空。因为我们没办法在message.properties中动态的定义fieldName，故messageParams中是找不到fieldName的。\n1 2 3 4  @JNotBlank(message = \u0026#34;{fieldName}：不能为空\u0026#34;) private String tmpString;   我们可以如何处理这个问题呢？如下代码，我们在开发ConstraintValidator时，是可以在isValid方法中获得一个ConstraintValidatorContext的，通过调用该context的addMessageParameters方法，我们就可以将参数加载到messageParams，从而完成映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class JNotBlankValidator implements ConstraintValidator\u0026lt;JNotBlank, String\u0026gt; { @Override public void initialize(JNotBlank constraintAnnotation) { } @Override public boolean isValid(String value, ConstraintValidatorContext context) { ValidationUtils.addMessageParameters(context); return StringUtils.isNotBlank(value); } } public class ValidationUtils { /** * 添加fieldName参数到ConstraintValidatorContext中 * \u0026lt;p\u0026gt; * 该工具可以在ConstraintValidatorContext添加一个额外的fieldName参数，这样你在 * 使用参数校验的注解时，可以在message中使用{@code fieldName} * \u0026lt;p\u0026gt; * 仅当注解基于字段时，该工具有效。 */ public static void addMessageParameters(ConstraintValidatorContext context) { if (context instanceof HibernateConstraintValidatorContext) { try { Field basePathField = context.getClass().getDeclaredField(\u0026#34;basePath\u0026#34;); basePathField.setAccessible(true); Path basePath = (Path) (basePathField.get(context)); ((HibernateConstraintValidatorContext) context).addMessageParameter(\u0026#34;fieldName\u0026#34;, basePath); } catch (NoSuchFieldException | IllegalAccessException e) { e.printStackTrace(); throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } } } }   至于如何获得fieldName的名称，我想到的办法只有反射了，我花费了很长时间，都没有找到可以获取fieldName字段的api，遂走反射这个方案。\n总结 我其实是无话可说的，这个方案是一点一点的探索出来的。不过这些技术的研究确实可以很好的减少我们工作量，我非常满意。另外，我想把这些技术开发成一个starter，然后用在我们的项目中。\n参考资料   Setting Custom Field Name and Code\nSpring Validation custom messages - field name\n印证了我的一些思想，同时提到了Validator的开发，我目前没有相关的技术需求。\n  spikefin-goby/spring-boot-validation-sample\n讲到了message.properties技术的应用，并提供了相关的案例代码。\n  ","description":"","id":178,"section":"notes","tags":null,"title":"ConstraintValidator中调用addMessageParameter方法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/constraintvalidator%E4%B8%AD%E8%B0%83%E7%94%A8addmessageparameter%E6%96%B9%E6%B3%95/"},{"content":"Converter是通用元件，可以将一种类型转换成另一种类型，可以在应用程序中的任意层使用。\nFormatter只能将String转换成另一种Java类型，是专门为 Web 层设计的；在Spring MVC应用程序中，选择Formatter比选择Converter更合适。\n我目前只能获取比较片面的知识，无法知道Converter和Formatter在整个框架中的定位，所以我计划之后有时间再整理这部分。\n","description":"","id":179,"section":"notes","tags":null,"title":"Converter与Formatter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/converter%E4%B8%8Eformatter/"},{"content":"如下代码为《奔跑吧，Ansible》中得一段源码，结果在运行的时候提示目标地址不存在。\n --- - name: Configure webserver with nginx hosts: webservers sudo: True tasks: - name: install nginx apt: name=nginx update_cache=yes - name: copy nginx config file copy: src=files/nginx.conf dest=/etc/nginx/sites-available/default - name: enable configuration file: \u0026gt; dest=/etc/nginx/sites-enabled/default src=/etc/nginx/sites-available/default state=link - name: copy index.html template: src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html mode=0644 - name: restart nginx service: name=nginx state=restarted 经过搜索资料发现，copy的参数最后如果是目录，则不会存在该报错，如果是文件则会存在该报错，而配置src=files/nginx.conf dest=/etc/nginx/sites-available/default因为末尾没有反斜杠，被视为了文件，所以发生了该报错。\n参考资料  【Ansible学习】- 常用文件操作模块之copy模块  ","description":"","id":180,"section":"notes","tags":null,"title":"copy模块使用时需要注意的问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/copy%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"源目录为source，目标目录为target，则如果target不存在，可直接使用如下指令完成复制：\n1 2 3  cp -r source target   如果target目录已经存在，则需要使用（我已经踩过该坑），此时执行cp -r source target，会将source复制到target中：\n1 2 3  cp -r source/* target   参考资料  linux复制指定目录下的全部文件到另一个目录中，linux cp 文件夹  ","description":"","id":181,"section":"notes","tags":null,"title":"cp将一个目录下的文件复制到另一个目录中","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/cp%E5%B0%86%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%AD/"},{"content":"我用curl帮助我解决不少问题了，我打算整理下我对其的需求及用法：\n  curl -v google.com\n测试google.com是否可以正常访问，google.com域名是否正确解析。\n  curl \u0026ndash;socks5-hostname 127.0.0.1:2000 google.com\n将域名解析的工作交给socks5服务器。\n  很高级的知识，我的curl工具部分options用不了，我也想解决这个问题（暂时没有研究）\n 打造你自己的cURL命令 Problem running CURL with the dns option     ","description":"","id":182,"section":"notes","tags":null,"title":"curl常用指令","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/curl%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"指令如下：\n curl -k https://192.168.13.155:8006 curl --insecure https://192.168.13.155:8006 适用场景：https站点是我自己搭建的~~~\n参考资料  CURL 请求时不检测证书  ","description":"","id":183,"section":"notes","tags":null,"title":"curl访问时不检查证书","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/curl%E8%AE%BF%E9%97%AE%E6%97%B6%E4%B8%8D%E6%A3%80%E6%9F%A5%E8%AF%81%E4%B9%A6/"},{"content":"没有办法带来在Linux上使用的体验，故作废\n截图如下：\n核心需要注意的是，需要在skip上点一下，直到点出版本号。\n参考资料  Windows 下如何在cygwin上安装curl？  ","description":"","id":184,"section":"notes","tags":null,"title":"Cygwin上安装curl","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/cygwin%E4%B8%8A%E5%AE%89%E8%A3%85curl/"},{"content":"比较简单，我直接截图了：\n需要断开已有的数据库，然后重新链接。\n参考资料  DataGrip设置时区  ","description":"","id":185,"section":"notes","tags":null,"title":"DataGrip设置时区为上海","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/datagrip-h2/datagrip%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA%E4%B8%BA%E4%B8%8A%E6%B5%B7/"},{"content":"可以Backports理解为一个仓库，仓库里放的都是一些未进行充分测试的包，任何人都可以创建自己的Backports。\n我们想安装某个软件的的非稳定版时，需要找到某个特定的Backports，然后从这个仓库中进行安装。\n需求的产生是这样的，我目前下载的wireguard-tools版本为wireguard-tools v1.0.20210223，我想尝试一下新版本的功能。\n操作步骤如下：\n 在Debian Packages页面搜索wireguard，搜索时注意需要选择Distribution为unstable：  根据架构选择一个（最好都点开看看）：  在搜索结果页选择一个结果项打开：\n在结果项的详情页选择一个架构，点击进去：\n按照教程，将如下地址添加到source.list中，然后执行更新apt update：  添加进去后，执行搜索apt search wireguard，这个时候已经可以看到最新版本的wireguard-tools：  参考资料  Backports Backports  ","description":"","id":186,"section":"notes","tags":null,"title":"Debain搜索Backports包","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debain%E6%90%9C%E7%B4%A2backports%E5%8C%85/"},{"content":"授人以鱼不如授人以渔，使用如下操作，可以看到fdisk支持的命令集：\n fdisk m 删除分区 删除分区的指令如下（核心思路就是使用使用d）：\n fdisk d 2 d 分区 参考资料  linux 硬盘分区，分区，删除分区，格式化，挂载，卸载笔记  ","description":"","id":187,"section":"notes","tags":null,"title":"Debian删除和新建分区","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E5%88%A0%E9%99%A4%E5%92%8C%E6%96%B0%E5%BB%BA%E5%88%86%E5%8C%BA/"},{"content":"需求非常少，故作废该笔记\n操作步骤  替换/etc/apt/sources.list文件为如下内容：   # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free 运行apt update  ","description":"","id":188,"section":"notes","tags":null,"title":"Debian更换软件源","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E6%9B%B4%E6%8D%A2%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"content":"之所以需要这个教程了，是因为我想在Debian上使用最新版的wireguard-tools（我现在已经使用backports的方式安装了），官方的软件源里没有这个资源，所以我决定自己编译安装。\n安装教程是从哪找到的呢？是从下面这个地方：\n我的操作步骤如下（我的内核高于5.6，所以不需要编译内核模块）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 准备编译工具 sudo apt-get install libelf-dev linux-headers-$(uname -r) build-essential pkg-config # 下载项目源码 git clone https://git.zx2c4.com/wireguard-tools # 切换标签，我没有用master分支，这一步是官方文档上没有的 cd wireguard-tools \u0026amp;\u0026amp; checkout out v1.0.20210914 \u0026amp;\u0026amp; checkout .. # 编译并安装 make -C wireguard-tools/src -j$(nproc) make -C wireguard-tools/src install   参考资料   Compilation From Source Code\n  wireguard-tools — tools for configuring WireGuard\n这个页面也有相关的教程，但是我没有实践。\n  ","description":"","id":189,"section":"notes","tags":null,"title":"Debian系统上编译Wireguard","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/debian%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%BC%96%E8%AF%91wireguard/"},{"content":"操作步骤  执行如下指令：  1 2 3 4  systemctl poweroff systemctl reboot   ","description":"","id":190,"section":"notes","tags":null,"title":"Debian系统关机","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/debian%E7%B3%BB%E7%BB%9F%E5%85%B3%E6%9C%BA/"},{"content":" 在该页面搜索wireguard包  选择一个搜索项，进入详情页，在详情页的下载列表中选择amd64架构  进入amd64架构的详情页，如图，拿到源地址，配置到source.list中  之后就是debain常见的软件安装方式，这儿不整理了  ","description":"","id":191,"section":"notes","tags":null,"title":"Debian系统安装最新版的wireguard-tools","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/debian%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%89%88%E7%9A%84wireguard-tools/"},{"content":"我们数据表中有一个gmt_modify_time的审计字段，我最近发现调用deleteById和deleteBatchIds这个字段不会更新这个字段。\n这个字段不被更新会带来什么问题呢？当我们发现我们数据库中数据被删除的时候，我们没有办法知道是谁，在什么时间进行删除的（虽然查日志可以解决这个问题，但是查成本非常高）。\n我准备研究MyBatis-Plus的自定义Interceptor，自己实现这个效果。\n","description":"","id":192,"section":"notes","tags":null,"title":"deleteById和deleteBatchIds没有更新到gmt_modify_time（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/deletebyid%E5%92%8Cdeletebatchids%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0%E5%88%B0gmt_modify_time%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"最近发现了一些新的东西：使用阿里SpringBoot初始化SpringBoot项目时，并不需要继承SpringBoot的starter-parent就可以完成版本裁决。我观察其为我们生成的pom.xml文件，其核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;   这些知识已将超出了我的知识范围，所以我决定花点时间搞懂这些东西。\n搞懂值为import的scope Maven是不支持多重集成的，如果我们想要多重继承的效果，我们就需要import scope。我们可以将dependencyManagement放到单独的专门用来管理依赖的pom中，然后在需要使用依赖的模块中通过import scope依赖，就可以引入dependencyManagement。\n我决定使用Idea多Maven项目的方式来验证一下这个问题（先创建一个普通项目，再创建多个Maven的模块，这样方便代码的管理）。在project_01中，我们准备如下的pom文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;project_01\u0026lt;/artifactId\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.7.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;/project\u0026gt;   在project_02中，我们准备如下的pom文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;project_02\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-api\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;project_01\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;/project\u0026gt;   最终实验结果如我们所期待的一致，我们的project_02项目拿到了正确的预设的：\n需要注意的是import scope只能用在dependencyManagemen里面。\nimport scope会导入properties么 这部分我所关注的问题在于：\n 我有办法修改import scope中的版本么 我可以利用import scope中定义的变量么（意义不大，仅实验）  使用import scope方式的表现 了解了这些后，我产生了一个问题：import scope会帮我们导入properties标签中定义的各种标签么，为了验证这一点，我在project_01的pom文件中加入了如下内容：\n1 2 3  \u0026lt;j.fastjson.version\u0026gt;1.2.76\u0026lt;/j.fastjson.version\u0026gt;   并在project_02的pom文件中添加了如下的依赖：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${j.fastjson.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   实验的过程中，Idea无法找到j.fastjson.version，这个和使用继承的方式的表现有点不一样。\nparent标签的表现 现在来验证一下继承，我创建了project_03，并准备了如下的pom文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;artifactId\u0026gt;project_01\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;artifactId\u0026gt;project_03\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${j.fastjson.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-jupiter-api\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt;   最终发现变量被正确的继承了：\n这个是符合我的预期的。\n验证import scope的版本号是否可修改 实验中我先将project_01的版本信息抽取成property，然后调整project_02的代码，使其可以正常的拿到版本信息。然后我定义了如下的变量：\n1 2 3 4  \u0026lt;j.junit-jupiter-api.version\u0026gt;5.6.3\u0026lt;/j.junit-jupiter-api.version\u0026gt; \u0026lt;j.log4j.version\u0026gt;2.14.1\u0026lt;/j.log4j.version\u0026gt;   实验的过程中发现，我没有办法覆盖掉import scope中的配置。\n我对这个结果是不太满意的，因为在我们的日常开发过程中，是存在通过修改property变量来替换掉SpringBoot给我们预定义的版本的需求的（用于升级某个组件或者降级），如果import scope不支持这种操作的话，会给我们带来很大的麻烦。\n参考资料  使用import scope解决maven继承（单）问题  ","description":"","id":193,"section":"notes","tags":null,"title":"dependencyManager中的import scope","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/dependencymanager%E4%B8%AD%E7%9A%84import-scope/"},{"content":"问题描述  使用XShellssh到PVE服务器，账号使用的是junjie，然后使用su root切换root用户，再使用depmod指令，这时候会提示not found。  解决方法  使用如下指令：  1 2 3  /sbin/depmod `uname -r`   参考教程  安装Realtek8168 网卡驱动  ","description":"","id":194,"section":"notes","tags":null,"title":"depmod not found","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/depmod-not-found/"},{"content":"第三方镜像直接Run的话可能就没有办法进入到系统的终端，我用如下指令定义了我要执行的指令，从而覆盖Dockerfile中的CMD指令：\n docker run -it python:3.8.6 bash 我用该技术测试第三方image是否支持安装Git的软件，当我直接走docker run -it或者ducker attach时，仍然会进入python程序，这不是我想要的。\n","description":"","id":195,"section":"notes","tags":null,"title":"docker run指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker-run%E6%8C%87%E4%BB%A4/"},{"content":"使用场景很多，比如我测试Dockerfile文件后删除测试时生成的镜像，或者在做K8s的实验时，批量删除一些用不到的镜像。\n这篇收藏比较久远了，我基本忘记当时的需求和实践了，所以这块只整理一下。\n 【Docker实战】批量删除指定名称的容器镜像  ","description":"","id":196,"section":"notes","tags":null,"title":"Docker批量删除指定名称的容器镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E5%90%8D%E7%A7%B0%E7%9A%84%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F/"},{"content":"最近在研究GitHub Action，攒了几个Dockerfile，并构建了自己的镜像，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12  FROMpython:3.8.6# Copies your code file from your action repository to the filesystem path `/` of the containerCOPY adjust_pictures_in_md_files.py adjust_pictures_in_md_files.pyCOPY entrypoint.sh entrypoint.shRUN chmod +x entrypoint.sh# Code file to execute when the docker container starts up (`entrypoint.sh`)CMD [\u0026#34;/entrypoint.sh\u0026#34;]  运行的指令如下：\n docker build -t tmp:v1 . 我目前用的指令还比较简单，因为我还没有抽出时间系统、深入的学习Docker，先记录一下吧。\n","description":"","id":197,"section":"notes","tags":null,"title":"Docker构建自己的镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/docker%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E9%95%9C%E5%83%8F/"},{"content":" docker attach 容器ID 参考资料  进入容器  ","description":"","id":198,"section":"notes","tags":null,"title":"Docker进入容器内部","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/docker%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8%E5%86%85%E9%83%A8/"},{"content":"需求的产生是这样的，客户提供了一份Excel模板文件，需要我们用数据库中的数据进行填充，要求我们填充后生成的Excel文件和模板基本一致。我们以前一直是直接生成Excel文件，所以有必要研究一下EasyExcel的模板填充技术呢。\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  @RestController public class EasyExcelController { @GetMapping(\u0026#34;/download\u0026#34;) public void download(HttpServletResponse response) throws IOException { Map\u0026lt;String, String\u0026gt; values = new HashMap\u0026lt;\u0026gt;(); values.put(\u0026#34;column1\u0026#34;, \u0026#34;列1\u0026#34;); values.put(\u0026#34;column2\u0026#34;, \u0026#34;列2\u0026#34;); values.put(\u0026#34;column3\u0026#34;, \u0026#34;列3\u0026#34;); response.setContentType(\u0026#34;application/vnd.ms-excel\u0026#34;); response.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); response.setHeader( \u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + URLEncoder.encode(\u0026#34;测试文件\u0026#34;, \u0026#34;UTF-8\u0026#34;) + \u0026#34;.xls\u0026#34;); String excelPath = ResourceUtils.getFile(\u0026#34;classpath:excel/template.xlsx\u0026#34;).getAbsolutePath(); ExcelWriterBuilder excelWriterBuilder = EasyExcel .write(response.getOutputStream()) .withTemplate(excelPath); ExcelWriterSheetBuilder sheet = excelWriterBuilder.sheet(); sheet.doFill(values); } }   准备的模板如下：\n使用Postman测试是，注意使用如下的按钮：\n该部分实验只是EasyYapi最基础的使用，后续更高级的应用还需要再深入研究一下。\n","description":"","id":199,"section":"notes","tags":null,"title":"EasyExcel填充模板","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/easyexcel%E5%A1%AB%E5%85%85%E6%A8%A1%E6%9D%BF/"},{"content":"我开发的相应Handler如下，因为这部分需求比较久远了，具体的就不整理了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98  public class FreezeHeaderHandlerFactory { /** * {@code CellWriteHandler}确保Cell锁定状态被正确设置：当为首行时，单元格锁定状态为true， * 当不为首行时，单元格锁定状态为false */ public static CellWriteHandler getCellWriteHandler() { return new CellWriteHandler() { @Override public void beforeCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Row row, Head head, Integer columnIndex, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellDataConverted(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, CellData cellData, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellDispose(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, List\u0026lt;CellData\u0026gt; cellDataList, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { // 目前不确定Sheet接口的其他实现是否支持锁定，为了避免以后遇到Bug，所以这块限制为SXSSFSheet  if (writeSheetHolder.getSheet() instanceof SXSSFSheet) { if (isHead) { // Workbook workbook = writeSheetHolder.getSheet().getWorkbook(); // CellStyle cellStyle = workbook.createCellStyle();  CellStyle cellStyle = cell.getCellStyle(); cellStyle.setLocked(true); cell.setCellStyle(cellStyle); } else { // Workbook workbook = writeSheetHolder.getSheet().getWorkbook(); // CellStyle cellStyle = workbook.createCellStyle();  CellStyle cellStyle = cell.getCellStyle(); cellStyle.setLocked(false); cell.setCellStyle(cellStyle); } } } }; } /** * S{@code heetWriteHandler}确保Sheet开启了保护工作表的功能，且相应的列被正确的设置了锁定状态。 * * @param freezeColStart 被锁定的列起始位置（0代表第一列即A列） * @param freezeColEnd 被锁定的类终止位置（不包含该列，如果该值为4则代表E列） */ public static SheetWriteHandler getSheetWriteHandler(int freezeColStart, int freezeColEnd) { return new SheetWriteHandler() { @Override public void beforeSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { } @Override public void afterSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { // 目前不确定Sheet接口的其他实现是否支持锁定，为了避免以后遇到Bug，所以这块限制为SXSSFSheet  if (writeSheetHolder.getSheet() instanceof SXSSFSheet) { // 配置加锁  SXSSFSheet sheet = (SXSSFSheet) writeSheetHolder.getSheet(); sheet.enableLocking(); sheet.lockInsertColumns(true); sheet.lockDeleteColumns(true); sheet.lockInsertRows(false); Workbook workbook = writeSheetHolder.getSheet().getWorkbook(); CellStyle cellStyle = workbook.createCellStyle(); for (int i = freezeColStart; i \u0026lt; freezeColEnd; i++) { // CellStyle cellStyle=sheet.getColumnStyle(i);  cellStyle.setLocked(false); sheet.setDefaultColumnStyle(i, cellStyle); } } } }; } }   ","description":"","id":200,"section":"notes","tags":null,"title":"EasyExcel实现锁定表头","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/easyexcel%E5%AE%9E%E7%8E%B0%E9%94%81%E5%AE%9A%E8%A1%A8%E5%A4%B4/"},{"content":"项目中原有的封装过于麻烦，学习成本太高了，出现问题定位成本太高，所以我对EasyExcel简单的封装了下：\nEasyExcelUtilsWithNewScheme.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  package com.sdstc.anta.material.utils.excel; import com.alibaba.excel.EasyExcel; import com.alibaba.excel.ExcelWriter; import com.alibaba.excel.metadata.Sheet; import com.alibaba.excel.write.builder.ExcelWriterSheetBuilder; import com.alibaba.excel.write.handler.CellWriteHandler; import com.alibaba.excel.write.handler.SheetWriteHandler; import com.alibaba.excel.write.handler.WriteHandler; import com.alibaba.excel.write.metadata.WriteSheet; import com.alibaba.excel.write.metadata.style.WriteCellStyle; import com.alibaba.excel.write.style.HorizontalCellStyleStrategy; import com.alibaba.excel.write.style.column.LongestMatchColumnWidthStyleStrategy; import com.alibaba.excel.write.style.column.SimpleColumnWidthStyleStrategy; import org.apache.poi.ss.usermodel.BorderStyle; import org.apache.poi.ss.usermodel.IndexedColors; import java.io.OutputStream; import java.util.ArrayList; import java.util.HashMap; import java.util.List; public class EasyExcelUtilsWithNewScheme { public static void writeExcelWithModel(OutputStream outputStream, List\u0026lt;? extends Object\u0026gt; dataList, Class\u0026lt;? extends Object\u0026gt; classT, String sheetName, WriteHandler... writeHandlers) { ExcelWriterSheetBuilder excelWriterSheetBuilder = EasyExcel.write(outputStream, classT).sheet(sheetName); for (WriteHandler writeHandler : getDefaultWriteHandlerList()) { excelWriterSheetBuilder.registerWriteHandler(writeHandler); } if (null != writeHandlers \u0026amp;\u0026amp; writeHandlers.length \u0026gt; 0) { for (WriteHandler writeHandler : writeHandlers) { excelWriterSheetBuilder.registerWriteHandler(writeHandler); } } // 开始导出  excelWriterSheetBuilder.doWrite(dataList); } private static List\u0026lt;WriteHandler\u0026gt; getDefaultWriteHandlerList() { List\u0026lt;WriteHandler\u0026gt; writeHandlerList = new ArrayList\u0026lt;\u0026gt;(); WriteCellStyle headWriteCellStyle = new WriteCellStyle(); headWriteCellStyle.setWrapped(false); setBorderStyle(headWriteCellStyle); List\u0026lt;WriteCellStyle\u0026gt; contentWriteCellStyleList = new ArrayList\u0026lt;\u0026gt;(); WriteCellStyle writeCellStyle = new WriteCellStyle(); setBorderStyle(writeCellStyle); contentWriteCellStyleList.add(writeCellStyle); writeHandlerList.add(new HorizontalCellStyleStrategy(headWriteCellStyle, contentWriteCellStyleList)); writeHandlerList.add(new LongestMatchColumnWidthStyleStrategy()); return writeHandlerList; } private static void setBorderStyle(WriteCellStyle writeCellStyle) { writeCellStyle.setBorderTop(BorderStyle.THIN); writeCellStyle.setBorderRight(BorderStyle.THIN); writeCellStyle.setBorderBottom(BorderStyle.THIN); writeCellStyle.setBorderLeft(BorderStyle.THIN); writeCellStyle.setTopBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setRightBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setBottomBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setLeftBorderColor(IndexedColors.BLACK.getIndex()); } }   目前开发的Handlers：\nDropDownSheetHandler.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112  package com.sdstc.anta.material.utils.excel.handlers_with_new_scheme; import com.alibaba.excel.metadata.CellData; import com.alibaba.excel.metadata.Head; import com.alibaba.excel.util.StyleUtil; import com.alibaba.excel.write.handler.CellWriteHandler; import com.alibaba.excel.write.handler.SheetWriteHandler; import com.alibaba.excel.write.metadata.holder.WriteSheetHolder; import com.alibaba.excel.write.metadata.holder.WriteTableHolder; import com.alibaba.excel.write.metadata.holder.WriteWorkbookHolder; import com.alibaba.excel.write.metadata.style.WriteCellStyle; import com.alibaba.excel.write.metadata.style.WriteFont; import lombok.extern.slf4j.Slf4j; import org.apache.commons.collections4.CollectionUtils; import org.apache.poi.ss.usermodel.*; import org.apache.poi.ss.util.CellRangeAddressList; import org.apache.poi.xssf.usermodel.XSSFDataValidation; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; @Slf4j public class DropDownSheetHandler implements SheetWriteHandler { private static final String DROP_BOX_HIDDEN_SHEET = \u0026#34;DROP_BOX_HIDDEN_SHEET\u0026#34;; // 下拉框值  private final HashMap\u0026lt;Integer, String[]\u0026gt; dropDownMap; public DropDownSheetHandler(HashMap\u0026lt;Integer, String[]\u0026gt; dropDownMap) { this.dropDownMap = dropDownMap; } @Override public void beforeSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { } @Override public void afterSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { Workbook workbook = writeWorkbookHolder.getWorkbook(); // region 在另一张Sheet中准备下拉数据  // 因为行只能创建一次，所以需要计算出最大行  int maxRows = Integer.MIN_VALUE; for (String[] arr : dropDownMap.values()) { if (arr.length \u0026gt; maxRows) { maxRows = arr.length; } } Sheet dropBoxHiddenSheet = workbook.createSheet(DROP_BOX_HIDDEN_SHEET); for (int i = 0; i \u0026lt; maxRows; i++) { Row row = dropBoxHiddenSheet.createRow(i); for (Map.Entry\u0026lt;Integer, String[]\u0026gt; entry : dropDownMap.entrySet()) { if (i \u0026lt; entry.getValue().length) { row.createCell(entry.getKey()).setCellValue(entry.getValue()[i]); } } } // 隐藏Sheet  if (!workbook.isSheetHidden(workbook.getSheetIndex(DROP_BOX_HIDDEN_SHEET))) { workbook.setSheetHidden(workbook.getSheetIndex(DROP_BOX_HIDDEN_SHEET), true); } // endregion  DataValidationHelper helper = writeSheetHolder.getSheet().getDataValidationHelper(); for (Map.Entry\u0026lt;Integer, String[]\u0026gt; entry : dropDownMap.entrySet()) { String excelTag = getExcelTag(entry.getKey(), entry.getValue().length); DataValidationConstraint dataValidationConstraint = helper.createFormulaListConstraint( String.format(\u0026#34;%s!%s\u0026#34;, DROP_BOX_HIDDEN_SHEET, excelTag)); CellRangeAddressList cellRangeAddressList = new CellRangeAddressList(1, 65536, entry.getKey(), entry.getKey()); DataValidation dataValidation = helper.createValidation(dataValidationConstraint, cellRangeAddressList); // 设置错误提示  dataValidation.setErrorStyle(DataValidation.ErrorStyle.STOP); dataValidation.setShowErrorBox(true); dataValidation.setSuppressDropDownArrow(true); dataValidation.createErrorBox(\u0026#34;错误提示\u0026#34;, \u0026#34;请选择下拉框内选项!\u0026#34;); writeSheetHolder.getSheet().addValidationData(dataValidation); } } private String getExcelTag(int row, int length) { if (row \u0026lt; 0) { throw new RuntimeException(\u0026#34;Wrong RowIndex Show Bigger Then 0\u0026#34;); } int leftRow = row / 26; int rightRow = row % 26; String leftRowChar = leftRow == 0 ? \u0026#34;\u0026#34; : String.valueOf((char) (65 + leftRow - 1)); String rightRowChar = String.valueOf((char) (65 + rightRow)); return String.format(\u0026#34;$%s%s$%d:$%s%s$%d\u0026#34;, leftRowChar, rightRowChar, 1, leftRowChar, rightRowChar, length); } }   ColorWithHeadCellHandler.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  package com.sdstc.anta.material.utils.excel.handlers_with_new_scheme; import com.alibaba.excel.metadata.CellData; import com.alibaba.excel.metadata.Head; import com.alibaba.excel.util.StyleUtil; import com.alibaba.excel.write.handler.CellWriteHandler; import com.alibaba.excel.write.metadata.holder.WriteSheetHolder; import com.alibaba.excel.write.metadata.holder.WriteTableHolder; import com.alibaba.excel.write.metadata.style.WriteCellStyle; import com.alibaba.excel.write.metadata.style.WriteFont; import org.apache.commons.collections4.CollectionUtils; import org.apache.poi.ss.usermodel.*; import java.util.List; public class ColorWithHeadCellHandler implements CellWriteHandler { //操作列  private final List\u0026lt;Integer\u0026gt; colorList; //颜色  private final Short color; public ColorWithHeadCellHandler(List\u0026lt;Integer\u0026gt; colorList, Short color) { this.colorList = colorList; this.color = color; } @Override public void beforeCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Row row, Head head, Integer columnIndex, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellDataConverted(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, CellData cellData, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { } @Override public void afterCellDispose(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, List\u0026lt;CellData\u0026gt; cellDataList, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) { if (isHead) { // 设置标题字体样式  Workbook workbook = writeSheetHolder.getSheet().getWorkbook(); WriteCellStyle headWriteCellStyle = new WriteCellStyle(); WriteFont headWriteFont = new WriteFont(); if (CollectionUtils.isNotEmpty(colorList) \u0026amp;\u0026amp; color != null \u0026amp;\u0026amp; colorList.contains(cell.getColumnIndex())) { // 设置字体颜色  headWriteFont.setColor(color); } headWriteCellStyle.setWriteFont(headWriteFont); headWriteCellStyle.setFillForegroundColor(IndexedColors.GREY_25_PERCENT.getIndex()); CellStyle cellStyle = StyleUtil.buildHeadCellStyle(workbook, headWriteCellStyle); cell.setCellStyle(cellStyle); } } }   使用时的案例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  @Override public void exportTemplate(OutputStream outputStream) { // 增补系列  String[] supplementSeriesArr = new String[]{\u0026#34;篮球\u0026#34;, \u0026#34;跑鞋\u0026#34;, \u0026#34;综训\u0026#34;, \u0026#34;生活\u0026#34;, \u0026#34;儿童\u0026#34;}; // 申请季节  String[] applySeasonsArr = new String[YEARS * 4]; int start = LocalDateTime.now().getYear() % 2000; for (int i = 0; i \u0026lt; YEARS; i++) { for (int j = 0; j \u0026lt; 4; j++) { applySeasonsArr[4 * i + j] = String.format(\u0026#34;%sQ%s\u0026#34;, start + i, j + 1); } } HashMap\u0026lt;Integer, String[]\u0026gt; dropDown = new HashMap\u0026lt;\u0026gt;(); dropDown.put(1, applySeasonsArr); dropDown.put(5, supplementSeriesArr); // 必填字段  List\u0026lt;Integer\u0026gt; columns = Arrays.asList(0, 1, 4, 5); DropDownSheetHandler dropDownSheetHandler = new DropDownSheetHandler(dropDown); ColorWithHeadCellHandler colorWithHeadCellHandler = new ColorWithHeadCellHandler(columns, IndexedColors.RED.index); EasyExcelUtilsWithNewScheme.writeExcelWithModel( outputStream, new ArrayList\u0026lt;\u0026gt;(), MaterialSupplementDto.class, \u0026#34;面料增补\u0026#34;, dropDownSheetHandler, colorWithHeadCellHandler); }   1 2 3    参考资料  EasyExcel增加下拉选择框 2.1.3版本 写Excel 列宽自适应策略的问题  ","description":"","id":201,"section":"notes","tags":null,"title":"EasyExcel工具简单整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/easyexcel%E5%B7%A5%E5%85%B7%E7%AE%80%E5%8D%95%E6%95%B4%E7%90%86/"},{"content":"如下代码：\n对应生成的YApi文档为：\n这其实不是我想要的，因为我们的@RequestAttribute会从Header中获取一个值赋给该字段，而这个Header来源于网关对token的解析。\n参考了官方的文档，似乎没有零侵入的方案，所以我采用了自己实现注解的方案，我开发的方案如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package com.sdstc.authcenter.annotations; import java.lang.annotation.*; /** * 用于EasyYAPI隐藏@RequestAttribute */ @Documented @Retention(RetentionPolicy.SOURCE) @Target(ElementType.PARAMETER) public @interface EasyYAPIIgnoreParam { boolean hide() default true; }   easyyapi的配置如下：\n param.ignore=@com.sdstc.authcenter.annotations.EasyYAPIIgnoreParam#hide 代码中的写法如下：\n1 2 3 4 5 6 7 8 9  @PostMapping(\u0026#34;/createAuthAppRole\u0026#34;) public ResponseVo\u0026lt;String\u0026gt; createAuthAppRole( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @EasyYAPIIgnoreParam @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid CreateAuthAppRoleRequest request) { return ResponseVo.createSuccessByData(authAppRoleService.createAuthAppRole(userId, tenantId, request)); }   目前YApi的表现和期待的一样，我将持续关注这个问题。\n方案优化 当然，这件事到此并没有结束，在我后来的研究中我发现我们的项目时注解了@RequestAttribute(APICons.REQUEST_USER_ID)的参数需要被忽略，所以我完全可以针对这个注解进行EasyYapi的配置，所以我删除了我开发的注解，并进行了如下的配置。\n param.ignore=@org.springframework.web.bind.annotation.RequestAttribute 代码中的写法如下：\n1 2 3 4 5 6 7 8 9  @PostMapping(\u0026#34;/createAuthAppRole\u0026#34;) public ResponseVo\u0026lt;String\u0026gt; createAuthAppRole( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @EasyYAPIIgnoreParam @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid CreateAuthAppRoleRequest request) { return ResponseVo.createSuccessByData(authAppRoleService.createAuthAppRole(userId, tenantId, request)); }   目前的这个方案我还是挺满意的，哈哈。\n参考资料  EasyYapi官方文档：param_ignore java在注解中绑定方法参数的解决方案  ","description":"","id":202,"section":"notes","tags":null,"title":"EasyYApi处理@RequestAttribute注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E5%A4%84%E7%90%86requestattribute%E6%B3%A8%E8%A7%A3/"},{"content":"我用渣英语提交的Issues，官方一天的时间就帮我修复了，非常棒的体验，哈哈。\n另外EasyYApi真的非常非常的好用，大爱。\n","description":"","id":203,"section":"notes","tags":null,"title":"EasyYApi提交的Bug被处理了，非常棒的体验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E6%8F%90%E4%BA%A4%E7%9A%84bug%E8%A2%AB%E5%A4%84%E7%90%86%E4%BA%86%E9%9D%9E%E5%B8%B8%E6%A3%92%E7%9A%84%E4%BD%93%E9%AA%8C/"},{"content":"Postman 我先从Postman整理起，虽然Postman相关的配置是我最后才实践的，但是确实提升了我不少编码幸福度。我比较喜欢使用Postman进行接口的测试，没有原因就是单纯的习惯了。我之前的方案是先用EasyYapi导出成一个文件，再在Postman中导入这个文件，步骤比较多，挺麻烦的。\n新方案为：\n 先生成一个Postman Token，然后配置到Idea中，这样我就可以直接通过EasyYapi将接口导入到我的Postman中了（Postman Token获取地址：https://go.postman.co/integrations/services/pm_pro_api）  配置postman.prerequest为如下内容，这样导出的每个接口在请求时都会自动加上token和Sdtc-Tenant-Id的Header，这样就不需要我手动填写了，非常舒服   pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({key: \u0026quot;token\u0026quot;,value: \u0026quot;{{token}}\u0026quot;}) pm.request.headers.add({key: \u0026quot;Sdtc-Tenant-Id\u0026quot;,value: \u0026quot;12345678910\u0026quot;}) 当然我Postman上还有一个登录用的脚本，可以同时请求dev和sit环境的登录接口，将token设置到环境变量中（具体实现可以在postman分类下寻找相关笔记）。\n这套方案我目前还是有一些不太舒服的地方，EasyYapi每次导出到Postman时都是新建一个分类，而不是与旧的分类进行融合。这会导致我们Postman看上去非常的乱。\n实际上我是比较希望它们进行融合的，因为我希望完成所有的接口开发后，我能拥有一套带数据的Postman接口，用于日后的维护工作（我不喜欢@Mock等注解，会增加维护成本）\n![2021-06-30-15-52-53](https://junjie2018sz.oss-cn-shenzhen.aliyuncs.com/images/2021-06-30-15-52-53.png) 20220218后续： 没有必要去维护什么，因为很多接口及接口调试数据只是在开发期间使用频率比较高，开发完成后就基本不会用到了，所以我采用的方案是开发时每次到导出接口，然后复制之前旧的调试数据进行调试。待Collection生成过多的时候，我再使用我开发的一个脚本，一键清理所有的Collection。 ## YApi ### markdown.render.server配置 上来的第一问题就是markdown.render.server配置，我发现官网默认提供的地址被DNS污染了（我经过测试得出了这个结论），所以我不得不自行搭建一个yapi-markdown-render，在搭建yapi-markdown-render中我主要遇到的问题是：使用官方的源码，无法启动项目，因为某个依赖出现了错误，我解决这个问题的方法Fork一份源码，然后修改package.json文件，将该依赖的版本适当的改小，然后项目就可以正常的启动了，非常舒服。 [我Fork的源码地址](https://github.com/junjie2018/yapi-markdown-render) 我后来又开发了自己的Dockerfile，以在Docker中启动yapi-markdown-render，相关的笔记我放在了Docker分类下的**利用Docker快速启动开发环境**中（文章标题及目录未来可能调整），我不打算在这儿赘述了。 具体到Idea项目中，我需要在`.easy.api.config`文件的配置如下： markdown.render.server=http://192.168.13.68:3001/render\n 很尴尬，因为后来DNS又恢复了，我已经注释掉这行配置了。 ### method.return.main配置 如下代码： ~~~ java /** * xxx接口 * * @return 这是返回数据 */ @PostMapping(\u0026quot;/test\u0026quot;) public ResponseVo\u0026lt;String\u0026gt; test() { return ResponseVo.createSuccessByData(\u0026quot;tmp\u0026quot;); } 默认情况下，渲染出来的YApi文档如下：\n我们不知道返回的data类型是什么，含义是什么，当我们在.easy.api.config配置了如下代码后（具体配置要视各自项目情况而定）：\n method.return.main[groovy:it.returnType().isExtend(\u0026quot;com.sdstc.core.vo.ResponseVo\u0026quot;)]=data YApi渲染出来的页面如下：\nparam.ignore配置 1 2 3 4 5 6 7 8  @PostMapping(\u0026#34;/test\u0026#34;) public ResponseVo\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; createPdmProjMemberGroups(@RequestAttribute(APICons.REQUEST_USER_ID) String userId) { return ResponseVo.createSuccessByData(\u0026#34;tmp\u0026#34;); }   默认情况下，YAPI渲染出来时，会多一个userId的参数，这个会让人很迷惑，实际上userId是我们的网关通过解析Token，然后塞到了Header中，我们在UserIntercept中拿到这个值，然后塞到Attributes中，这儿不截图了。\n所以我进行了如下的配置：\n param.ignore=@org.springframework.web.bind.annotation.RequestAttribute postman.prerequest 这个配置是偷懒用的，我在postman分类下一篇笔记已经谈到过其用意，我目前的配置如下：\n postman.prerequest=``` pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({key: \u0026quot;token\u0026quot;,value: \u0026quot;{{token}}\u0026quot;}) pm.request.headers.add({key: \u0026quot;Sdtc-Tenant-Id\u0026quot;,value: \u0026quot;12345678910\u0026quot;}) ``` 备注与备注中分行 目标是这样的：\n代码中这么写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** * 更新项目团队（包含团队成员信息） * \u0026lt;p\u0026gt; * groupInfo中如果包含projectGroupId，则将对该团队进行更新\u0026lt;br\u0026gt; * groupInfo中如果不包含projectGroupId，则创建该团队信息\u0026lt;br\u0026gt; * 对于属于当前项目的projectGroupId，而在编辑时没有传递的，一律删除\u0026lt;br\u0026gt; */ @PostMapping(\u0026#34;/projectGroup/updatePdmProjMemberGroup\u0026#34;) @Transactional public ResponseVo updatePdmProjMemberGroup( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid UpdatePdmProjMemberGroupsRequest request) { pdmProjMemberGroupService.updatePdmProjMemberGroups(userId, tenantId, request); return ResponseVo.createSuccess(); }   json.rule.convert 目标是让Request和Response中的LocalDateTime类型，呈现在YApi上为Integer类型，具体的配置如下：\n json.rule.convert[java.time.LocalDateTime]=java.lang.Integer 默认情况下是String类型，这个不符合我们的项目场景。\n","description":"","id":204,"section":"notes","tags":null,"title":"EasyYApi目前配置总结","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/%E6%96%B9%E6%A1%88/easyyapi%E7%9B%AE%E5%89%8D%E9%85%8D%E7%BD%AE%E6%80%BB%E7%BB%93/"},{"content":"我自己开发了一条校验注解，可以省去配置message字段，我需要EasyYapi也支持这套注解，配置如下：\n # 参数配置 param.required=@com.sdstc.csc.common.validation.JNotBlank param.required=@com.sdstc.csc.common.validation.JNotNull # 字段配置 field.required=@com.sdstc.csc.common.validation.JNotBlank field.required=@com.sdstc.csc.common.validation.JNotNull 参考资料  NotBlank注解不起作用  ","description":"","id":205,"section":"notes","tags":null,"title":"EasyYapi配置以支持自定义的校验注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/easyyapi%E9%85%8D%E7%BD%AE%E4%BB%A5%E6%94%AF%E6%8C%81%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3/"},{"content":"之所以安装ElasticSearch 1.4.1，是因为《ElasticSearch实战》这本书使用的是该版本的ElasticSearch，在启动的过程中，我发现了该版本的ElasticSearch会闪退。\n我目前没有定位该问题，但是我发现如果我配置了JAVA_HOME，然后去启动我最新版的ElasticSearch，也会闪退，我估计大概率是因为JAVA_HOME导致的闪退，但是我现在没有证据。\n20210615后续：\n该问题在Linux上并不会复现。\n","description":"","id":206,"section":"notes","tags":null,"title":"ElasticSearch 1.4.1闪退问题记录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/elasticsearch/elasticsearch-1.4.1%E9%97%AA%E9%80%80%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"content":"任务调度 ScheduledExecutorService的实现具有局限性，作为线程池的管理的一部分，将会有额外的线程创建。如果有大量任务被紧凑地调度，那么这将成为一个瓶颈。Netty通过Channel的EventLoop实现任务调度解决了这一问题：\n1 2 3 4 5 6 7 8 9 10 11  Channel ch = ...; ScheduledFuture\u0026lt;?\u0026gt; future = ch.eventLoop().schedule( new Runnable() { @Override public void run(){ sout(\u0026#34;60 seconds later\u0026#34;); } }, 60, TimeUnit.SECONDS); )   如果要调度任务以隔60秒执行一次，请使用scheduleAtFixedRate()，代码如下：\n1 2 3 4 5 6 7 8 9 10 11  Channel ch = ...; ScheduledFuture\u0026lt;?\u0026gt; future = ch.eventLoop().scheduleAtFixedRate( new Runnable() { @Override public void run(){ sout(\u0026#34;Run every 60 seconds\u0026#34;); } }, 60, 60, TimeUnit.SECONDS); )   线程管理 Netty线程模型的卓越性取决于对于当前执行的Thread的身份的确认，也就是说，确定它是否是分配给当前Channel以及它的EventLoop的那一个线程。\n（不是很理解这句话，什么叫做多当前执行的Thread的身份的确认，这个确认又有什么意义）\n如果当前调用线程正是支撑EventLoop的线程，那么所提交的代码块将被直接执行。否则，EventLoop将调度该任务以便稍后执行，并将它放入到内部队列中。当EventLoop下次处理它的事件时，它会执行队列中的那些任务/事件。这也就解释了任何的Thread是如何与Channel直接教化而无需在ChannelHandler中进行额外的同步的。\n（我的理解是这样的，你缓存了Channel，然后在一个非EventLoop线程中调用write方法，这时候这个调用会被放入到EventLoop的内部队列中，当EventLoop下次处理它的事件时，这些事件会被一起处理）\n书中的图（感觉和我的理解有一点出入）\n需要注意的是，EventLoop的分配方式对ThreadLocal的使用的影响。因为一个EventLoop通常会被用于支撑多个Channel，所以多余所有相关的Channel来说，ThreadLocal都是一样的。这使得它对于实现状态跟踪来说是一个糟糕的选择。然而，在一些无状态的上下文中，它仍然可以被用来在多个Channel之间共享一些重度或者代价昂贵的对象，甚至是事件。\n","description":"","id":207,"section":"notes","tags":null,"title":"EventLoop","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/eventloop/"},{"content":"合并单元格 之前的版本中，一直是右键，然后选择合并单元格，最近用的版本貌似不支持这种方法了。\n锁定单元格 需求产生于我们开发，需要在代码中模拟单元格的锁定，所以先掌握在Excel中对其的操作。\n我简单描述下操作过程吧：\n 全选，然后右键，选择单元格属性，然后在保护选项卡中选择取消锁定。 选中需要保护的内容，然后右键，选择单元格属性，然后在保护选项卡中选择锁定。 在Excel顶部的审阅中选择保护工作簿  okay，这就实现了锁定单元格\n隐藏单元格   选中需要隐藏的第一列，按ctrl + stift + left键，选中右侧所有的键，对选中区域右键，选择隐藏\n  选中需要隐藏的第一行，按ctrl + stift + down键，选中下侧所有的键，对选中区域右键，选择隐藏\n  选择工作区域，点击右键，选择单元格格式，调整单元格边框（好看）\n  20210426补充：\n额，这是很久前整理的，我好奇能不能先选中我想要的区域，然后再执行反选呢？\n相关资料  怎么只显示EXCEL编辑区域  ","description":"","id":208,"section":"notes","tags":null,"title":"Excel常用操作","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/excel%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"content":"NodePort类型的服务默认执行源地址，这意味着从Nginx的角度来看，HTTP请求的源IP始终是接受请求的Kubernetes节点的IP地址。\n在NodePort设置中保留源IP的推荐方法是将ingress-nginx服务规范的externalTraffixPolicy字段设置为Local。\n警告：此设置有效地丢弃发送到未运行任何NGINX Ingress控制器实例的Kubernetes节点的数据包。考虑将NGINX Pod分配给特定节点，以控制NGINX Ingress控制器应该在哪些节点上被调度或不被调度。\n（我对这个配置的理解是这样的：externalTraffixPolicy设置为Local后，请求到了某个节点，这个节点上的LVPS就会将数据包路由到本机的POD上，所以，如果本机没有运行POD，则将会丢弃这个POD。从这个角度来看，我似乎不需要这个技术）\n生产中可能存在的问题 可能我们是需要记录源IP地址的，在这个问题下该如何处理呢？生产中IngressService的类型肯定不是NodePort，而负载均衡器方面的细节我还不是太了解，需要再继续研究下。即使是使用了NodePort，我觉得我们还是可以Http头中带一些信息过来，应该不是太严重，这个问题。\n参考资料  Source IP address ingress-nginx/deploy/provider/aws/service-nlb.yaml  ","description":"","id":209,"section":"notes","tags":null,"title":"externalTrafficPolicy字段的配置","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/externaltrafficpolicy%E5%AD%97%E6%AE%B5%E7%9A%84%E9%85%8D%E7%BD%AE/"},{"content":"最近又想将项目中的LocalDateTime序列化和反序列化统一起来，所以需要对Fastjson进行全局化配置，Fastjson全局化配置并不是很复杂，如下代码即可完成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器 serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); });   在这段配置中，我为fastjson的序列化配置增加了一项针对LocalDateTime类型的序列化器，该序列化器会将LocalDateTime类型的对象转换成一个时间戳。\n","description":"","id":210,"section":"notes","tags":null,"title":"Fastjson全局配置的一些事情","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%E6%83%85/"},{"content":"没有比较优雅的方案，代码如下：\n1 2 3 4 5 6 7 8 9 10  Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;json数据格式错误\u0026#34;); }   参考资料  FastJSON判断JSON字符串是JSONObject或JSONArray 如何判断一个JSON字符串是普通JSON(JSONObject)还是数组JSON(JSONArray)  ","description":"","id":211,"section":"notes","tags":null,"title":"FastJSON判断json字符串是array还是object","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%88%A4%E6%96%ADjson%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AFarray%E8%BF%98%E6%98%AFobject/"},{"content":"问题已经定位了，其实就是我自己编写的一个针对LocalDataTime序列化器没有针对null进行处理，而1.2.79会将Null传递给该序列化器，所以最终导致报错。但是报错比较隐晦，而且和出问题的点相差很远，所以定位花了很长时间。\n不过这些定位问题时发现了一个非常棒的断点位，可以很方便下次出问题时定位问题。JavaBeanSerializer的如下位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  protected void write(JSONSerializer serializer, //  Object object, //  Object fieldName, //  Type fieldType, //  int features, boolean unwrapped ) throws IOException { // ...  for (int i = 0; i \u0026lt; getters.length; ++i) { FieldSerializer fieldSerializer = getters[i]; Field field = fieldSerializer.fieldInfo.field; FieldInfo fieldInfo = fieldSerializer.fieldInfo; // 在这块进行条件断点，非常舒服  String fieldInfoName = fieldInfo.name; Class\u0026lt;?\u0026gt; fieldClass = fieldInfo.fieldClass; // ...  } // ... }   该循环会循环处理每个字段，如果字段是一个对象的话，还会进行递归处理，所以基本上可以看到每个字段是如何被处理的。\n","description":"","id":212,"section":"notes","tags":null,"title":"Fastjson升级到1.2.79问题定位","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/fastjson%E5%8D%87%E7%BA%A7%E5%88%B01.2.79%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"},{"content":"代码如下:\n1 2 3  JSONObject obj = JSONObject.parseObject(jsonStr, Feature.OrderedField);   整理这个笔记的时候发现了新的知识点。我之前一直再用JSON.parsetObject()方法，需要将返回结果再强转为JSONObject类型，很繁琐。其实上可以使用JSONObject.parseObject()方法。\n","description":"","id":213,"section":"notes","tags":null,"title":"FastJson反序列化时保持字段的顺序","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E4%BF%9D%E6%8C%81%E5%AD%97%E6%AE%B5%E7%9A%84%E9%A1%BA%E5%BA%8F/"},{"content":"事情是这样的，我用entity包下的Company开发了一个Controller，但是我FeignClient返回的是response包下Company做为返回值，由于response包下的Company缺少一部分字段，结果导致我消费端始终获取不到一部分字段，很难受。\n该问题如何避免呢？我们目前的开发方法是：Controller和FeignClient共用同一个API接口，所有的方法都在API接口中定义。\n这篇笔记主要是用于记录，防止以后在相同的事情上浪费时间。\n","description":"","id":214,"section":"notes","tags":null,"title":"Feign客户端的返回值和Controller的返回值之间没有强约束","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/feign%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC%E5%92%8Ccontroller%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC%E4%B9%8B%E9%97%B4%E6%B2%A1%E6%9C%89%E5%BC%BA%E7%BA%A6%E6%9D%9F/"},{"content":"如下代码为我们框架中自己开发的Decoder：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Slf4j public class FeignDecoder extends SpringDecoder { public FeignDecoder(ObjectFactory\u0026lt;HttpMessageConverters\u0026gt; messageConverters) { super(messageConverters); } @Override public Object decode(final Response response, Type type) throws IOException, FeignException { Object result = super.decode(response, type); if(Objects.nonNull(result)){ if (result.getClass() == ResponseVo.class) { ResponseVo vo = (ResponseVo) result; if (vo.getCode() != HttpStatus.OK.value()) { log.info(String.format(\u0026#34;Feign calling fail [%s] : %s\u0026#34;, response.headers().get(APICons.TRACKING_CODE), JSONObject.toJSONString(vo))); throw new FeignCallException(vo); } } } return result; } }   这个Decoder增加了一些我们默认的行为：如果我们client的返回结果为ResponseVo，则我们需要判断我们的code值是否为HttpStatus.OK，如果不是的话，则抛出异常。我肯定是不喜欢这种写法的，因为这不是FeighCallException的默认行为，会让人很疑惑。而且，如果我们想将服务提供端的错误消息抛出去，则我们需要用如下的写法：\n1 2 3 4 5 6 7 8 9 10 11 12  ResponseVo\u0026lt;Void\u0026gt; response = null; try { response = inviteForMaterialPlatformClient.commitInviteData(request); } catch (DecodeException e) { if (e.getCause() instanceof FeignCallException) { //noinspection unchecked  response = ((FeignCallException) e.getCause()).getResponse(); } }   ","description":"","id":215,"section":"notes","tags":null,"title":"Feign抛出了异常，及异常的处理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/feign%E6%8A%9B%E5%87%BA%E4%BA%86%E5%BC%82%E5%B8%B8%E5%8F%8A%E5%BC%82%E5%B8%B8%E7%9A%84%E5%A4%84%E7%90%86/"},{"content":"flush操作负责将ByteBuffer消息写入到SocketChannel中发送给对方。write和flush的作用概括如下：\n write：将需要写的ByteBuf存储到ChannelOutboundBuffer中 flush：从ChannelOutboundBuffer中将需要发送的数据读出来通过Channel发送出去  ChannelOutboundBuffer ChannelOutboundBuffer类主要用于存储其待处理的出站写请求的内部数据。当Netty调用write时数据不会真正的去发送而是写入到ChannelOutboundBuffer缓存队列，直到调用flush方法Netty才会从ChannelOutboundBuffer取数据发送。\n每个Unsafe都会绑定一个ChannelOutboundBuffer，也就是说每个客户端连接上服务端都会创建一个ChannelOutboundBuffer绑定客户端Channel。Netty设计ChannelOutboundBuffer是为了减少TCP缓存的压力提高系统的吞吐率。\n（这个ChannelOutboundBuffer应该客户端和服务端都需要创建吧，如果客户端使用的也是Netty的话）\n理解flushedEntry、unflushedEntry、tailEntry、flushed ChannelOutboundBuffer应该是用链表缓存数据，flushedEntry是当前已经被刷新的数据首个元素；unflushedEntry是当前没有被数显的数据的首个元素；tailEntry是链表的最后一个元素。flushed应该flushedEntry到unflushedEntry中的元素个数。在链表中展示其位置：\nEntry(flushedEntry) -\u0026gt; \u0026hellip; -\u0026gt; Entry(unflushedEntry) -\u0026gt; \u0026hellip; -\u0026gt; Entry(tailEntry)\nChannelOutboundBuffer中的数据被flush了，并不代表被写入了。所以flushedEntry到unflushedEntry之间的就是待发送的数据，unflushedEntry到tailEntry就是暂存数据，flushed就是待发送数据个数。正常情况下待发送数据发送完成后会flushedEntry指向unflushedEntry位置，并将unflushedEntry置空。\nChannelOutboundBuffer中的方法 方法如下：\n addMessage：将数据添加到队列的末尾 addFlush：准备待发送的数据，在flush前调用 nioBuffers：获取待发送数据，发送数据的时候调用 removeBytes：发送完成后调用，删除已成功写入TCP缓存的数据  参考资料  Netty——ChannelHandler之flush行为控制  ","description":"","id":216,"section":"notes","tags":null,"title":"flush行为控制","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/flush%E8%A1%8C%E4%B8%BA%E6%8E%A7%E5%88%B6/"},{"content":"布尔类型 FreeMarker中不可以直接在渲染出布尔值，需要使用如下的语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ${flag?c}\u0026lt;#assign foo = true\u0026gt; ${foo?then(\u0026#39;Y\u0026#39;, \u0026#39;N\u0026#39;)}\u0026lt;#assign foo2 = false\u0026gt; ${foo2?then(\u0026#39;Y\u0026#39;, \u0026#39;N\u0026#39;)}\u0026lt;#assign x = 10\u0026gt; \u0026lt;#assign y = 20\u0026gt; ${100 + (x \u0026gt; y)?then(x, y)}  日期类型 FreeMarker中不可以直接输出日期类型，需要使用如下的语法：\n1 2 3  renderData.put(\u0026#34;openingTime\u0026#34;, new Date());   1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;#assign x = openingTime\u0026gt; ${openingTime?time}\u0026lt;#assign openingTimeTime = openingTime?time\u0026gt; ${openingTimeTime}\u0026lt;#-- 将datetime类型转成date和time --\u0026gt; \u0026lt;#assign openingTimeDateTime = openingTime?datetime\u0026gt; ${openingTimeDateTime}${openingTimeDateTime?date}${openingTimeDateTime?time}  如果问号左边是字符串，那么这些内建函数将字符串转换成日期/时间/日期事件（实验中datetime并不好使）：\n1 2 3 4 5  renderData.put(\u0026#34;openingTimeTimeStr\u0026#34;, \u0026#34;19:27:58\u0026#34;); renderData.put(\u0026#34;openingTimeDateStr\u0026#34;, \u0026#34;2021-6-23\u0026#34;); renderData.put(\u0026#34;openingTimeDatetimeStr\u0026#34;, \u0026#34;2021-6-23 19:27:58\u0026#34;);   1 2 3 4 5  ${openingTimeTimeStr?time}${openingTimeDateStr?date}${openingTimeDateTimeStr?datetime}  还可以使用?string：\n1 2 3 4 5 6  renderData.put(\u0026#34;openingTime\u0026#34;, new java.sql.Time(123456789)); renderData.put(\u0026#34;nextDiscountDay\u0026#34;, new java.sql.Date(123456789)); renderData.put(\u0026#34;lastUpdated\u0026#34;, new java.sql.Timestamp(123456789)); renderData.put(\u0026#34;lastUpdated2\u0026#34;, new java.util.Date(123456789));   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  ${openingTime?string.short}${openingTime?string.medium}${openingTime?string.long}${openingTime?string.full}${openingTime?string.xs}${openingTime?string.iso}${nextDiscountDay?string.short}${nextDiscountDay?string.medium}${nextDiscountDay?string.long}${nextDiscountDay?string.full}${nextDiscountDay?string.xs}${nextDiscountDay?string.iso}${lastUpdated?string.short}${lastUpdated?string.medium}${lastUpdated?string.long}${lastUpdated?string.full}${lastUpdated?string.medium_short}\u0026lt;#-- medium date, short time --\u0026gt; ${lastUpdated?string.xs}${lastUpdated?string.iso}\u0026lt;#-- SimpleDateFormat patterns: --\u0026gt; ${lastUpdated?string[\u0026#34;dd.MM.yyyy, HH:mm\u0026#34;]}${lastUpdated?string[\u0026#34;EEEE, MMMM dd, yyyy, hh:mm a \u0026#39;(\u0026#39;zzz\u0026#39;)\u0026#39;\u0026#34;]}${lastUpdated?string[\u0026#34;EEE, MMM d, \u0026#39;\u0026#39;yy\u0026#34;]}${lastUpdated?string.yyyy}\u0026lt;#-- Same as ${lastUpdated?string[\u0026#34;yyyy\u0026#34;]}--\u0026gt; \u0026lt;#-- Advanced ISO 8601-related formats: --\u0026gt; ${lastUpdated?string.iso_m_u}${lastUpdated?string.xs_ms_nz}  ","description":"","id":217,"section":"notes","tags":null,"title":"FreeMarker中的数据类型","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"content":"之前学习Thymeleaf时，对其include和fragment影响深刻，其功能大致描述如下，我们在一个文件中定义多个fragment，然后在另一份文件中通过include指令，应用这份文件中的fragment。\n我非常喜欢这种方式，因为这种方式很适合模板代码的管理，模板代码中有很多时候实现一个功能的代码分散在Controller、Service、Mapper层，如果支持这种fragment，则我们可以将这些fragment写到同一个文件中，然后再不同层的模板代码中引用这些fragment代码，很可惜FreeMarker的include指令并不支持fragment。所以我决定自己实现该功能。\n这个功能我实现了两版，两版都是通过自定义指令实现的。区别是第一版在自定义指令回调中寻找模板内容，而第二版在SpringBoot项目启动时，扫描相关的目录，加载所有的模板内容到缓存中，然后在自定义指令的回调中从缓存中获取模板内容，然后渲染到页面中。\n相关的实现，在我的工具包代码中。\njunjie2018/AutoTools\n","description":"","id":218,"section":"notes","tags":null,"title":"FreeMarker实现Thymeleaf中的include和fragment","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E5%AE%9E%E7%8E%B0thymeleaf%E4%B8%AD%E7%9A%84include%E5%92%8Cfragment/"},{"content":"我在开发模板代码时，我期待我的模板代码足够清晰，所以我指令和指令之间会空较多的行，用于代码排版，如下所示：\n\u0026lt;#list columnInfos as columnInfo\u0026gt; \u0026lt;@noSpaceLine\u0026gt; \u0026lt;#-- 忽略审计字段 --\u0026gt; \u0026lt;#if columnInfo.columnName == \u0026quot;org_id\u0026quot; || columnInfo.columnName == \u0026quot;creator\u0026quot; || columnInfo.columnName == \u0026quot;modifier\u0026quot; || columnInfo.columnName == \u0026quot;gmt_create_time\u0026quot; || columnInfo.columnName == \u0026quot;gmt_modify_time\u0026quot;\u0026gt; \u0026lt;#continue\u0026gt; \u0026lt;/#if\u0026gt; \u0026lt;#if columnInfo.enumInfo??\u0026gt; /** * ${columnInfo.columnComment} * * @see ${properties.enumsPackage}.${columnInfo.enumInfo.enumClass}#value */ \u0026lt;#if columnInfo.columnName == \u0026quot;id\u0026quot;\u0026gt; @NotBlank \u0026lt;/#if\u0026gt; private ${columnInfo.enumInfo.enumValueType} ${columnInfo.beanObject}; \u0026lt;#elseif columnInfo.internalClassInfo??\u0026gt; /** * ${columnInfo.columnComment} */ private JSONObject ${columnInfo.beanObject}; \u0026lt;#else\u0026gt; /** * ${columnInfo.columnComment} */ \u0026lt;#if columnInfo.columnName == \u0026quot;id\u0026quot;\u0026gt; @NotBlank \u0026lt;/#if\u0026gt; private ${columnInfo.fieldType} ${columnInfo.beanObject}; \u0026lt;/#if\u0026gt; \u0026lt;/@noSpaceLine\u0026gt; \u0026lt;/#list\u0026gt; 其实javadoc的注释、注解和代码之间我不希望有的空行。如果不自行开发指令的话，渲染出来的代码会有很大的空隙，非常影响阅读，我阅读过FreeMarker的文档，没有找到任何好用的指令，所以最后决定自行开发。\n相关的代码体现在我的工具包中：\nNoSpaceLineDiretive.java\n思路核心为：在指令中拿取指令体，然后渲染出指令体，处理掉渲染后的内容中的空白行，再调用env.getOut().write()写回处理后的内容。\n参考资料  Freemarker自定义指令和方法\n学会  ","description":"","id":219,"section":"notes","tags":null,"title":"FreeMarker开发NoSpaceLine指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E5%BC%80%E5%8F%91nospaceline%E6%8C%87%E4%BB%A4/"},{"content":"如果现在让我处理这个问题，我会选择使用自定义指令的方式（也不一定，自定义会让模板代码增加很多无关的标签），但是当时的话我自定义指令也并不是很熟悉，所以我选择了自定义Writer，让后将Writer传递给FreeMarker的渲染方法，代码如下：\nTemplateUtilsMax.java\n代码还处理调整期，未来还可能调整代码。\n","description":"","id":220,"section":"notes","tags":null,"title":"FreeMarker渲染后的内容至多一行空行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E6%B8%B2%E6%9F%93%E5%90%8E%E7%9A%84%E5%86%85%E5%AE%B9%E8%87%B3%E5%A4%9A%E4%B8%80%E8%A1%8C%E7%A9%BA%E8%A1%8C/"},{"content":"我目前没有相关的需求，但是看这篇文章通俗易读易实践，就记录一下。\n参考资料  [Freemarker] Freemarker自定义函数  ","description":"","id":221,"section":"notes","tags":null,"title":"FreeMarker自定义函数的开发","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/freemarker/freemarker%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E7%9A%84%E5%BC%80%E5%8F%91/"},{"content":"犯的错 login to server failed: EOF  [root@localhost frp]# ./frpc -c frpc.ini 2021/04/26 08:01:32 [W] [service.go:104] login to server failed: EOF EOF 应该是网络管制的原因，我今天问同事，frp支持秘钥加密，实际上我担心的就是我的流量会被监听，被某些软件拦截。一旦对流量进行一些混淆，就可以绕过公司的网络管制了，解决方法为客户端common中加tls_enable = true配置：\n [common] server_addr = 106.53.136.171 server_port = 7000 token = password2021 tls_enable = true [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 Segmentation fault (core dumped) 出现这个错误，完全是因为自己傻逼了，下载错系统，我貌似下了个freeBsd的。这个错误我之前应该也犯过，整理时我感觉我自己貌似处理过这种错误。\n客户端启动后无法访问 额，这个主要是忘记在服务器防火墙中放开端口了，糟心！！！\n超级愚蠢的错误 我配置好的frp，并通过云服务器的端口链接到了我的客户端，但是xshell上的会话名称我用的是云服务器的ip地址，然后我恍惚了，我发现我的云服务器上frp全是frpc，我把他们都清掉，然后换成了frps，直到我的系统崩溃，我都没有反应出这件事！！！现在客户端又需要重新下载frp，额~\n实验步骤  客户端通知下载frp，解压，并去除无用的软件（去掉无用的软件主要是清晰，防止搞错东西）：  1 2 3 4 5 6 7 8 9 10 11 12 13  wget https://github.com/fatedier/frp/releases/download/v0.36.2/frp_0.36.2_linux_amd64.tar.gz mkdir frp tar -zxvf frp_0.36.2_linux_amd64.tar.gz -C frp --strip-components 1 rm -f frp_0.36.2_linux_amd64.tar.gz # 服务端 rm -f frp/frpc* # 客户端 rm -f frp/frps*   准备配置文件，并启动软件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 服务端 tee frp/frps.ini \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [common] bind_port = 9001 token = @#%#@12123adqw!@##$ tls_only = true EOF ./frp/frps -c frp/frps.ini nohup ./frp/frps -c frp/frps.ini \u0026gt; frp.log 2\u0026gt;\u0026amp;1 \u0026amp; # 客户端 tee frp/frpc.ini \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [common] server_addr = 106.53.136.171 server_port = 9001 token = @#%#@12123adqw!@##$ tls_enable = true [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 EOF nohup ./frp/frpc -c frp/frpc.ini \u0026gt; frp.log 2\u0026gt;\u0026amp;1 \u0026amp;     疑似被局域网禁用连接\n  记一次frp的被阻断的问题\n这篇博文虽然不是直接帮助我的博文，但是其记录了一些处理网络问题的过程，这个过程我非常需要，我目前正在积累知识，未来也希望能够定位处理这些问题。\n  内网渗透代理之frp的应用与改造（二）\n有些有用的东西，源码级别的，额，暂时不准备深入研究。\n  frp实现内网穿透\n有一些关于服务仪表盘的东西，我暂时没有精力研究它们。\n  官方文档\n  ","description":"","id":222,"section":"notes","tags":null,"title":"frp初步实验","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/frp/frp%E5%88%9D%E6%AD%A5%E5%AE%9E%E9%AA%8C/"},{"content":"9000 Shadowsocks\n9001 frp\n9002 openvpn\n","description":"","id":223,"section":"notes","tags":null,"title":"Frp端口设计","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/frp/frp%E7%AB%AF%E5%8F%A3%E8%AE%BE%E8%AE%A1/"},{"content":"cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf\nopenssl genrsa -out ca.key 2048\nopenssl req -x509 -new -nodes -key ca.key -subj \u0026ldquo;/CN=example.ca.com\u0026rdquo; -days 5000 -out ca.crt\nopenssl genrsa -out server.key 2048\nopenssl req -new -sha256 -key server.key\n-subj \u0026ldquo;/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com\u0026rdquo;\n-reqexts SAN\n-config \u0026lt;(cat my-openssl.cnf \u0026lt;(printf \u0026ldquo;\\n[SAN]\\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com\u0026rdquo;))\n-out server.csr\nopenssl x509 -req -days 365\n-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial\n-extfile \u0026lt;(printf \u0026ldquo;subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com\u0026rdquo;)\n-out server.crt\nopenssl genrsa -out client.key 2048\nopenssl req -new -sha256 -key client.key\n-subj \u0026ldquo;/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com\u0026rdquo;\n-reqexts SAN\n-config \u0026lt;(cat my-openssl.cnf \u0026lt;(printf \u0026ldquo;\\n[SAN]\\nsubjectAltName=DNS:client.com,DNS:example.client.com\u0026rdquo;))\n-out client.csr\nopenssl x509 -req -days 365\n-in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial\n-extfile \u0026lt;(printf \u0026ldquo;subjectAltName=DNS:client.com,DNS:example.client.com\u0026rdquo;)\n-out client.crt\n","description":"","id":224,"section":"notes","tags":null,"title":"Frp证书生成","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/frp/frp%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90/"},{"content":"我不确定我未来会不会用到相关的技术，先收集整理一下。\n参考资料   CentOS安装FRR（很重要）\n  如何使用 VTY Shell 配置路由器\n  官网文档\n  CentOS7下利用FRR路由套件实现OSPF动态路由组网\n  ","description":"","id":225,"section":"notes","tags":null,"title":"FRR相关资料整理","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/frp/frr%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":" 打开Git Bash，执行如下指令：   git config --global core.quotepath false 按如下截图操作：  参考资料  git 显示中文和解决中文乱码  ","description":"","id":226,"section":"notes","tags":null,"title":"Git Bash换成中文（待整理）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git-bash%E6%8D%A2%E6%88%90%E4%B8%AD%E6%96%87%E5%BE%85%E6%95%B4%E7%90%86/"},{"content":"该技术在做Docker镜像的时候非常好使。\n git clone git@github.com.user/my-project.git . 参考资料  git clone如何克隆到当前目录  ","description":"","id":227,"section":"notes","tags":null,"title":"Git Clone到当前目录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git-clone%E5%88%B0%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95/"},{"content":"执行如下指令：\n git reset --soft HEAD^ 这个是在push到远程分支前有效的，如果已经push到远程分支了，需要参考我另一篇笔记。\n该撤销会保存文件~~~\n参考教程  git commit之后，想撤销commit  ","description":"","id":228,"section":"notes","tags":null,"title":"git commit后撤销该commit","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git-commit%E5%90%8E%E6%92%A4%E9%94%80%E8%AF%A5commit/"},{"content":"一代版本一代神，又得开始研究GitHub Token相关的技术了。\n命令行使用  git clone https://github.com/username/repo.git Username: your_username Password: your_token 在CentOS系统上，这个东西是不会缓存的，非常的不爽。\n实际上命令行的使用方法上，还是支持原来的这种写法：https://USERNAME:TOKEN@github.com/username/repo.git，从这个角度说，应该原来的那种配置免密的方案也是支持的。\n在Windows中配置GitHub凭证 我偶然见不小心配置了GitHub凭证，先说说我是怎么操作的。\n如图，我拉取一份代码，会弹出一个页面，让我选择使用浏览器登陆还是使用code登录，我选择了使用浏览器登陆，登陆完成之后会在Windows的凭证面板生成一条凭证，下次拉取代码时，就不需要输入密码了：\n正常情况下，可以通过如下方式，进入凭证管理页面：\n然后添加一个普通的凭证即可：\n","description":"","id":229,"section":"notes","tags":null,"title":"Git Hub Token的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/git-hub-token%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"参考我的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  { \u0026#34;plugins\u0026#34;: [ \u0026#34;-search\u0026#34;, \u0026#34;-lunr\u0026#34;, \u0026#34;-sharing\u0026#34;, \u0026#34;-livereload\u0026#34;, \u0026#34;-font-settings\u0026#34;, \u0026#34;lightbox\u0026#34;, \u0026#34;expandable-chapters\u0026#34;, \u0026#34;chapter-fold\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;back-to-top-button\u0026#34;, \u0026#34;code\u0026#34;, \u0026#34;hide-element\u0026#34;, \u0026#34;custom-favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;copyButtons\u0026#34;: true }, \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/junjie2018\u0026#34; }, \u0026#34;hide-element\u0026#34;: { \u0026#34;elements\u0026#34;: [\u0026#34;.gitbook-link\u0026#34;] }, \u0026#34;favicon\u0026#34;:\u0026#34;favicon.ico\u0026#34; } }   然后执行如下指令：\n gitbook install . 配置说明 -search：去除默认的搜索插件\n-sharing：去除默认的分享插件\n-livereload：去除git serve热更新插件\n-font-settings：去除页面上的A按钮插件\nlightbox：单击查看图片\nexpandable-chapters：\nhide-element：隐藏页面一些元素用的，目前和其他插件有一些冲突\ncustom-favicon：修改标题栏的图标（我的图标是在https://favicon.io/生成的，还不错）\n参考资料  GitBook插件整理  ","description":"","id":230,"section":"notes","tags":null,"title":"GitBook安装插件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/gitbook%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6/"},{"content":"参考资料  https://segmentfault.com/a/1190000019806829 GitBook - 插件安装 - 弹出查看大图  ","description":"","id":231,"section":"notes","tags":null,"title":"gitbook常用插件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/gitbook%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/"},{"content":"试出来的：\n gitbook --version gitbook current ","description":"","id":232,"section":"notes","tags":null,"title":"Gitbook显示版本号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/gitbook%E6%98%BE%E7%A4%BA%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"指令如下：\n1 2 3 4 5  cd ~ mkdir -p Blogs/output gitbook build Blogs Blogs/output   参考资料  输出为静态网站  ","description":"","id":233,"section":"notes","tags":null,"title":"GitBook生成静态html文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/gitbook%E7%94%9F%E6%88%90%E9%9D%99%E6%80%81html%E6%96%87%E4%BB%B6/"},{"content":"在开发GitHub Actions时，我其实挺建议在脚本里写清楚各个步骤执行的指令，及指令执行后的结果的，因为这样更有利于排除错误，举一个简单的例子。\n1 2 3 4 5 6 7 8 9 10 11 12  # 执行的指令 echo \u0026#34;gitbook init\u0026#34; # 执行指令 gitbook init # 执行的结果 ls cat SUMMARY.md cat README.md   我在修复问题时就用到了这种方式，定位问题挺快的。\n","description":"","id":234,"section":"notes","tags":null,"title":"GitHub Actions开发时的一点小心得","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/github-actions%E5%BC%80%E5%8F%91%E6%97%B6%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E5%BF%83%E5%BE%97/"},{"content":"问题描述 向GitHub仓库推送代码时，先后出现了如下错误：\n1 2 3 4  git push -u origin main fatal: unable to access \u0026#39;https://github.com/junjie2018/blogs.git/\u0026#39;: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054   1 2 3 4  git push -u origin main fatal: unable to access \u0026#39;https://github.com/junjie2018/blogs.git/\u0026#39;: Failed to connect to github.com port 443: Timed out   解决方案  为Git客户端端配置代理：  1 2 3 4  git config --local http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39;   问题给的信息是真的难以定位，只是习惯性的去配一下代码。\n","description":"","id":235,"section":"notes","tags":null,"title":"GitHub推送代码失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/github%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81%E5%A4%B1%E8%B4%A5/"},{"content":"过程比较简单，直接截图了：\n","description":"","id":236,"section":"notes","tags":null,"title":"GitHub生成Token","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/github%E7%94%9F%E6%88%90token/"},{"content":"我fork了一个仓库，做了一些自己的修改，然后发起一个Pull Request，希望该仓库的原作者看到我的修改，然后决定是否采用这些修改。这个就是Pull Request的作用。\n我之前从字面意思理解这个，很糗。\n参考资料  GitHub 的 Pull Request 是指什么意思？  ","description":"","id":237,"section":"notes","tags":null,"title":"GitHub的Pull Requst","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/github%E7%9A%84pull-requst/"},{"content":"问题描述 考虑到最近GitHub经常无法正常使用，而我在开发博客脚本需要从GitHub上拉取推送代码，所以我打算在代码中使用代理，我的代码如下：\n1 2 3 4 5 6  Repo.clone_from(\u0026#34;https://github.com/junjie2018/blogs.git\u0026#34;, to_path=blogs_path, branch=\u0026#34;main\u0026#34;, config=\u0026#34;https.proxy=socks://localhost:1080\u0026#34;)   这份代码的问题是，只会偶尔一次两次成功，我并不确定是什么原因产生的。我有尝试过将socks换为http、https，情况也是一样的，都是偶尔一两次成功。我是在Windows环境下进行测试的。\n解决方案 这方面的资料太少了，我决定先绕开这个问题，在执行脚本是前，我设置Git客户端的全局代理。\n1 2 3 4  git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39;   ","description":"","id":238,"section":"notes","tags":null,"title":"gitpython模块中代理无法正常使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/gitpython%E6%A8%A1%E5%9D%97%E4%B8%AD%E4%BB%A3%E7%90%86%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E4%BD%BF%E7%94%A8/"},{"content":"我的需求是这样的，同事将代码提交到自己的分支上了，我需要查看他的代码，所以我需要切换到他的分支上，然后查看代码，我使用命令行操作git。\n我之前将这个问题复杂化了，实际上我只需要在当前分支拉取一下代码，就可以拉取到他的分支的信息，然后使用git checkout切换到他的分支上。\n参考资料   git 拉取远程分支到本地\n简单接触了一下git fetch指令\n  git获取远程服务器的指定分支\ngit pull \u0026lt;远程库名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt;：单独拉下某个分支，我使用这个指令的场景还是蛮多的\n这条指令还可以拉取远程分支与当前分支合并。\ngit pull指令相当于先做了git fetch，再做了git merge\n  ","description":"","id":239,"section":"notes","tags":null,"title":"Git切换到远程分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%88%87%E6%8D%A2%E5%88%B0%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"content":"操作步骤  指令如下  1 2 3 4  # 删除xxx.txt的跟踪，并保留在本地 git rm --cached xxx.txt   ","description":"","id":240,"section":"notes","tags":null,"title":"Git取消对文件的追踪","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%8F%96%E6%B6%88%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%BD%E8%B8%AA/"},{"content":"适用场景：在Uat或生产环境等分支不经常变更的场景，为了定位问题，增加了许多无用的代码，并提交到分支上了。待问题解决后，需要删除这些代码，建议适用分支回退功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  git checkout uat \u0026amp;\u0026amp; git pull # 本地和远程备份分支 git branch uat_backup \u0026amp;\u0026amp; git push origin uat_backup git reset --hard the_commit_id # 删除远程分支，并用本地分支重建 git push origin :uat git push origin uat # 删除远程备份分支 git push origin :uat_backup   其实并不建议使用这个方案，这个方案要删除远程分支，可能因为权限等问题无法实现，且可能因为一些意外情况，造成这个分支永远被销毁了。\n参考资料  git 远程分支回滚  ","description":"","id":241,"section":"notes","tags":null,"title":"Git回退远程分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%9B%9E%E9%80%80%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"content":"操作步骤  指令如下   git remote set-url origin https://github.com/junjie2018/out_of_memory.git ","description":"","id":242,"section":"notes","tags":null,"title":"Git客户端修改远程仓库地址","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BF%AE%E6%94%B9%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E5%9C%B0%E5%9D%80/"},{"content":"操作步骤  指令如下  1 2 3  git config --global core.editor vim   使用场景比较窄，但是当你需要的时候，你又必须去设置。\n相关教程  修改git默认的编辑器  ","description":"","id":243,"section":"notes","tags":null,"title":"Git客户端修改默认的编辑器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/"},{"content":"操作步骤  指令如下：  1 2 3 4 5 6 7  git config --global credential.helper store sudo tee ~/.git-credentials \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; https://user:password@gitee.com EOF   这个在只能走https协议的场景下非常好使，但是要记得将自己的账号设置成需要邮箱或手机号验证的，因为这种方案很容易泄漏账号信息。\n","description":"","id":244,"section":"notes","tags":null,"title":"Git客户端配置https免密","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AEhttps%E5%85%8D%E5%AF%86/"},{"content":"操作步骤  指令如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # 全局 git config --global http.proxy \u0026#39;http://192.168.13.59:1080\u0026#39; git config --global https.proxy \u0026#39;http://192.168.13.59:1080\u0026#39; git config --global http.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global http.proxy \u0026#39;http://192.168.28.118:2080\u0026#39; git config --global https.proxy \u0026#39;http://192.168.28.118:2080\u0026#39; git config --global --unset http.proxy git config --global --unset https.proxy # 本地 git config --local http.proxy \u0026#39;http://127.0.0.1:2080\u0026#39; git config --local https.proxy \u0026#39;http://127.0.0.1:2080\u0026#39; git config --local http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --local --unset http.proxy git config --local --unset https.proxy   ","description":"","id":245,"section":"notes","tags":null,"title":"Git客户端配置代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"错误如下：\n error: RPC failed; curl 56 GnuTLS recv error (-9) 解决方法：\n apt-get install gnutls-bin git config --global http.sslVerify false git config --global http.postBuffer 1048576000 参考方案  解决git clone 完成后提示\u0026rsquo;error: RPC failed; curl 56 GnuTLS recv error (-9)'  ","description":"","id":246,"section":"notes","tags":null,"title":"Git拉取代码时报错","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E6%8B%89%E5%8F%96%E4%BB%A3%E7%A0%81%E6%97%B6%E6%8A%A5%E9%94%99/"},{"content":"代码如下：\n1 2 3  git branch -r   ","description":"","id":247,"section":"notes","tags":null,"title":"Git查看远程分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E6%9F%A5%E7%9C%8B%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"content":"我准备换pygit为GitPython，但是我导入git包后找不到用不了git.Repo，我已经在PyCharm的Inspector中去掉了pygit、gitdb，这些可能影响到我的模块，并开了一个新的项目去测试GitPython，发现是正常的。\n我按住ctrl后，点击git模块，在项目定位到了一个名为git的目录，我感觉这个我的情况不符合，所以我删掉了GitPython，又重新引入，然后按住ctrl后，点击git模块，这此进来的一个git.py文件，这个比较符合我的情况。\n可能是之前导入模块的时候，相互影响了吧。\n","description":"","id":248,"section":"notes","tags":null,"title":"git模块的小问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/git%E6%A8%A1%E5%9D%97%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8  # 删除untracker files git clean -f # 连untracked的目录一起删除 git clean -fd   ","description":"","id":249,"section":"notes","tags":null,"title":"Git清除未跟踪的文件和文件夹","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E6%B8%85%E9%99%A4%E6%9C%AA%E8%B7%9F%E8%B8%AA%E7%9A%84%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"代码如下：\n git config --global user.name 小桀 git config --global user.email 812797569@qq.com ","description":"","id":250,"section":"notes","tags":null,"title":"Git设置提交时的用户名和账号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E8%AE%BE%E7%BD%AE%E6%8F%90%E4%BA%A4%E6%97%B6%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E8%B4%A6%E5%8F%B7/"},{"content":"重建分支 因为分支错乱，所以我们决定用uat分支重建dev和sit\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 备份分支，并推送到远程 git branch develop_20211026 \u0026amp;\u0026amp; git push origin develop_20211026 git branch sit_20211026 \u0026amp;\u0026amp; git push origin sit_20211026 # 删除远程分支 git push origin :develop git push origin :sit # 删除本地分支 git branch -D develop git branch -D sit # 重建本地分支，并推送到远程 git checkout uat \u0026amp;\u0026amp; git checkout -b develop \u0026amp;\u0026amp; git push --set-upstream origin develop git checkout uat \u0026amp;\u0026amp; git checkout -b sit \u0026amp;\u0026amp; git push --set-upstream origin sit   操作过程中药多检查，确保每一步操作都到位了。\n","description":"","id":251,"section":"notes","tags":null,"title":"Git重建分支","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/git%E9%87%8D%E5%BB%BA%E5%88%86%E6%94%AF/"},{"content":"今天第一次接触GRpc，之前有做游戏开发时用的ProtoBuf，对这个东西印象很好，GRpc的底层貌似就是ProtoBuf。\n大概说下我做了哪些操作吧：\n  为类加上@GRpcService注解，这个注解是我们自己开发的，我还没有去了解这些注解的细节。\n  启动应用程序，在日志里搜索port，可以看到GRpcService监听的是9090端口\n  下载grpcui，解压后配置一些环境变量，然后打开cmd执行grpcui -help\n  执行如下指令，将打开一个新的Web页面，该页面就是用来测试GRpc的工具。\n   grpcui -plaintext localhost:9090 GRpc服务的代码如何编写？我刚开始在这个方面犯错了，错误表现为在grpcui点击了invoke按钮后，invoke按钮一直是灰色的。后来按照同事提供的方式编写了如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Override public void create(com.sdstc.catalog.paas.dm.api.EnterModel.CreateRequest request, io.grpc.stub.StreamObserver\u0026lt;com.sdstc.catalog.paas.dm.api.EnterModel.CreateResponse\u0026gt; responseObserver) { System.out.println(\u0026#34;This is Create\u0026#34;); printObject(request); responseObserver.onNext(EnterModel.CreateResponse.newBuilder() .setCode(200) .setRelateId(\u0026#34;1111\u0026#34;) .build()); responseObserver.onCompleted(); }   我犯错的原因是，我没有执行responseObserver.onCompleted()。\n我们的GRpc用在什么场景中？我们有一个目录服务，我们公司所有上传的项目最终都会将内容提交到这个项目中。之前我们的方案中，用户提交的内容先提交到各自服务，然后再调用目录服务的接口，将这些数据提交到目录服务中（是这样么，我不确定之前是不是这样实现的）。\n这样做有什么坏处呢？我们服务间通信使用的是Restful风格的接口，Http请求的时候是有可能失败的，我们是需要进行重试处理的。我们虽然有自己的重试服务，重试工作会比较简单，但是我们每个服务依旧需要提供Client去处理重试逻辑，这会增加每个开发人员的工作量。而且重试只是最终保证了我们的数据时正确的，当数据驻留在消息服务器上的时候，可能会给我们的项目Debug时带来一些困扰。\n还有什么问题呢？目录服务是一个中心服务，向其提交数据有两种方式，暴露接口，让中心服务自己拉取；调用中心服务的接口，将数据主动推送过去。很多时候，我们的服务是需要同时支持这两种方式的，这无形中增加了各个服务的开发量。而且由各个服务决定数据的形式，目录服务本身也会进行一些开发，进行适配。\n总之，在我看来，之前的这种方案，隐含了很多的开发任务，和系统运行的不稳定因素。\n我们新方案的思路是怎样的呢？前端直接将数据提交到目录服务，目录服务完成处理后，调各个服务的接口将用户的数据通知到各个服务。然后服务拿到这些数据后，再按照设计进行入库、或更新。有时候目录中心需要全量的服务数据，这个也是通过GRpc的服务实现的。\n我对这套设计的理解就这些了，还在探索中。\n","description":"","id":252,"section":"notes","tags":null,"title":"GRpc与我们的项目","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/grpc/grpc%E4%B8%8E%E6%88%91%E4%BB%AC%E7%9A%84%E9%A1%B9%E7%9B%AE/"},{"content":"因为需要更换为新Service，所以导致项目中新旧同时存在，项目启动的时候没有任何问题，但是我用grpcui去连接的时候，报了如下的错误：\n Failed to compute set of methods to expose: Symbol not found: com.sdstc.catalog.paas.dm.api.DataModel_12CatalogDMAdapterService DataModel_12CatalogDMAdapterService是我开发的新服务，我的解决方法是将旧服务的代码全部注解掉。\n暂时没有精力对这些问题深入研究，先记录下吧。\n","description":"","id":253,"section":"notes","tags":null,"title":"GRpc问题记录：两个版本的服务同时存在","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/grpc/grpc%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E4%B8%A4%E4%B8%AA%E7%89%88%E6%9C%AC%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8/"},{"content":"我用的时候一般直接解压到当前目录：\n gzip xxx.gz -d 解压位置 参考资料  解压.gz和.tar.gz文件  ","description":"","id":254,"section":"notes","tags":null,"title":"gzip解压.gz后缀结尾的文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/gzip%E8%A7%A3%E5%8E%8B.gz%E5%90%8E%E7%BC%80%E7%BB%93%E5%B0%BE%E7%9A%84%E6%96%87%E4%BB%B6/"},{"content":"目前这个方式适用的场景有点窄，只用为Docker Hub和同Harbor仓库进行代理缓存。先观望着吧。\n参考资料  使用harbor代理缓存docker hub  ","description":"","id":255,"section":"notes","tags":null,"title":"Harbor配置代理缓存","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/harbor%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86%E7%BC%93%E5%AD%98/"},{"content":"简单指令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 展示可配置项 helm show values bitnami/wordpress # 使用指定文件覆盖默认配置 echo \u0026#39;{mariadb.auth.database: user0db, mariadb.auth.username: user0}\u0026#39; \u0026gt; values.yaml helm install -f values.yaml bitnami/wordpress --generate-name # 查看指定release中--set设置的值 helm get values \u0026lt;release-name\u0026gt; # 清除--set中设置的值 helm upgrade --reset-values   两种方式传递配置数据  \u0026ndash;values(或-f)：使用YAML文件覆盖配置。可以指定多次，优先使用最右边的文件。 \u0026ndash;set：通过命令行的方式对指定项进行覆盖。  如果同时使用两种方式，则\u0026ndash;set中的值会被合并到\u0026ndash;values中，但是\u0026ndash;set中的值优先级更高。\n\u0026ndash;set的格式和限制 \u0026ndash;set选项使用0或多个name/value对。最简单的用法类似于：\u0026ndash;set name=value，等价于如下YAML格式：\n1 2 3  name:value  多个值使用逗号分割，因此\u0026ndash;set a=b,c=d的YAML表示是：\n1 2 3 4  a:bc:d  支持更复杂的表达式。例如，\u0026ndash;set outer.inner=value 被转换成了：\n1 2 3 4  outer:inner:value  列表使用花括号（{}）来表示。例如，\u0026ndash;set name={a, b, c} 被转换成了：\n1 2 3 4 5 6  name:- a- b- c  可以使用数组下标的语法来访问列表中的元素。例如 \u0026ndash;set servers[0].port=80 就变成了：\n1 2 3 4  servers:- port:80  多个值也可以通过这种方式来设置。\u0026ndash;set servers[0].port=80,servers[0].host=example 变成了：\n1 2 3 4 5  servers:- port:80host:example  如果需要在 \u0026ndash;set 中使用特殊字符，你可以使用反斜线来进行转义；\u0026ndash;set name=value1,value2 就变成了：\n1 2 3  name:\u0026#34;value1,value2\u0026#34;  类似的，你也可以转义点\u0008序列（英文句号）。这可能会在 chart 使用 toYaml 函数来解析 annotations，labels，和 node selectors 时派上用场。\u0026ndash;set nodeSelector.\u0026ldquo;kubernetes.io/role\u0026rdquo;=master 语法就变成了：\n1 2 3 4  nodeSelector:kubernetes.io/role:master  深层嵌套的数据结构可能会很难用\u0026ndash;set表达。我们希望Chart的设计者们在设计values.yaml文件的格式时，考虑到\u0026ndash;set的使用。\n参考资料  安装前自定义 chart  ","description":"","id":256,"section":"notes","tags":null,"title":"Helm安装Chart前修改配置文件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/helm%E5%AE%89%E8%A3%85chart%E5%89%8D%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"content":"执行指令如下：\n1 2 3 4 5  helm upgrade --install ingress-nginx ingress-nginx \\  --repo https://kubernetes.github.io/ingress-nginx \\  --namespace ingress-nginx --create-namespace   创建服务进行测试  创建必要的资源  1 2 3 4 5 6 7 8 9 10  # 创建一个Deployment及Service kubectl create deployment demo --image=httpd --port=80 kubectl expose deployment demo # 创建Ingress资源 kubectl create ingress demo-localhost \\  --class=nginx \\  --rule=demo.localdev.me/*=demo:80   使用kubectl get services -n ingress-nginx -o wide查看Ingress的端口  配置开发机的Host  使用浏览器进行访问  检查Ingress Controller Version 1 2 3 4 5  POD_NAMESPACE=ingress-nginx POD_NAME=$(kubectl get pods -n $POD_NAMESPACE -l app.kubernetes.io/name=ingress-nginx --field-selector=status.phase=Running -o name) kubectl exec $POD_NAME -n $POD_NAMESPACE -- /nginx-ingress-controller --version   生成证书 1 2 3 4 5 6  openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\  -keyout nginx.key \\  -out nginx.crt \\  -subj \u0026#34;/CN=th-2\u0026#34;     CountryName(/C)\n  StateOrProvinceName(/ST)\n  LocalityName(/L)\n  OrganizationName(/O)\n  OrganizationUnitName(/OU)\n  CommonName(ed,your name or your server\u0026rsquo;s name)(/CN)\n  EmailAddress(/emailAddress)\n  参考资料  NGINX Ingress Controller  ","description":"","id":257,"section":"notes","tags":null,"title":"Helm安装IngressNginx（作废）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/helm%E5%AE%89%E8%A3%85ingressnginx%E4%BD%9C%E5%BA%9F/"},{"content":" 从Artifact Hub中、repo中搜索chart  1 2 3 4 5 6 7 8  # 从hub中 helm search hub wordpress # 从repo中 helm repo add brigade https://brigadecore.github.io/charts helm search repo brigade   安装chart  1 2 3 4 5 6 7 8 9 10 11 12 13  # release名字和chart名字 helm install happy-panda bitnami/wordpress helm install bitnami/wordpress --generate-name # 多种来源进行安装 helm install foo foo-0.1.1.tgz helm install foo path/to/foo helm install foo https://example.com/charts/foo-1.2.3.tgz # 查看Release状态 helm status happy-panda   安装前自定义chart（简单版）  1 2 3 4 5 6 7 8  # 查看chart中的可配置项 helm show values bitnami/wordpress # 使用yaml格式文件覆盖任意配置 echo \u0026#39;{mariadb.auth.database: user0db, mariadb.auth.username: user0}\u0026#39; \u0026gt; values.yaml helm install -f values.yaml bitnami/wordpress --generate-name   升级release和失败时恢复  1 2 3 4 5 6 7 8 9 10  # 升级chart的新版本或修改release的配置 helm upgrade -f panda.yaml happy-panda bitnami/wordpress # 可以用于失败时回滚 helm rollback happy-panda 1 # 查看一个特定release的修订版本号 helm history [RELEASE]   卸载相关   helm uninstall happy-panda helm list helm uninstall --keep-history helm list --uninstalled helm list --all 仓库管理   helm repo list helm repo add dev https://example.com/dev-charts # 更新仓库 helm repo update # 移除仓库 helm repo remove dev 创建Chart   helm create deis-workflow # 验证格式 helm lint # 打包分发 helm package deis-workflow # 安装chart helm install deis-workflow ./deis-workflow-0.1.0.tgz 参考资料  使用Helm  ","description":"","id":258,"section":"notes","tags":null,"title":"Helm常用指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/helm%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"如下插件配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  { \u0026#34;plugins\u0026#34;: [ \u0026#34;-search\u0026#34;, \u0026#34;-sharing\u0026#34;, \u0026#34;-livereload\u0026#34;, \u0026#34;-font-settings\u0026#34;, \u0026#34;lightbox\u0026#34;, \u0026#34;expandable-chapters\u0026#34;, \u0026#34;github\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;back-to-top-button\u0026#34;, \u0026#34;code\u0026#34;, \u0026#34;hide-element\u0026#34;, \u0026#34;custom-favicon\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;code\u0026#34;: { \u0026#34;copyButtons\u0026#34;: true }, \u0026#34;github\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://github.com/junjie2018\u0026#34; }, \u0026#34;hide-element\u0026#34;: { \u0026#34;elements\u0026#34;: [\u0026#34;.gitbook-link\u0026#34;,\u0026#34;chapter\u0026#34;] }, \u0026#34;favicon\u0026#34;:\u0026#34;favicon.ico\u0026#34; } }   我在使用中发现，如果我不清除search、sharing、livereload插件，则hide-element插件会起到作用。但是一旦清除了它们，则该插件不会起到任何作用。\n是为什么发生这个问题呢？其实如上的配置，其实会导致我页面报错，页面报错，可能会导致我hide-element的方法没有被执行到，从而无法影藏我想隐藏的内容。\n该如何处理这个问题呢？其实search有一个lunr的插件，这个插件应该是search的后端（具体实现不是太了解），如果我们需要删除search插件，则需要同时删除lunr插件，否则就会导致页面报错。\n后续：\n我在定位这个问题时，在hide-elements配置中加了如下的配置：\n结果后来忘记清除了，导致我这个配置用在了各个地方，最终导致我发布笔记左侧没有目录结构，糟心。\n","description":"","id":259,"section":"notes","tags":null,"title":"hide-element插件冲突的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/hide-element%E6%8F%92%E4%BB%B6%E5%86%B2%E7%AA%81%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"这是之前处理问题时用到的资料，整理一份。\n背景是这样的，我们的http可以正常的建立链接，但是https无法正常的建立链接。\n参考资料  SSL Handshake 被莫名其妙地 RST  ","description":"","id":260,"section":"notes","tags":null,"title":"https无法正常链接","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/istio/https%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E9%93%BE%E6%8E%A5/"},{"content":"这个问题只能算作是记录，我目前也不知道具体产生的原因。我知道curl指令默认情况下不会通过socks5解析域名，所以测试的时候我需要使用socks5h。但是http不存在这个问题，使用http协议时，会将url发送到代理的服务端去解析（实际上，这个问题我还没有从原理层面理解）。\n所以，我想将kt的socks5代理转为http代理，当我这样实践的时候，我已经可以确保我的curl工具是按照我的想法成功的访问我的服务的。但是，将访问服务的代码移动到Java代码中时，一切都发生了变化，始终报无法正确的解析hostname（我使用了Proxifier工具，Proxifier可以全局代理应用的流量，我想不修改代码，就完成网络环境的切换）。\n后来经过分析我发现，我的Java代码在访问的时候，一定需要先将我的url解析成ip地址，然后再通过Proxifier去访问我的代理服务器，这肯定是我不想要的（我已经设置了Proxifier的域名解析，但是没有任何效果）。在我的理解中，我的代码应该将url的解析也交给我的代理服务器实现。\n最后我偶然发现将协议换成socks5的话，该问题不存在，我的url可以正常的通过我的代理服务器解析。\n这件事只能说用暴力破解法，挨个挨个试不同的方案，然后得出的结果，没有任何有价值的知识收获。\n我在解决这个问题时用了如下的方案，但是这些方案实操都挺复杂而且还有问题，不是很容易推广：\n  在Linux虚拟机上用CoreDNS搭一个DNS服务器，然后给开发机配多一个DNS。实践的过程中发现Win只会在首选DNS服务器无法正常访问时才启用备用DNS，如果首选DNS服务器返回错误信息，并不会向备用DNS服务器请求。\n  打算走OpenVPN方案，但是运维组卡死了权限，什么都做不了。\n  切换RestTemplate底层的实现，失败了，无论是okHttp还是HttpClient都存在这个问题。\n  切换kt为vpn模式，失败了，无论如何都无法正常启动。\n  研究的过程中使用了如下资料：\n HttpClient设置DNS HTTP客户端连接，选择HttpClient还是OkHttp？ Proxies With RestTemplate 精讲RestTemplate第10篇-使用代理作为跳板发送请求 Name Resolution Proxifier使用教程        ","description":"","id":261,"section":"notes","tags":null,"title":"http协议的代理和Socks5协议的代理","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/http%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%BB%A3%E7%90%86%E5%92%8Csocks5%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%BB%A3%E7%90%86/"},{"content":"指令：\n hugo -D 输出的文件默认放在public目录下，可以通过-d/\u0026ndash;destination修改文件生成时存放的位置，或者在配置文件中通过publishdir修改文件生成后存放的位置。\n参考资料  Build static pages  ","description":"","id":262,"section":"notes","tags":null,"title":"Hugo输出静态文件","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/hugo%E8%BE%93%E5%87%BA%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6/"},{"content":"安装主题后，用如下指令运行代码：\n hugo server --minify --theme book --bind=\u0026quot;0.0.0.0\u0026quot; --baseUrl=\u0026quot;http://192.168.27.121:1313\u0026quot; 报错，无法运行。我安装的是非扩展版，去官方下载扩展版即可。\nhugo release\n","description":"","id":263,"section":"notes","tags":null,"title":"Hugo运行时提示：you need the extended version to build SCSSSASS","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/hugo%E8%BF%90%E8%A1%8C%E6%97%B6%E6%8F%90%E7%A4%BAyou-need-the-extended-version-to-build-scsssass/"},{"content":"Hutool v5.6.3\n","description":"","id":264,"section":"notes","tags":null,"title":"Hutool工具的研究（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/hutool%E5%B7%A5%E5%85%B7%E7%9A%84%E7%A0%94%E7%A9%B6%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"这个问题的核心原因在于Idea版本和Maven版本不兼容。这篇文章整理的太晚了，好多细节信息没有记录下来。先这样吧，知道版本不兼容问题可能会带来问题就好。\n参考资料   Maven3.6.3 在IntelliJ IDEA2019新版本中问题，Unable to import maven project: See logs for details\n  #org.jetbrains.idea.maven - com.google.inject.CreationException: Unable to create injector, see the\n  ","description":"","id":265,"section":"notes","tags":null,"title":"Idea与Maven集成的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%8Emaven%E9%9B%86%E6%88%90%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我其实一致没有系统深入的学习Git，但是现在新工作已经对我这方面能力提出了要求，我先从Idea中Git的使用下手，然后陆续学习更高级的Git知识。\n","description":"","id":266,"section":"notes","tags":null,"title":"Idea中Git的使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%ADgit%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"content":"想看一下spring-boot-starter-parent的源码，看看版本裁决时用了哪些变量，但是发现Idea无法调整到这些源码，这就很奇怪了。\n我没有找到解决跳转问题的办法，先记录一下。我pom文件中parent标签内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt;   通过重新定义spring-boot-starter-parent，从而改变所依赖的组件的版本是一个蛮重要的技术（个人认为），所以以后还是要解决这个问题的。我目前选择的绕开这个问题的方法是，在仓库里手动找到这个pom文件，然后再打开这个文件。\nspring-boot-starter-parent项目的父依赖为spring-boot-dependencies，版本裁决时用到的变量都存在了这个项目中。\n关于版本裁决的利用 针对我们自行开发的starter，如果这些starter中引入了其他的组件，我们想对这些组件进行版本管理，我觉得可行的方案是，我们自行开发一个starter-parent，该starter的parent为spring-boot-starter-parent，其中增加了许多企业内部使用的组件的版本。甚至该starter-parent中可以对spring-boot-starter-parent中的一些变量进行覆盖，从而控制它们的版本号。\n我简单开发了一个Demo用于验证我这种思想，项目结构如下，其中demo为父项目，jj-starter-parent为父依赖，jj-demo依赖于jj-starter-parent。\ndemo的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;jj-parent-starter\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;jj-demo\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/project\u0026gt;   jj-starter-parent的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jj-parent-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;/project\u0026gt;   jj-demo的pom.xml文件为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jj-parent-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;relativePath\u0026gt;../jj-parent-starter/pom.xml\u0026lt;/relativePath\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;artifactId\u0026gt;jj-demo\u0026lt;/artifactId\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;   实验中，效果和我预计的一样，基本上是实验成功的。\n项目中的starter-parent开发思路 待续。。。\n","description":"","id":267,"section":"notes","tags":null,"title":"Idea中无法跳转到spring-boot-starter-parent源码了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/idea%E4%B8%AD%E6%97%A0%E6%B3%95%E8%B7%B3%E8%BD%AC%E5%88%B0spring-boot-starter-parent%E6%BA%90%E7%A0%81%E4%BA%86/"},{"content":"之前看源码时频繁用到的技术，最近这段时间看源码比较少，先收藏一下，未来用到了再整理。\n参考资料  idea查看类层次结构图  ","description":"","id":268,"section":"notes","tags":null,"title":"Idea中查看类层次结构","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%AD%E6%9F%A5%E7%9C%8B%E7%B1%BB%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/"},{"content":"有时候习惯了VSCode的小图标，在Idea中会不自觉的去找分屏的小图标：\n","description":"","id":269,"section":"notes","tags":null,"title":"Idea中进行分屏显示代码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%88%86%E5%B1%8F%E6%98%BE%E7%A4%BA%E4%BB%A3%E7%A0%81/"},{"content":"需求是这样的，我需要查看datasource的username被哪个Properties类接受了，只需按住ctrl键，然后按这个配置即可。\n我之前犯的错误是这样的：我按住ctrl键，然后点击datasource，始终无法跳转，很是糟心。\n","description":"","id":270,"section":"notes","tags":null,"title":"Idea从application.yml配置项跳转到配置项对应的Properties类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%BB%8Eapplication.yml%E9%85%8D%E7%BD%AE%E9%A1%B9%E8%B7%B3%E8%BD%AC%E5%88%B0%E9%85%8D%E7%BD%AE%E9%A1%B9%E5%AF%B9%E5%BA%94%E7%9A%84properties%E7%B1%BB/"},{"content":"操作步骤  Setting \u0026gt; Editor \u0026gt; File Encodings 或者直接搜索File Encodings，将三处都修改为UTF-8。  ","description":"","id":271,"section":"notes","tags":null,"title":"IDEA修改编码方式","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E4%BF%AE%E6%94%B9%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F/"},{"content":"操作如图：\n开发模板代码时，很有必要关闭这个自动格式化。\n参考资料  IntelliJ IDEA粘贴多行代码时，总是自动缩进  ","description":"","id":272,"section":"notes","tags":null,"title":"Idea关闭粘贴代码时的自动缩进","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%85%B3%E9%97%AD%E7%B2%98%E8%B4%B4%E4%BB%A3%E7%A0%81%E6%97%B6%E7%9A%84%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B/"},{"content":"该方法可以一劳永逸的解决问题，我家用电脑上就是使用的这个方案。\n参考资料  IntelliJ IDEA 修改内存大小，使得idea运行更流畅。  ","description":"","id":273,"section":"notes","tags":null,"title":"Idea内存不足的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"Idea今日份Bug：\n  仓库中明明有包，但是pom.xml始终报红色，右侧的maven选项卡中得dependencies也始终报红色。解决该问题的方法是重启Idea。\n  项目启动不起来，表现为非常缓慢的打印日志，具体打印的什么没有研究。如果直接使用命令行启动jar包，则不存在该问题。解决该问题的方案是拉一份新代码，重新启动。\n  同事提供了一个方案，直接去删Idea的工作空间，暂时项目有点忙，没时间这么搞。\n","description":"","id":274,"section":"notes","tags":null,"title":"Idea卡Bug","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%8D%A1bug/"},{"content":"如图，我想在目录树中快速定位我当前打开的文件：\n只需要按如下按钮即可：\n我常用这个功能来找到源码，然后复制一份源码，在源码上进行一些微调。因为我比较喜欢通过复制来复用Request、Response等POJO，而不喜欢通过继承等来复用，我觉得通过继承等手段会增加代码阅读时的复杂度。\n","description":"","id":275,"section":"notes","tags":null,"title":"Idea在目录树中查看当前打开文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%9C%A8%E7%9B%AE%E5%BD%95%E6%A0%91%E4%B8%AD%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6/"},{"content":"操作步骤  File \u0026gt; Settings \u0026gt; Editor \u0026gt; CodeStyle  编写代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // @formatter:on  this.sagaDefinition = step() .withCompensation( orderService.reject, CreateOrderSagaState::makeRejectOrderCommand) .step() .invokeParticipant( consumerService.validateOrder, CreateOrderSagaState::makeValidateOrderByConsumerCommand) .onReply( CreateTicketReply.class, CreateOrderSagaState::handleCreateTicketReply) .withCompensation( kitchenService.cancel, CreateOrderSagaState::makeConfirmCreateTicketCommand) .step() .invokeParticipant( kitchenService.create, CreateOrderSagaState::makeCreateTicketCommand) .step() .invokeParticipant( accountingService.authorize, CreateOrderSagaState::makeAuthorizeCommand) .step() .invokeParticipant( kitchenService.confirmCreate, CreateOrderSagaState::makeConfirmCreateTicketCommand) .step() .invokeParticipant( orderService.approve, CreateOrderSagaState::makeApproveOrderCommand) .build(); // @formatter:off    如上代码，默认情况下使用atrl + art + l时，肯定会被格式化，但是启动了部分格式化后，则不会  参考资料   IDEA(AS)代码格式化部分忽略\n  idea 代码部分格式化\n  ","description":"","id":276,"section":"notes","tags":null,"title":"Idea开启部分代码格式化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E5%BC%80%E5%90%AF%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%E5%8C%96/"},{"content":"操作步骤 解决该问题需要检查三处的配置，如下图所示：\n参考教程  Error:java: Compilation failed: internal java compiler error 解决办法  ","description":"","id":277,"section":"notes","tags":null,"title":"Idea报错：Compilation failed：internal java compiler error","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%8A%A5%E9%94%99compilation-failedinternal-java-compiler-error/"},{"content":"操作步骤  按两下Shift 输入需要搜索的类  参考资料  IDEA中快速搜索Jar包里面的内容  ","description":"","id":278,"section":"notes","tags":null,"title":"Idea搜索jar包中的类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E7%B1%BB/"},{"content":"今天在看SpringBoot源码时，在如下代码出进行了断点，结果断点没有生效，代码直接运行到后面了。此处代码我当时只断点了一处，我以为该处代码没有进入，花了一点时间排查，最后才发现是这个问题导致的。\n我不确定这个是不是一个普遍存在的现象，先记录一下。\n","description":"","id":279,"section":"notes","tags":null,"title":"Idea断点时的一个小问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%96%AD%E7%82%B9%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E9%97%AE%E9%A2%98/"},{"content":"偶然间发现的，如图省略部分是可以点击的，点击后就可以查看终端运行的指令：\n","description":"","id":280,"section":"notes","tags":null,"title":"Idea查看启动程序时的终端指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%9F%A5%E7%9C%8B%E5%90%AF%E5%8A%A8%E7%A8%8B%E5%BA%8F%E6%97%B6%E7%9A%84%E7%BB%88%E7%AB%AF%E6%8C%87%E4%BB%A4/"},{"content":"记录一下，最近阅读源码的需求非常的多，有了这种技术，切面、动态代理的实现都可以轻松的查阅到，非常的舒服。\n","description":"","id":281,"section":"notes","tags":null,"title":"Idea查看调用栈","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%9F%A5%E7%9C%8B%E8%B0%83%E7%94%A8%E6%A0%88/"},{"content":"我们有多个Maven项目需要进行同时编辑，所以我决定使用Idea的多Module技术进行管理。我之前使用多Module是在新建项目的场景下，比较简单，对于已经存在的项目，我也是第一次使用多Module技术。\n我的操作如下：\n  New \u0026gt; Project from Existing Sources\n 选择Create project from existing sources Idea会自动检测你源码所在的位置，我建议使用Unmark All    New \u0026gt; Module from Existing Sources\n  ","description":"","id":282,"section":"notes","tags":null,"title":"Idea添加多Module项目","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E6%B7%BB%E5%8A%A0%E5%A4%9Amodule%E9%A1%B9%E7%9B%AE/"},{"content":"操作步骤  打开：Tools -\u0026gt; Generate JavaDoc other command line arguments栏里输入：   -encoding utf-8 -charset utf-8 ","description":"","id":283,"section":"notes","tags":null,"title":"IDEA生成JavaDoc文档时显示：编码GBK的不可映射字符","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E7%94%9F%E6%88%90javadoc%E6%96%87%E6%A1%A3%E6%97%B6%E6%98%BE%E7%A4%BA%E7%BC%96%E7%A0%81gbk%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6/"},{"content":"如图可以进行调整：\n","description":"","id":284,"section":"notes","tags":null,"title":"Idea目录树中隐藏某个文件或文件夹","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E7%9B%AE%E5%BD%95%E6%A0%91%E4%B8%AD%E9%9A%90%E8%97%8F%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"配置如下：\n我感觉配置并没有生效，后来我手动点击了一下下载：\n","description":"","id":285,"section":"notes","tags":null,"title":"Idea自动下载Maven依赖源码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BDmaven%E4%BE%9D%E8%B5%96%E6%BA%90%E7%A0%81/"},{"content":"最近String总是被自动导入成com.sun.org.apache.xpath.internal.operations.String，这个很奇怪，甚至Idea一些奇怪的现象因为这个原因造成的，所以我决定屏蔽这个类的自动导入：\n参考资料  idea 自动提示导包忽略某些包  ","description":"","id":286,"section":"notes","tags":null,"title":"Idea自动导包的时候忽略一些类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%8C%85%E7%9A%84%E6%97%B6%E5%80%99%E5%BF%BD%E7%95%A5%E4%B8%80%E4%BA%9B%E7%B1%BB/"},{"content":"操作步骤 勾选如下配置：\nFile \u0026gt; Settings \u0026gt; Tools \u0026gt; Server Certificates \u0026gt; Accept non-trusted certificates automatically\n","description":"","id":287,"section":"notes","tags":null,"title":"Idea警告：Untrusted Server's certificate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%AD%A6%E5%91%8Auntrusted-servers-certificate/"},{"content":" Map好处理，如下即可：  展开之后，键的名称可以直接通过copyValue拿到。\n字段名称处理如下：  然后直接复制Label就可以得到字段名称。\n该技术有什么意义？联调的时候可以快速拿到别人定义字段、Map中得名称。\n","description":"","id":288,"section":"notes","tags":null,"title":"Idea调试值复制字段名称及Map中的key名称","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%B0%83%E8%AF%95%E5%80%BC%E5%A4%8D%E5%88%B6%E5%AD%97%E6%AE%B5%E5%90%8D%E7%A7%B0%E5%8F%8Amap%E4%B8%AD%E7%9A%84key%E5%90%8D%E7%A7%B0/"},{"content":"我不确定这项技术有没有意义，但是我目前的方案要求我多次断点，然后步进执行，知道找到出问题的代码，我觉得这样太低效率了。我希望能快速定位到出问题的代码，然后再该处进行断点。\n（目前还没有研究该技术，仅记录一下自己的需求。）\n","description":"","id":289,"section":"notes","tags":null,"title":"Idea调试的时候，如何快速到抛异常代码点（待研究）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%B0%83%E8%AF%95%E7%9A%84%E6%97%B6%E5%80%99%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%88%B0%E6%8A%9B%E5%BC%82%E5%B8%B8%E4%BB%A3%E7%A0%81%E7%82%B9%E5%BE%85%E7%A0%94%E7%A9%B6/"},{"content":"SpringBoot实例并行比较简单，如下图所示：\n类实例并行，如下图所示（和SpringBoot不一样，我也是第一次遇到）：\n","description":"","id":290,"section":"notes","tags":null,"title":"Idea运行多个类实例并行及SporingBoot实例并行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E8%BF%90%E8%A1%8C%E5%A4%9A%E4%B8%AA%E7%B1%BB%E5%AE%9E%E4%BE%8B%E5%B9%B6%E8%A1%8C%E5%8F%8Asporingboot%E5%AE%9E%E4%BE%8B%E5%B9%B6%E8%A1%8C/"},{"content":"配好PG数据源后，可以愉快的在mapper.xml文件中使用文本格式化快捷键了，但是我发现字段显示为红色，且提示该字段不存在。我猜想是PG的scheme导致的这个问题，我们的表不是放在默认的public scheme下，而是放在别的schema下。\n正好我之前解决这个问题的时候发现了currentScheme参数，所以我尝试在URL上配置了这个参数，结果非常满意，红色提示消失了。\n jdbc:postgresql://192.168.19.12:5432/dev?currentScheme=auth ","description":"","id":291,"section":"notes","tags":null,"title":"Idea配置PG数据源时的currentSchema参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E9%85%8D%E7%BD%AEpg%E6%95%B0%E6%8D%AE%E6%BA%90%E6%97%B6%E7%9A%84currentschema%E5%8F%82%E6%95%B0/"},{"content":"操作步骤  配置步骤如下所示，如果需要使用高级功能，可以查阅相关手册  图中绿色区域为编辑器中使用该目标时需要输入的内容  ","description":"","id":292,"section":"notes","tags":null,"title":"Idea配置模板","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/idea%E9%85%8D%E7%BD%AE%E6%A8%A1%E6%9D%BF/"},{"content":"问题描述  网络配置后，点击应用配置出现如下提示：   you need ifupdown2 to reload network configuration(500) 解决方案  执行如下指令：   apt-get install ifupdown2 参考教程  PVE修改网络配置报错需要ifupdown2  ","description":"","id":293,"section":"notes","tags":null,"title":"ifupdown2无法加载网络配置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/ifupdown2%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"content":"我在看Helm的\u0026ndash;dry-run生成的yaml时，注意到了一些名为ingress-nginx-controller-admission的资源，然后我在阅读NginxIngress文档时，又看到了如下的警告：\n 控制器使用Admission Webhook来验证Ingress定义，确保没有阻止从API服务器连接到ingress-nginx-controller-admission服务的网络策略或其他防火墙。 我猜想这个资源就是完成Ingress资源合法性的检查，然后更新Nginx的配置文件。\n","description":"","id":294,"section":"notes","tags":null,"title":"ingress-nginx-controller-admission的作用","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/ingress-nginx-controller-admission%E7%9A%84%E4%BD%9C%E7%94%A8/"},{"content":"当需要覆盖某台主机的Ansible默认配置时，需要使用到行为参数\n ansible_ssh_host ansible_ssh_port ansible_ssh_user ansible_ssh_pass ansible_connection smart Ansible使用何种连接模式连接到主机 ansible_ssh_private_key_file ansible_shell_type ansible_python_interpreter /user/bin/python 主机上的Python解释器 ansible_*_interpreter none 类似Python解析器配置的其他语言版 ","description":"","id":295,"section":"notes","tags":null,"title":"inventory行为参数","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/inventory%E8%A1%8C%E4%B8%BA%E5%8F%82%E6%95%B0/"},{"content":"看资料中无意间看到的，感觉最近挺需要这个的，故记录下来：\n下面两条指令首先将防火墙的当前规则保存，如果因为规则混乱无法上网了可以还原：\n iptables-save \u0026gt; iptables.rules iptables-restore \u0026lt; iptables.rules ","description":"","id":296,"section":"notes","tags":null,"title":"iptables常用操作（待实践）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%BE%85%E7%A0%94%E7%A9%B6/iptables%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%BE%85%E5%AE%9E%E8%B7%B5/"},{"content":"这块是以前用的资料整理，我会后会重新在实验机环境安装，到时候会重新整理一份。\n 使用 Istioctl 安装 IstioOperator Options 调试 Envoy 和 Pilot 最佳实践：Service Mesh 基准性能测试 Serverless与Kubernetes该如何选择？ Istio 网关中的 Gateway 和 VirtualService 配置深度解析 Istio 1.0学习笔记(六)：初识Istio Gateway 使用 Istio 进行金丝雀部署 kubeadm 更改NodePort端口范围 Traffic Management Problems 在Istio上创建自定义的ingress-gateway DevOps的持续部署方法大全  Helm相关资料（我还没有开始系统学习这个工具）\n Helm 从入门到实践  ","description":"","id":297,"section":"notes","tags":null,"title":"Istio安装","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/istio/istio%E5%AE%89%E8%A3%85/"},{"content":"防止以后又蹦出这种想法，现在先断了这个念想。怎么理解这个问题了，在C、C++中，我们定义枚举的时候，可以指定枚举项的值，相同的需求在jdk8中是无法实现的。\n参考资料  我可以在Java中为枚举指定序号吗？  ","description":"","id":298,"section":"notes","tags":null,"title":"java不能指定枚举的ordinal值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%8D%E8%83%BD%E6%8C%87%E5%AE%9A%E6%9E%9A%E4%B8%BE%E7%9A%84ordinal%E5%80%BC/"},{"content":"python中有个readLines的api，这个api可以一次性的将整个文件的文本读取到一个字符串中，我理所当然的认为java中也有类似的api，结果找了一圈没有找到相关的资料，最后我用如下的方式实现了相同的效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  File tplFile = tplFilePath.toFile(); try (FileInputStream fis = new FileInputStream(tplFile)) { byte[] tplBytes = new byte[(int) tplFile.length()]; //noinspection ResultOfMethodCallIgnored  fis.read(tplBytes); String tplContent = new String(tplBytes); tplContentsMap.put(tplFile.getName(), StringUtils.strip(tplContent.trim())); loadFragmentContents(tplFile.getName(), tplContent); } catch (IOException e) { e.printStackTrace(); }   这种方式并不是很直观，我以后看看有没有相应的工具包。\n参考资料  java 读取文件——按照行取出（使用BufferedReader和一次将数据保存到内存两种实现方式）  ","description":"","id":299,"section":"notes","tags":null,"title":"Java中将整个文本读取到字符串中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%AD%E5%B0%86%E6%95%B4%E4%B8%AA%E6%96%87%E6%9C%AC%E8%AF%BB%E5%8F%96%E5%88%B0%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD/"},{"content":"案例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  Set\u0026lt;String\u0026gt; set1 = new HashSet\u0026lt;\u0026gt;(); Set\u0026lt;String\u0026gt; set2 = new HashSet\u0026lt;\u0026gt;(); # 交集 set1.retailAll(set2); # 差集 set.removeAll(set2); # 并集 set1.addAll(set2);   在项目中应用的代码一：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  @Override public void updateUserInfoInEnterprise(String tenantId, UpdateUserInfoInEnterpriseRequest request) { // 判断用户是否存在  selectUserById(request.getUserId()); // 判断传递的用户是否已和当前企业建立关联（获取关联表信息）  List\u0026lt;AuthGroupUserRole\u0026gt; authGroupUserRoles = selectAuthGroupUserRoleByTenantIdAndUserId(tenantId, request.getUserId()); // 处理企业内部组织架构更新  boolean organizeUpdateFlag = StringUtils.isNotBlank(request.getOrganizeId()) \u0026amp;\u0026amp; !authGroupUserRoles.get(0).getOrganizeId().equals(request.getOrganizeId()); String organizeIdValue = organizeUpdateFlag ? request.getOrganizeId() : authGroupUserRoles.get(0).getOrganizeId(); // 处理企业内部角色信息更新  Set\u0026lt;String\u0026gt; roleIdsInRequest = new HashSet\u0026lt;\u0026gt;(request.getRoleIds()); Set\u0026lt;String\u0026gt; roleIdsInDb = authGroupUserRoles.stream() .map(AuthGroupUserRole::getRoleId) .collect(Collectors.toSet()); Set\u0026lt;String\u0026gt; toInsert = new HashSet\u0026lt;\u0026gt;(roleIdsInRequest); Set\u0026lt;String\u0026gt; toUpdate = new HashSet\u0026lt;\u0026gt;(roleIdsInRequest); Set\u0026lt;String\u0026gt; toDelete = new HashSet\u0026lt;\u0026gt;(roleIdsInDb); // 请求中包含的roleId，而数据库中不包含的roleId，则为需要插入的roleId  toInsert.removeAll(roleIdsInDb); // 数据库中包含的roleId，而请求中不包含的roleId，则为需要删除的roleId  toDelete.removeAll(roleIdsInRequest); // 请求中和数据库中同时包含的roleId则为需要更新的Id  toUpdate.retainAll(roleIdsInDb); if (toDelete.size() != 0) { deleteBatchIdsLogic(new ArrayList\u0026lt;\u0026gt;(toDelete)); } if (toInsert.size() != 0) { insertAuthGroupUserRole(tenantId, request.getUserId(), organizeIdValue, new ArrayList\u0026lt;\u0026gt;(toInsert)); } if (toUpdate.size() != 0 \u0026amp;\u0026amp; organizeUpdateFlag) { LambdaQueryWrapper\u0026lt;AuthGroupUserRole\u0026gt; queryWrapperForAuthAppRole = new LambdaQueryWrapper\u0026lt;AuthGroupUserRole\u0026gt;() .eq(AuthGroupUserRole::getOrgId, tenantId) .eq(AuthGroupUserRole::getUserId, request.getUserId()) .eq(AuthGroupUserRole::getDelete, IsDelete.NOT_DELETE.getValue()); AuthGroupUserRole authGroupUserRoleUpdate = AuthGroupUserRole.builder() .organizeId(request.getOrganizeId()) .build(); authGroupUserRoleMapper.update(authGroupUserRoleUpdate, queryWrapperForAuthAppRole); } // 通知到网关  informGatewayUserRoleChange(Collections.singletonList(request.getUserId()), tenantId); }   在项目中应用的代码二：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  public void updatePdmProjMemberGroups( String userId, String tenantId, UpdatePdmProjMemberGroupsRequest request) { // todo 检查projectId是否存在  Map\u0026lt;String, PdmProjMemberGroup\u0026gt; projectGroupIdToProjectMemberGroupMap = getProjectGroupIdToProjectMemberGroupMap(request.getProjectId(), tenantId); List\u0026lt;CreatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO\u0026gt; toAdd = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO\u0026gt; toUpdate = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; toDelete = new ArrayList\u0026lt;\u0026gt;(projectGroupIdToProjectMemberGroupMap.keySet()); // 如果传递的请求中包含Id则进行更新， 否则进行添加  for (UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO groupInfo : request.getGroupInfos()) { if (StringUtils.isBlank(groupInfo.getProjectGroupId())) { // 完成参数转换，方便接下来复用已有方法  toAdd.add(BeanUtil.copyProperties(groupInfo, CreatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO.class)); } else { // 查看用户传递的Id是否已经在数据库中存在  if (!projectGroupIdToProjectMemberGroupMap.containsKey(groupInfo.getProjectGroupId())) { throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } toUpdate.add(groupInfo); toDelete.remove(groupInfo.getProjectGroupId()); } } // 新增  if (toAdd.size() != 0) { createPdmProjMemberGroups(userId, tenantId, request.getProjectId(), toAdd); } // 删除  if (toDelete.size() != 0) { // 删除成员信息  deleteProjectMembersByProjectIdAndTenantId( request.getProjectId(), toDelete, tenantId); // 删除分组信息  deleteProjectMemberGroupsByProjectIdAndTenantId( request.getProjectId(), toDelete, tenantId); } // 修改（成员信息直接删除重建，分组信息进行更新）  if (toUpdate.size() != 0) { deleteProjectMembersByProjectIdAndTenantId( request.getProjectId(), toUpdate.stream() .map(UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO::getProjectGroupId) .collect(Collectors.toList()), tenantId); for (UpdatePdmProjMemberGroupsRequest.PdmProjMemberGroupDTO groupInfo : toUpdate) { PdmProjMemberGroup pdmProjMemberGroup = projectGroupIdToProjectMemberGroupMap.get(groupInfo.getProjectGroupId()); PdmProjMemberGroup pdmProjMemberGroupUpdate = PdmProjMemberGroup.builder() .id(pdmProjMemberGroup.getId()) .modifier(userId) .gmtModifyTime(LocalDateTime.now()) .name((JSONObject) JSONObject.toJSON(groupInfo.getName())) .build(); pdmProjMemberGroupMapper.updateById(pdmProjMemberGroupUpdate); // 重新插入成员信息  createProjectMembersBatch(userId, tenantId, request.getProjectId(), groupInfo.getProjectGroupId(), groupInfo.getUserIds()); } } }   参考资料  Java ArrayList retainAll() 方法  ","description":"","id":300,"section":"notes","tags":null,"title":"java中的交集、并集、差集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E4%B8%AD%E7%9A%84%E4%BA%A4%E9%9B%86%E5%B9%B6%E9%9B%86%E5%B7%AE%E9%9B%86/"},{"content":"判断是否是静态方法的代码如下：\n1 2 3 4 5  Method method = 类.getMethod(相关参数); int modifiers = getModifiers(); Modifier.isStatic(modifiers )   调用静态方法的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public static Object invokeConvertMethod(String enumClazzName, Object methodParam) { if (!methodCache.containsKey(enumClazzName)) { throw new RuntimeException(\u0026#34;Wrong\u0026#34;); } try { Method method = methodCache.get(enumClazzName); // todo 临时，因为还没有决定枚举要不要分String和Integer  return method.invoke(null, String.valueOf(methodParam)); } catch (IllegalAccessException | InvocationTargetException e) { e.printStackTrace(); return null; } }   参考资料  Ｊava判断是否是static方法 Java 反射调用静态方法  ","description":"","id":301,"section":"notes","tags":null,"title":"java反射中如何判断是否是静态方法及静态方法调用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E5%8F%8D%E5%B0%84%E4%B8%AD%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%98%AF%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E5%8F%8A%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8/"},{"content":"之前一直使用的是hashCode，但是在使用一个框架的时候发现hashCode方法被重写了，根本没有参考意义，所以找到了如下的方法：\n1 2 3  System.out.println(System.identityHashCode(obj));   参考资料  [Java中打印对象内存地址)  ","description":"","id":302,"section":"notes","tags":null,"title":"Java查看内存地址","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E6%9F%A5%E7%9C%8B%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80/"},{"content":"我确实有深拷贝的需求，我之前的方案是实现了一个静态工具类，在工具类中通过FastJson序列化和反序列化实现深拷贝（我主要用在工具类中，性能问题并不在意），但是毕竟不是非常的方便。最近找资料时发现了几款工具，打算测试一下这几款工具。\ncommons-beanutils 依赖引入：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-beanutils\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-beanutils\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   测试代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public class Test { @Getter @Setter @NoArgsConstructor @AllArgsConstructor static class User { private String name; private Address address; } @NoArgsConstructor @AllArgsConstructor static class Address { private String country; private String province; private String city; } public static void main(String[] args) { User user1 = new User(\u0026#34;test\u0026#34;, new Address(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)); User user2 = new User(); BeanUtils.copyProperties(user1, user2); System.out.println(user1); System.out.println(user2); System.out.println(user1.address); System.out.println(user2.address); } }   输出为：\n com.example.demo.test.Test$User@18e8568 com.example.demo.test.Test$User@33e5ccce com.example.demo.test.Test$Address@5a42bbf4 com.example.demo.test.Test$Address@5a42bbf4 实际上只进行了浅拷贝。\norika 依赖引入：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ma.glasnost.orika\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;orika-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   测试代码编写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  public class Test { @Getter @Setter @NoArgsConstructor @AllArgsConstructor static class User { private String name; private Address address; } @NoArgsConstructor @AllArgsConstructor static class Address { private String country; private String province; private String city; } public static void main(String[] args) { User user1 = new User(\u0026#34;test\u0026#34;, new Address(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)); User user2 = new User(); MapperFactory mapperFactory = new DefaultMapperFactory.Builder() .useAutoMapping(true) .mapNulls(true) .build(); MapperFacade mapperFacade = mapperFactory.getMapperFacade(); mapperFacade.map(user1, user2); System.out.println(\u0026#34;mapperFacade.map(user1, user2)\u0026#34;); System.out.println(user1); System.out.println(user2); System.out.println(user1.address); System.out.println(user2.address); System.out.println(\u0026#34;User user3 = mapperFacade.map(user1, User.class)\u0026#34;); User user3 = mapperFacade.map(user1, User.class); System.out.println(user1); System.out.println(user3); System.out.println(user1.address); System.out.println(user3.address); } }   输出为：\n mapperFacade.map(user1, user2) com.example.demo.test.Test$User@6043cd28 com.example.demo.test.Test$User@4d3167f4 com.example.demo.test.Test$Address@76a3e297 com.example.demo.test.Test$Address@ed9d034 User user3 = mapperFacade.map(user1, User.class) com.example.demo.test.Test$User@6043cd28 com.example.demo.test.Test$User@1060b431 com.example.demo.test.Test$Address@76a3e297 com.example.demo.test.Test$Address@612679d6 可以看到是深拷贝。这个工具略微有点麻烦，需要开发成静态工具类，但是看推荐，说是效率极高。\nBeanUtils（Spring版）、BeanUtil（hutool） 这两款都是浅拷贝，这款就不呈现测试代码了。\n测试总结 我觉得orika是有研究价值的，深度拷贝的应用还是蛮多的，我会花时间对这门技术进行系统学习。\n参考资料  java浅拷贝与深拷贝及拷贝工具推荐  ","description":"","id":303,"section":"notes","tags":null,"title":"Java浅拷贝深拷贝工具测试","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E6%B5%85%E6%8B%B7%E8%B4%9D%E6%B7%B1%E6%8B%B7%E8%B4%9D%E5%B7%A5%E5%85%B7%E6%B5%8B%E8%AF%95/"},{"content":"最近有如下需求，我想用状态机实现该需求：\n最后实现上，我用了比较简单的方案，就简单的使用方法代替各个Action，以后遇到更复杂的需求再深入研究吧。\n","description":"","id":304,"section":"notes","tags":null,"title":"Java状态机","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E7%8A%B6%E6%80%81%E6%9C%BA/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11  Properties properties = new Properties(); properties.load(new FileInputStream(\u0026#34;src\\\\main\\\\resources\\\\tmp3.properties\u0026#34;)); Enumeration enumeration = properties.propertyNames(); while (enumeration.hasMoreElements()) { String key = (String) enumeration.nextElement(); String value = properties.getProperty(key); System.out.println(key); System.out.println(value); }   写法很糟糕，而且中文还乱码了。\n参考资料  了解自动配置原理  ","description":"","id":305,"section":"notes","tags":null,"title":"Java读取properties文件中的内容，并将它们封装到JavaBean中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/java%E8%AF%BB%E5%8F%96properties%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%E5%B9%B6%E5%B0%86%E5%AE%83%E4%BB%AC%E5%B0%81%E8%A3%85%E5%88%B0javabean%E4%B8%AD/"},{"content":"做实验的时候，利用jdbcTemplate开发了一个简单的方法，用于查看当前链接的时区，感觉还不错，就简单整理一下：\n1 2 3 4 5 6 7 8 9 10 11 12  List\u0026lt;String\u0026gt; timezones = jdbcTemplate.query( \u0026#34;show time zone\u0026#34;, new RowMapper\u0026lt;String\u0026gt;() { @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException { return rs.getString(1); } }); System.out.println(timezones);   ","description":"","id":306,"section":"notes","tags":null,"title":"JdbcTemplate查看当前链接的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/jdbctemplate%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E9%93%BE%E6%8E%A5%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"相关技术的应用我会体现在我的工具包代码里。\n参考资料  jdbcTemplate高效率获取表结构，数据库元数据信息  ","description":"","id":307,"section":"notes","tags":null,"title":"JdbcTemplate获取表的元数据","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/jdbctemplate%E8%8E%B7%E5%8F%96%E8%A1%A8%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE/"},{"content":"问题描述  在配置ShardingSphere-Jdbc时，按照官网官网最新配置，遇到了jdbcUrl is required with driverClassName异常  解决步骤  修改配置中的url为jdbc-url，代码如下：  spring: shardingsphere: props: sql: show: true datasource: names: mmp mmp: # jdbc-url: jdbc:mysql://192.168.53.100:3306/mmp_watsons_junjie?useUnicode=true\u0026amp;characterEncoding=UTF8\u0026amp;serverTimezone=CTT jdbc-url: jdbc:mysql://192.168.53.100:3306/mmp_watsons_junjie?useUnicode=true\u0026amp;characterEncoding=UTF8\u0026amp;serverTimezone=CTT type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver username: promotion_app password: promotion_app 20210617后续：\n很尴尬啊，这篇笔记是很久前整理的，我忘记我当时修改什么东西了\n参考资料  jdbcUrl is required with driverClassName  ","description":"","id":308,"section":"notes","tags":null,"title":"jdbcUrl is required with driverClassName","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/shardingsphere-jdbc/jdbcurl-is-required-with-driverclassname/"},{"content":"问题描述  按照教程走完所有流程后，始终得不到项目的日志输出，项目状态一致处于运行中 查看slave pod的describe和log都没有任何提示 查看master pod的log得到如下日志  VM settings: Max. Heap Size (Estimated): 247.50M Ergonomics Machine Class: server Using VM: OpenJDK 64-Bit Server VM Running from: /usr/share/jenkins/jenkins.war webroot: EnvVars.masterEnvVars.get(\u0026quot;JENKINS_HOME\u0026quot;) 2020-07-24 02:35:59.320+0000 [id=1]\tINFO\torg.eclipse.jetty.util.log.Log#initialized: Logging initialized @671ms to org.eclipse.jetty.util.log.JavaUtilLog 2020-07-24 02:35:59.470+0000 [id=1]\tINFO\twinstone.Logger#logInternal: Beginning extraction from war file 2020-07-24 02:35:59.540+0000 [id=1]\tWARNING\to.e.j.s.handler.ContextHandler#setContextPath: Empty contextPath 2020-07-24 02:35:59.641+0000 [id=1]\tINFO\torg.eclipse.jetty.server.Server#doStart: jetty-9.4.27.v20200227; built: 2020-02-27T18:37:21.340Z; git: a304fd9f351f337e7c0e2a7c28878dd536149c6c; jvm 1.8.0_242-b08 2020-07-24 02:36:00.642+0000 [id=1]\tINFO\to.e.j.w.StandardDescriptorProcessor#visitServlet: NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet 2020-07-24 02:36:00.749+0000 [id=1]\tINFO\to.e.j.s.s.DefaultSessionIdManager#doStart: DefaultSessionIdManager workerName=node0 2020-07-24 02:36:00.749+0000 [id=1]\tINFO\to.e.j.s.s.DefaultSessionIdManager#doStart: No SessionScavenger set, using defaults 2020-07-24 02:36:00.757+0000 [id=1]\tINFO\to.e.j.server.session.HouseKeeper#startScavenging: node0 Scavenging every 660000ms 2020-07-24 02:36:01.618+0000 [id=1]\tINFO\thudson.WebAppMain#contextInitialized: Jenkins home directory: /var/jenkins_home found at: EnvVars.masterEnvVars.get(\u0026quot;JENKINS_HOME\u0026quot;) 2020-07-24 02:36:01.890+0000 [id=1]\tINFO\to.e.j.s.handler.ContextHandler#doStart: Started w.@21be3395{Jenkins v2.235.2,/,file:///var/jenkins_home/war/,AVAILABLE}{/var/jenkins_home/war} 2020-07-24 02:36:01.930+0000 [id=1]\tINFO\to.e.j.server.AbstractConnector#doStart: Started ServerConnector@62043840{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} 2020-07-24 02:36:01.931+0000 [id=1]\tINFO\torg.eclipse.jetty.server.Server#doStart: Started @3283ms 2020-07-24 02:36:01.932+0000 [id=20]\tINFO\twinstone.Logger#logInternal: Winstone Servlet Engine running: controlPort=disabled 2020-07-24 02:36:03.435+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Started initialization 2020-07-24 02:36:03.892+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Listed all plugins 2020-07-24 02:36:09.728+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Prepared all plugins 2020-07-24 02:36:09.738+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Started all plugins 2020-07-24 02:36:09.941+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Augmented all extensions 2020-07-24 02:36:11.228+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: System config loaded 2020-07-24 02:36:11.229+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: System config adapted 2020-07-24 02:36:11.229+0000 [id=25]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Loaded all jobs 2020-07-24 02:36:11.235+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Configuration for all jobs updated 2020-07-24 02:36:11.624+0000 [id=39]\tINFO\thudson.model.AsyncPeriodicWork#lambda$doRun$0: Started Download metadata 2020-07-24 02:36:11.919+0000 [id=39]\tINFO\thudson.model.AsyncPeriodicWork#lambda$doRun$0: Finished Download metadata. 202 ms 2020-07-24 02:36:12.815+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@6effd93a: display name [Root WebApplicationContext]; startup date [Fri Jul 24 10:36:12 CST 2020]; root of context hierarchy 2020-07-24 02:36:12.816+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@6effd93a]: org.springframework.beans.factory.support.DefaultListableBeanFactory@62c07203 2020-07-24 02:36:12.827+0000 [id=26]\tINFO\to.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@62c07203: defining beans [authenticationManager]; root of factory hierarchy 2020-07-24 02:36:13.227+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#prepareRefresh: Refreshing org.springframework.web.context.support.StaticWebApplicationContext@1a5fd292: display name [Root WebApplicationContext]; startup date [Fri Jul 24 10:36:13 CST 2020]; root of context hierarchy 2020-07-24 02:36:13.227+0000 [id=26]\tINFO\to.s.c.s.AbstractApplicationContext#obtainFreshBeanFactory: Bean factory for application context [org.springframework.web.context.support.StaticWebApplicationContext@1a5fd292]: org.springframework.beans.factory.support.DefaultListableBeanFactory@449df8fb 2020-07-24 02:36:13.228+0000 [id=26]\tINFO\to.s.b.f.s.DefaultListableBeanFactory#preInstantiateSingletons: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@449df8fb: defining beans [filter,legacy]; root of factory hierarchy 2020-07-24 02:36:13.445+0000 [id=26]\tINFO\to.c.j.p.k.KubernetesClientProvider$SaveableListenerImpl#onChange: Invalidating Kubernetes client: kubernetes null 2020-07-24 02:36:13.450+0000 [id=26]\tINFO\tjenkins.InitReactorRunner$1#onAttained: Completed initialization 2020-07-24 02:36:13.552+0000 [id=19]\tINFO\to.c.j.p.k.KubernetesClientProvider$SaveableListenerImpl#onChange: Invalidating Kubernetes client: kubernetes null 2020-07-24 02:36:13.860+0000 [id=19]\tINFO\thudson.WebAppMain$3#run: Jenkins is fully up and running 2020-07-24 02:37:20.320+0000 [id=11]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: Found invalid crumb 8912d904c747a67dab090ad588545030425547e720e49e7a2af899038c6844b3. If you are calling this URL with a script, please use the API Token instead. More information: https://jenkins.io/redirect/crumb-cannot-be-used-for-script 2020-07-24 02:37:20.320+0000 [id=11]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: No valid crumb was included in request for /ajaxBuildQueue by wujunjie. Returning 403. 2020-07-24 02:37:20.373+0000 [id=15]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: Found invalid crumb 8912d904c747a67dab090ad588545030425547e720e49e7a2af899038c6844b3. If you are calling this URL with a script, please use the API Token instead. More information: https://jenkins.io/redirect/crumb-cannot-be-used-for-script 2020-07-24 02:37:20.373+0000 [id=15]\tWARNING\thudson.security.csrf.CrumbFilter#doFilter: No valid crumb was included in request for /ajaxExecutors by wujunjie. Returning 403. 2020-07-24 02:38:41.563+0000 [id=24]\tINFO\to.c.j.p.k.KubernetesCloud#provision: Excess workload after pending Kubernetes agents: 1 2020-07-24 02:38:41.565+0000 [id=24]\tINFO\to.c.j.p.k.KubernetesCloud#provision: Template for label joker-jnlp: jenkins-slave 2020-07-24 02:38:43.128+0000 [id=24]\tINFO\to.internal.platform.Platform#log: ALPN callback dropped: HTTP/2 is disabled. Is alpn-boot on the boot class path? 2020-07-24 02:38:51.948+0000 [id=38]\tINFO\thudson.slaves.NodeProvisioner#lambda$update$6: jenkins-slave-wrpbz provisioning successfully completed. We have now 2 computer(s) 2020-07-24 02:38:52.176+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Created Pod: devops/jenkins-slave-wrpbz 2020-07-24 02:38:52.324+0000 [id=71]\tINFO\to.internal.platform.Platform#log: ALPN callback dropped: HTTP/2 is disabled. Is alpn-boot on the boot class path? 2020-07-24 02:38:52.348+0000 [id=71]\tWARNING\ti.f.k.c.d.i.WatchConnectionManager$1#onFailure: Exec Failure: HTTP 403, Status: 403 - events is forbidden: User \u0026quot;system:serviceaccount:devops:jenkins-sa\u0026quot; cannot watch resource \u0026quot;events\u0026quot; in API group \u0026quot;\u0026quot; in the namespace \u0026quot;devops\u0026quot; java.net.ProtocolException: Expected HTTP 101 response but was '403 Forbidden' at okhttp3.internal.ws.RealWebSocket.checkResponse(RealWebSocket.java:229) at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:196) at okhttp3.RealCall$AsyncCall.execute(RealCall.java:203) at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2020-07-24 02:38:52.354+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#eventWatch: Cannot watch events on devops/jenkins-slave-wrpbz Also: java.lang.Throwable: waiting here at io.fabric8.kubernetes.client.utils.Utils.waitUntilReady(Utils.java:144) at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager.waitUntilReady(WatchConnectionManager.java:341) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:755) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:739) at io.fabric8.kubernetes.client.dsl.base.BaseOperation.watch(BaseOperation.java:70) at org.csanchez.jenkins.plugins.kubernetes.KubernetesLauncher.eventWatch(KubernetesLauncher.java:230) at org.csanchez.jenkins.plugins.kubernetes.KubernetesLauncher.launch(KubernetesLauncher.java:138) at hudson.slaves.SlaveComputer.lambda$_connect$0(SlaveComputer.java:296) at jenkins.util.ContextResettingExecutorService$2.call(ContextResettingExecutorService.java:46) at jenkins.security.ImpersonatingExecutorService$2.call(ImpersonatingExecutorService.java:71) at java.util.concurrent.FutureTask.run(FutureTask.java:266) io.fabric8.kubernetes.client.KubernetesClientException: events is forbidden: User \u0026quot;system:serviceaccount:devops:jenkins-sa\u0026quot; cannot watch resource \u0026quot;events\u0026quot; in API group \u0026quot;\u0026quot; in the namespace \u0026quot;devops\u0026quot; at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager$1.onFailure(WatchConnectionManager.java:203) at okhttp3.internal.ws.RealWebSocket.failWebSocket(RealWebSocket.java:571) at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:198) at okhttp3.RealCall$AsyncCall.execute(RealCall.java:203) at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2020-07-24 02:38:54.672+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Pod is running: devops/jenkins-slave-wrpbz 2020-07-24 02:39:25.039+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Waiting for agent to connect (30/100): jenkins-slave-wrpbz 2020-07-24 02:39:55.272+0000 [id=67]\tINFO\to.c.j.p.k.KubernetesLauncher#launch: Waiting for agent to connect (60/100): jenkins-slave-wrpbz 解决步骤  使用如下RABC配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  apiVersion:v1kind:ServiceAccountmetadata:name:jenkins-sanamespace:devops---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:jenkins-crdlabels:name:jenkinssubjects:- kind:ServiceAccountname:jenkins-sanamespace:devopsroleRef:kind:ClusterRolename:cluster-adminapiGroup:rbac.authorization.k8s.io  ","description":"","id":309,"section":"notes","tags":null,"title":"Jenkins定位Kubernetes集群中，简单的echo实验失败","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/jenkins%E5%AE%9A%E4%BD%8Dkubernetes%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%AE%80%E5%8D%95%E7%9A%84echo%E5%AE%9E%E9%AA%8C%E5%A4%B1%E8%B4%A5/"},{"content":"问题描述 因为我们客户端在上传数据时没有进行输入检查（服务端也没有检查），导致我们数据库t_material_info表中插入了一些错误数据。t_material_info表的extra_property列的类型json，可能会被插入如下的值：\n1 2 3 4 5 6  { \u0026#34;\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;field\u0026#34;:\u0026#34;key\u0026#34; }   现在的需求是修改t_material_info表的extra_property列，如果该列的json数据包含了key为空字符串的字段，则去掉该字段。\n我开发的SQL如下：\n1 2 3 4 5 6  UPDATEt_material_infoSETextra_property=jsonb(extra_property)-\u0026#39;\u0026#39;WHEREIDIN(SELECTIDFROMt_material_infoWHEREextra_property::json-\u0026gt;\u0026gt;\u0026#39;\u0026#39;=\u0026#39;\u0026#39;)  因为考虑到该SQL需要在生产环境执行，所以做了一些调整（将原来的一条SQL拆成了两条），我们生产环境处理该问题的逻辑是，先查出所有需要修改的数据，然后update语句的where条件中指明需要修改的记录的id，这样可以最大限度防止SQL错误影响到线上的数据。当然我们可以结合一些工具，批量的生成这些update语句。\n","description":"","id":310,"section":"notes","tags":null,"title":"jsonb中如何key为空字符串怎么办","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/jsonb%E4%B8%AD%E5%A6%82%E4%BD%95key%E4%B8%BA%E7%A9%BA%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%80%8E%E4%B9%88%E5%8A%9E/"},{"content":"需要说明的是，我目前考虑的是：只支持为三种结构的json自动生成数据源和检查源，这三种json如下：\n # 适用于简单的下拉框 [\u0026quot;\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;\u0026quot;] # 适用于二级联动的下拉框 { \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[], \u0026quot;\u0026quot;:[], } # 适用于三级联动的下拉框 { \u0026quot;\u0026quot;:{ \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] }, \u0026quot;\u0026quot;:{ \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] } } ","description":"","id":311,"section":"notes","tags":null,"title":"jsonStructure生成算法（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/jsonstructure%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"我开启了一个新的项目，尝试传递如下json，然后用如下对象接受，结果无法正常接受，这个是符合我预期的。\n { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } @Data private static class TestJson { private String testJson; } @PostMapping(\u0026quot;/testJson\u0026quot;) public TestJson testJson(@RequestBody TestJson testJson) { return testJson; } 按照教程，做了如下配置后spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES，我的请求和返回如下：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } 目前的表现和我们项目框架已经不一样了，我们项目框架中，即使不做任何配置，有如下请求和返回：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;code\u0026quot;: 200, \u0026quot;data\u0026quot;: { \u0026quot;testJson\u0026quot;: \u0026quot;testJson\u0026quot; }, \u0026quot;message\u0026quot;: \u0026quot;成功\u0026quot; } 截止目前，我产生了一下需要探索的项：\n 如何看项目做了哪些配置，比如spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES 是不是因为在项目中实验的时候，返回值在第二层，所以导致返回的testJson没有下滑线  解答一 开启SpringBoot Actuator，然后请求localhost:8888/actuator/configprops，返回结果中搜索jackson就可以看到相关的配置：\n从这份配置甚至可以猜到其可以对输入输出分别配置，从而达到我们项目框架的效果，但是看了其配置后发现它根本没有进行这项的配置：\n我觉得我们项目可能更多的是通过代码进行配置。现在就是不清楚通过JavaConfig进行的配置能够通过configprops反应出来么（已经证实：我们项目中使用的并不是jackson，所以看不到相关的配置。）。\n经过向架构师的咨询，了解到我们项目的HttpMessageConvert使用的并不是Jackson，而是Fastjson，配置代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  @Bean public HttpMessageConverters fastJsonHttpMessageConverters() { return new HttpMessageConverters(getFastJsonHttpMessageConverter()); } public HttpMessageConverter\u0026lt;?\u0026gt; getFastJsonHttpMessageConverter() { // 1.定义一个converters转换消息的对象 \tFastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); List\u0026lt;MediaType\u0026gt; supportedMediaTypes = new ArrayList\u0026lt;\u0026gt;(); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.APPLICATION_ATOM_XML); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_OCTET_STREAM); supportedMediaTypes.add(MediaType.APPLICATION_PDF); supportedMediaTypes.add(MediaType.APPLICATION_RSS_XML); supportedMediaTypes.add(MediaType.APPLICATION_XHTML_XML); supportedMediaTypes.add(MediaType.APPLICATION_XML); supportedMediaTypes.add(MediaType.IMAGE_GIF); supportedMediaTypes.add(MediaType.IMAGE_JPEG); supportedMediaTypes.add(MediaType.IMAGE_PNG); supportedMediaTypes.add(MediaType.TEXT_EVENT_STREAM); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_MARKDOWN); supportedMediaTypes.add(MediaType.TEXT_PLAIN); supportedMediaTypes.add(MediaType.TEXT_XML); fastConverter.setSupportedMediaTypes(supportedMediaTypes); // 2.添加fastjson的配置信息，比如: 是否需要格式化返回的json数据 \tFastJsonConfig fastJsonConfig = new FastJsonConfig(); // 修改配置返回内容的过滤 \t// WriteNullListAsEmpty ：List字段如果为null,输出为[],而非null \t// WriteNullStringAsEmpty ： 字符类型字段如果为null,输出为\u0026#34;\u0026#34;,而非null \t// DisableCircularReferenceDetect ：消除对同一对象循环引用的问题，默认为false（如果不配置有可能会进入死循环） \t// WriteNullBooleanAsFalse：Boolean字段如果为null,输出为false,而非null \t// WriteMapNullValue：是否输出值为null的字段,默认为false \t// PrettyFormat：结果是否格式化  fastJsonConfig.setSerializerFeatures(SerializerFeature.DisableCircularReferenceDetect, SerializerFeature.WriteNullStringAsEmpty, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullBooleanAsFalse); // 配置全局long转String \tSerializeConfig serializeConfig = SerializeConfig.globalInstance; serializeConfig.put(Long.class, ToStringSerializer.instance); serializeConfig.put(Long.TYPE, ToStringSerializer.instance); fastJsonConfig.setSerializeConfig(serializeConfig); fastJsonConfig.setDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); // 3.在converter中添加配置信息 \tfastConverter.setFastJsonConfig(fastJsonConfig); // 4.将converter赋值给HttpMessageConverter \t// HttpMessageConverter\u0026lt;?\u0026gt; converter = fastConverter; \t// 5.返回HttpMessageConverters对象 \treturn fastConverter; }   经过实验，我了解到FastJson是默认支持下滑线式的json key转成java中的驼峰，当需要序列化成json时，需要如下代码实现驼峰装下滑线（这段代码我暂时没有优化，等我需要的时候，我会优化下）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Data @AllArgsConstructor private static class TestJson { private String testJson; } public static void main(String[] args) { // 下滑线转驼峰  String jsonInput = \u0026#34;{\\\u0026#34;test_json\\\u0026#34;:\\\u0026#34;testJson\\\u0026#34;}\u0026#34;; TestJson testJson = JSON.parseObject(jsonInput, TestJson.class); // 驼峰转下划线  TestJson testJson2 = new TestJson(\u0026#34;testJson\u0026#34;); SerializeConfig config = new SerializeConfig(); config.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase; String s = JSON.toJSONString(testJson2, config); }   解答二 包装后，请求与返回如下：\n # 请求 { \u0026quot;test_json\u0026quot;:\u0026quot;testJson\u0026quot; } # 返回 { \u0026quot;test_json\u0026quot;: { \u0026quot;test_json\u0026quot;: \u0026quot;testJson\u0026quot; } } 其实从这些表现就可以发现spring.jackson.property-naming-strategy= CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES配置的工作原理。它大概是请求时建立了test_json和testJson到testJson的映射，而返回的时候，它会将对象的所有字段都转换成下划线式的。\nhttps://blog.csdn.net/java_cxrs/article/details/105850597\nhttps://www.jianshu.com/p/cb02796dfbd2\n参考资料  springboot(15)修改HTTP默认序列化工具 Java Json 数据下划线与驼峰格式进行相互转换 FastJson下划线转驼峰 springboot与web前端的下划线与驼峰的json转换配置   ","description":"","id":312,"section":"notes","tags":null,"title":"Json序列化时驼峰与下滑线的转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/json%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E9%A9%BC%E5%B3%B0%E4%B8%8E%E4%B8%8B%E6%BB%91%E7%BA%BF%E7%9A%84%E8%BD%AC%E6%8D%A2/"},{"content":"问题是这样的，我在写测试类的时候使用了Lombok的RequiredArgsConstructor注解，结果一直有如下报错：\n org.junit.jupiter.api.extension.ParameterResolutionException: No ParameterResolver registered for parameter [org.springframework.web.client.RestTemplate arg0] in constructor [public fun.junjie.auto.tools.tools.YApiTools(org.springframework.web.client.RestTemplate)]. at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameter(ExecutableInvoker.java:200) at org.junit.jupiter.engine.execution.ExecutableInvoker.resolveParameters(ExecutableInvoker.java:183) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:74) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:333) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:280) at org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:77) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:262) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$2(ClassBasedTestDescriptor.java:256) at java.util.Optional.orElseGet(Optional.java:267) at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$3(ClassBasedTestDescriptor.java:255) at org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:29) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:108) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:107) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:71) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$1(NodeTestTask.java:107) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:107) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:75) at java.util.ArrayList.forEach(ArrayList.java:1259) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at java.util.ArrayList.forEach(ArrayList.java:1259) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:125) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:135) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:123) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:122) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:80) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:69) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) 我其实很久前就解决过这个问题，但是当时没有记录任何笔记，结果今天又遇到了这个问题。这个是因为在Junit5的测试类中，必须使用@Autowire来注入待测试的类，而不能使用Lombok的@RequiredArgsConstructor。\n","description":"","id":313,"section":"notes","tags":null,"title":"junit5不支持构造函数注入","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/junit5%E4%B8%8D%E6%94%AF%E6%8C%81%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E6%B3%A8%E5%85%A5/"},{"content":"Kubernetes推荐的标签 除了 kubectl 和 dashboard 之外，您可以使用其他工具来可视化和管理 Kubernetes 对象。一组通用的标签可以让多个工具之间相互操作，用所有工具都能理解的通用方式描述对象。除了支持工具外，推荐的标签还以一种可以查询的方式描述了应用程序。\n共享标签和注解都使用同一个前缀：app.kubernetes.io，没有前缀的标签是用户私有的，共享前缀可以确保共享标签不会干扰用户自定义的标签。\n app.kubernetes.io/name 应用名称的名字 app.kubernetes.io/instance 用于唯一确定应用实例的名称（不是很理解） app.kubernetes.io/version 应用程序的当前版本 app.kubernetes.io/component 架构中得组件 app.kubernetes.io/part-of 此级别的更高级别应用程序的名称 app.kubernetes.io/managed-by 用于管理应用程雪的工具 app.kubernetes.io/created-by 创建该资源的控制器或者用户 案例：\n1 2 3 4 5 6 7 8 9 10  labels:- app.kubernetes.io/name:mysql- app.kubernetes.io/instance:mysql-abcxzy- app.kubernetes.io/version:5.7.21- app.kubernetes.io/componnet:database- app.kubernetes.io/part-of:wordpress- app.kubernetes.io/managed-by:helm- app.kubernetes.io/created-by:controller-manager  helm启动的程序的：\n1 2 3 4 5 6 7 8  labels:- app.kubernetes.io/name:anvil- app.kubernetes.io/instance:anvil-1641889555- app.kubernetes.io/version:9.17.49- app.kubernetes.io/managed-by:Helm- helm.sh/chart:anvil-0.1.0  Helm通用标签 以下定义了Helm Chart使用的通用标签：\n app.kubernetes.io/name app.kubernetes.io/managed-by app.kubernetes.io/version app.kubernetes.io/instance app.kubernetes.io/component app.kubernetes.io/part-of helm.sh/chart # chart的名称和版本{{ .Chart.Name }}--{{Chart.Version | replace \u0026quot;+\u0026quot; \u0026quot;_\u0026quot;}} ","description":"","id":315,"section":"notes","tags":null,"title":"K8S推荐使用的标签及Helm常用的标签","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/k8s%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E7%9A%84%E6%A0%87%E7%AD%BE%E5%8F%8Ahelm%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A0%87%E7%AD%BE/"},{"content":"使用脚本前置条件：\n ktctl、kubectl、config三个文件放置在同一个目录中（且为该目录配置到PATH中，Ktctl工具硬性要求kubectl全局可访问） 启动时需要通过参数指定需要链接的环境 启动时需要通过参数指定ktctl、kubectl、config所在的目录 启动时需要通过参数指定scoat的参数（默认为12345）  脚本逻辑：\n 启动时检查ktctl是否已经启动，如果启动了，则杀掉 启动时检查12345参数是否被占用，如果被占用了，则杀掉相关的进程 后台启动ktctl，并监听相关端口是否可用 后台启动scoat，并监听相关端口是否可用 修改/ect/hosts逻辑  20211020后续：\n实际开发过程中，我没有完全按照这个需求做，哈哈\n","description":"","id":316,"section":"notes","tags":null,"title":"KtConnect脚本需求","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/ktconnect%E8%84%9A%E6%9C%AC%E9%9C%80%E6%B1%82/"},{"content":"我使用的指令如下：\n kubectl -v=8 get pods 参考资料  kubectl get pod卡住的问题  ","description":"","id":317,"section":"notes","tags":null,"title":"Kubectl执行时显示日志","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubectl%E6%89%A7%E8%A1%8C%E6%97%B6%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97/"},{"content":"看资料时看到了一个Kubernetes原生支持灰度发布的案例，他是利用两个发布不同版本的镜像Deployment实现的。这个方案的特点在于两个Deployment发布的Pod的标签是一致的（我这儿其实是有疑惑的，这样真的不会有影响到Deployment的调度么，我之前貌似进行过一个相关的实验，貌似标签一致的Pod也会被管理，可能我的实验是RS，而Deployment不存在该问题吧），而Service会将流量路由到指定标签的Pod上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  apiVersion:v1kind:Servicemetadata:name:nginx-servicelabels:app:nginxspec:selector:app:nginxports:- name:nginx-portprotocol:TCPport:80nodePort:32600targetPort:80type:NodePort---apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentlabels:app:nginxspec:replicas:3selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9---apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deployment-canarylabels:app:nginxtrack:canaryspec:replicas:1selector:matchLabels:app:nginxtrack:canarytemplate:metadata:labels:app:nginxtrack:canaryspec:containers:- name:nginximage:nginx:1.8.0  这样Service的流量将会在两个release之间分配，且在新旧版本之间，流量分配的比例为两个版本副本数的比例，此处为1:3。当确定了新的版本没有问题之后，可以将nginx-deployment的镜像标签改为新版本的镜像，然后进行滚动更新。\nKubernetes Service 只在 TCP 层面解决负载均衡的问题，并不对请求响应的消息内容做任何解析和识别。因此这个方案是有局限性地：\n 不能根据用户注册时间、地区等请求中的内容属性进行流量分配 同一个用户如果多次调用该Service，有可能第一次请求到了旧版本的Pod，第二次请求到了新版本的Pod  我们可以考虑如下方案：\n 业务代码编码实现 Spring Cloud灰度发布 Istio灰度发布  （突然发现自己基本功还是不够）\n","description":"","id":318,"section":"notes","tags":null,"title":"Kubernetes与灰度发布的一些思考","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%B8%8E%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"content":"前言  怎么说，犯了低级错误，但是在定位解决这个低级错误的时候又学到了很多知识  操作步骤  拉取代码，将Jenkins运行起来：  1 2 3 4 5 6 7 8  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Devops/Jenkins kubectl apply -f PersistentVolumeClaim.yml kubectl apply -f RBAC.yml kubectl apply -f Jenkins.yml    如图位置，进入Cloud配置页  选择添加kubernetes云，并对如下关键数据配置，配置完成后点击测试连接  配置slave信息，完成后点击保存  创建测试项目，完成配置测试：  相关教程   kubernetes中部署Jenkins并简单使用(完全按照这篇文档\n  在 Kubernetes 上动态创建 Jenkins Slave(知识点丰富，给了解决问题的思路)\n  Kubernetes下Jenkins CI的搭建(截图更晚上，补充了第一篇截图没有截到的地方)\n  ","description":"","id":319,"section":"notes","tags":null,"title":"Kubernetes中搭建Jenkins","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%B8%AD%E6%90%AD%E5%BB%BAjenkins/"},{"content":"操作步骤  拉取代码，将Nexus运行起来：  1 2 3 4 5 6 7 8 9 10 11  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Devops/Jenkins kubectl apply -f PersistentVolumeClaim.yml kubectl apply -f Nexus.yml kubectl create configmap setting.xml \\  -- from-file=setting.xml \\  -n devops   相关资料  Kubernetes部署Nexus3  ","description":"","id":320,"section":"notes","tags":null,"title":"Kubernetes中搭建Nexus","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%B8%AD%E6%90%AD%E5%BB%BAnexus/"},{"content":"操作步骤  拉取代码，将Ingress-Nginx运行起来：  1 2 3 4 5 6 7  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/Kubernetes/IngressNginx kubectl apply -f mandatory.yml kubectl apply -f service-nodeport.yml   查看pods时会发现镜像拉不下来，可以查看相关的教程，解决这个问题  相关教程   见异思迁：K8s 部署 Nginx Ingress Controller 之 kubernetes/ingress-nginx\n  NGINX Ingress Controller(无法下载插件，未使用该方案，该方案目前最新)\n  ingress-nginx github地址\n  ","description":"","id":321,"section":"notes","tags":null,"title":"Kubernetes使用ingress-nginx","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%BD%BF%E7%94%A8ingress-nginx/"},{"content":"这边笔记已经被废弃了，废弃的原因是我把https://gitee.com/junjie2019/kubernetes.git仓库设置成了私有。我重新整理了一份笔记，可以在相关目录下寻找。\n操作步骤   搭建NFS服务器，参考相关教程\n  配置Kubernetes使用NFS持久卷，指令如下：\n  1 2 3 4 5 6 7 8 9 10  git clone https://gitee.com/junjie2019/kubernetes.git cd kubernetes/PersistentVolume/PersistentVolume2 kubectl apply -f rabc.yml kubectl apply -f deployment.yml kubectl apply -f class.yml kubectl apply -f test-claim.yml kubectl apply -f test-pod.yml   相关教程   利用NFS动态提供Kubernetes后端存储卷\n  K8S 之 使用NFS作为持久卷使用POD\n  ","description":"","id":322,"section":"notes","tags":null,"title":"Kubernetes使用NFS持久卷（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E4%BD%BF%E7%94%A8nfs%E6%8C%81%E4%B9%85%E5%8D%B7%E5%BA%9F%E5%BC%83/"},{"content":"处理步骤  查看pods状态，发现pod没有成功创建：  1  kubectl get po   查看deployment状态，发现deployment一直处于NotReady状态，查看其描述，得不到任何讯息  1 2 3 4  kubectl get deploy kubectl describe deploy nfs-client-provisioner   查看ReplicationSet状态，发现出错，查看其描述，找到出错的原因   kubectl get rs kubectl describe rs nfs-client-provisioner-56596b5cc5 ","description":"","id":323,"section":"notes","tags":null,"title":"Kubernetes解决Deployment一直处于NotReady","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3deployment%E4%B8%80%E7%9B%B4%E5%A4%84%E4%BA%8Enotready/"},{"content":"报错如下：\n [root@node1 nfs]# kubectl describe pod nfs-client-provisioner-6f7bf77fd6-fbzhw -n nfs Name: nfs-client-provisioner-6f7bf77fd6-fbzhw Namespace: nfs Priority: 0 Node: node4/192.168.23.63 Start Time: Thu, 06 Jan 2022 03:50:28 -0500 Labels: app=nfs-client-provisioner pod-template-hash=6f7bf77fd6 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: IPs: \u0026lt;none\u0026gt; Controlled By: ReplicaSet/nfs-client-provisioner-6f7bf77fd6 Containers: nfs-client-provisioner: Container ID: Image: quay.io/external_storage/nfs-client-provisioner:latest Image ID: Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: PROVISIONER_NAME: fuseim.pri/ifs NFS_SERVER: 192.168.23.60 NFS_PATH: /root/NFSDirectory Mounts: /persistentvolumes from nfs-client-root (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-b7qkh (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: nfs-client-root: Type: NFS (an NFS mount that lasts the lifetime of a pod) Server: 192.168.23.60 Path: /root/NFSDirectory ReadOnly: false kube-api-access-b7qkh: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 23s default-scheduler Successfully assigned nfs/nfs-client-provisioner-6f7bf77fd6-fbzhw to node4 Warning FailedMount 7s (x6 over 23s) kubelet MountVolume.SetUp failed for volume \u0026quot;nfs-client-root\u0026quot; : mount failed: exit status 32 Mounting command: mount Mounting arguments: -t nfs 192.168.23.60:/root/NFSDirectory /var/lib/kubelet/pods/9d88096e-b189-4510-a4d6-f3ec93585930/volumes/kubernetes.io~nfs/nfs-client-root Output: mount: wrong fs type, bad option, bad superblock on 192.168.23.60:/root/NFSDirectory, missing codepage or helper program, or other error (for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.\u0026lt;type\u0026gt; helper program) In some cases useful info is found in syslog - try dmesg | tail or so. 解决方案是每个节点执行如下指令：\n yum install -y nfs-utils 类似问题在Ubuntu上遇到过，只是报错内容不一样，我是没有想到是nfs-utils工具导致的。\n参考资料  解决nfs挂载错误wrong fs type, bad option, bad superblock  ","description":"","id":324,"section":"notes","tags":null,"title":"Kubernetes解决NFS挂载报错的问题（CentOS版）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3nfs%E6%8C%82%E8%BD%BD%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98centos%E7%89%88/"},{"content":"问题描述：  日志如下   Name: nfs-client-provisioner-56596b5cc5-kvsff Namespace: default Priority: 0 Node: kubernetes3/172.17.30.103 Start Time: Thu, 23 Jul 2020 04:06:48 +0000 Labels: app=nfs-client-provisioner pod-template-hash=56596b5cc5 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: IPs: \u0026lt;none\u0026gt; Controlled By: ReplicaSet/nfs-client-provisioner-56596b5cc5 Containers: nfs-client-provisioner: Container ID: Image: quay.io/external_storage/nfs-client-provisioner:latest Image ID: Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Waiting Reason: ContainerCreating Ready: False Restart Count: 0 Environment: PROVISIONER_NAME: fuseim.pri/ifs NFS_SERVER: 192.168.30.174 NFS_PATH: /home/junjie/nfs Mounts: /persistentvolumes from nfs-client-root (rw) /var/run/secrets/kubernetes.io/serviceaccount from nfs-client-provisioner-token-9dv54 (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: nfs-client-root: Type: NFS (an NFS mount that lasts the lifetime of a pod) Server: 192.168.30.174 Path: /home/junjie/nfs ReadOnly: false nfs-client-provisioner-token-9dv54: Type: Secret (a volume populated by a Secret) SecretName: nfs-client-provisioner-token-9dv54 Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedMount 4m28s kubelet, kubernetes3 MountVolume.SetUp failed for volume \u0026quot;nfs-client-root\u0026quot; : mount failed: exit status 32 Mounting command: systemd-run Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root --scope -- mount -t nfs 192.168.30.174:/home/junjie/nfs /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root Output: Running scope as unit: run-r3196c404e0bd48b89adbb143ac8ba079.scope mount: /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.\u0026lt;type\u0026gt; helper program. Normal Scheduled 4m28s default-scheduler Successfully assigned default/nfs-client-provisioner-56596b5cc5-kvsff to kubernetes3 Warning FailedMount 4m28s kubelet, kubernetes3 MountVolume.SetUp failed for volume \u0026quot;nfs-client-root\u0026quot; : mount failed: exit status 32 Mounting command: systemd-run Mounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root --scope -- mount -t nfs 192.168.30.174:/home/junjie/nfs /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root Output: Running scope as unit: run-rbed921e0b7cd49a99857c958a1f04a1a.scope mount: /var/lib/kubelet/pods/fb44a773-c2ba-41fa-8b2a-9f9c52115495/volumes/kubernetes.io~nfs/nfs-client-root: bad option; for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.\u0026lt;type\u0026gt; helper program. 处理步骤  三台虚拟机上运行如下指令  1 2 3  sudo apt install -y nfs-common   相关教程  KUBERNETES挂载NFS报错：MOUNTVOLUME.SETUP FAILED FOR VOLUME “HTTPD-STORAGE” : MOUNT FAILED: EXIT STATUS 32  ","description":"","id":325,"section":"notes","tags":null,"title":"Kubernetes解决NFS挂载报错的问题（Ubuntu版）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3nfs%E6%8C%82%E8%BD%BD%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98ubuntu%E7%89%88/"},{"content":"问题描述  service原为NodePort类型，改为默认类型时，有报错如下：   kubectl apply -f Jenkins.yml The Service \u0026quot;jenkins\u0026quot; is invalid: spec.ports[1].nodePort: Forbidden: may not be used when `type` is 'ClusterIP' 直接删除原Service，重新建一个Service   kubectl delete -f Jenkins.yml kubectl apply -f Jenkins.yml 问题分析  可能时不同yml文件走了merge逻辑  ","description":"","id":326,"section":"notes","tags":null,"title":"Kubernetes解决Service is invalid问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3service-is-invalid%E9%97%AE%E9%A2%98/"},{"content":"问题描述：  日志如下   Name: jenkins-7d6c886b8-nkl4g Namespace: devops Priority: 0 Node: kubernetes3/172.17.30.103 Start Time: Thu, 23 Jul 2020 06:13:34 +0000 Labels: app=jenkins pod-template-hash=7d6c886b8 Annotations: \u0026lt;none\u0026gt; Status: Pending IP: 10.244.2.3 IPs: IP: 10.244.2.3 Controlled By: ReplicaSet/jenkins-7d6c886b8 Containers: jenkins: Container ID: Image: 192.168.30.174:80/test/jenkins:lts Image ID: Ports: 8080/TCP, 50000/TCP Host Ports: 0/TCP, 0/TCP State: Waiting Reason: ImagePullBackOff Ready: False Restart Count: 0 Limits: cpu: 1 memory: 1Gi Requests: cpu: 500m memory: 512Mi Liveness: http-get http://:8080/login delay=60s timeout=5s period=10s #success=1 #failure=12 Readiness: http-get http://:8080/login delay=60s timeout=5s period=10s #success=1 #failure=12 Environment: JAVA_OPTS: -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Duser.timezone=Asia/Shanghai Mounts: /var/jenkins_home from jenkinshome (rw) /var/run/secrets/kubernetes.io/serviceaccount from jenkins-sa-token-nt57q (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: jenkinshome: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: jenkins-pvc ReadOnly: false jenkins-sa-token-nt57q: Type: Secret (a volume populated by a Secret) SecretName: jenkins-sa-token-nt57q Optional: false QoS Class: Burstable Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 5m38s (x3 over 6m45s) default-scheduler persistentvolumeclaim \u0026quot;jenkins-pvc\u0026quot; not found Warning FailedScheduling 4m54s default-scheduler running \u0026quot;VolumeBinding\u0026quot; filter plugin for pod \u0026quot;jenkins-7d6c886b8-nkl4g\u0026quot;: error getting PVC \u0026quot;devops/jenkins-pvc\u0026quot;: could not find v1.PersistentVolumeClaim \u0026quot;devops/jenkins-pvc\u0026quot; Warning FailedScheduling 4m54s (x2 over 4m54s) default-scheduler running \u0026quot;VolumeBinding\u0026quot; filter plugin for pod \u0026quot;jenkins-7d6c886b8-nkl4g\u0026quot;: pod has unbound immediate PersistentVolumeClaims Normal Scheduled 4m50s default-scheduler Successfully assigned devops/jenkins-7d6c886b8-nkl4g to kubernetes3 Normal Pulling 3m26s (x4 over 4m48s) kubelet, kubernetes3 Pulling image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot; Warning Failed 3m26s (x4 over 4m48s) kubelet, kubernetes3 Failed to pull image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://192.168.30.174:80/v2/: http: server gave HTTP response to HTTPS client Warning Failed 3m26s (x4 over 4m48s) kubelet, kubernetes3 Error: ErrImagePull Normal BackOff 3m12s (x6 over 4m47s) kubelet, kubernetes3 Back-off pulling image \u0026quot;192.168.30.174:80/test/jenkins:lts\u0026quot; Warning Failed 2m59s (x7 over 4m47s) kubelet, kubernetes3 Error: ImagePullBackOff 处理步骤  三台上配置/etc/docker/deamon.json文件，具体配置内容参考相关教程（我已提供相关教程）  ","description":"","id":327,"section":"notes","tags":null,"title":"Kubernetes解决使用Harbor时无法拉取镜像的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8harbor%E6%97%B6%E6%97%A0%E6%B3%95%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"说在前面  真的有点喜极而泣的感觉，花了一下午，终于解决了这个问题，心理很舒服  解决步骤  下载flannel的yml文件，在如下部分增加一条条目，并修改为需要使用的网卡：  卸载原有的flannel插件，并安装更改后的插件：   kubectl delete -f kube-flannel.yml kubectl apply -f kube-flannel.yml 问题分析  我的虚拟机是用两张网卡的，在搭建Kubernetes时，两张网卡可能会影响到我搭建，所以之前的搭建中我会关闭一张网卡 本次实验中，我使用了kubeadm新的参数：apiserver-advertise-address=172.17.30.101。避免了在搭建阶段对我的影响 但是该方案在搭建完成后，安装flannel时出现新的问题，我认为flannel会默认使用我enp0s3网卡，导致我无法进行实验  相关教程  kubernetes\u0026ndash;flannel（kubeadm安装）的不同node上的pod间无法通信 解决k8s无法通过svc访问其他节点pod的问题(同上) Kubernetes主机间curl cluster ip时通时不通(给了一点思路) 解决Kubernetes中Pod无法正常域名解析问题分析与IPVS parseIP Error问题 Kubernetes中coredns无法正常域名解析问题分析(同上)  ","description":"","id":328,"section":"notes","tags":null,"title":"Kubernetes解决运行在不同主机上的Pod无法ping通的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kubernetes%E8%A7%A3%E5%86%B3%E8%BF%90%E8%A1%8C%E5%9C%A8%E4%B8%8D%E5%90%8C%E4%B8%BB%E6%9C%BA%E4%B8%8A%E7%9A%84pod%E6%97%A0%E6%B3%95ping%E9%80%9A%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"作废的理由是我不打算自己这样手动安装了，我想使用Helm进行安装\n这个是我结合之前的笔记写的新的方案，因为这个方案只是应用于我自己的开发环境，所以我想用更简单、更容易理解的方案来实现，而不像之前一样，创建了太多的资源。\n创建NameSpace 这次我不打算将NFS放在默认命名空间，我想放在一个叫做nfs的空间里。\n1 2 3 4 5 6  apiVersion:v1kind:Namespacemetadata:name:nfs  创建ServiceAccount及ClusterRoleBinding 这次我不打算创建自己的Role、ClusterRole、RoleBinding、ClusterRoleBinding，因为我对配置rules部分不是太熟悉。所以我打算直接从创建ServiceAccount，然后创建一个ClusterRoleBinding，将这个ServiceAccount绑定到集群管理员上。其实可以使用nfs命名空间下的default ServiceAccount，这样更省事，只是以后会增加理解成本。\n 创建ServiceAccount代码如下：  1 2 3 4 5 6 7  apiVersion:v1kind:ServiceAccountmetadata:name:nfs-client-provisionernamespace:nfs  创建ClusterRoleBinding代码如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14  kind:ClusterRoleBindingapiVersion:rbac.authorization.k8s.io/v1metadata:name:nfs-client-provisionersubjects:- kind:ServiceAccountname:nfs-client-provisionernamespace:nfsroleRef:kind:ClusterRolename:cluster-adminapiGroup:rbac.authorization.k8s.io  创建NfsClientProvisioner ","description":"","id":329,"section":"notes","tags":null,"title":"Kubernetes配置StorageClass（NFS）实验（作废）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%AE%9E%E9%AA%8C/kubernetes%E9%85%8D%E7%BD%AEstorageclassnfs%E5%AE%9E%E9%AA%8C%E4%BD%9C%E5%BA%9F/"},{"content":"MyBatis-Plus中发现的关于泛型的问题 在使用MyBatis-Plus的LambdaQueryWrapper时，发现了一个有趣的小问题，先记录下来：\n嗯，从Java泛型的实现原理上，我应该是有能力解释这个问题的，但是现在不太着急解决它，哈哈。\n","description":"","id":330,"section":"notes","tags":null,"title":"LambdaQueryWrapper泛型写法的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/lambdaquerywrapper%E6%B3%9B%E5%9E%8B%E5%86%99%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我之前学习Netty的课程时出现了LengthFieldBasedFrameDecoder解码器，当时我只想了解学习这门技术，所以很多技术点我都没有深入研究，现在工作有这方面的需要了，我需要开始深入研究一下。\nLengthFieldBasedFrameDecoder解码器主要用于自定义协议，通常协议的格式为：\nheader | length | body\n构造函数 其构造函数如下：\n1 2 3 4 5 6 7 8  public LengthFieldBasedFrameDecoder( int maxFrameLength, int lengthFieldOffset, int lengthFieldLength, int lengthAdjustment, int initialBytesToStrip);   参数含义分别如下：\n  maxFrameLength：最大帧长度。也就是可以接收的数据的最大长度。如果超过，此次数据会被丢弃\n  lengthFieldOffset：长度域偏移。就是说数据开始的几个字节可能不是表示数据长度，需要后移几个字节才是长度域\n  lengthFieldLength：长度域字节数。用几个字节来表示数据长度\n  lengthAdjustment：数据长度修正。因为长度域指定的长度可以是header + body的整个长度，也可以只是body的长度。如果表示header + body的整个长度，那么我们需要修正数据长度\n  initialBytesToStrip：跳过的字节数。如果你需要接收header+body的所有数据，此值就是0，如果你只想接收body数据，那么需要跳过header所占用的字节数。\n  原课程中的应用 如下代码为我对该类的应用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class MsgSpliter extends LengthFieldBasedFrameDecoder { public MsgSpliter() { super(Integer.MAX_VALUE, SystemConstant.LENGTH_FIELD_OFFSET, SystemConstant.LENGTH_FIELD_LENGTH); } @Override protected Object decode(ChannelHandlerContext ctx, ByteBuf in) throws Exception { if (in.getInt(in.readerIndex()) != SystemConstant.MAGIC_NUMBER) { ctx.channel().close(); return null; } return super.decode(ctx, in); } }   我的代码源于之前学习的课程，我的方案中我使用了一个叫做魔数的东西，如果用户传递的消息的魔数和我定义的不符合，则我会关闭消息通道。\n在我的应用中，我的消息的长度可以是任意的，长度从第7个字节开始，长度本身占用四个字节。至于lengthAdjustment，由于我的length记录的就是我body的长度，所以我传递为零；因为我需要接受所有的数据，所以，initialBytesToStrip同样为零。\n如果不使用该解码器该如何实现 我会在read中，判断当前可读的字节数是否大于4 + 4，如果大于，则我会先读取7个字节作为魔数，然后再读4个字节作为长度。\n在实现的过程中，我可能会将对消息的解码放在同一个解码器中实现，所以我下一步可能会持续判断可读字节数是否为消息中定义的长度，如果是，则读取该长度的字节数，转码为package对象，然然后从package对象中获得字节码数据，转成对应的消息。在该实现过程中，我进行调用了package对象进行了两次转换。\n如果需要进行优化，我会选择将package对象给刨除掉，我直接在，我的消息格式大概如下：\n魔数 | 协议编号 | 消息体长度 | 消息内容\n（实际上协议编号和消息体长度的先后顺序没有任何影响，所以没有必要纠结其前后）\n我暂时不打算考虑协议版本号、编解码算法等问题，我直接默认用protobuf。\n","description":"","id":331,"section":"notes","tags":null,"title":"LengthFieldBasedFrameDecoder学习","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/lengthfieldbasedframedecoder%E5%AD%A6%E4%B9%A0/"},{"content":"操作如下  优化后的方案，指令如下   ssh-copy-id mmpprd@10.44.2.106 ssh-copy-id mmpprd@10.44.0.177 i29PmmpImK ","description":"","id":332,"section":"notes","tags":null,"title":"Linux 建立SSH免密登录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux-%E5%BB%BA%E7%AB%8Bssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"},{"content":"指令如下：\n env ","description":"","id":333,"section":"notes","tags":null,"title":"Linux查看所有的环境变量","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"df -h\n","description":"","id":334,"section":"notes","tags":null,"title":"Linux查看硬盘使用情况","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E6%9F%A5%E7%9C%8B%E7%A1%AC%E7%9B%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5/"},{"content":"需求很少，且需要的时候，更多的是直接谷歌，故作废该笔记\n我不想用iptables、和firewall的方案，因为我对这些工具还不够熟悉，我只想一个小小的工具完成我的工作。最后我找到了socat（话说我用的kt connect工具貌似也需要这个工具）。\n指令如下：\n yum install -y socat socat TCP4-LISTEN:12345,reuseaddr,fork TCP4:127.0.0.1:2223 完美收工\n参考资料  Linux端口转发的几种常用方法  ","description":"","id":335,"section":"notes","tags":null,"title":"Linux端口映射","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%BD%9C%E5%BA%9F/linux%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"},{"content":"指令如下：\n systemctl enable wg-quick@wg0 参考资料   轻松几步搭建 WireGuard （快速安全的下一代 VPN）\n该指令是从这篇教程中学习到的。\n  ","description":"","id":336,"section":"notes","tags":null,"title":"Linux系统配置wireguard开启启动","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AEwireguard%E5%BC%80%E5%90%AF%E5%90%AF%E5%8A%A8/"},{"content":"我开发了一个外卖提醒的脚本，每次运行的时候，会发送一条消息到我们的钉钉群，提醒我们点外卖，我将它放到了我的实验机上。开发的定时任务脚本如下：\n # 编辑/etc/crontab增加如下内容 vi /etc/crontab # 增加的内容 30,32,35 11 * * 1-6 /root/Software/launch/dist/launch 45,50 17 * * 1-6 /root/Software/launch/dist/launch # 加载任务 crontab /etc/crontab # 查看任务 crontab -l crontab -u root -l 我想要的效果是：周一到周六每天中午11.30、11.32、11.35提醒一次，晚上17.45、17.50提醒一次。\n参考资料  CentOS 7 定时计划任务设置  ","description":"","id":337,"section":"notes","tags":null,"title":"Linux设置定时任务","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E8%AE%BE%E7%BD%AE%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"content":"这份笔记来自对另一份笔记的拆分，这篇笔记偏重于LocalDateTime，为了方便查阅，所以我移动到了另一篇笔记中。\n项目目前对对timestamptz的应用 首先对着我们库执行show timezone得到的结果为GMT。GMT表明了我们数据库服务设计的初心：我们中美服务器的数据库都统一使用一个时区。结合我们的实践，现在我产生了如下几个问题：\n  向表中插入一条当前系统的时间，然后再去查表中的记录，这个时候的时间是什么呢（我期待的是做过转换的GMT时间）\n  当我们的项目链接到数据库时，此时的链接的时区是什么，也是GMT么？\n  我们用于接受timestamptz的LocalDateTime类型，有什么特殊的地方么，在插入和查询结果时。\n  我们的Java服务实例的时区对整个时间戳有什么影响么，要求我们的Java实例必须设置正确的时区吗？\n  到底如何和前端配置，前端的意思是我们可以给一个+00的时间戳，但是我们又使用了LocalDateTime，LocalDateTime在反序列化时貌似自动完成了+08运算。\n  第一个问题 如下实验：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  CREATE TABLE timestamp_demo (ts TIMESTAMP, tstz TIMESTAMPTZ); INSERT INTO timestamp_demo (ts, tstz) VALUES ( \u0026#39;2021-07-19 11:00:00-00\u0026#39;, \u0026#39;2021-07-19 11:00:00-00\u0026#39; ); INSERT INTO timestamp_demo (ts, tstz) VALUES ( now(), now() );   最后查看数据库中的数据：\n我发现当我使用字符串的进行timestamptz类型插入的时候，timestamptz类型的字段没有按照我的现象根据我操作系统当前所在的时区（链接、用户所在的时区），将时间转换成GMT时间。按照MySQL的经验，show timezone或许得到的就是当前链接（即session）的时区，那么这个现象是可以理解的：我在GMT的时区里插入任何数据，都不需要进行转换。\n我现在手动切换当前session时区到PRC，我先执行了一次select语句，我发现timestamp的数据没有任何变化，timestamptz类型的数据按照设计完成了+8运算。\n实验到这儿，我才发现了一些问题，我在插入数据的时候，已经带上了时区~~~，秒后面的+00和-00其实就是时区信息，我一直没有意识到这个问题，不过好在该细节对前面我作出来的分析并没有任何影响，我前面的分析都是正确的。此时我将当前链接的时区设置为PRC，然后用如下代码进行插入实验，最终插入数据库的数据确实完成了PRC时区到GMT时区（即UTC时间）转换，非常的开心。\n1 2 3 4 5 6 7 8  INSERT INTO timestamp_demo (ts, tstz) VALUES ( \u0026#39;2021-07-19 11:00:00\u0026#39;, \u0026#39;2021-07-19 11:00:00\u0026#39; );   发现数据没有像我想象的一样转换成GMT时间。看了上面的资料，我认为可能是因为我用户或者我链接的所在的时区影响了数据库出数据（自动帮我完成了时区的缓存）。\n第二个问题 我用如下代码，查看了当前数据库的链接，发现数据库的链接的时区为：Asia/Shanghai。\n1 2 3 4 5 6 7 8 9 10 11 12  List\u0026lt;String\u0026gt; timezones = jdbcTemplate.query( \u0026#34;show time zone\u0026#34;, new RowMapper\u0026lt;String\u0026gt;() { @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException { return rs.getString(1); } }); System.out.println(timezones);   这个结果是比较出乎我的意料的，因为我们数据库的请求url上并没有配置时区，我现在不知道这个时区数据是从何而来的。最后我查找资料，成功的将SpringBoot实例的时区更换为了GMT，相关笔记我整理在了SpringBoot分类下。\n我仅仅只是处于技术探索的目的进行SpringBoot时区的调整，实践中该技术貌似没有太大的需求。\n第三个问题 在写入的时候，在我们自定义的typeHandler中，LocalDateTime类型的参数被转换成了Timestamp类型的对象。这个然后这个timestamp对象由pg自己的驱动器了进行处理（我想pg自己的驱动器类应该很清楚知道pg数据库支持的类型，所以可以很好的根据数据库中的类型处理这个timestamp对象，我之所以作出这个判断，是因为我在开发库上做实验，而开发库没有开启sql日志）\n在读出数据的时候，在我们自定义的typeHandler中，pg的数据库交给我们一个Timestamp类型的对象，然后我们将这个timestamp对象转换成LocalDateTime对象。整个过程平平无奇，并没有涉及到过于底层的东西（最底层的东西都被PG的驱动器类自己处理了）。\n第四个问题 SpringBoot实例所设置的时区，对时间戳影响很大。我们在程序内部是很少使用时间戳概念的，我们使用的都是Date、Time、DateTime之类的概念（我们不会拿时间戳做运算，但是我们会拿DateTime等做运算）。我之前没有意识到这个问题，其实Date、Time、DateTime之类的概念都蕴含了时区的概念，也就是说，我们只能说某某时区的Date、Time和DateTime，而不能脱离时区谈论这些概念。\n因此，从这些对象转换成时间戳的时候，运算过程一定是带上了时区的。举个例子，一个时间2021-07-19 16:00:00转换成时间戳，如果单纯的计算秒数，我们实际上是假设了这个时间是零时区的。但是我们目前处于+8时区，所以在计算秒数的时候，需要先将这个时间减去8小时，然后再计算秒数。\nSpringBoot实例应该会根据系统当前的时区，来设置整个实例的时区，同时，这个时区会用于与pg数据建立链接（即我们的链接的session和SpringBoot的时区是一致的）。\n第五个问题 综上，产生这个问题的原因在我们项目中在讲LocalDateTime转换成时间戳的时传递了错误的ZoneOffset，我们硬编码了一个+8的值。当项目跑在国内的环境中时，这个问题的印象是比较小的，当我们的项目跑在国外的环境中时，这个问题时灾难的，因为此时的LocalDateTime中记录的时区并不是+8时区，但是强行按照了+8时区进行时间戳转换，所以算出来的数据是错误的。\n此时如下编码，即可解决这个问题：\n1 2 3 4 5 6 7 8  LocalDateTime localDateTime = LocalDateTime.of(2021, 7, 19, 15, 0, 0); ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(localDateTime); localDateTime.toInstant(offset).toEpochMilli();   这段代码中，我们应用当前系统所在的时区来转换LocalDateTime对象，是符合需求的。\n","description":"","id":338,"section":"notes","tags":null,"title":"LocalDateTime与timestamptz","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/localdatetime%E4%B8%8Etimestamptz/"},{"content":"这是我使用在我们项目中的一个方案，我挺喜欢这个方案的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // LocalDateTime到时间戳  ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(localDateTime); return String.valueOf(localDateTime.toInstant(offset).toEpochMilli()); // 时间戳到LocalDateTime  long timestamp = Long.parseLong(text); Instant instant = Instant.ofEpochMilli(timestamp); ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone);   参考资料  java8中时间的各种转换(LocalDateTime)  ","description":"","id":339,"section":"notes","tags":null,"title":"LocalDateTime与时间戳互相转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/localdatetime%E4%B8%8E%E6%97%B6%E9%97%B4%E6%88%B3%E4%BA%92%E7%9B%B8%E8%BD%AC%E6%8D%A2/"},{"content":"最近服务的消费者提出了新的需求，要求我们的时间字段的格式都必须为时间戳，我原本以为是一个简单的问题，结果发现Fastjson在处理LocalDateTime时不是那么简单（我还没有思考过为什么使用LocalDateTime而不是Date等类）。找了一圈，没有很好的方案，所以我开发了如下的代码，我打算在下次遇到该需求的时候再重构代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  // todo 临时方案，以后需要优化  @Data public static class DataPoDTO { private String formId; private String orgId; private Map\u0026lt;String, Object\u0026gt; extraData; protected String id; protected Integer delete = 0; protected LocalDateTime gmtModifyTime; protected LocalDateTime gmtCreateTime; protected String modifier; protected String creator; public Long getGmtModifyTime() { return gmtModifyTime.toEpochSecond(ZoneOffset.of(\u0026#34;+8\u0026#34;)); } public Long getGmtCreateTime() { return gmtCreateTime.toEpochSecond(ZoneOffset.of(\u0026#34;+8\u0026#34;)); } }   我们从数据库中查出来的数据，先COPY到DataPoDTO中，然后再进行序列化。\n相关资料收集 整理一下这些资料，便于以后深入研究：\n  从LocalDateTime序列化探讨全局一致性序列化\n这篇文章提到了序列化工具和反序列化工具全局一致性，但是作者的案例使用的是JackJson。\n  FastJson输出时间类型强转为时间戳\n提到了fastJsonConfig.setSerializeFilters()，对我当前的问题来说，这个解决方案太重了，但是如果是全局一致性的话，可以考虑使用这个方案。\n  Java8 LocalDateTime获取时间戳（毫秒/秒）、LocalDateTime与String互转、Date与LocalDateTime互转\nlocaldatetime实现时间戳(相互转换)\n包含了LocalDateTime时间戳转换的知识。\n  ","description":"","id":340,"section":"notes","tags":null,"title":"LocalDateTime序列化时格式问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/localdatetime%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E6%A0%BC%E5%BC%8F%E9%97%AE%E9%A2%98/"},{"content":"参考资料  SpringBoot—整合log4j2入门和log4j2.xml配置详解  ","description":"","id":341,"section":"notes","tags":null,"title":"Log4j2的配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/log4j2%E7%9A%84%E9%85%8D%E7%BD%AE/"},{"content":"上周把Idea升级到了最新版，结果启动项目时出现了如下错误：\n我最后修复该问题的方案是放弃我自己进行lombok版本管理，让SpringBoot进行版本裁决：\n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;!--\u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt;--\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   参考资料  You aren‘t using a compiler supported by lombok, so lombok will not work and has been disabled.  ","description":"","id":342,"section":"notes","tags":null,"title":"Lombok与Idea版本不兼容","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/lombok%E4%B8%8Eidea%E7%89%88%E6%9C%AC%E4%B8%8D%E5%85%BC%E5%AE%B9/"},{"content":"scope取值   compile\n 默认为compile，什么都不配置就意味着compile compile表示被依赖项目需要参与当前项目的编译、测试、运行 打包的时候，compile也会被打包进去    test\n 仅参与测试相关的工作，包括测试代码的编译、执行    runtime\n 被依赖项目无需参与项目的编译，但是需要参与后期的测试和运行 与compile相比，仅跳过编译，与compile区别不是很大 案例：JSR xxx等，API Jar是compile的，具体实现是runtime的，编译时只需要知道接口即可 案例：jdbc驱动框架，jdbc相关api是compile，而具体实现可以通过Class.forName获取 备注：可以与optional搭配使用，optional为true，则可以用A实现也可以用B实现    provided\n 打包时可以不用打包进去，别的设施会提供 该依赖理论上可以参与编译、测试、运行等周期 相比于compile，在打包阶段做了exclude动作    system\n 从参与角度来说，与provide相同 依赖项不会被maven仓库抓，而是从本地文件系统拿 一定需要配合systemPath属性使用    scope依赖传递 A -\u0026gt; B -\u0026gt; C。\n知道了B在A项目中的scope，如何知道C在A中的scope呢？\n 如果C是test或者provided，C直接被抱起，A不依赖C 否则A依赖于C，C的scope继承于B的scope  参考资料  Maven依赖中的scope详解spring-boot-starter-tomcat  ","description":"","id":343,"section":"notes","tags":null,"title":"Maven中的Scope","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E4%B8%AD%E7%9A%84scope/"},{"content":"我在deploy auth-center项目的时候，在根项目执行deploy，报如下错误（没有太多的有用的信息）：\n \u0026quot;C:\\Program Files\\Java\\jdk1.8.0_281\\bin\\java.exe\u0026quot; -Dmaven.multiModuleProjectDirectory=D:\\Project\\auth-center \u0026quot;-Dmaven.home=D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\u0026quot; \u0026quot;-Dclassworlds.conf=D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\\bin\\m2.conf\u0026quot; \u0026quot;-javaagent:D:\\Software\\IntelliJ IDEA 2019.1.4\\lib\\idea_rt.jar=55517:D:\\Software\\IntelliJ IDEA 2019.1.4\\bin\u0026quot; -Dfile.encoding=UTF-8 -classpath \u0026quot;D:\\Software\\IntelliJ IDEA 2019.1.4\\plugins\\maven\\lib\\maven3\\boot\\plexus-classworlds-2.6.0.jar\u0026quot; org.codehaus.classworlds.Launcher -Didea.version2019.1.4 -s D:\\MavenRepository\\settings-guoxiong.xml -Dmaven.repo.local=D:\\MavenRepository\\repository -DskipTests=true deploy -P local [WARNING] [WARNING] Some problems were encountered while building the effective settings [WARNING] 'servers.server.id' must be unique but found duplicate server with id maven-public @ D:\\MavenRepository\\settings-guoxiong.xml [WARNING] [INFO] Scanning for projects... [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-common:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-client:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-server:jar:1.0 [WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-install-plugin is missing. @ line 136, column 21 [WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-deploy-plugin is missing. @ line 152, column 21 [WARNING] [WARNING] Some problems were encountered while building the effective model for com.sdstc:authcenter-login:jar:1.0 [WARNING] The expression ${name} is deprecated. Please use ${project.name} instead. [WARNING] [WARNING] It is highly recommended to fix these problems because they threaten the stability of your build. [WARNING] [WARNING] For this reason, future Maven versions might no longer support building such malformed projects. [WARNING] [INFO] ------------------------------------------------------------------------ [INFO] Reactor Build Order: [INFO] [INFO] authcenter-common [jar] [INFO] authcenter-client [jar] [INFO] authcenter-login [jar] [INFO] authcenter-server [jar] [INFO] authcenter [pom] [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-common \u0026gt;--------------------- [INFO] Building authcenter-common 1.0 [1/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-common --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-common --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-common --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-common\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-common --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-common --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-common --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-common --- [INFO] Installing D:\\Project\\auth-center\\authcenter-common\\target\\authcenter-common.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-common\\1.0\\authcenter-common-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-common\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-common\\1.0\\authcenter-common-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-common --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.jar (237 kB at 2.1 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/1.0/authcenter-common-1.0.pom (1.8 kB at 87 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml (302 B at 9.4 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-common/maven-metadata.xml (302 B at 1.5 kB/s) [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-client \u0026gt;--------------------- [INFO] Building authcenter-client 1.0 [2/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-client --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-client --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-client --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-client\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-client --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-client --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-client --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-client --- [INFO] Installing D:\\Project\\auth-center\\authcenter-client\\target\\authcenter-client.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-client\\1.0\\authcenter-client-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-client\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-client\\1.0\\authcenter-client-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-client --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.jar (36 kB at 1.3 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/1.0/authcenter-client-1.0.pom (2.3 kB at 63 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml (302 B at 14 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-client/maven-metadata.xml (302 B at 1.7 kB/s) [INFO] [INFO] ---------------------\u0026lt; com.sdstc:authcenter-login \u0026gt;--------------------- [INFO] Building authcenter-login 1.0 [3/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-login --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\main\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-login --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-login --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] skip non existing resourceDirectory D:\\Project\\auth-center\\authcenter-login\\src\\test\\resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-login --- [INFO] No sources to compile [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-login --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-login --- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-login --- [INFO] Installing D:\\Project\\auth-center\\authcenter-login\\target\\authcenter-login.jar to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-login\\1.0\\authcenter-login-1.0.jar [INFO] Installing D:\\Project\\auth-center\\authcenter-login\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter-login\\1.0\\authcenter-login-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-login --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.jar (181 kB at 4.2 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/1.0/authcenter-login-1.0.pom (3.5 kB at 55 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml Downloaded from project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml (301 B at 15 kB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/com/sdstc/authcenter-login/maven-metadata.xml (301 B at 1.8 kB/s) [INFO] [INFO] --------------------\u0026lt; com.sdstc:authcenter-server \u0026gt;--------------------- [INFO] Building authcenter-server 1.0 [4/5] [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ authcenter-server --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] Copying 13 resources [INFO] Copying 13 resources [INFO] Copying 0 resource [INFO] [INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ authcenter-server --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ authcenter-server --- [INFO] Using 'UTF8' encoding to copy filtered resources. [INFO] Copying 19 resources [INFO] [INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ authcenter-server --- [INFO] Nothing to compile - all classes are up to date [INFO] [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ authcenter-server --- [INFO] Tests are skipped. [INFO] [INFO] --- maven-jar-plugin:3.2.0:jar (default-jar) @ authcenter-server --- [INFO] Building jar: D:\\Project\\auth-center\\authcenter-server\\target\\authcenter.jar [INFO] [INFO] --- spring-boot-maven-plugin:2.2.5.RELEASE:repackage (default) @ authcenter-server --- [INFO] Replacing main artifact with repackaged archive [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter-server --- [INFO] Skipping artifact installation [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter-server --- [INFO] Skipping artifact deployment [INFO] [INFO] ------------------------\u0026lt; com.sdstc:authcenter \u0026gt;------------------------ [INFO] Building authcenter 1.0 [5/5] [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-install-plugin:2.4:install (default-install) @ authcenter --- [INFO] Installing D:\\Project\\auth-center\\pom.xml to D:\\MavenRepository\\repository\\com\\sdstc\\authcenter\\1.0\\authcenter-1.0.pom [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy (default-deploy) @ authcenter --- [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for authcenter 1.0: [INFO] [INFO] authcenter-common .................................. SUCCESS [ 3.053 s] [INFO] authcenter-client .................................. SUCCESS [ 0.516 s] [INFO] authcenter-login ................................... SUCCESS [ 0.817 s] [INFO] authcenter-server .................................. SUCCESS [ 2.236 s] [INFO] authcenter ......................................... FAILURE [ 0.008 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 6.958 s [INFO] Finished at: 2021-05-10T14:14:49+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project authcenter: Deployment failed: repository element was not specified in the POM inside distributionManagement element or in -DaltDeploymentRepository=id::layout::url parameter -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn \u0026lt;goals\u0026gt; -rf :authcenter Process finished with exit code 1 我并没有定位出这个问题，我解决该问题的方案是只Deploy子项目，不要用根项目Deploy。\n","description":"","id":344,"section":"notes","tags":null,"title":"Maven无法从根项目deploy","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E6%97%A0%E6%B3%95%E4%BB%8E%E6%A0%B9%E9%A1%B9%E7%9B%AEdeploy/"},{"content":"1 2 3 4  mvn dependency:tree mvn dependency:tree -Doutput=*.txt   参考资料  如何查看Maven项目中的jar包依赖树情况？  ","description":"","id":345,"section":"notes","tags":null,"title":"Maven查看依赖树","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E6%9F%A5%E7%9C%8B%E4%BE%9D%E8%B5%96%E6%A0%91/"},{"content":"需求产生于一个非常特殊的场景，在做内部应用上云时，我们的流水线始终无法拉取下面的包（我们已经配置了VPN，且阿里云的Maven仓库已经做了全量同步），所以没有办法，只能通过下面的方式将jar包上传到阿里的仓库上（是这样的么，我好想忘记细节了）\n指令如下  mvn deploy:deploy-file \\ -DgroupId=com.oracle \\ -DartifactId=ojdbc7 \\ -Dversion=12.1.0.2 \\ -Dfile=./ojdbc7-12.1.0.2.jar \\ -Durl=http://ci.pc.com.cn/nexus/content/repositories/releases/ \\ -DrepositoryId=releases 20210421后续：\n有意思，我没想到这种需求也能再次遇到，今天在做GRpc相关的功能时，需要用到个grpc-starter.jar的包，这个包在Maven仓库里没有。我先尝试修改上面的指令，改动结果如下，企图简简单单的完成推送任务，但是一直报如下错误：\n1 2 3 4 5 6 7 8 9  mvn deploy:deploy-file \\ \t-DgroupId=com.sdstc.paas \\  -DartifactId=grpc-starter \\  -Dversion=1.0.0-RELEASE \\  -Dfile=./grpc-starter.jar \\  -Durl=http://192.168.20.9:8081/repository/mavenreleases/ \\  -DrepositoryId=maven-releases    [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- Uploading to maven-releases: http://192.168.20.9:8081/repository/mavenreleases/com/sdstc/paas/grpc-starter/1.0.0-RELEASE/grpc-starter-1.0.0-RELEASE.jar Uploading to maven-releases: http://192.168.20.9:8081/repository/mavenreleases/com/sdstc/paas/grpc-starter/1.0.0-RELEASE/grpc-starter-1.0.0-RELEASE.pom [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.748 s [INFO] Finished at: 2021-04-21T16:31:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy-file (default-cli) on project standalone-pom: Failed to deploy artifacts: Could not find artifact com.sdstc.paas:grpc-starter:jar:1.0.0-RELEASE in maven-releases (http://192.168.20.9:8081/repository/mavenreleases/) -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 我登录Nexus后并没有感觉到异常，maven-releases仓库都是存在的。而且maven-releases下有很多com.sdstc的包，我感觉推送到到这块应该是没有问题的（我被包名称上的Release给忽悠了，感觉这个包就应该推到release仓库）。后来我尝试在浏览器访问http://192.168.20.9:8081/repository/mavenreleases/地址，结果发现该地址报404错误。\n我再次检查我的setting文件，在文件中找到了新的仓库地址，并检查了该仓库地址，是正常可以访问的，所以重新配置使用这个仓库，最终成功的完成了推送。成功配置如下：\n mvn deploy:deploy-file \\ -DgroupId=com.sdstc.paas \\ -DartifactId=grpc-starter \\ -Dversion=1.0.0-RELEASE \\ -Dfile=./grpc-starter.jar \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo 在解决这个问题时，我学习到了将包安装在本地的指令，我想我下次可能会优先使用这个指令。我是在Win10上执行的，代码需要写成一行，但是，为了整理笔记时好看，我按Linux的方式重新调整了代码：\n mvn install:install-file \\ -DgroupId=com.sdstc.paas \\ -DartifactId=grpc-starter \\ -Dversion=1.0.0-RELEASE \\ -Dfile=./grpc-starter.jar -Durl=http://192.168.20.9:8081/repository/mavenreleases/ -DrepositoryId=maven-releases \\ -Dpackaging=jar 20210426后续：\n没想到还有相关的需求？？？而且我们运维也是通过这种方式上传的（假的吧）,这次我用如下代码上传，遇到了如下的报错，我的解决方法是将jar包从本地的maven仓库中移出来，放到一个临时的文件夹中，然后再执行这行指令（玄学），然后就成功的推送了。\n mvn deploy:deploy-file \\ -DgroupId=cn.hutool \\ -DartifactId=hutool-all \\ -Dversion=5.6.3 \\ -Dfile=./hutool-all-5.6.3.jar \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo  // 报错上传的日志 D:\\MavenRepository\\repository\\cn\\hutool\\hutool-all\\5.6.3\u0026gt;mvn deploy:deploy-file -DgroupId=cn.hutool -DartifactId=hutool-all -Dversion=5.6.3 -Dfile=./hutool-all-5.6.3.jar -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 0.264 s [INFO] Finished at: 2021-04-26T10:08:57+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy-file (default-cli) on project standalone-pom: Cannot deploy artifact from the local repository: D:\\MavenRepository\\repository\\cn\\hutool\\hutool-all\\5.6.3\\hutool-all-5.6.3.jar -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException // 正确上传的日志 C:\\Users\\wujj\\Desktop\\tmp3\u0026gt;mvn deploy:deploy-file -DgroupId=cn.hutool -DartifactId=hutool-all -Dversion=5.6.3 -Dfile=./hutool-all-5.6.3.jar -Durl=http://192.168.20.9:8081/repository/project-repo/ -DrepositoryId=project-repo [INFO] Scanning for projects... [INFO] [INFO] ------------------\u0026lt; org.apache.maven:standalone-pom \u0026gt;------------------- [INFO] Building Maven Stub Project (No POM) 1 [INFO] --------------------------------[ pom ]--------------------------------- [INFO] [INFO] --- maven-deploy-plugin:2.7:deploy-file (default-cli) @ standalone-pom --- Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.jar Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.jar (1.9 MB at 4.2 MB/s) Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.pom Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/5.6.3/hutool-all-5.6.3.pom (393 B at 2.4 kB/s) Downloading from project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml Uploading to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml Uploaded to project-repo: http://192.168.20.9:8081/repository/project-repo/cn/hutool/hutool-all/maven-metadata.xml (299 B at 2.4 kB/s) [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.514 s [INFO] Finished at: 2021-04-26T10:55:08+08:00 [INFO] ------------------------------------------------------------------------ 我很讨厌这种充满玄学的问题，我觉得一个问题不知道其底层的缘由都是在给自己给别人埋坑，所以我计划花时间解决好这个问题，我目前的疑惑有：\n  为什么在本地Maven仓库下不能成功，非要拷贝到一个临时文件夹中执行，是路径太长了么，还是Maven仓库中的一些文件影响了结果（我查看了日志，没有找到任何有用的信息）？\n  我发现我最终推到Nexus仓库后的pom文件和该jar包原本的pom文件不一致，我觉得这是一个隐患（我有办法解决这个问题了）\n  我觉得存在技术，将本地Maven仓库的某个依赖整体推送到Nexus仓库。我在做阿里云的Maven时，阿里云就提供了这个工具，阿里云是将整个maven的本地仓库都推送过去，我觉得Nexus也提供相应的工具。（我还是没有找到这种工具）  问题一 我已经实验过了，不是目录太深、不是目录中带有数字、不是目录与版本号一致造成的问题。\n当在本地仓库的jar包所在目录，新建一个临时目录，把jar包放进去，然后执行指令，也是可以成功的上传的。\n知道问题的答案后，我不知道该用什么语言形容我的心情，只要你当前使用的maven工具的setting.xml文件中的localRepository和你正在上传的jar包不是同一个仓库，就可以成功的上传。我大致猜到了实现逻辑了，它会先通过命令的groupId、artificialId、version加上setting.xml文件中的localRepository，得到一个jar包的地址，然后与你当前希望上传的jar包地址进行对比，如果两者是一样的就会阻止上传。实际上报错中已经说明白了这个问题:Cannot deploy artifact from the local repository。只是我理解错了方向。\n我没有找到解释为什么这样设计的资料。\n问题二 我用如下指令解决了这个问题，但是前提是我还是得把pom文件和jar包拷贝到一个临时文件夹：\n mvn deploy:deploy-file \\ -DgeneratePom=false \\ -DrepositoryId=project-repo \\ -Durl=http://192.168.20.9:8081/repository/project-repo/ \\ -DpomFile=./hutool-all-5.6.3.pom \\ -Dfile=./hutool-all-5.6.3.jar 参考资料   将jar推送到本地maven库和nexus中的方法\n  jar包上传maven私服出错Cannot deploy artifact from the local repository\n  使用Nexus3搭建Maven私服+上传第三方jar包到本地maven仓库\n  Maven私服Nexus3.x环境构建操作记录\n学习到一些Nexus仓库的基础知识，知道了如果存在proxy仓库，使用第三方包时可以通过这个仓库获取。我们的Nexus也确实存在一个proxy，但是我们的本地环境和dev环境的setting.xml文件中都没有配置这个仓库，难受。\n  ","description":"","id":346,"section":"notes","tags":null,"title":"Maven用命令行将jar包上传到Nexus仓库","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B0%86jar%E5%8C%85%E4%B8%8A%E4%BC%A0%E5%88%B0nexus%E4%BB%93%E5%BA%93/"},{"content":"使用如下指令为Maven项目设置新的版本候，会生成一份pom.xml的备份文件，该备份文件可能导致Idea的行为异常，表现为：导入项目时呈现多个项目，而且会在项目的目录中生成多个xxx.iml。\n mvn versions:set -DnewVersion=1.1.0 我目前没有严格的去验证这个问题，只是多个项目都出现了类似的情况，我提出来自己的一种猜想：\n","description":"","id":347,"section":"notes","tags":null,"title":"Maven的pom.xml的备份文件，可能导致Idea行为异常","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/maven%E7%9A%84pom.xml%E7%9A%84%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E5%8F%AF%E8%83%BD%E5%AF%BC%E8%87%B4idea%E8%A1%8C%E4%B8%BA%E5%BC%82%E5%B8%B8/"},{"content":"我们的项目有一个比较便利的功能，如图，当我们选择了local后，我们启动SpringBoot项目时，将自动使用application-local.yml配置文件，当我们选择sit后，则会使用application-sit.yml配置文件。\n该功能是如何实现的呢，如图，在我们公司自己的starter-parent上有如下的配置：\n而在我们的bootstrap.properties中有如下配置：\n我认为项目在启动的时候，会将@spring.profiles.active@转换为相应的Maven Profile的值，从而实现使用相应的配置文件。\n对上述分析的验证 我准备了如下配置文件：\n # application.properties spring.profiles.active=@spring.profiles.active@ # applicaiton-local.yml tmp: key: local # applicaiton-sit.yml tmp: key: sit 我准备了如下配置类：\n1 2 3 4 5 6 7 8  @Data @Component @ConfigurationProperties(prefix = \u0026#34;tmp\u0026#34;) public class TmpConfiguration { private String key; }   在测试类中，我们发现当我们选择了不同的Maven Profile后，tmpConfiguration中的key值将会为local或者sit。\n实验基本证实了我的想法。\n还存在的问题 我在实验的过程中又产生了一些新的问题，如下：\n @spring.profiles.active@只能写在application.properties中，不能写在application.yml中，如果写在application.yml中，则会在启动时报如下的错误（已解决，参考同目录下的笔记）：   Caused by: while scanning for the next token found character '@' that cannot start any token. (Do not use @ for indentation) in 'reader', line 3, column 13: active: @spring.profiles.active@ 那么如果我想达到和application.properties相同的配置效果，我又该如何写这个值呢？\n我目前不知道Maven Profile与SpringBoot项目的关系，application.properties中是如何获取我们在Maven Profile中配置的Profile呢？（已解决）  ","description":"","id":348,"section":"notes","tags":null,"title":"Maven的profiles与SpringBoot的application.yml","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/maven%E7%9A%84profiles%E4%B8%8Espringboot%E7%9A%84application.yml/"},{"content":"先声明一下，我觉得下面的技术在实践过程中并没有太大的意义，只是碰巧看到了，所以就整理一下。\n如下，我们可以如下配置pom.xml文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83  \u0026lt;profiles\u0026gt; \u0026lt;!--部署环境--\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;local\u0026lt;/id\u0026gt; \u0026lt;!--local环境--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/profiles/local\u0026lt;/directory\u0026gt; \u0026lt;!--引入properties文件地址--\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.env\u0026gt;local\u0026lt;/profile.env\u0026gt; \u0026lt;!--变量，标识环境--\u0026gt; \u0026lt;log.root.level\u0026gt;INFO\u0026lt;/log.root.level\u0026gt; \u0026lt;log.logger.level\u0026gt;DEBUG\u0026lt;/log.logger.level\u0026gt; \u0026lt;log.console.level\u0026gt;INFO\u0026lt;/log.console.level\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;development\u0026lt;/id\u0026gt; \u0026lt;!--local环境--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/profiles/development\u0026lt;/directory\u0026gt; \u0026lt;!--引入properties文件地址--\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.env\u0026gt;development\u0026lt;/profile.env\u0026gt; \u0026lt;!--变量，标识环境--\u0026gt; \u0026lt;log.root.level\u0026gt;INFO\u0026lt;/log.root.level\u0026gt; \u0026lt;log.logger.level\u0026gt;DEBUG\u0026lt;/log.logger.level\u0026gt; \u0026lt;log.console.level\u0026gt;INFO\u0026lt;/log.console.level\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;preview\u0026lt;/id\u0026gt; \u0026lt;!--local环境--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/profiles/preview\u0026lt;/directory\u0026gt; \u0026lt;!--引入properties文件地址--\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.env\u0026gt;preview\u0026lt;/profile.env\u0026gt; \u0026lt;!--变量，标识环境--\u0026gt; \u0026lt;log.root.level\u0026gt;INFO\u0026lt;/log.root.level\u0026gt; \u0026lt;log.logger.level\u0026gt;DEBUG\u0026lt;/log.logger.level\u0026gt; \u0026lt;log.console.level\u0026gt;INFO\u0026lt;/log.console.level\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;product\u0026lt;/id\u0026gt; \u0026lt;!--生产部署环境--\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/profiles/production\u0026lt;/directory\u0026gt; \u0026lt;!--引入properties文件地址--\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;profile.env\u0026gt;product\u0026lt;/profile.env\u0026gt; \u0026lt;!--product--\u0026gt; \u0026lt;log.root.level\u0026gt;INFO\u0026lt;/log.root.level\u0026gt; \u0026lt;log.logger.level\u0026gt;DEBUG\u0026lt;/log.logger.level\u0026gt; \u0026lt;log.console.level\u0026gt;INFO\u0026lt;/log.console.level\u0026gt; \u0026lt;!--相关占位符变量配置，例如：xml中配置为${node.path},则pom进行如下配置--\u0026gt; \u0026lt;node.path\u0026gt;main.js\u0026lt;/node.path\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt;   这段配置出乎意料的是，我们可以在配置profile时，同时配置build和properties，从而来覆盖默认的配置。我为什么会觉得这项技术没有多大的意义呢，因为DevOPS中希望，一个软件制品可以通过不同的配置文件启动，从而达到不同的效果。使用上面的方式进行构建，我们的每个软件制品其实都是不一样的，所以就不可能实现通过不同的配置文件来启动同一个软件制品。\n参考资料  java引用pom中定义的变量解决方案  ","description":"","id":349,"section":"notes","tags":null,"title":"Maven的一项技术及这项技术的现实意义","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/maven%E7%9A%84%E4%B8%80%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%8F%8A%E8%BF%99%E9%A1%B9%E6%8A%80%E6%9C%AF%E7%9A%84%E7%8E%B0%E5%AE%9E%E6%84%8F%E4%B9%89/"},{"content":"配置代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-source-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;attach\u0026gt;true\u0026lt;/attach\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;compile\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   我直接将这个配置在了根目录，最近用Maven时产生了一些疑惑，有些插件的配置配在了根目录，有些配在了子模块的目录中，感觉这样有些乱糟糟的，想规范化一下这些配置（实际上我更想使用Grade）。\n20220104后续：\n后来运维反应，构建后会打两个Jar包，他们只想打一个Jar，所以我对配置进行如下调整（将compile改成了compile）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-source-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;attach\u0026gt;true\u0026lt;/attach\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;deploy\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   注意，在Idea上测试该配置的时候，一定需要先执行maven clean，否则实验结果会被干扰。\n参考资料  maven deploy的时候把源码也上传  ","description":"","id":350,"section":"notes","tags":null,"title":"Maven配置源码打包","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E9%85%8D%E7%BD%AE%E6%BA%90%E7%A0%81%E6%89%93%E5%8C%85/"},{"content":"流水线中，通过Maven构建项目之后，无法找到构建后的jar包，和同事讨论后得知，我们项目中规定了构建后的jar包的名称，所以在Maven中需要进行如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  \u0026lt;build\u0026gt; \u0026lt;finalName\u0026gt;srm\u0026lt;/finalName\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-jar-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;addDefaultImplementationEntries\u0026gt;true\u0026lt;/addDefaultImplementationEntries\u0026gt; \u0026lt;addDefaultSpecificationEntries\u0026gt;true\u0026lt;/addDefaultSpecificationEntries\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-install-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;default-install\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;install\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;install\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-deploy-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;default-deploy\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;deploy\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;deploy\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;8\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   实际上核心只需要\u0026lt;finalName\u0026gt;的配置，我将它们全部整理下来方便我下次使用。我本人并不是很喜欢通过jar包名称来适应自动化工具，jar包的名称给了我们很多很有价值的讯息。\n","description":"","id":351,"section":"notes","tags":null,"title":"Maven配置生成的jar包名称","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/maven%E9%85%8D%E7%BD%AE%E7%94%9F%E6%88%90%E7%9A%84jar%E5%8C%85%E5%90%8D%E7%A7%B0/"},{"content":"问题描述 报错如下：\n Caused by: java.lang.IllegalStateException: Method has too many Body parameters: public abstract void com.sdstc.authcenter.client.UserConfigClient.updateUserListConfig(java.lang.String,com.sdstc.authcenter.request.UpdateListConfigRequest) at feign.Util.checkState(Util.java:127) ~[feign-core-10.1.0.jar:?] at feign.Contract$BaseContract.parseAndValidateMetadata(Contract.java:117) ~[feign-core-10.1.0.jar:?] at org.springframework.cloud.openfeign.support.SpringMvcContract.parseAndValidateMetadata(SpringMvcContract.java:188) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at feign.Contract$BaseContract.parseAndValidatateMetadata(Contract.java:66) ~[feign-core-10.1.0.jar:?] at feign.ReflectiveFeign$ParseHandlersByName.apply(ReflectiveFeign.java:154) ~[feign-core-10.1.0.jar:?] at feign.ReflectiveFeign.newInstance(ReflectiveFeign.java:52) ~[feign-core-10.1.0.jar:?] at feign.Feign$Builder.target(Feign.java:251) ~[feign-core-10.1.0.jar:?] at org.springframework.cloud.openfeign.HystrixTargeter.target(HystrixTargeter.java:36) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.cloud.openfeign.FeignClientFactoryBean.getTarget(FeignClientFactoryBean.java:284) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.cloud.openfeign.FeignClientFactoryBean.getObject(FeignClientFactoryBean.java:247) ~[spring-cloud-openfeign-core-2.1.1.RELEASE.jar:2.1.1.RELEASE] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:171) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:101) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1818) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getObjectForBeanInstance(AbstractAutowireCapableBeanFactory.java:1266) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:260) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.addCandidateEntry(DefaultListableBeanFactory.java:1510) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1467) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1250) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1207) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ~[spring-beans-5.2.4.RELEASE.jar:5.2.4.RELEASE] ... 19 more Feign客户端代码：\n // Version 1 @PostMapping(\u0026quot;/updateUserListConfig\u0026quot;) void updateUserListConfig( @RequestAttribute(APICons.REQUEST_USER_ID) @NotEmpty String userId, @RequestBody @Validated UpdateListConfigRequest request); // Version 2 @PostMapping(\u0026quot;/updateUserListConfig\u0026quot;) void updateUserListConfig( String userId, @RequestBody @Validated UpdateListConfigRequest request); 以上两种写法都不可以，会导致Feign消费端报错。\n解决方案 如下写法不会报错：\n1 2 3 4 5 6  @PostMapping(\u0026#34;/updateUserListConfig\u0026#34;) void updateUserListConfig( @RequestParam(\u0026#34;tmp\u0026#34;) String userId, @RequestBody @Validated UpdateListConfigRequest request);   截止目前，已经从技术上解决这个报错的问题了。接下来我谈一谈我在项目中如何修复该问题，及我的思考。\n我们之所以在项目中使用@RequestAttribute是因为通过网关进入到服务内部时，网关会根据Token取得用户的一些信息，并塞到请求里的Header中，然后请求到下一个服务。我们的Controller通过@RequestAttribute获得的属性可以快速进行逻辑处理。理论上，服务会将这个Header信息存储起来，在下一跳请求中，塞上这个Header（具体的技术细节可以参考如何塞traceId）。下一个服务于是就可以同样使用该Header信息，并使用@RequestAttribute注解。\n我们的问题在于，我们将这样的一份Controller复制成了Client，只删除了方法体，而没有删除@RequestAttribute。最后导致了Feign服务端导入失败。从技术上讲，复制的时候删除所有@RequestAttribute参数，这个问题也不会出现了。\n我最后怎么改，我将其全部改为了@RequestParam，因为我得到消息说，我们内部服务之间的请求可能不包含Header信息，而且，我们有些接口可能是从MQ消费者请求的，这些MQ消费者是没有任何Token信息的，它们发出的请求也就没有Header了。\n很糟糕的开发体验哦，一种非常好的框架，结果不能发挥出其强大的作用。如何避免这个问题呢？我觉得区分内部接口和外部接口可能会有点作用（需要在路径、Client命名上进行区分），所有可能被网关直接、间接访问到的接口都是外部接口，外部接口是一定可以使用@RequestAttribute属性的；除此之外的接口都是内部接口，内部接口主要服务于MQ等。\n这可能会带来一些冗余，一份相同功能的接口将会存在两个版本，其区别仅仅是Controller接受参数的方式不同。我这边能给到的建议只是：Controller层只做参数的简单处理，Service层做真正的逻辑，这样Service层的复用性增加，可以稍微减少冗余带来的不爽快的体验。（实际开发中，肯定是假设所有的接口都是外部接口，等到MQ有需求后，再去开发一个内部接口，开发内部接口时，如果有Service有机会复用，这个时候重构下代码就好了）\n这里面可能还存在一个问题：可能有一部分外部接口需要调到内部接口，这种事情应该绝对不可以发生，这个需要从规则层面限制。还有一个问题：可能一个接口会被网关调用的接口间接调用，但是他实际上不应该暴露给网关，我们该处理这个问题（这是一个非常常见的需求），如何处理这个问题？我对这个问题的提出的解决方法是，每个controller中的方法都写完整的路径名（不要使用类上的@RequestMapping来提升一丁点的复用性），通过在路径名最前方上加internel。然后在网关上配置，确保internel不会暴露给外部。 （这个地方应该设计以下关键字，使用internel关键字可能会让人疑惑）\n项目管理方面，服务提供方，大概需要一个服务于外部接口的Feign客户端，加一个服务于内部接口的Feign客户端。\n服务部署时，我们也可以将提供外部接口的服务和提供内部接口的服务分开部署，尽管它们是同一套代码。\n这件事没想到还有后续：在后续对项目的研究中，我发现我们的确是存在两种Controller，一种服务于外部，没有找到相关的Feign Client；一种是服务于内部，其Controller以I打头，会存在相关的Feign Client，服务于内部的的Controller的方法的返回值，没有使用ResponseVo包装，其方法没有使用@RequestAttribute注解标注。这样的设计，可能最终会降低服务于外部的接口的复用性，且最后导致接口管理混乱。\n小结 综上，接口存在以下几种：\n 被网关直接调用的接口 被网关间接调用的接口，其本身也可能被网关直接调用 被网关间接调用的接口，其本身不应该被网关调用 服务于MQ消费者的接口  对上述内容总结如下：\n 从网关进入的请求，请求的接口，及这些接口请求到的内部服务的接口都视为外部接口，其他的接口视为内部接口 网关的一个请求将会形成请求树，这个树上的每个节点都需要是外部接口 外部接口可以使用@RequestAttribute注解，返回值需要用RequestVo包装 服务提供方提供两份Feign客户端代码用于调用服务于外部的接口，一份用于调用服务于内部的接口。 部署服务提供方时需要部署两份，一份为外部接口提供服务，一份为内部接口提供服务  我将会持续关注这部分，收集相关的需求，并完善这部分的文档。\n","description":"","id":352,"section":"notes","tags":null,"title":"Method has too many Body parameters","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/method-has-too-many-body-parameters/"},{"content":"问题描述 PG库中的字段类型为varchar，实体中字段类型为String，PO的简化后结构如下：\n1 2 3 4 5 6 7 8 9 10  @Data @Builder @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_field\u0026#34;, autoResultMap = true) class FieldVo extends BaseVo { private String id; private Integer dataType }   通过MyBatis-Plus的BaseMapper中的selectOne方法查询实体的时候报了如下错误：\n 2021-04-19 11:44:45.580 INFO StartupInfoLogger.java:61- [b3=,TraceId=,SpanId=,ParentSpanId=,Export=,Sampled=,Flags=] [Org=,User=] Started StartDyfProviderTest in 12.897 seconds (JVM running for 14.333) Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@69aeeb5] was not registered for synchronization because synchronization is not active JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7058c450] will not be managed by Spring ==\u0026gt; Preparing: SELECT id,org_id,domain_id,field_code,field_name,lang_code,field_type,data_type,default_value,note,group_id,expression,display_type,fill_note,example,unit,default_json_schema,is_required,is_delete,gmt_modify_time,gmt_create_time,modifier,creator FROM t_dyf_field WHERE is_delete=0 AND (id = ? AND org_id = ?) ==\u0026gt; Parameters: 17393408226095104(String), 100(String) \u0026lt;== Columns: id, org_id, domain_id, field_code, field_name, lang_code, field_type, data_type, default_value, note, group_id, expression, display_type, fill_note, example, unit, default_json_schema, is_required, is_delete, gmt_modify_time, gmt_create_time, modifier, creator \u0026lt;== Row: 17393408226095104, 100, 测试数据72, 测试数据71, 字段名, 测试数据52, 74920, 2659, 测试数据3, 测试数据36, 测试数据52, 测试数据27, 测试数据32, 测试数据18, 测试数据44, 测试数据5, {}, 46501, 0, 2021-04-19 11:00:54.086+08, 2021-04-19 11:00:54.086+08, 100, 100 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@69aeeb5] 2021-04-19 11:44:48.480 ERROR CloudControllerExceptionHandler.java:79- [b3=,TraceId=8ba0bed669734552,SpanId=8ba0bed669734552,ParentSpanId=,Export=true,Sampled=,Flags=] [Org=,User=] 运行时异常 org.springframework.dao.DataIntegrityViolationException: Error attempting to get column 'lang_code' from result set. Cause: org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 ; 不良的类型值 int : 测试数据52; nested exception is org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) ~[spring-jdbc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:88) ~[mybatis-spring-2.0.5.jar:2.0.5] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.sun.proxy.$Proxy151.selectOne(Unknown Source) ~[?:?] at org.mybatis.spring.SqlSessionTemplate.selectOne(SqlSessionTemplate.java:159) ~[mybatis-spring-2.0.5.jar:2.0.5] at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:90) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy$PlainMethodInvoker.invoke(MybatisMapperProxy.java:148) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:89) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.sun.proxy.$Proxy155.selectOne(Unknown Source) ~[?:?] at com.baomidou.mybatisplus.extension.service.impl.ServiceImpl.getOne(ServiceImpl.java:201) ~[mybatis-plus-extension-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.extension.service.IService.getOne(IService.java:229) ~[mybatis-plus-extension-3.4.2.jar:3.4.2] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl.selectField(FieldServiceImpl.java:83) ~[classes/:?] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl$$FastClassBySpringCGLIB$$ed8fc6c7.invoke(\u0026lt;generated\u0026gt;) ~[classes/:?] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) ~[spring-core-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687) ~[spring-aop-5.2.12.RELEASE.jar:5.2.12.RELEASE] at com.sdstc.dyf.admin.core.service.impl.FieldServiceImpl$$EnhancerBySpringCGLIB$$2162c38d.selectField(\u0026lt;generated\u0026gt;) ~[classes/:?] at com.sdstc.dyf.admin.core.controller.DyfController.getField(DyfController.java:53) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:626) ~[tomcat-embed-core-9.0.41.jar:4.0.FR] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.12.RELEASE.jar:5.2.12.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:733) ~[tomcat-embed-core-9.0.41.jar:4.0.FR] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at brave.servlet.TracingFilter.doFilter(TracingFilter.java:68) ~[brave-instrumentation-servlet-5.12.7.jar:?] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at com.sdstc.scdp.log.filter.GlobalLogFilter.doFilterInternal(GlobalLogFilter.java:60) ~[scdp-log-1.0.2-20210417.042821-8.jar:?] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at brave.servlet.TracingFilter.doFilter(TracingFilter.java:87) ~[brave-instrumentation-servlet-5.12.7.jar:?] at org.springframework.cloud.sleuth.instrument.web.LazyTracingFilter.doFilter(TraceWebServletAutoConfiguration.java:139) ~[spring-cloud-sleuth-core-2.2.6.RELEASE.jar:2.2.6.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93) ~[spring-boot-actuator-2.3.8.RELEASE.jar:2.3.8.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:374) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:888) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1597) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_281] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_281] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.41.jar:9.0.41] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281] Caused by: org.postgresql.util.PSQLException: 不良的类型值 int : 测试数据52 at org.postgresql.jdbc.PgResultSet.toInt(PgResultSet.java:3014) ~[postgresql-42.2.18.jar:42.2.18] at org.postgresql.jdbc.PgResultSet.getInt(PgResultSet.java:2188) ~[postgresql-42.2.18.jar:42.2.18] at org.postgresql.jdbc.PgResultSet.getInt(PgResultSet.java:2626) ~[postgresql-42.2.18.jar:42.2.18] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1173) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterAdapter.resultSet_getInt(FilterAdapter.java:1645) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1169) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterAdapter.resultSet_getInt(FilterAdapter.java:1645) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.filter.FilterChainImpl.resultSet_getInt(FilterChainImpl.java:1169) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.proxy.jdbc.ResultSetProxyImpl.getInt(ResultSetProxyImpl.java:492) ~[druid-1.2.4.jar:1.2.4] at com.alibaba.druid.pool.DruidPooledResultSet.getInt(DruidPooledResultSet.java:292) ~[druid-1.2.4.jar:1.2.4] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.apache.ibatis.logging.jdbc.ResultSetLogger.invoke(ResultSetLogger.java:69) ~[mybatis-3.5.6.jar:3.5.6] at com.sun.proxy.$Proxy184.getInt(Unknown Source) ~[?:?] at org.apache.ibatis.type.IntegerTypeHandler.getNullableResult(IntegerTypeHandler.java:37) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.type.IntegerTypeHandler.getNullableResult(IntegerTypeHandler.java:26) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.type.BaseTypeHandler.getResult(BaseTypeHandler.java:85) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createUsingConstructor(DefaultResultSetHandler.java:710) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createByConstructorSignature(DefaultResultSetHandler.java:693) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:657) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.createResultObject(DefaultResultSetHandler.java:630) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.getRowValue(DefaultResultSetHandler.java:397) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValuesForSimpleResultMap(DefaultResultSetHandler.java:354) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleRowValues(DefaultResultSetHandler.java:328) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSet(DefaultResultSetHandler.java:301) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.resultset.DefaultResultSetHandler.handleResultSets(DefaultResultSetHandler.java:194) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:65) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) ~[mybatis-3.5.6.jar:3.5.6] at com.baomidou.mybatisplus.core.executor.MybatisSimpleExecutor.doQuery(MybatisSimpleExecutor.java:69) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:325) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) ~[mybatis-3.5.6.jar:3.5.6] at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:165) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at com.baomidou.mybatisplus.core.executor.MybatisCachingExecutor.query(MybatisCachingExecutor.java:92) ~[mybatis-plus-core-3.4.2.jar:3.4.2] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:147) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:140) ~[mybatis-3.5.6.jar:3.5.6] at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:76) ~[mybatis-3.5.6.jar:3.5.6] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:426) ~[mybatis-spring-2.0.5.jar:2.0.5] ... 75 more 定位问题时发现如下现象（按照发现顺序）：\n 注释FieldVo中所有的字段，selectOne可以正常执行 注释FieldVo中的Integer字段，selectOne可以正常执行 注释FieldVo不继承BaseVO代码，selectOne可以正常执行  现象到这块就已经有点离奇了，后来一个同事发现，注释掉@Builder，其他部分保持不变，该代码也可以正常执行。开始意识到可能是Lombok与PG库驱动存在或者MyBatis-Plus存在某些冲突，果断按照这些关键字查找，寻找到如下资料：\nMybatisPlus 3.X 与lombok @Builder 冲突 解决方案\n我按照该文档修复了该问题，但是这个现象我是无法理解的，查看添加@Builder和不添加@Builder后生成的代码，发现区别仅仅是，当加了@Builder、@NoArgsConstructor、@AllArgsConstructor后会生成公共的无参数构造函数、全参的构造函数、和Builder类；如果只加了@Builder，会生成一个默认访问权限的全参构造函数、和Builder类，信息截止到目前，还是没有办法解释这个现象的。\n我只能暂时记录下这个现象，未来有机会去解决。\n","description":"","id":353,"section":"notes","tags":null,"title":"MyBatis 3.0 与 Lombok中的@Builder","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-3.0-%E4%B8%8E-lombok%E4%B8%AD%E7%9A%84builder/"},{"content":"这个报错非常的迷惑人，让人感觉是自己的sql查出来了多条记录，但是代码中将多条数据塞到了一个对象中，实际上并不是这样的，MyBatis拼出来的SQL最终检查出来的也是一条记录。\n这个问题最终是因为Entity上加了@Builder后，缺少默认构造函数导致的，我已经第二次踩这个坑了。\n参考资料  mybatis-plus java.lang.IndexOutOfBoundsException: Index: 23, Size: 23  ","description":"","id":354,"section":"notes","tags":null,"title":"mybatis-plus java.lang.IndexOutOfBoundsException","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-plus-java.lang.indexoutofboundsexception/"},{"content":"这是我自己开发的工具，从entity到typeHandler、到枚举代码如下：\n1 2 3 4 5 6 7 8  /** * 是否是模型必须 */ @TableField(typeHandler = IsModelRequiredTypeHandler.class) private IsModelRequired modelRequired; private Integer isModelRequired;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public class IsModelRequiredTypeHandler extends AbstractEnumTypeHandler\u0026lt;IsModelRequired\u0026gt; { @Override protected IsModelRequired parseValue(String inputParam) { return IsModelRequired.convert(inputParam); } @Override protected String toValue(IsModelRequired isModelRequired) { return isModelRequired.getValue(); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  /** * 是否是模型必须 */ @AllArgsConstructor(access = AccessLevel.PROTECTED) public enum IsModelRequired { /** * 否 */ NOT_MODEL_REQUIRED(\u0026#34;0\u0026#34;), /** * 是 */ MODEL_REQUIRED(\u0026#34;1\u0026#34;), ; @Getter private String value; public static IsModelRequired convert(String inputValue) { for (IsModelRequired enumItem : IsModelRequired.values()) { if (enumItem.getValue().equals(inputValue)) { return enumItem; } } throw new RuntimeException(\u0026#34;Enum Transfer Wrong.\u0026#34;); } }   参考资料  如何在MyBatis中优雅的使用枚举  ","description":"","id":355,"section":"notes","tags":null,"title":"MyBatis-Plus处理枚举的转换","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-plus%E5%A4%84%E7%90%86%E6%9E%9A%E4%B8%BE%E7%9A%84%E8%BD%AC%E6%8D%A2/"},{"content":"核心就在于使用select方法，参考代码如下：\n1 2 3 4 5 6  LambdaQueryWrapper\u0026lt;AuthFun\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;AuthFun\u0026gt;() .eq(AuthFun::getTreeCode, TreeCode.SERVICE_PACKAGE.getValue()) .in(AuthFun::getParentId, authFuncParentIds) .select(AuthFun::getId, AuthFun::getOperaList);   使用这个方法精准的限制被搜索到的字段是非常的有意义的，可以避免浪费太多的网络资源、减少对数据库的压力。\n参考资料  使用Mybatis-plus，查询表中某个字段的值，返回List集合_cc920095705的博客-程序员宅基地_mybatisplus查询指定字段  ","description":"","id":356,"section":"notes","tags":null,"title":"MyBatis-Plus拼SQL时不要拼全部的字段","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-plus%E6%8B%BCsql%E6%97%B6%E4%B8%8D%E8%A6%81%E6%8B%BC%E5%85%A8%E9%83%A8%E7%9A%84%E5%AD%97%E6%AE%B5/"},{"content":"这个问题我暂时只能描述一下，因为这个问题发生的时候，我询问了同事，结果这是我们架构中已知的问题，所以很快就解决了，我并没有查找任何资料，也没有做任何分析。\n该问题大致是这样的，我在开发时使用了MyBatis-Plus中从BaseMapper中继承而来的方法selectById（其他方法也有这个问题），该方法在本地运行的时候非常的正常，能够正确的检查出我想要的数据。但是，当把项目部署到dev环境的时候，该方法会报no statement的错误（具体错误细节我忘记了，大概是这个意思）。\n同事告诉我，dev环境的配置文件需要进行如下配置：\n mybatis-plus: global-config: super-mapper-class: com.baomidou.mybatisplus.core.mapper.BaseMapper 就是将BaseMapper指向我们自己实现的一个BaseMapper。我大概知道是怎么回事了，dev环境默认执行的BaseMapper的实现中并没有该方法的实现，所以在运行的时候会报no statement错误。\n","description":"","id":357,"section":"notes","tags":null,"title":"MyBatis-plus指定BaseMapper实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-plus%E6%8C%87%E5%AE%9Abasemapper%E5%AE%9E%E7%8E%B0/"},{"content":"最近的工作又是在跟TypeHandler较劲，同样的错误我已经在两个场景中发现了，这次的场景是我修改了typeHandlerPackage配置，我想测一下我自己的typeHandler是否能实现我想要的效果，结构就出现了这个问题。\n事后我分析，可能两次问题都是同一个原因：我在我自己的TypeHandler中的Mapped中配置了Object.class。\n","description":"","id":358,"section":"notes","tags":null,"title":"MyBatis-Plus生成的SQL中包含双引号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis-plus%E7%94%9F%E6%88%90%E7%9A%84sql%E4%B8%AD%E5%8C%85%E5%90%AB%E5%8F%8C%E5%BC%95%E5%8F%B7/"},{"content":"这个问题是我同事遇到的，这个问题大概是说，当一个字段注解了@TypeHandler后，在使用LambdaQueryWrapper时，你传递的参数不会给TypeHandler中指定的类转换，从而导致数据库报出异常。\n我比较关注这个问题，是因为我最近也在大量的使用TypeHandler，我怕我自己也掉进去了。\n参考资料  在字段上设置typeHandler，使用LambdaQueryWrapper查询时没有生效  ","description":"","id":359,"section":"notes","tags":null,"title":"MyBatisPlus中使用TypeHandler时的一个坑","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatisplus%E4%B8%AD%E4%BD%BF%E7%94%A8typehandler%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9  @Mapper public interface CommonMaterialMapper extends BaseMapper\u0026lt;CommonMaterial\u0026gt; { @Select(\u0026#34;\u0026lt;script\u0026gt;select * from t_common_material where id in \u0026lt;foreach collection=\u0026#39;ids\u0026#39; item=\u0026#39;id\u0026#39; open=\u0026#39;(\u0026#39; separator=\u0026#39;,\u0026#39; close=\u0026#39;)\u0026#39;\u0026gt; #{id} \u0026lt;/foreach\u0026gt;\u0026lt;/script\u0026gt;\u0026#34;) List\u0026lt;CommonMaterial\u0026gt; selectListWithDelete(@Param(\u0026#34;ids\u0026#34;) List\u0026lt;String\u0026gt; ids); }   参考资料  Mybatis @Select注解，使用in传入ids数组作为参数  ","description":"","id":360,"section":"notes","tags":null,"title":"MyBatis使用foreach","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis%E4%BD%BF%E7%94%A8foreach/"},{"content":"diamante如下：\n1 2 3 4 5 6 7 8 9 10 11 12  LambdaUpdateWrapper\u0026lt;ColorScheme\u0026gt; updateWrapperForColorScheme = new LambdaUpdateWrapper\u0026lt;ColorScheme\u0026gt;() .eq(ColorScheme::getId, colorScheme.getId()) .set(ColorScheme::getCode, colorScheme.getCode()) .set(ColorScheme::getProgress, colorScheme.getProgress()) .set(ColorScheme::getName, colorScheme.getName()) .set(ColorScheme::getStartTime, colorScheme.getStartTime()) .set(ColorScheme::getEndTime, colorScheme.getEndTime()) .set(ColorScheme::getExecutor, JSON.toJSON(colorScheme.getExecutor())); colorSchemeMapper.update(null, updateWrapperForColorScheme);   参考资料  【Mybatis-Plus】使用updateById()、update()将字段更新为null Mybatis plus 更新方法  ","description":"","id":361,"section":"notes","tags":null,"title":"MyBatis将Null更新进字段","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis%E5%B0%86null%E6%9B%B4%E6%96%B0%E8%BF%9B%E5%AD%97%E6%AE%B5/"},{"content":"我目前比较中意的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 查询思路：table.id = fieldId and (table.orgId = orgId or table.orgId = 超管orgId)  LambdaQueryWrapper\u0026lt;FieldPo\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;FieldPo\u0026gt;() .eq(FieldPo::getId, fieldId) .and(queryWrapperInner -\u0026gt; queryWrapperInner .eq(FieldPo::getOrgId, orgId) .or() .eq(FieldPo::getOrgId, SystemAdmin.ORG_ID.getOrgId())); FieldPo fieldPo = fieldDao.selectOne(queryWrapper); if (fieldPo == null) { throw new ApiException( ExceptionCode.FIELD_NOT_FOUND.getCode(), ExceptionCode.FIELD_NOT_FOUND.getMsg()); } return fieldPo;   参考资料  Mybatis Plus中的lambdaQueryWrapper条件构造图介绍  ","description":"","id":362,"section":"notes","tags":null,"title":"MyBatis条件构造器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis%E6%9D%A1%E4%BB%B6%E6%9E%84%E9%80%A0%E5%99%A8/"},{"content":"今天想小小满足一下前端的一个超大JSON的需求，结果发现MyBatis限制了分页查询时最大查询条数为500条，即使传入limit为10000也不行。\n解决方法是将limit改为-1。\n参考资料  mybatisplus解决分页最多500条数据  ","description":"","id":363,"section":"notes","tags":null,"title":"MyBatis框架限制Page查询最大只能查500条","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis%E6%A1%86%E6%9E%B6%E9%99%90%E5%88%B6page%E6%9F%A5%E8%AF%A2%E6%9C%80%E5%A4%A7%E5%8F%AA%E8%83%BD%E6%9F%A5500%E6%9D%A1/"},{"content":"在application.yml配置中增加如下配置：\n1 2 3 4 5  mybatis-plus:configuration:log-impl:org.apache.ibatis.logging.stdout.StdOutImpl  参考资料  mybatisPlus配置控制台打印sql语句  ","description":"","id":364,"section":"notes","tags":null,"title":"MyBatis配置打印日志信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/mybatis%E9%85%8D%E7%BD%AE%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E4%BF%A1%E6%81%AF/"},{"content":"不知道算不算一个Bug，我通过Navicat Premium 12创建的表，无法在Navicat Premium 12中查看。\n该问题目前仅针对PG数据库。\n参考资料  Navicat Premium 下看不到PostgreSQL下已创建的表（已解决！！）  ","description":"","id":365,"section":"notes","tags":null,"title":"Navicat Premium 12看不到PostgreSQL创建的表","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/navicat/navicat-premium-12%E7%9C%8B%E4%B8%8D%E5%88%B0postgresql%E5%88%9B%E5%BB%BA%E7%9A%84%E8%A1%A8/"},{"content":"PooledByteBufAllocator是netty分配池化内存的操作入口。\n","description":"","id":366,"section":"notes","tags":null,"title":"Netty分配池化的堆外内存的细节","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty%E5%88%86%E9%85%8D%E6%B1%A0%E5%8C%96%E7%9A%84%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E7%9A%84%E7%BB%86%E8%8A%82/"},{"content":"   ","description":"","id":367,"section":"notes","tags":null,"title":"Netty服务端启动过程分析","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/netty%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90/"},{"content":"我目前正处于Netty的学习过程中，所学的知识并没有覆盖到我接下来要进行的实验，但是为了更好的理解pipeline，我设计了如下的实验：\n 准备5个ChannelInBoundHandler，依次输出inBound 1~5 准备5个ChannelOutBoundHandler，依次输出outBound 1~5 发送一条消息，看是否是按照设计先输出inBound 1~5，然后再输出outBound 1~5  实验过程设计 我准备了如下的InboundHandler（1~4是一致的，我就不呈现了）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class Inbound1 extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(this.getClass().getSimpleName()); ctx.fireChannelRead(msg); } } public class Inbound5 extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(this.getClass().getSimpleName()); ctx.writeAndFlush(msg); } }   我准备了如下的OutboundHandler（1~5是一致的，我就不呈现了）：\n1 2 3 4 5 6 7 8 9 10 11  public class Outbound1 extends ChannelOutboundHandlerAdapter { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(this.getClass().getSimpleName()); ctx.write(msg); } }   然后开发Bootstrap类，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop  try { ServerBootstrap serverBootstrap = new ServerBootstrap() .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline() .addLast(new Outbound1()) .addLast(new Outbound2()) .addLast(new Outbound3()) .addLast(new Outbound4()) .addLast(new Outbound5()) .addLast(new Inbound1()) .addLast(new Inbound2()) .addLast(new Inbound3()) .addLast(new Inbound4()) .addLast(new Inbound5()); } }); System.out.println(\u0026#34;Server Ready.\u0026#34;); ChannelFuture channelFuture = serverBootstrap.bind(Constant.PORT).sync(); channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }   启动服务端后，使用telnet工具进行链接并发送消息，服务端有如下输出：\n实验中遇到的问题 一开始的时候，我进行Handler编排的时候按如下代码编排：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ServerBootstrap serverBootstrap = new ServerBootstrap() .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline() .addLast(new Inbound1()) .addLast(new Inbound2()) .addLast(new Inbound3()) .addLast(new Inbound4()) .addLast(new Inbound5()) .addLast(new Outbound1()) .addLast(new Outbound2()) .addLast(new Outbound3()) .addLast(new Outbound4()) .addLast(new Outbound5()); } });   可以看到，我将inbound写在了前头将outbound写在了后头，最终导致了Outbound中没有任何输出。\n","description":"","id":368,"section":"notes","tags":null,"title":"Netty理解pipeline实验设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/netty%E7%90%86%E8%A7%A3pipeline%E5%AE%9E%E9%AA%8C%E8%AE%BE%E8%AE%A1/"},{"content":"Netty对NIO进行的封装   设计优雅：适用于各种传输类型的统一（API阻塞和非阻塞Socket）；基于灵活可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型（单线程，一个或多个线程池）\n  适用方便：详细记录的Javadoc，用户指南和示例，没有其他依赖项\n  高性能、吞吐量更高：延迟更低，减少资源消耗，最小化不必要的内存复制\n  安全：完整的SSL/TLS和StartTLS支持\n  不同的线程模型   不同的线程模型，对程序的性能有很大的影响，目前存在的线程模型有：传统的阻塞IO服务模型、Reactor模式。\n  根据Reactor的数量和处理资源线程池的数量不同，有3种典型的实现：\n 单Reactor单线程 单Reactor多线程 主从Reactor多线程    Netty线程模型（Netty主要基于主从Reactor多线程模型做了一定的改进，其中主从Reactor多线程模型有多个Reactor）\n  理解Reactor 在传统的IO阻塞编程模型中，增加线程池，就构成了Reactor模式的基本设计思想。可以用如下的方式理解Reactor：\n  Reactor模式是通过一个或多个输入同时传递给服务处理器的模式（基于事件驱动）\n  服务器端程序处理传入的多个请求，并将它们分派到相应的处理线程，因此Reactor模式也叫Dispatcher模式\n  Reactor模式使用IO复用监听\n  Reactor模式中核心组成：\n  Reactor：Reactor在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理器程序来对IO事件作出反应。\n  Handlers：处理程序执行IO事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor通过调度适当的处理程序来响应IO事件，处理程序执行非阻塞操作。\n  理解主从Reactor多线程：\n  Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件\n  当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor\n  SubReactor将连接加入到连接队列进行监听并创建handler进行各种事件处理\n  当有新事件发生时，SubReactor就会调用对应的handler处理\n  handler通过Read取数据，分发给后面的worker线程处理\n  worker线程池分配独立的worker线程进行业务处理，并返回结果\n  handler收到响应的结果后，再通过send将结果返回给client\n  Reactor主线程可以多赢多个Reactor子线程，即MainReactor可以关联多个SubReactor\n  理解Netty中的BoosGroup和WorkerGroup   Netty抽象出两组线程池：BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络的读写\n  BossGroup和WorkerGroup类型都是NioEventLoopGroup\n  NioEventLoopGroup相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是NioEventLoop\n  NioEventLoop表示一个不断循环的执行处理任务的线程，每个NioEventLoop都有一个selector，用于监听绑定在其上的socket的网络通讯\n  NioEventLoopGroup可以有多个线程，即可以含有多个NioEventLoop\n  每个Boss NioEventLoop执行的步骤有3步\n  轮询accept事件\n  处理accept事件，与client建立连接，生成NioScocketChannel，并将其注册到某个worker NIOEventLoop上的selector中\n  处理任务队列的任务，即runAllTasks\n    每个Worker NIOEventLoop循环执行的步骤\n  轮询read、write事件\n  处理IO事件，即read、write事件，在对应NioSocketChannel处理\n  处理任务队列的任务，即runAllTasks\n    每个Worker NIOEventLoog处理业务时，会使用pipeline（管道），pipeline中包含了channel，即通过pipeline可以获取到对应的通道。\n  BoosGroup和WorkerGroup干什么的\n  BossGroup程维护Selector，只关注Accecpt当接收到Accept事件，获取到对应的SocketChannel，封装成NIOScoketChannel并注册到Worker线程（事件循环），并进行维护\n  当Worker线程监听到selector中通道发生自己感兴趣的事件后，就进行处理（就由handler），注意handler已经加入到通道\n  异步模型   Netty中的IO操作是异步的，包括Bind、Write、Connect等操作会简单的返回一个ChannelFuture。\n  调用者并不能立刻获得结果，而是通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获得IO操作结果。\n  Netty的异步模型是建立在future和callback的之上的，callback就是回调。重点说Future，它的核心思想是：假设一个方法fun，计算过程可能非常耗时，等待fun返回显然不合适。那么可以在调用fun的时候，立马返回一个Future，后续可以通过Future去监控方法fun的处理过程（即：Future-Listener机制）\n  Netty与异步模型：\n  在使用Netty进行编程时，拦截操作和转换出入站数据只需要提供callback或利用future即可。这使得链式操作简单、高效，并且有利于编写可重用的、通用的代码。\n  Netty框架的目标就是让业务逻辑从网络基础应用编码中分离处理，解脱出来。\n  TaskQueue 任务队列中的Task有3种典型的使用场景（这部分我不是很理解）：\n 用户程序自定义的普通任务 用户自定义定时任务 非当前Reactor线程调用Channel的各种方法  例如在推送系统的业务线程里面，根据用户的标识，找到对应的Channel应用，然后调用Write类方法想该用户推送消息，就会进入到这种场景。最终的Write会提交到任务队列中被异步消费。\nFuture-Listener机制   当Future对象刚刚创建时，处于非完成状态，调用者可以通过返回ChannelFuture来获取操作执行的状态，注册监听函数来执行完成后的操作。\n  常见的操作如下：\n    通过isDone方法来判断当前操作是否完成\n  通过isSuccess方法来判断已经完成的操作是否成功\n  通过getCause方法来获取已经完成的当前操作失败的原因\n  通过isCancelled方法来判断已完成的当前操作是否被取消\n  通过addlistener方法来注册监听器，当操作已完成（isDone方法返回完成），将会通知指定的监听器；如果Future对象已完成，则通知指定的监听器\n  Bootstrap和ServerBootstrap   Bootstrap的意思是引导，一个Netty应用通常由一个Bootstrap开始，主要作用是配置整个Netty程序，串联各个组件，Netty中的Bootstrap类是客户端程序的引导类，ServerBootstrap是服务端启动引导类。\n  常用的方法有：\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  // 设置EventLoop public B group(EventLoopGroup group); public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup); // 设置一个服务端的通道实现 public B channel(Class\u0026lt;? extends C\u0026gt; channelClass); // 用来给ServerChannel添加配置 public \u0026lt;T\u0026gt; B option(ChannelOption\u0026lt;T\u0026gt; option, T value); // 用来给接受到的通道添加配置 public \u0026lt;T\u0026gt; ServerBootstrap childOption(ChannelOption\u0026lt;T\u0026gt; childOption, T value); // 用来设置业务处理器类 public ServerBootstrap childHandler(ChannelHandler childHandler); // 用来设置绑定的端口 public ChannelFuture bind(int inetPort); // 用来链接服务器 public ChannelFuture connect(String inetHost, int inetPort);   Future和ChannelFuture  常用方法有：  1 2 3 4 5 6 7  // 返回当前正在进行IO操作的通道 Channel channel(); // 等待异步操作执行完毕 ChannelFuture sync();   Channel   Netty网络通信的组件，能够用于执行网络IO操作。\n  通过Channel可获得当前网络连接的通道的状态\n  通过Channel可获得网络连接的配置参数（例如接收缓冲区大小）\n  Channel提供异步的网络IO操作（如建立连接，读写，绑定端口），异步调用意味着任何IO调用都将立即返回，并且不保证在调用结束时所请求的IO操作已完成\n  调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上，可以IO操作成功、失败或取消时回调通知调用方\n  支持关联IO操作与对应的处理程序\n  不同的协议、不同的阻塞类型的链接都有不同的Channel类型与之对应，常用的Channel类型有：\n NioSocketChannel，异步的客户端TCP Socket连接 NioServerSocketChannel，异步的服务TCP Socket连接 NioDatagramChannel，异步的UDP连接 NioSctpChannel，异步的客户端Sctp连接 NioSctpServerChannel，异步的Sctp服务器端连接，这些通道涵盖了UDP和TCP网络IO以及文件IO    Selector   Netty基于Selector对象实现IO多路复用，通过Selector一个线程可以监听多个连接的Channel事件。\n  当向一个Selector中注册Channel后，Selector内部的机制就可以自动不断地查询这些注册的Channel是否有已就绪的IO事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个Channel\n  ChannelHandler及其实现类   ChannelHandler是一个接口，处理IO事件或拦截IO操作，并将其转发到其ChannelPipeline（业务处理链）中的下一个处理程序（我似乎目前没有看到转发的操作）。\n  ChannelHandler本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类\n  实现类一览：\n ChannelInboundHandler： ChannelOutboundHandler： ChannelInBoundHandlerAdapter： ChannelOutboundHandlerAdapter：    Netty的组件设计   Netty的主要组件有Channel、EventLoop、ChannelFuture、ChannelHandler、ChannelPipe等。\n  ChannelHandler充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现ChannellnboundHandler接口（或ChannellnboundHandlerAdapter），你就可以接收入站事件和数据，这些数据随后会被你的应用程序的业务逻辑处理。当你要给连接的客户端发送响应时，也可以从ChannellnboundHandler冲刷数据。你的业务逻辑通常写在一个或者多个ChannellnboundHandler中ChannelOutboundHandler原理一样，只不过它是用来处理出站数据的\n  ChannelPipeline提供了ChannelHandler链的容器。以客户端应用程序为例，如果事件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过pipeline中的一系列ChannelOutboundHandler，并被这些Handler处理，反之则称为入站的\n  Pipeline与ChannelPipeline  在Netty中，每个Channel都有且仅有一个ChannelPipeline与之对应，它们的组成关系如下：  一个Channel包含了一个ChannelPipeline，而ChannelPipeline中又维护了一个由ChannelHandlerContext组成的双向链表，并且每个ChannelHandlerContext中又关联着一个ChannelHandler。\n入栈事件和出站事件在一个双向链表中，入栈事件会从链表的head往后传递到最后一个入栈的handler，出站事件会从链表的tail往前专递到最前一个出站的handler，两种类型的handler互不干扰。\nChannelPipeLine的重点知识：\n ChannelPipeline实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及Channel中各个的ChannelHandler如何相互交互（我们还可以控制控制各个ChannelHandler如何交互，这是我没有想到的）  ChannelHandlerContext   保存Channel相关的所有上下文信息，同时关联一个ChannelHandler对象\n  即ChannelHandlerContext中包含一个具体的事件处理器ChannelHandler，同时ChannelHandlerContext中也绑定了对应的pipeline和Channel的信息，方便对ChannelHandler进行调用.\n  常用方法：\n  1 2 3 4 5 6 7 8 9 10  // 关闭通道 ChannelFuture close(); // 刷新 ChannelOutboundInvoker flush(); // 将数据写到ChannelPipeline中当前ChannelHandler的下一个ChannelHandler（出站）（感觉理解的不是很透彻哦） ChannelFuture writeAndFlush(Object msg);   ChannelOption   Netty在创建Channel实例后，一般都需要设置ChannelOption参数。\n  ChannelOption参数如下：\n  ChannelOption.SO_BACKLOG\n对应TCP/IP协议listen函数中的backlog参数，用来初始化服务器可连接队列大小。服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小。\n  ChannelOption.SO_KEEPALIVE\n一直保持连接活动状态\n    EventLoopGroup及其实现类NioEventLoopGroup   EventloopGroup是一组EventLoop的抽象，Netty为了更好的利用多核CPU资源，一般会有多个Eventloop同时工作，每个Eventloop维护着一个Selector实例。\n  EventLoopGroup提供next接口，可以从组里面按照一定规则获取其中一个Eventloop来处理任务。在Netty服务器端编程中，我们一般都需要提供两个EventloopGroup，如：BossEventloopGroup和WorkerEventloopGroup。\n  通常一个服务端口即一个ServerSocketChannel对应一个Selector和一个EventLoop线程。BossEventLoop负责接收客户端的连接并将SocketChannel交给WorkerEventLoopGroup来进行IO处理。\n  Unpooled类   Netty提供一个专门用来操作缓冲区（即Netty的数据容器）的工具类\n  常用方法：\n  1 2 3 4  // 通过给定的数据和字符编码返回一个ByteBuf对象 public static ByteBuf copiedBuffer(CharSequence string, Charset charset);   编码解码   Netty提供的编码器\n StringEncoder：对字符串进行编码 ObjectEncoder：对Java对象进行编码    Netty提供的解码器\n StringDecoder：对字符串进行解码 ObjectDecoder：对Java对象进行解码    Netty提供的一系列实用的编解码器，都实现了ChannelInboundHandler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。以入站为例，对于每个从入站Channel读取的消息，这个方法都会被调用。随后，它被调用由解码器多提供的decode方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannelInboundHandler。\n  ByteToMessageDecoder直接继承于ChannelInboundHandlerAdapter。ByteToMessageDecoder会对入站数据进行缓冲，知道它准备好被处理（这个工作并不是ByteToMessageDecoder做的，而是实现decode方法是做的）\n  1 2 3 4 5 6 7 8 9 10  protected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) throws Exception { if (in.readableBytes() \u0026gt;= 8) { out.add(in.readLong()); } }   无论是编码器或者解码器，接受的消息类型必须与待处理的消息类型一致，否则该handler不会被执行。  ReplayingDecoder 使用这个类我们不需要调用readableBytes，参数S指定了用户状态管理的类型，其中Void代表不需要状态管理（我该如何去理解这个状态管理？）。\nReplayingDecoder有一些局限性：\n  并不是所有的ByteBuf操作都被支持，如果调用了一个不被支持的方法，将会抛出一个UnsupportOperationException。\n  ReplayingDecoder在某些情况下可能会鳗鱼ByteToMessageDecoder，例如网络缓慢并且消息格式复杂时，消息会被拆成多个碎片，速度变慢。\n  （我感觉我不需要关注这些技术，因为我极大可能性是使用Protobuf）\n其他解码器   LineBasedFrameDecoder：这个类在Netty内部也有使用，它使用行尾控制字符（\\n或者\\r\\n）作为分隔符来解析数据。\n  DelimiterBasedFrameDecoder：使用自定义的特殊字符作为消息的分隔符。\n  HttpObjectDecoder：一个HTTP数据的解码器\n  LengthFieldBasedFrameDecoder：通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。\n  ","description":"","id":369,"section":"notes","tags":null,"title":"Netty的基础知识","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%B0%9A%E7%A1%85%E8%B0%B7netty/netty%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"content":"技术研究后发现不符合我的需求，故作废\n我内网使用NextCloud，所以安全性要求没有那么高，我计划配置成http + ip访问，目前ip访问已经找到方案了，因为不再考虑使用NextCloud技术，所以就不再研究http配置了，现在将配置成ip访问的技术整理如下。\n编辑：/var/www/nextcloud/config/config.php\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  \u0026lt;?php $CONFIG = array ( \u0026#39;passwordsalt\u0026#39; =\u0026gt; \u0026#39;85f1383c62f31c578cdb40a933c5cf85\u0026#39;, \u0026#39;secret\u0026#39; =\u0026gt; \u0026#39;e6aeed91e9c4461dbbc8157d83ca2f1807087b8880c625403c15caf3882595358d25bd2bdfa571910aecfcfe041ee064\u0026#39;, \u0026#39;trusted_domains\u0026#39; =\u0026gt; array ( 0 =\u0026gt; \u0026#39;localhost\u0026#39;, 1 =\u0026gt; \u0026#39;www.example.com\u0026#39;, # 增加的东西 2 =\u0026gt; preg_match(\u0026#39;/cli/i\u0026#39;,php_sapi_name())?\u0026#39;127.0.0.1\u0026#39;:$_SERVER[\u0026#39;SERVER_NAME\u0026#39;], ), \u0026#39;datadirectory\u0026#39; =\u0026gt; \u0026#39;/var/www/nextcloud-data\u0026#39;, \u0026#39;dbtype\u0026#39; =\u0026gt; \u0026#39;mysql\u0026#39;, \u0026#39;version\u0026#39; =\u0026gt; \u0026#39;21.0.1.1\u0026#39;, \u0026#39;overwrite.cli.url\u0026#39; =\u0026gt; \u0026#39;http://localhost\u0026#39;, \u0026#39;dbname\u0026#39; =\u0026gt; \u0026#39;nextcloud\u0026#39;, \u0026#39;dbhost\u0026#39; =\u0026gt; \u0026#39;localhost\u0026#39;, \u0026#39;dbport\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;dbtableprefix\u0026#39; =\u0026gt; \u0026#39;oc_\u0026#39;, \u0026#39;mysql.utf8mb4\u0026#39; =\u0026gt; true, \u0026#39;dbuser\u0026#39; =\u0026gt; \u0026#39;nextcloud\u0026#39;, \u0026#39;dbpassword\u0026#39; =\u0026gt; \u0026#39;f84a0375a5816eb6992e240afc957b13\u0026#39;, \u0026#39;installed\u0026#39; =\u0026gt; true, \u0026#39;memcache.local\u0026#39; =\u0026gt; \u0026#39;\\\\OC\\\\Memcache\\\\Redis\u0026#39;, \u0026#39;redis\u0026#39; =\u0026gt; array ( \u0026#39;host\u0026#39; =\u0026gt; \u0026#39;/var/run/redis/redis.sock\u0026#39;, \u0026#39;port\u0026#39; =\u0026gt; 0, \u0026#39;timeout\u0026#39; =\u0026gt; 0.0, ), \u0026#39;filelocking.enabled\u0026#39; =\u0026gt; true, \u0026#39;memcache.locking\u0026#39; =\u0026gt; \u0026#39;\\\\OC\\\\Memcache\\\\Redis\u0026#39;, \u0026#39;instanceid\u0026#39; =\u0026gt; \u0026#39;6dae39940f000\u0026#39;, );   如上，增加2 =\u0026gt; preg_match('/cli/i',php_sapi_name())?'127.0.0.1':$_SERVER['SERVER_NAME'],即可。该修改是即时生效的，不需要重新启动。\n参考资料  Nextcloud 通过不被信任的域名访问 动态IP解决方案，允许所有IP访问  ","description":"","id":370,"section":"notes","tags":null,"title":"NextCloud配置所有IP都可以方案","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E4%BD%9C%E5%BA%9F/nextcloud%E9%85%8D%E7%BD%AE%E6%89%80%E6%9C%89ip%E9%83%BD%E5%8F%AF%E4%BB%A5%E6%96%B9%E6%A1%88/"},{"content":"默认情况下，控制器会监视所有命名空间的Ingress对象。如果要更改此行为，请使用-watch-namespace或检查Helm图表值controller.scope，以将控制器限制为单个命名空间。\n","description":"","id":371,"section":"notes","tags":null,"title":"NginxIngress的Scope配置","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/nginxingress%E7%9A%84scope%E9%85%8D%E7%BD%AE/"},{"content":"今天配置好Actuator后，访问其接口时报如下错误：\n { \u0026quot;code\u0026quot;: 100101, \u0026quot;data\u0026quot;: null, \u0026quot;message\u0026quot;: \u0026quot;params invalidate: No converter for [class org.springframework.boot.actuate.beans.BeansEndpoint$ApplicationBeans] with preset Content-Type 'null'\u0026quot;, \u0026quot;success\u0026quot;: false } 我一步一步知道我们的框架层，发现如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { Iterator\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; iterator = converters.iterator(); while(iterator.hasNext()){ HttpMessageConverter\u0026lt;?\u0026gt; converter = iterator.next(); if(StringUtils.containsIgnoreCase(converter.getClass().getName(),\u0026#34;jackson2\u0026#34;)){ iterator.remove(); } } FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); //自定义fastjson配置  FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures(FastJsonUtil.serializerFeatures); fastJsonHttpMessageConverter.setFastJsonConfig(config); // 添加支持的MediaTypes;不添加时默认为*/*,也就是默认支持全部  // 但是MappingJackson2HttpMessageConverter里面支持的MediaTypes为application/json  // 参考它的做法, fastjson也只添加application/json的MediaType  List\u0026lt;MediaType\u0026gt; fastMediaTypes = new ArrayList\u0026lt;\u0026gt;(); fastMediaTypes.add(MediaType.APPLICATION_JSON_UTF8); // fastMediaTypes.add(MediaType.ALL); 这行代码为我边写  fastJsonHttpMessageConverter.setSupportedMediaTypes(fastMediaTypes); converters.add(fastJsonHttpMessageConverter); }   我发现我们的messageConverters仅支持MediaType.APPLICATION_JSON_UTF8，我尝试将其改为fastMediaTypes.add(MediaType.ALL)，发现接口能正确的返回数据。\n我简单的查看了一下源码，发现实现Actuator接口的实现并不是通过Controller，而是@EndPoint和@ReadOperation注解，我猜想可能在一个切面中会得到@ReadOperation的返回值，然后在HttpMessageConverts中寻找一个可以处理Content-Type为null的转换器进行处理，结果没有找到，结果就报错了。\n针对这个案例，我不打算做框架层面任何修改，因为我们Maven管理方面走的是OverWrite，我修改了底层框架，很大概率会影响到线上的代码，有点担心会带来不好的影响。\n参考资料  springBoot或者springCloud 的集成 Prometheus监控-数据无法解析  ","description":"","id":372,"section":"notes","tags":null,"title":"No convert for xxx with preset Content-Type 'null'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/no-convert-for-xxx-with-preset-content-type-null/"},{"content":"在CentOS上自行编译python3后，安装依赖时出现了如下问题：\n [root@base launch]# pip3 install pyinstaller Collecting pyinstaller Downloading pyinstaller-4.3.tar.gz (3.7 MB) |████████████████████████████████| 3.7 MB 1.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done ERROR: Exception: Traceback (most recent call last): File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\u0026quot;, line 228, in _main status = self.run(options, args) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\u0026quot;, line 182, in wrapper return func(self, options, args) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/commands/install.py\u0026quot;, line 323, in run requirement_set = resolver.resolve( File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 183, in resolve discovered_reqs.extend(self._resolve_one(requirement_set, req)) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 388, in _resolve_one abstract_dist = self._get_abstract_dist_for(req_to_install) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\u0026quot;, line 340, in _get_abstract_dist_for abstract_dist = self.preparer.prepare_linked_requirement(req) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\u0026quot;, line 482, in prepare_linked_requirement abstract_dist = _get_prepared_distribution( File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\u0026quot;, line 91, in _get_prepared_distribution abstract_dist.prepare_distribution_metadata(finder, build_isolation) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py\u0026quot;, line 38, in prepare_distribution_metadata self._setup_isolation(finder) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py\u0026quot;, line 96, in _setup_isolation reqs = backend.get_requires_for_build_wheel() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/wrappers.py\u0026quot;, line 160, in get_requires_for_build_wheel return self._call_hook('get_requires_for_build_wheel', { File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/wrappers.py\u0026quot;, line 265, in _call_hook raise BackendUnavailable(data.get('traceback', '')) pip._vendor.pep517.wrappers.BackendUnavailable: Traceback (most recent call last): File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/pip/_vendor/pep517/_in_process.py\u0026quot;, line 86, in _build_backend obj = import_module(mod_path) File \u0026quot;/usr/local/python3/lib/python3.8/importlib/__init__.py\u0026quot;, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 1014, in _gcd_import File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 991, in _find_and_load File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 961, in _find_and_load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 219, in _call_with_frames_removed File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 1014, in _gcd_import File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 991, in _find_and_load File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 975, in _find_and_load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 671, in _load_unlocked File \u0026quot;\u0026lt;frozen importlib._bootstrap_external\u0026gt;\u0026quot;, line 783, in exec_module File \u0026quot;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026quot;, line 219, in _call_with_frames_removed File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/__init__.py\u0026quot;, line 18, in \u0026lt;module\u0026gt; from setuptools.dist import Distribution File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/dist.py\u0026quot;, line 38, in \u0026lt;module\u0026gt; from setuptools import windows_support File \u0026quot;/tmp/pip-build-env-sme_dbro/overlay/lib/python3.8/site-packages/setuptools/windows_support.py\u0026quot;, line 2, in \u0026lt;module\u0026gt; import ctypes File \u0026quot;/usr/local/python3/lib/python3.8/ctypes/__init__.py\u0026quot;, line 7, in \u0026lt;module\u0026gt; from _ctypes import Union, Structure, Array ModuleNotFoundError: No module named '_ctypes' WARNING: You are using pip version 20.2.3; however, version 21.1.3 is available. You should consider upgrading via the '/usr/local/python3/bin/python3.8 -m pip install --upgrade pip' command. 我执行了如下指令：\n yum install libffi-devel -y make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 因为环境变量之前在第一次编译安装时我已经配置过了，所以这块不需要进行任何配置。\n参考资料  ModuleNotFoundError: No module named \u0026lsquo;_ctypes\u0026rsquo;的解决方案  ","description":"","id":373,"section":"notes","tags":null,"title":"No module named '_ctypes'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/no-module-named-_ctypes/"},{"content":"这个错误发生的非常让人哭笑不得，现象就是运行测试时如论如何都无法正确的运行，总是显示No tests were found。\n最后检查代码发现，是因为编写了如下的代码：\n我分析我当时是先注入什么对象的，结果因为其他事情给耽搁了，所以就导致写了一半，最后就发生了这个Bug。\n参考资料   JAVA——JUNIT运行错误[No tests were found]\n我解决问题的时候，这篇教程没有帮到我，当时我定位问题后，发现问题正是文章里罗列的排查项，有点意思。\n  ","description":"","id":374,"section":"notes","tags":null,"title":"No tests were found","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/no-tests-were-found/"},{"content":"我决定使用nvm技术，故作废该笔记\n问题描述  C:\\Users\\wujj\\Desktop\\ElectronProject\u0026gt;npm install electron --save (node:14808) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification. (Use `node --trace-warnings ...` to show where the warning was created) \u0026gt; core-js@3.9.1 postinstall C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\core-js \u0026gt; node -e \u0026quot;try{require('./postinstall')}catch(e){}\u0026quot; \u0026gt; electron@12.0.2 postinstall C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\electron \u0026gt; node install.js (node:27104) Warning: Setting the NODE_TLS_REJECT_UNAUTHORIZED environment variable to '0' makes TLS connections and HTTPS requests insecure by disabling certificate verification. (Use `node --trace-warnings ...` to show where the warning was created) RequestError: read ECONNRESET at ClientRequest.\u0026lt;anonymous\u0026gt; (C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\got\\source\\request-as-event-emitter.js:178:14) at Object.onceWrapper (events.js:422:26) at ClientRequest.emit (events.js:327:22) at ClientRequest.origin.emit (C:\\Users\\wujj\\Desktop\\ElectronProject\\node_modules\\@szmarczak\\http-timer\\source\\index.js:37:11) at TLSSocket.socketErrorListener (_http_client.js:469:9) at TLSSocket.emit (events.js:315:20) at emitErrorNT (internal/streams/destroy.js:106:8) at emitErrorCloseNT (internal/streams/destroy.js:74:3) at processTicksAndRejections (internal/process/task_queues.js:80:21) npm WARN bookmarker@1.0.0 No repository field. npm ERR! code ELIFECYCLE npm ERR! errno 1 npm ERR! electron@12.0.2 postinstall: `node install.js` npm ERR! Exit status 1 npm ERR! npm ERR! Failed at the electron@12.0.2 postinstall script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above. npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\wujj\\AppData\\Roaming\\npm-cache\\_logs\\2021-03-29T10_29_25_848Z-debug.log 试了很多种方法，改源、修改全局tsl，最后只有这个办法成功了，执行指令前，执行如下代码（我在Win 10系统）：\n set NODE_TLS_REJECT_UNAUTHORIZED=0 参考文档  npm install时报unable to verify the first certificate 证书无效的错误  ","description":"","id":375,"section":"notes","tags":null,"title":"Node.js install总是失败的问题（作废）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/%E4%BD%9C%E5%BA%9F/node.js-install%E6%80%BB%E6%98%AF%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%E4%BD%9C%E5%BA%9F/"},{"content":"问题描述 执行如下指令时，报如下错误：\n npm install -g yo npm WARN registry Unexpected warning for https://registry.npmjs.org/: Miscellaneous Warning UNABLE_TO_VERIFY_LEAF_SIGNATURE: request to https://registry.npmjs.org/yo failed, reason: unable to verify the first certificate npm WARN registry Using stale data from https://registry.npmjs.org/ due to a request error during revalidation. npm ERR! code UNABLE_TO_VERIFY_LEAF_SIGNATURE npm ERR! errno UNABLE_TO_VERIFY_LEAF_SIGNATURE npm ERR! request to https://registry.npmjs.org/generator-code failed, reason: unable to verify the first certificate npm ERR! A complete log of this run can be found in: npm ERR! C:\\Users\\wujj\\AppData\\Roaming\\npm-cache\\_logs\\2021-03-22T10_23_21_944Z-debug.log 解决方案  执行如下指令，关闭strict-ssl：   npm config set strict-ssl false 执行如下指令，完成安装任务：   npm install -g yo 执行如下指令，开启strict-ssl：   npm config set strict-ssl true 参考教程  npm install 出现UNABLE_TO_VERIFY_LEAF_SIGNATURE的解决办法  ","description":"","id":376,"section":"notes","tags":null,"title":"Node.js中的UNABLE_TO_VERIFY_LEAF_SIGNATURE","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/node.js%E4%B8%AD%E7%9A%84unable_to_verify_leaf_signature/"},{"content":"我在Debain上使用默认的库安装Node.js，版本过低，报npm冲突了。所以我不得不寻找其他的安装方法。\n我最终使用的指令如下：\n1 2 3 4  curl -sL https://deb.nodesource.com/setup_12.x | bash - sudo apt install nodejs   参考资料  在Debian 10系统上安装Node.js和npm的三种不同方法  ","description":"","id":377,"section":"notes","tags":null,"title":"NodeSource存储库安装Node.js和npm（作废）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/%E4%BD%9C%E5%BA%9F/nodesource%E5%AD%98%E5%82%A8%E5%BA%93%E5%AE%89%E8%A3%85node.js%E5%92%8Cnpm%E4%BD%9C%E5%BA%9F/"},{"content":"我用NuGET下载了Microsoft.NET.Test.Sdk 16.10.0，这个问题就修复了。\n","description":"","id":378,"section":"notes","tags":null,"title":"not runnable nuget package microsoft.net.test.sdk is not installed","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/rider/not-runnable-nuget-package-microsoft.net.test.sdk-is-not-installed/"},{"content":"指令如下：\n npm config set proxy=http://127.0.0.1:1080 npm config set https-proxy=http://127.0.0.1:1080 npm config set registry=http://registry.npmjs.org npm config set proxy=http://127.0.0.1:2080 npm config set https-proxy=http://127.0.0.1:2080 ","description":"","id":379,"section":"notes","tags":null,"title":"npm设置代理","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/npm%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"客户端   任意一个接口A，这个接口模拟用户没有登录（授权）的情况，将用户重定向到OAuth授权服务器，进行登录（授权）。接口A需要记录下自己传递的自身的重定向地址，这个重定向地址就是接口B（如果使用过滤器实现，则为当期请求的地址，因为是Demo性质的，所以只需要知道有这些细节就好了），因为稍后客户端通过授权码获取收取AccessToken的时候，需要再将这个重定向地址传递给OAuth2授权服务器。接口A同时需要传递state值，并记录state值。\n  任意一个接口B，这个接口用来处理授权服务器通过重定向传递的code参数。拿到code参数后，请求授权服务器的AccessToken端点，获取AccessToken时需要传递接口A中记录的重定向地址，这块就是接口B本身。接口B需要验证获取的state值是否正确。\n  任意一个接口C，在这个接口中客户端向资源服务器请求资源，请求的过程中需要带上接口B获取到的AccessToken。\n  任意一个接口D，在这个接口中模拟用户的AccessToken过期了，然后通过刷新令牌重新获取AccessToken。\n  服务端 资源服务器  在过滤器A中，需要通过Authoriztion、表单参数、查询参数完成AccessToken的验证。资源服务器和授权服务器链接的是同一个数据库，所以资源服务器可以直接从数据库中检索出授权服务器插入的AccessToken（这部分不适用于生产）  补充知识   另外，为什么在这个请求中包含redirect_uri？毕竟此处是不需要执行重定向的。根据OAuth规范，如果在授权请求中指定了重定向URI，那么令牌请求中也必须包含该重定向URI。这可以防止攻击者使用被篡改的重定向URI获取受害用户的授权码，让并无恶意的客户端将受害用户的资源访问权限关联到攻击者账户。\n  有一点我好像理解错了，客户端指导浏览器重定向到授权服务器授权页面时传递的redirectUrl是不可以随便传递的，因为授权服务器要对比该值与客户端注册时使用的redirectUrl是否一致，从而判断clientId值是否被篡改。那么问题就来了，客户端如何在完成授权后重新访问之前的页面（我觉得我对OAuth使用场景理解的还不够）。\n  OAuth规范允许在一个客户端注册信息中包含多个redirectUri值，这样就可以让客户端在不同场景下使用不同的URL提供服务，有利于功能的聚合。\n  疑惑  假设我访问客户端的A接口，这个接口是获取某个页面的接口，这个接口发现我并未登录，所以将我重定向授权页面，重定向到授权页面时传递的redirectUrl必须是我注册客户端时填写的redirectUrl，这儿我可以理解为一个客户端接受授权码的Url。授权完成后，浏览器将重定向到该redirectUrl，客户端因此接受到授权码完成接下来的一系列工作。再之后，这个接口该怎么做？我觉得应该再次重定向到之前用户访问的Url（我对OAuth研究的还不够，还需要细细的去体会这些细节）。  ","description":"","id":380,"section":"notes","tags":null,"title":"OAuth2 Demo开发整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/oauth2-demo%E5%BC%80%E5%8F%91%E6%95%B4%E7%90%86/"},{"content":"OAuth2有三个重要的Endpoint，其中授权Endpoint、Token Endpoint节点在授权服务器中，还有一个可选的重定向Endpoint在客户端中。\n 授权Endpoint：使用授权Endpoint去获取资源Owner的授权 Token Endpoint：客户端获取token 重定向Endpoint：授权服务器使用重顶线Endpoint返回授权相应给客户端（是这样的么，感觉有点奇怪）  20210915后续 经过继续对OAuth2的学习，我对这些Endpoint有稍微深入一点的理解，现整理如下：\n  OAuth2授权服务器一定要提供一个多个用于用户录入自己账号和密码的表单，为什么可能是多个，我觉得在生产环境中，我们可能会提供许多不同样式的页面，这些不同样式的页面最终会将用户录入的数据Post到同一个登录接口。\n  OAuth2授权服务器提供的登录接口，会验证表单中的数据，如果验证通过了，会让浏览器重定向到Client的某个接口（这个接口由Client重定向到OAuth2授权服务器时提供的，具体参考该协议），在这次重定向的过程中，OAuth2授权服务器会将授权码通过code参数告知给Client。\n  Client拿到授权码，访问OAuth2授权服务器的Token结构，获取到AccessToken，所以OAuth2授权服务器还需要提供一个接口，将授权码转换成AccessToken。\n  截止到目前，我只理清楚了需要的接口，还没有理清楚每个接口背后的逻辑，现在开始理一理每个接口到底该怎么设计和实现。\n获取登录界面的接口 这个接口比较简单，客户端服务器指导浏览器重定向到授权服务器的接口，这个接口会返回一个登录页面，用户在这个页面填写用户凭证提交给授权服务器的登录接口。\n在具体实现上，我看QQ、微博等都是自己提供了一个登录页面，如果OAuth2仅在企业内部做单点登录用，我觉得可以根据不同的需求返回不同样式的登录页面，比如提供一个A产品线的登录接口、B产品线的登录接口，实际上这两个登录接口都将用户凭证提交到同一个登录接口。\n这个获取登录页面的接口还需要其他的逻辑么？我看到一份Demo中将用户提交的RedirectUrl放在了Session中，我猜到了下一步在登录接口中会怎么做，它会从Session中取出这个RedirectUrl，然后指导浏览器重定向到这个RedirectUrl，并带着计算处理的Code码。实际上，我觉得没有必要这么做，完全可以将这些参数放到页面中，然后通过页面一起提交给登录接口，这样还避免了拥有多个授权服务器时需要进行数据的同步等。\n如果这个获取登录界面的接口的作用仅仅是返回一个页面，用户用户填写用户凭证，我们一定需要使用模板渲染技术实现么，我其实并不是很喜欢模板渲染技术，因为这个技术会让我不得不再去关注一些页面渲染层面的东西。或许可以直接将这个Url指向一个静态页面，然后在静态页面中获取Url中的请求参数，然后在访问登录接口时，将这些Url中的请求参数传递给登录接口。\n上面的想法是肯定可行的，甚至在实践中我们可以有一些更骚的应用，我们直接将A产品线的登录页面的登录接口换成授权服务器的登录接口，然后开始走OAuth的各个流程。\n但是现在的问题时，如何实现单点登录？如果使用静态网页，或者直接嵌入到某个产品线的登录页面，我们就没有办法通过登录页面的域名实现单点登录，我们各个产品线每次都需要重新登录，整套系统又退化到了普通的登录系统。\n我打算目前就简单化处理这个问题，就使用模板技术渲染技术渲染出登录页面吧。\n登录接口 登录接口核心目标是验证用户的用户凭证，生成授权码，并指导浏览器重定向到客户端服务器的某个接口。这个过程中需要明白一个点：客户端服务器稍后的时候会通过授权码获取AccessToken，所以生成的授权码需要被我们缓存起来。\n通过授权码获取AccessToken的接口 参考资料  一文带你了解 OAuth2 协议与 Spring Security OAuth2 集成！  ","description":"","id":381,"section":"notes","tags":null,"title":"OAuth2的Endpoint","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/oauth2%E7%9A%84endpoint/"},{"content":" GitHub OAuth应用注册页  ","description":"","id":382,"section":"notes","tags":null,"title":"OAuth2资源整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/oauth2%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86/"},{"content":"如下为一份粗略的授权方式及适用场景：\n  授权码（Authorisation Code）：适用于具有后端的传统Web应用程序以及原生（移动或桌面）应用程序，通过系统浏览器进行单点登录\n  隐式（Implict）：适用于没有后端的基于浏览器的应用程序\n  密码（Password）：对于应用程序和授权服务器属于同一个提供者的受信任的本地客户端\n  客户凭证（Client Credentials）：对于代表自己行事的客户端，例如 Web 服务。\n  Refresh Token：一种特殊的授权，让客户无需再次执行代码或密码授权步骤即可刷新其访问令牌。\n  SAML 2.0 Bearer（不是很理解）：让拥有 SAML 2.0 断言（登录令牌）的客户端将其交换为 OAuth 2.0 访问令牌。\n  JWT Bearer（不是很理解）：让拥有来自一个安全域的JSON Web令牌 (JWT) 断言的客户端将其交换为另一个域中的 OAuth 2.0 访问令牌。\n  Device：对于某有浏览器或输入受限的设备，例如智能电视、媒体控制台、打印机等。\n  Token Exchange：让应用程序和服务在委托和模拟场景中获取访问令牌。\n  ","description":"","id":383,"section":"notes","tags":null,"title":"OAuth授权方式及使用场景","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/oauth%E6%8E%88%E6%9D%83%E6%96%B9%E5%BC%8F%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"},{"content":" 存储器 \u0026gt; 磁盘：对数据盘进行擦除  存储器 \u0026gt; 文件系统：为数据盘创建文件系统  存储器 \u0026gt; 文件系统：挂载数据盘   访问权限管理 \u0026gt; 共享文件夹：创建一个共享文件夹\n  服务 \u0026gt; SMB/CIFS\n  （SMB其实是所有共享中真正能面向全平台的共享）\n 启动该服务 在共享点击添加（将共享文件夹添加进去，则可以共享）  访问权限管理 \u0026gt; 用户：修改账户的密码  之所以要做这一步是因为，SMB服务启动晚于用户创建，所以导致用户的信息没有进入SMB的账户认证体系中，手动更新一次密码可以让账户的信息刷入到SMB的账户认证体系中。因为我在安装OMV时并没有创建用户，所以我的该列表是不存在用户，也就不存在说刷新密码的操作。这是存在问题的，我使用Admin的账号没有登录我共享服务，我最终选择了创建一个拥有所有用户组的账号，从而让自己可以登录共享文件夹。\n参考资料  第三期 快速创建 OpenMediaVault 的第一个共享文件夹 | 一台电脑的 NAS 之旅  ","description":"","id":384,"section":"notes","tags":null,"title":"OMV配置共享文件夹（实验版）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BD%9C%E5%BA%9F/openmediavault/omv%E9%85%8D%E7%BD%AE%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%E5%AE%9E%E9%AA%8C%E7%89%88/"},{"content":"考虑到Ubuntu的一些底层的包和CentOS不一样，我决定重新查找CentOS上OpenVPN的安装方法。\n安装OpenVPN  安装前的准备工作，我执行了如下指令（因为我的机器之前编译过别的东西，所以没有完全按照教程来）   yum install -y lz4-devel lzo-devel pam-devel openssl-devel systemd-devel sqlite-devel 下载OpenVPN并解压（我是去官网找的下载链接）   wget https://swupdate.openvpn.org/community/releases/openvpn-2.5.2.tar.gz tar -zxvf openvpn-2.5.2.tar.gz cd openvpn-2.5.2  编译安装（github上给的教程很简单，这个地方反倒有点复杂，我没有对比，不知道差别）：   cd openvpn-2.5.2 autoreconf -i -v -f ./configure --prefix=/usr/local/openvpn --enable-lzo --enable-lz4 --enable-crypto --enable-server --enable-plugins --enable-port-share --enable-iproute2 --enable-pf --enable-plugin-auth-pam --enable-pam-dlopen --enable-systemd make \u0026amp;\u0026amp; make install ln -s /usr/local/openvpn/sbin/openvpn /usr/local/sbin/openvpn 修改配置文件，并配置系统服务，并设置开机启动   vim /usr/local/openvpn/lib/systemd/system/openvpn-server@.service ### 找到 ExecStart 这行，改为如下 ExecStart=/usr/local/openvpn/sbin/openvpn --config server.conf cp -a /usr/local/openvpn/lib/systemd/system/openvpn-server@.service /usr/lib/systemd/system/openvpn.service systemctl enable openvpn.service 配置OpenVPN  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  tee /etc/openvpn/server/server.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; local 0.0.0.0 port 1194 proto tcp dev tun ca /etc/openvpn/server/ca.crt cert /etc/openvpn/server/server.crt key /etc/openvpn/server/server.key dh /etc/openvpn/server/dh.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \u0026#34;route 172.16.10.0 255.255.255.0\u0026#34; ;client-to-client ;duplicate-cn keepalive 10 120 tls-auth /etc/openvpn/server/ta.key 0 cipher AES-256-CBC compress lz4-v2 push \u0026#34;compress lz4-v2\u0026#34; ;comp-lzo max-clients 1000 user nobody group nobody persist-key persist-tun status openvpn-status.log log /var/log/openvpn.log verb 3 ;explicit-exit-notify 1 EOF   sed -i \u0026lsquo;/net.ipv4.ip_forward/s/0/1/\u0026rsquo; /etc/sysctl.conf\nsed -i \u0026lsquo;/net.ipv4.ip_forward/s/#//\u0026rsquo; /etc/sysctl.conf\nsysctl -p\n配置Window客户端  官网下载  https://openvpn.net/community-downloads/\nping不通：\n 关闭防火墙 设置端口转发 关闭Selinux 额，我的机器上不是eth0 断开链接了！！！  iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eno1 -j MASQUERADE\niptables-save \u0026gt; /etc/sysconfig/iptables\ngrep \u0026lsquo;net.ipv4.ip_forward = 1\u0026rsquo; /etc/sysctl.conf || echo \u0026lsquo;net.ipv4.ip_forward = 1\u0026rsquo; \u0026raquo; /etc/sysctl.conf\nsysctl -p\n一直无法链接，需要关闭防火墙（有点矛盾）\n虚拟机未开！！！\nhttp://www.r9it.com/20190420/install-openvpn.html#%E5%AE%89%E8%A3%85-openvpn\nfirewall-cmd \u0026ndash;zone=public \u0026ndash;add-port=1194/tcp \u0026ndash;permanent\n参考资料  在Linux CentOS 7搭建OpenVPN服务与管理  ","description":"","id":385,"section":"notes","tags":null,"title":"OpenVPN的安装与配置（高安全级别的）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/openvpn%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%E9%AB%98%E5%AE%89%E5%85%A8%E7%BA%A7%E5%88%AB%E7%9A%84/"},{"content":"CentOS版 easy-rsa下载与配置修改  下载easy-ras并解压   wget https://github.com/OpenVPN/easy-rsa/archive/v3.0.7.tar.gz mv v3.0.7.tar.gz easy-rsa-3.0.7.tar.gz tar xf easy-rsa-3.0.7.tar.gz 根据vars.example生成全局配置文件vars   cd easy-rsa-3.0.7/easyrsa3 cp -a vars.example vars 修改vars文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  tee -a vars \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; set_var EASYRSA_REQ_COUNTRY \u0026#34;CN\u0026#34; set_var EASYRSA_REQ_PROVINCE \u0026#34;GD\u0026#34; set_var EASYRSA_REQ_CITY \u0026#34;GuangZhou\u0026#34; set_var EASYRSA_REQ_ORG \u0026#34;jj\u0026#34; set_var EASYRSA_REQ_EMAIL \u0026#34;junjie2025@gmail.com\u0026#34; set_var EASYRSA_REQ_OU \u0026#34;jj\u0026#34; set_var EASYRSA_KEY_SIZE 2048 # 长度 set_var EASYRSA_ALGO rsa # 算法 set_var EASYRSA_CA_EXPIRE 36500 # CA证书过期时间，单位天 set_var EASYRSA_CERT_EXPIRE 36500 # 签发证书的有效期是多少天，单位天 EOF   生成服务端证书和客户端证书 初始化与创建CA根证书  初始化，会在当前目录创建PKI目录，用于存储一些中间变量及最终生成的证书：   ./easyrsa init-pki 生成CA根证书：   ./easyrsa build-ca 这部分有如下注意点：\n 需要输入PEM密码，输入两次，此密码必须记住，不然以后不能为证书签名 需要输入common name，这个随便设置个独一无二的就好了，比如openvpn  生成服务端证书  为服务端生成证书对并在本地签名。nopass参数生成一个无密码的证书，在此过程中会让你确认ca密码   ./easyrsa build-server-full server nopass 创建Diffie-Hellman，确保key穿越不安全网络的命令，时间会有点长，耐心等待：   ./easyrsa gen-dh 生成客户端证书  执行如下指令，生成多个客户端证书对，并在本地签名。nopass参数生成一个无密码的证书（我暂时不考虑），在此过程中会让你确认ca密码。   ./easyrsa build-client-full client nopass # 无密码，实际应用中不推荐，客户端有密码可提高安全性 ./easyrsa build-client-full zhangsan # 让你输入密码，后续VPN连接时会使用 ./easyrsa build-client-full lisi # 让你输入密码，后续VPN连接时会使用 ./easyrsa build-client-full wangwu # 让你输入密码，后续VPN连接时会使用 为了提高安全性，生成ta.key  加强认证方式，防攻击。如果配置文件中启用此项(默认是启用的)，就需要执行上述命令，并把ta.key放到/etc/openvpn/server目录。配置文件中服务端第二个参数为0，同时客户端也要有此文件，且client.conf中此指令的第二个参数需要为1。（服务端有该配置，那么客户端也必须要有）   openvpn --genkey --secret ta.key 整理服务端证书  mkdir -p /etc/openvpn/server/ cp -a pki/ca.crt /etc/openvpn/server/ cp -a pki/private/server.key /etc/openvpn/server/ cp -a pki/issued/server.crt /etc/openvpn/server/ cp -a pki/dh.pem /etc/openvpn/server/ cp -a ta.key /etc/openvpn/server/ Ubunto版 整理这个版本，是因为OpenVPN是之前我成功配置的一个版本，我想知道它们的区别\nUbuntu版本相对比较简单，需要密码的地方都没有设置密码，而且版本比较旧，我就不整理了，毕竟我计划放弃Ubuntu。\n参考资料  在Linux CentOS 7搭建OpenVPN服务与管理 Ubuntu 搭建 OpenVPN 服务  目前的疑惑  easy-ras下载地址是怎么得到的呢？？？GitHub的一种特性么，我看作者下载OpenVPN是也是用这种方法。  ","description":"","id":386,"section":"notes","tags":null,"title":"OpenVPN证书生成","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/openvpn%E8%AF%81%E4%B9%A6%E7%94%9F%E6%88%90/"},{"content":"  openvpn 文件参数详解\n讲解了OpenVPN的参数，感觉还不错\n  OpenWRT 搭建 OpenVPN 服务器\n评论区讨论了其他技术，很有价值。\n  ","description":"","id":387,"section":"notes","tags":null,"title":"OpenVPN资料整理","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/openvpn%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"/etc/config/network\n","description":"","id":388,"section":"notes","tags":null,"title":"OpenWrt修改IP地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E4%BF%AE%E6%94%B9ip%E5%9C%B0%E5%9D%80/"},{"content":"操作步骤   System-\u0026gt;Software-\u0026gt;在 Filter 栏里面输入 -zh-cn 点击搜索\n  找到 luci-i18n-base-zh-cn 点击前面的安装。然后去设置语言即可。\n  （我可能需要配置科学上网）\n","description":"","id":389,"section":"notes","tags":null,"title":"OpenWrt修改语言","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E4%BF%AE%E6%94%B9%E8%AF%AD%E8%A8%80/"},{"content":"我最终选择了防火墙的方案，只指定部分mac地址访问我的77端口即可：\n 配置允许访问的端口（这一步应该先进行，否则就无法访问Web服务了）   # 192.168.13.113 # Base(192.168.13.68) # Node1(192.168.13.195) # Node2(192.168.13.83) # Node3(192.168.13.32) # Node4(192.168.13.105) # Node5(192.168.13.236) iptables -I INPUT -s 192.168.13.113 -j ACCEPT iptables -I INPUT -s 192.168.13.68 -j ACCEPT iptables -I INPUT -s 192.168.13.195 -j ACCEPT iptables -I INPUT -s 192.168.13.83 -j ACCEPT iptables -I INPUT -s 192.168.13.32 -j ACCEPT iptables -I INPUT -s 192.168.13.105 -j ACCEPT iptables -I INPUT -s 192.168.13.236 -j ACCEPT iptables -I INPUT -s 192.168.28.118 -j ACCEPT  设置lan口的入站规则为拒绝  Web服务（作废，不优雅，麻烦）  编辑/etc/config/uhttpd   config uhttpd 'main' list listen_http '0.0.0.0:80' list listen_http '[::]:80' list listen_https '0.0.0.0:443' list listen_https '[::]:443' option redirect_https '0' option home '/www' option rfc1918_filter '1' option max_requests '3' option max_connections '100' option cert '/etc/uhttpd.crt' option key '/etc/uhttpd.key' option cgi_prefix '/cgi-bin' list lua_prefix '/cgi-bin/luci=/usr/lib/lua/luci/sgi/uhttpd.lua' option script_timeout '60' option network_timeout '30' option http_keepalive '20' option tcp_keepalive '1' option ubus_prefix '/ubus' config cert 'defaults' option days '730' option key_type 'ec' option bits '2048' option ec_curve 'P-256' option country 'ZZ' option state 'Somewhere' option location 'Unknown' option commonname 'OpenWrt' 重启该服务   /etc/init.d/uhttpd restart 参考资料  Openwrt 修改Web页面默认访问端口  ","description":"","id":390,"section":"notes","tags":null,"title":"openwrt减少端口暴露","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E5%87%8F%E5%B0%91%E7%AB%AF%E5%8F%A3%E6%9A%B4%E9%9C%B2/"},{"content":"指令如下：\n opkg update \u0026amp;\u0026amp; opkg install curl 本来是个很简单的指令，但是每次直接执行opkg install curl，都提示找不到包，很奇怪。\n参考资料  请问如如何安装curl ，openwrt  ","description":"","id":391,"section":"notes","tags":null,"title":"OpenWrt安装Curl","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E5%AE%89%E8%A3%85curl/"},{"content":"问题描述 编译了官方镜像后，设置了代码，然后执行opkg update，结果确报错。报错内容没有整理，核心就是：wget returned 5。\n修复方法，备份/etc/opkg/distfeeds.conf，并将该文件中的https全部改为http。\nopkg设置代理 在软件包管理界面加上如下配置即可：\n option http_proxy http://192.168.13.113:1080 或者修改/etc/opkg.conf，加上如上配置。\n另外需要说一下，opkg貌似不支持https_proxy，我目前没有找到相关的资料，单纯的配置了这个后，opkg update会报错。\n参考资料   软件包更新失败，提示wget returned 5\n  Openwrt 国内源配置 · DarkGod’ Blog\n主要从这篇文章中查看修改哪个文件。\n  ","description":"","id":392,"section":"notes","tags":null,"title":"OpenWrt官方编译后，无法执行opkg update","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E5%AE%98%E6%96%B9%E7%BC%96%E8%AF%91%E5%90%8E%E6%97%A0%E6%B3%95%E6%89%A7%E8%A1%8Copkg-update/"},{"content":"使用如下指令：\n logread -f 参考资料  openwrt查看日志  ","description":"","id":393,"section":"notes","tags":null,"title":"OpenWrt查看日志","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/openwrt%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97/"},{"content":"我在OpenWRT上配置Wireguard时，忘记勾选Route Allowed IPs，导致路由表中没有相关的路由，最终无法ping通。\n虽然这是一个非常低级的错误，但是在解决这个问题的时候，我又简单复习了一下Wireguard的一些知识，还稍微升入的了解了一下OpenWRT上的防火墙配置，还算是有收获的。\n","description":"","id":394,"section":"notes","tags":null,"title":"OpenWRT配置wireguard时忘记勾选Route Allowed IPs导致地址不可访问","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/openwrt%E9%85%8D%E7%BD%AEwireguard%E6%97%B6%E5%BF%98%E8%AE%B0%E5%8B%BE%E9%80%89route-allowed-ips%E5%AF%BC%E8%87%B4%E5%9C%B0%E5%9D%80%E4%B8%8D%E5%8F%AF%E8%AE%BF%E9%97%AE/"},{"content":"我觉得我遇到的这个问题属于PyCharm的BUG！！！通过oss2推送图片到阿里云OSS时，因为网络环境的问题，我需要设置代理，我在网上找到了一篇教程，是通过环境变量的方式，我果断的设置环境变量后尝试该方案，结果失败了。我以为是这个方案不适用Win环境，于是我在Linux环境测试，发现该方案可行。\n我本人不信邪，我觉得从原理上讲，应该两个平台的表现是一致的，我有在Win平台寻找解决放案，后来发现了通过os.environ设置all_proxy的方式设置代理，是可行的。我意识到，可能是我设置了环境变量后，PyCharm没有立即获取到这些环境变量，于是，我设置了环境变量后，重启PyCharm，发现程序按照我的想法运行了。\n我明白造成我问题的原因了，就是我设置了环境变量后，在PyCharm中启动程序时，没有读取到最新的环境变量。我觉得这个就是PyCharm的BUG。\n其他讯息 其实这次解决问题，本来没有不会花费这么长时间的，我之前有做python中获取环境变量的实验，那个时候获取的始终是none，我没有想到是Pycharm的问题，而是以为我api调用错误，就搁置了这个问题，结果最后就导致这次解决问题花了很长时间。\n这次的问题，还有一些奇怪的现象。我Win机器上开启了代理，oss2的请求会阻塞很长时间，然后报proxy错误，我不知道这个请求最终请求到哪了，为什么会出现这种现象。我觉得我应该学习一些相关的技术，这样下次遇到类似的问题时，我至少知道我的数据包去到哪了。\n参考资料  需要在没有外网但可以使用代理的服务器上，上传文件到oss，该如何设置代理 Request高级用法 python 使用代理的几种方式 python 获取环境变量  后续 这个问题其实还没有结束，解决了环境变量的问题后，还可能存在成功一次上传，部分成功，部分报SSL错误的情况或者Post成功Get失败。真的是离奇到爆炸。但是这次我开始耐心定位问题，我先通过如下指令，判断我1080端口是否正在监听：\n # 要么用双引号，要么不用，单引号没有任何效果 netstat -aon|findstr 1080 当1080端口没有监听的时候，执行测试代码，发现报如下错误，这个错误是我预先知道的，是符合我们公司的网络环境的：\n (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1125)'))) 配置代码使用本地代理后，再次执行脚本，报如下错误：\n (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) 很明显，这是两种不同类型的SSL错误，我之前一直以为是一种，导致我以为是Request中某些玄学的因素导致无法正常请求。所以，也在尝试用一些玄学的办法解决这个问题~\n目前已经尝试的解决方案：\n Linux配置透明代理（失败） ALL_PROXY走socks5协议（失败） ALL_PROXY设置为其他机器（失败） 在VPS环境测试，免使用代理进行测试（失败） 为Bucket类传递Session参数（失败）  我现在真的觉得这种问题好哔狗，我清掉了OSS里的所有图片，重新运行脚本，这次运行的过程中因为我操作失误忘记清除max_retries=40的设置，结果整个脚本又跑成功了？？？但是这次运行花了很长一段时间，成功运行了脚本后，我又立即运行了一次，结果这次又出现了之前的错误！！！而且我还发现了一些怪异的现象，我如下代码断点，真正断点的时候，resp并没有获取到任何东西（如截图所示），我决定不在继续运行代码，在此等候代码执行，结果过了一会，resp的值又出现了。要命，难道这就是Python的异步？？？\n # Create the Request. req = Request( method=method.upper(), url=url, headers=headers, files=files, data=data or {}, json=json, params=params or {}, auth=auth, cookies=cookies, hooks=hooks, ) prep = self.prepare_request(req) proxies = proxies or {} settings = self.merge_environment_settings( prep.url, proxies, stream, verify, cert ) # Send the request. send_kwargs = { 'timeout': timeout, 'allow_redirects': allow_redirects, } send_kwargs.update(settings) resp = self.send(prep, **send_kwargs) return resp 我想锤人！！！我猜测是不是网络的问题，我的bucket在北京，我的vps在香港，而我在广州，请求需要从我这到香港，然后从香港到北京，这个过程太慢了，最后导致失败。我将bucket重建在深圳，结果脚本非常正确的运行了。真的哔狗啊，这种解决问题的方法已经超出我对事物的理解范围了，为什么post就可以无视请求时长的影响，而get就会受到印象呢？oss2又如何设置这个时长呢？我暂时不打算对这些东西深入研究了，知道有这些问题存在就好了。\n后续20210427 没想到这件事情还有后续！！！我今天要使用脚本的时候准备做一些脚本清理工作，结果发现之前用深圳的bucket做实验的时候和用北京节点的bucket做实验的时候没有控制变量，北京用的是https://oss-cn-beijing.aliyuncs.com，而深圳用的是oss-cn-shenzhen.aliyuncs.com，区别是北京的多了一个https。当我深圳的endpoint也加上https，会报和北京bucket一样的错误（区别在于可能可以多运行一会，遇到该问题的几率小一点）！！！，而当我的北京endpoint去到这个https后，也不会报任何错误，而且速度还很快。\n我这段代码是用的我很久前的代码，我以为是我当时写错了，我后来去网上搜索，发现很多代码都是加上https的，我之前写这段代码时也是参考的官方的文档，我认为大概率是官方文档调整了写法。\n我觉得这是oss2的bug或者是oss2底层使用的库的bug，这个问题最困扰人的一点是加不加https，不是绝对的，加了不一定失败，所以定位这个问题时完全靠观察能力。这个问题深入底层的分析，需要掌握抓包、过滤包、解析https包的技术，我暂时没有掌握这些技术，所以先放弃了。\n还有些东西需要记录下来，当抛出异常的时候，我貌似在鲨鱼上看到RST包了，不知道两者有没有关系。\n个人小结 这次实验让我开始注意到网络环境对实验的影响了，我之前对这些东西无感，我觉得都是毫秒级的差距，应该感觉不出来，但是这次很明显的看到从香港vps上传东西到北京bucket，需要上十分钟，而到深圳，只需要一分钟不到。同时，网络请求的跳数太多，可能会对实验结果代理不可预知的问题。\n其他知识 我发现其实我Shadowsocks客户端一打开，即使我调整为其为禁用，我1080端口也处于监听状态。额，我之前一直以为该端口会关闭，尴尬。\n参考资料   How to get around python requests SSL and proxy error?\n报错的位置和我很像，连代码的行数都很像，但是没有提供给我任何有用的讯息。\n  ","description":"","id":395,"section":"notes","tags":null,"title":"oss2代理设置问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/oss2%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE%E9%97%AE%E9%A2%98/"},{"content":"产品有一个上传多张图片的需求，前端同事开了多个任务进行处理，结果发现一个可以百分百复现的问题：5张相同的大图片，往往上传成功一两张后就报错了，其报错内容如下：\n1 2 3 4 5 6 7 8 9 10  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Error\u0026gt; \u0026lt;Code\u0026gt;NoSuchUpload\u0026lt;/Code\u0026gt; \u0026lt;Message\u0026gt;The specified upload does not exist. The upload ID may be invalid, or the upload may have been aborted or completed.\u0026lt;/Message\u0026gt; \u0026lt;RequestId\u0026gt;61CEC8AE0119273036885C73\u0026lt;/RequestId\u0026gt; \u0026lt;HostId\u0026gt;sdtc-1.oss-cn-shenzhen.aliyuncs.com\u0026lt;/HostId\u0026gt; \u0026lt;UploadId\u0026gt;0A03563474C84909AE9166914ABD989B\u0026lt;/UploadId\u0026gt; \u0026lt;/Error\u0026gt;   最后我们分析出是因为5张图片的哈希值是一样的，所以我们决定在上传前计算图片的Hash值，如果Hash值相同，则只开启一个上传任务。\n具体造成该问题的细节涉及到了OSS相关的知识，我知识储备还不足，就不讨论了。\n","description":"","id":396,"section":"notes","tags":null,"title":"OSS同时上传5张相同图片，上传被中断的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%85%B6%E4%BB%96%E9%97%AE%E9%A2%98/oss%E5%90%8C%E6%97%B6%E4%B8%8A%E4%BC%A05%E5%BC%A0%E7%9B%B8%E5%90%8C%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E8%A2%AB%E4%B8%AD%E6%96%AD%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":" 依赖配置如下：   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;p6spy\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;p6spy\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; application.yml配置如下   spring: datasource: # driver-class-name: org.postgresql.Driver # 原始的 driver-class-name: com.p6spy.engine.spy.P6SpyDriver # 使用p6spy后的 password: HelloWorld # url: jdbc:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 原始的 url: jdbc:p6spy:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 使用p6spy后的 username: postgres sps.properties配置   module.log=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory # 自定义日志打印 logMessageFormat=fun.junjie.autotools.config.P6spyLogFormat # 使用日志系统记录sql appender=com.p6spy.engine.spy.appender.Slf4JLogger ## 配置记录Log例外 excludecategories=info,debug,result,batc,resultset # 设置使用p6spy driver来做代理 deregisterdrivers=true # 日期格式 dateformat=yyyy-MM-dd HH:mm:ss # 实际驱动 #driverlist=com.mysql.jdbc.Driver #drive=com.p6spy.engine.spy.P6SpyDriver driverlist=com.p6spy.engine.spy.P6SpyDriver # 是否开启慢SQL记录 outagedetection=true # 慢SQL记录标准 秒 outagedetectioninterval=2 P6spyLogFormat开发   package fun.junjie.autotools.config; import com.p6spy.engine.spy.appender.MessageFormattingStrategy; import io.micrometer.core.instrument.util.StringUtils; public class P6spyLogFormat implements MessageFormattingStrategy { @Override public String formatMessage(final int connectionId, final String now, final long elapsed, final String category, final String prepared, final String sql, final String url) { return StringUtils.isNotEmpty(sql) ? new StringBuilder().append(\u0026quot; Execute SQL：\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026quot;).append(sql.replaceAll(\u0026quot;[\\\\s]+\u0026quot;, \u0026quot; \u0026quot;)).append(String.format(\u0026quot; \u0026lt;\u0026lt;\u0026lt;\u0026lt; Execute time: %s ms\u0026quot;, elapsed)).toString() : null; } } 小结 我配置p6spy是为了打印我通过JdbcTemplate获取表元数据时执行的SQL，但是，我发现这个工具根本不好使。我最后采用的方案是自己搭建一个PG数据库，然后开启SQL日志。\n我没有深入研究p6spy，毕竟它目前不满足我的需求。\n参考资料  使用P6Spy监控你的Spring boot数据库操作 springboot 配置 P6spy  ","description":"","id":397,"section":"notes","tags":null,"title":"p6spy的使用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/p6spy%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"content":"PanDownlaod我一直当做http下载器使用，使用浏览器默认的下载器，总是可能出现断流的情况，而且浏览器里下载，断流的话需要全部重新下，PanDownload不用。\n设置代理适用的场景是，下载Github里的东西，另外说一下，Github这东西，就连用代理也拯救不了它的速度。\n  进入软件所在目录，打开配置文件PanData/config.ini\n  修改proxy的值，格式为代理IP地址:端口，例如：proxy=192.168.1.1:3128，保存后重启程序\n  参考资料  PanDownlaod设置代理  ","description":"","id":398,"section":"notes","tags":null,"title":"PanDownlaod配置代理","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/pandownlaod%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"依赖如下：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.pdfbox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pdfbox\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   我的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public static List\u0026lt;byte[]\u0026gt; transferPdfToPictures(InputStream inputStream) { try (PDDocument document = PDDocument.load(inputStream)) { List\u0026lt;byte[]\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); PDFRenderer renderer = new PDFRenderer(document); for (int i = 0; i \u0026lt; document.getNumberOfPages(); ++i) { BufferedImage bufferedImage = renderer.renderImageWithDPI(i, DPI); ByteArrayOutputStream out = new ByteArrayOutputStream(); ImageIO.write(bufferedImage, IMG_TYPE, out); result.add(out.toByteArray()); } return result; } catch (Exception e) { e.printStackTrace(); throw new BusinessException(PDF_TRANSFER_WRONG); } }   参考资料  Java实现PDF转图片  ","description":"","id":399,"section":"notes","tags":null,"title":"PDF转图片","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/pdf%E8%BD%AC%E5%9B%BE%E7%89%87/"},{"content":"用的比较少，但是做实验中这些指令比较重要。\n1 2 3 4 5 6 7 8  # 查看时区 show time zone # 设置时区  set time zone \u0026#39;PRC\u0026#39;; # 相当于+08时区 set time zone \u0026#39;GMT\u0026#39;; # 相当于+00时区   参考资料   postgresql 时区配置，系统主机与数据库时间不一致\n  PostgreSQL时区、时间不一致、差8小时\n  ","description":"","id":400,"section":"notes","tags":null,"title":"PG查看并设置当前session的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/pg%E6%9F%A5%E7%9C%8B%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%BD%93%E5%89%8Dsession%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"问题描述 我在CentOS上通过自己编译的Python的pip工具下载oss2模块时，出现如下报错：\n [root@localhost ~]# pip3 install oss2 Collecting oss2 Using cached oss2-2.14.0.tar.gz (224 kB) ERROR: Command errored out with exit status 1: command: /usr/local/python3/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\u0026quot;'\u0026quot;'/tmp/pip-install-5yv_1h3n/oss2/setup.py'\u0026quot;'\u0026quot;'; __file__='\u0026quot;'\u0026quot;'/tmp/pip-install-5yv_1h3n/oss2/setup.py'\u0026quot;'\u0026quot;';f=getattr(tokenize, '\u0026quot;'\u0026quot;'open'\u0026quot;'\u0026quot;', open)(__file__);code=f.read().replace('\u0026quot;'\u0026quot;'\\r\\n'\u0026quot;'\u0026quot;', '\u0026quot;'\u0026quot;'\\n'\u0026quot;'\u0026quot;');f.close();exec(compile(code, __file__, '\u0026quot;'\u0026quot;'exec'\u0026quot;'\u0026quot;'))' egg_info --egg-base /tmp/pip-pip-egg-info-pi9uat3k cwd: /tmp/pip-install-5yv_1h3n/oss2/ Complete output (11 lines): Traceback (most recent call last): File \u0026quot;\u0026lt;string\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/__init__.py\u0026quot;, line 23, in \u0026lt;module\u0026gt; from setuptools.dist import Distribution File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/dist.py\u0026quot;, line 34, in \u0026lt;module\u0026gt; from setuptools import windows_support File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/setuptools/windows_support.py\u0026quot;, line 2, in \u0026lt;module\u0026gt; import ctypes File \u0026quot;/usr/local/python3/lib/python3.8/ctypes/__init__.py\u0026quot;, line 7, in \u0026lt;module\u0026gt; from _ctypes import Union, Structure, Array ModuleNotFoundError: No module named '_ctypes' ---------------------------------------- ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available. You should consider upgrading via the '/usr/local/python3/bin/python3.8 -m pip install --upgrade pip' command. 解决方案  执行如下指令：   yum install libffi-devel -y 然后重新编译安装你的Python。\n make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 参考资料  ModuleNotFoundError: No module named \u0026lsquo;_ctypes\u0026rsquo;的解决方案  ","description":"","id":401,"section":"notes","tags":null,"title":"pip3拉oss2包时报错","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip3%E6%8B%89oss2%E5%8C%85%E6%97%B6%E6%8A%A5%E9%94%99/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8  mkdir -p ~/.pip sudo tee ~/.pip/pip.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [global] index-url = https://mirrors.aliyun.com/pypi/simple EOF   ","description":"","id":402,"section":"notes","tags":null,"title":"pip3设置国内源","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip3%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E6%BA%90/"},{"content":"用于精细化定位问题，及修复问题：\n pip list pip freeze pip show module_name 参考资料  如何查看python包的版本号?  ","description":"","id":403,"section":"notes","tags":null,"title":"pip查看某个库的版本号","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pip%E6%9F%A5%E7%9C%8B%E6%9F%90%E4%B8%AA%E5%BA%93%E7%9A%84%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"今天用官方源初始化一个SpringBoot项目时发现parent标签下有一个relativePath标签，简单查询了一下，有如下解释：\n  查找顺序：relativePath元素中的地址 \u0026gt; 本地仓库 \u0026gt; 远程仓库\n  如果relateivePath设置为一个空值，将始终从仓库中获取，不从本地路径获取。\n  目前我主要到relateivePath标签主要应用于parent标签中，通过查资料对给标签有了进一步理解（查看该标签的描述信息）：\n  relativePath用于指定父pom.xml的相对位置\n  父pom.xml默认位置为../pom.xml\n  Maven首先从当前项目的Reactor中寻找父Pom.xml,然后从文件系统中寻找，然后从本地仓库寻找，然后从远程仓库\n  relativePath允许配置一个特定的位置，如果项目是扁平的，或者纵深的（总之没有一个清晰的父Pom）\n  groupId、artifactId、version仍然被需要，而且必须与配置的路径上的pom.xml文件相符合\n  这项特性只加强了项目的本地检查\n  参考资料   maven 工程 pom.xml 中 relativePath 的作用\n  Maven parent.relativePath 说明\n  ","description":"","id":404,"section":"notes","tags":null,"title":"pom.xml文件中的relativePath","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/pom.xml%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84relativepath/"},{"content":"写在application.yml配置文件中的：org.postgresql.Driver\n不记录一下，总是忘记，每次忘记再搜索，很麻烦。\n","description":"","id":405,"section":"notes","tags":null,"title":"postgresql的驱动配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/postgresql%E7%9A%84%E9%A9%B1%E5%8A%A8%E9%85%8D%E7%BD%AE/"},{"content":"使用场景是我配置了日志输出，配置了P6spy，但是依旧有些执行记录无法查看。\n使用的配置文件如下：\n # ----------------------------- # PostgreSQL configuration file # ----------------------------- # # This file consists of lines of the form: # # name = value # # (The \u0026quot;=\u0026quot; is optional.) Whitespace may be used. Comments are introduced with # \u0026quot;#\u0026quot; anywhere on a line. The complete list of parameter names and allowed # values can be found in the PostgreSQL documentation. # # The commented-out settings shown in this file represent the default values. # Re-commenting a setting is NOT sufficient to revert it to the default value; # you need to reload the server. # # This file is read on server startup and when the server receives a SIGHUP # signal. If you edit the file on a running system, you have to SIGHUP the # server for the changes to take effect, run \u0026quot;pg_ctl reload\u0026quot;, or execute # \u0026quot;SELECT pg_reload_conf()\u0026quot;. Some parameters, which are marked below, # require a server shutdown and restart to take effect. # # Any parameter can also be given as a command-line option to the server, e.g., # \u0026quot;postgres -c log_connections=on\u0026quot;. Some parameters can be changed at run time # with the \u0026quot;SET\u0026quot; SQL command. # # Memory units: kB = kilobytes Time units: ms = milliseconds # MB = megabytes s = seconds # GB = gigabytes min = minutes # TB = terabytes h = hours # d = days #------------------------------------------------------------------------------ # FILE LOCATIONS #------------------------------------------------------------------------------ # The default values of these variables are driven from the -D command-line # option or PGDATA environment variable, represented here as ConfigDir. #data_directory = 'ConfigDir'\t# use data in another directory # (change requires restart) #hba_file = 'ConfigDir/pg_hba.conf'\t# host-based authentication file # (change requires restart) #ident_file = 'ConfigDir/pg_ident.conf'\t# ident configuration file # (change requires restart) # If external_pid_file is not explicitly set, no extra PID file is written. #external_pid_file = ''\t# write an extra PID file # (change requires restart) #------------------------------------------------------------------------------ # CONNECTIONS AND AUTHENTICATION #------------------------------------------------------------------------------ # - Connection Settings - listen_addresses = '*' # comma-separated list of addresses; # defaults to 'localhost'; use '*' for all # (change requires restart) #port = 5432\t# (change requires restart) max_connections = 100\t# (change requires restart) #superuser_reserved_connections = 3\t# (change requires restart) #unix_socket_directories = '/var/run/postgresql'\t# comma-separated list of directories # (change requires restart) #unix_socket_group = ''\t# (change requires restart) #unix_socket_permissions = 0777\t# begin with 0 to use octal notation # (change requires restart) #bonjour = off\t# advertise server via Bonjour # (change requires restart) #bonjour_name = ''\t# defaults to the computer name # (change requires restart) # - TCP settings - # see \u0026quot;man tcp\u0026quot; for details #tcp_keepalives_idle = 0\t# TCP_KEEPIDLE, in seconds; # 0 selects the system default #tcp_keepalives_interval = 0\t# TCP_KEEPINTVL, in seconds; # 0 selects the system default #tcp_keepalives_count = 0\t# TCP_KEEPCNT; # 0 selects the system default #tcp_user_timeout = 0\t# TCP_USER_TIMEOUT, in milliseconds; # 0 selects the system default # - Authentication - #authentication_timeout = 1min\t# 1s-600s #password_encryption = md5\t# md5 or scram-sha-256 #db_user_namespace = off # GSSAPI using Kerberos #krb_server_keyfile = 'FILE:${sysconfdir}/krb5.keytab' #krb_caseins_users = off # - SSL - #ssl = off #ssl_ca_file = '' #ssl_cert_file = 'server.crt' #ssl_crl_file = '' #ssl_key_file = 'server.key' #ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL' # allowed SSL ciphers #ssl_prefer_server_ciphers = on #ssl_ecdh_curve = 'prime256v1' #ssl_min_protocol_version = 'TLSv1.2' #ssl_max_protocol_version = '' #ssl_dh_params_file = '' #ssl_passphrase_command = '' #ssl_passphrase_command_supports_reload = off #------------------------------------------------------------------------------ # RESOURCE USAGE (except WAL) #------------------------------------------------------------------------------ # - Memory - shared_buffers = 128MB\t# min 128kB # (change requires restart) #huge_pages = try\t# on, off, or try # (change requires restart) #temp_buffers = 8MB\t# min 800kB #max_prepared_transactions = 0\t# zero disables the feature # (change requires restart) # Caution: it is not advisable to set max_prepared_transactions nonzero unless # you actively intend to use prepared transactions. #work_mem = 4MB\t# min 64kB #hash_mem_multiplier = 1.0\t# 1-1000.0 multiplier on hash table work_mem #maintenance_work_mem = 64MB\t# min 1MB #autovacuum_work_mem = -1\t# min 1MB, or -1 to use maintenance_work_mem #logical_decoding_work_mem = 64MB\t# min 64kB #max_stack_depth = 2MB\t# min 100kB #shared_memory_type = mmap\t# the default is the first option # supported by the operating system: # mmap # sysv # windows # (change requires restart) dynamic_shared_memory_type = posix\t# the default is the first option # supported by the operating system: # posix # sysv # windows # mmap # (change requires restart) # - Disk - #temp_file_limit = -1\t# limits per-process temp file space # in kilobytes, or -1 for no limit # - Kernel Resources - #max_files_per_process = 1000\t# min 64 # (change requires restart) # - Cost-Based Vacuum Delay - #vacuum_cost_delay = 0\t# 0-100 milliseconds (0 disables) #vacuum_cost_page_hit = 1\t# 0-10000 credits #vacuum_cost_page_miss = 10\t# 0-10000 credits #vacuum_cost_page_dirty = 20\t# 0-10000 credits #vacuum_cost_limit = 200\t# 1-10000 credits # - Background Writer - #bgwriter_delay = 200ms\t# 10-10000ms between rounds #bgwriter_lru_maxpages = 100\t# max buffers written/round, 0 disables #bgwriter_lru_multiplier = 2.0\t# 0-10.0 multiplier on buffers scanned/round #bgwriter_flush_after = 512kB\t# measured in pages, 0 disables # - Asynchronous Behavior - #effective_io_concurrency = 1\t# 1-1000; 0 disables prefetching #maintenance_io_concurrency = 10\t# 1-1000; 0 disables prefetching #max_worker_processes = 8\t# (change requires restart) #max_parallel_maintenance_workers = 2\t# taken from max_parallel_workers #max_parallel_workers_per_gather = 2\t# taken from max_parallel_workers #parallel_leader_participation = on #max_parallel_workers = 8\t# maximum number of max_worker_processes that # can be used in parallel operations #old_snapshot_threshold = -1\t# 1min-60d; -1 disables; 0 is immediate # (change requires restart) #backend_flush_after = 0\t# measured in pages, 0 disables #------------------------------------------------------------------------------ # WRITE-AHEAD LOG #------------------------------------------------------------------------------ # - Settings - #wal_level = replica\t# minimal, replica, or logical # (change requires restart) #fsync = on\t# flush data to disk for crash safety # (turning this off can cause # unrecoverable data corruption) #synchronous_commit = on\t# synchronization level; # off, local, remote_write, remote_apply, or on #wal_sync_method = fsync\t# the default is the first option # supported by the operating system: # open_datasync # fdatasync (default on Linux and FreeBSD) # fsync # fsync_writethrough # open_sync #full_page_writes = on\t# recover from partial page writes #wal_compression = off\t# enable compression of full-page writes #wal_log_hints = off\t# also do full page writes of non-critical updates # (change requires restart) #wal_init_zero = on\t# zero-fill new WAL files #wal_recycle = on\t# recycle WAL files #wal_buffers = -1\t# min 32kB, -1 sets based on shared_buffers # (change requires restart) #wal_writer_delay = 200ms\t# 1-10000 milliseconds #wal_writer_flush_after = 1MB\t# measured in pages, 0 disables #wal_skip_threshold = 2MB #commit_delay = 0\t# range 0-100000, in microseconds #commit_siblings = 5\t# range 1-1000 # - Checkpoints - #checkpoint_timeout = 5min\t# range 30s-1d max_wal_size = 1GB min_wal_size = 80MB #checkpoint_completion_target = 0.5\t# checkpoint target duration, 0.0 - 1.0 #checkpoint_flush_after = 256kB\t# measured in pages, 0 disables #checkpoint_warning = 30s\t# 0 disables # - Archiving - #archive_mode = off\t# enables archiving; off, on, or always # (change requires restart) #archive_command = ''\t# command to use to archive a logfile segment # placeholders: %p = path of file to archive # %f = file name only # e.g. 'test ! -f /mnt/server/archivedir/%f \u0026amp;\u0026amp; cp %p /mnt/server/archivedir/%f' #archive_timeout = 0\t# force a logfile segment switch after this # number of seconds; 0 disables # - Archive Recovery - # These are only used in recovery mode. #restore_command = ''\t# command to use to restore an archived logfile segment # placeholders: %p = path of file to restore # %f = file name only # e.g. 'cp /mnt/server/archivedir/%f %p' # (change requires restart) #archive_cleanup_command = ''\t# command to execute at every restartpoint #recovery_end_command = ''\t# command to execute at completion of recovery # - Recovery Target - # Set these only when performing a targeted recovery. #recovery_target = ''\t# 'immediate' to end recovery as soon as a # consistent state is reached # (change requires restart) #recovery_target_name = ''\t# the named restore point to which recovery will proceed # (change requires restart) #recovery_target_time = ''\t# the time stamp up to which recovery will proceed # (change requires restart) #recovery_target_xid = ''\t# the transaction ID up to which recovery will proceed # (change requires restart) #recovery_target_lsn = ''\t# the WAL LSN up to which recovery will proceed # (change requires restart) #recovery_target_inclusive = on # Specifies whether to stop: # just after the specified recovery target (on) # just before the recovery target (off) # (change requires restart) #recovery_target_timeline = 'latest'\t# 'current', 'latest', or timeline ID # (change requires restart) #recovery_target_action = 'pause'\t# 'pause', 'promote', 'shutdown' # (change requires restart) #------------------------------------------------------------------------------ # REPLICATION #------------------------------------------------------------------------------ # - Sending Servers - # Set these on the master and on any standby that will send replication data. #max_wal_senders = 10\t# max number of walsender processes # (change requires restart) #wal_keep_size = 0\t# in megabytes; 0 disables #max_slot_wal_keep_size = -1\t# in megabytes; -1 disables #wal_sender_timeout = 60s\t# in milliseconds; 0 disables #max_replication_slots = 10\t# max number of replication slots # (change requires restart) #track_commit_timestamp = off\t# collect timestamp of transaction commit # (change requires restart) # - Master Server - # These settings are ignored on a standby server. #synchronous_standby_names = ''\t# standby servers that provide sync rep # method to choose sync standbys, number of sync standbys, # and comma-separated list of application_name # from standby(s); '*' = all #vacuum_defer_cleanup_age = 0\t# number of xacts by which cleanup is delayed # - Standby Servers - # These settings are ignored on a master server. #primary_conninfo = ''\t# connection string to sending server #primary_slot_name = ''\t# replication slot on sending server #promote_trigger_file = ''\t# file name whose presence ends recovery #hot_standby = on\t# \u0026quot;off\u0026quot; disallows queries during recovery # (change requires restart) #max_standby_archive_delay = 30s\t# max delay before canceling queries # when reading WAL from archive; # -1 allows indefinite delay #max_standby_streaming_delay = 30s\t# max delay before canceling queries # when reading streaming WAL; # -1 allows indefinite delay #wal_receiver_create_temp_slot = off\t# create temp slot if primary_slot_name # is not set #wal_receiver_status_interval = 10s\t# send replies at least this often # 0 disables #hot_standby_feedback = off\t# send info from standby to prevent # query conflicts #wal_receiver_timeout = 60s\t# time that receiver waits for # communication from master # in milliseconds; 0 disables #wal_retrieve_retry_interval = 5s\t# time to wait before retrying to # retrieve WAL after a failed attempt #recovery_min_apply_delay = 0\t# minimum delay for applying changes during recovery # - Subscribers - # These settings are ignored on a publisher. #max_logical_replication_workers = 4\t# taken from max_worker_processes # (change requires restart) #max_sync_workers_per_subscription = 2\t# taken from max_logical_replication_workers #------------------------------------------------------------------------------ # QUERY TUNING #------------------------------------------------------------------------------ # - Planner Method Configuration - #enable_bitmapscan = on #enable_hashagg = on #enable_hashjoin = on #enable_indexscan = on #enable_indexonlyscan = on #enable_material = on #enable_mergejoin = on #enable_nestloop = on #enable_parallel_append = on #enable_seqscan = on #enable_sort = on #enable_incremental_sort = on #enable_tidscan = on #enable_partitionwise_join = off #enable_partitionwise_aggregate = off #enable_parallel_hash = on #enable_partition_pruning = on # - Planner Cost Constants - #seq_page_cost = 1.0\t# measured on an arbitrary scale #random_page_cost = 4.0\t# same scale as above #cpu_tuple_cost = 0.01\t# same scale as above #cpu_index_tuple_cost = 0.005\t# same scale as above #cpu_operator_cost = 0.0025\t# same scale as above #parallel_tuple_cost = 0.1\t# same scale as above #parallel_setup_cost = 1000.0\t# same scale as above #jit_above_cost = 100000\t# perform JIT compilation if available # and query more expensive than this; # -1 disables #jit_inline_above_cost = 500000\t# inline small functions if query is # more expensive than this; -1 disables #jit_optimize_above_cost = 500000\t# use expensive JIT optimizations if # query is more expensive than this; # -1 disables #min_parallel_table_scan_size = 8MB #min_parallel_index_scan_size = 512kB #effective_cache_size = 4GB # - Genetic Query Optimizer - #geqo = on #geqo_threshold = 12 #geqo_effort = 5\t# range 1-10 #geqo_pool_size = 0\t# selects default based on effort #geqo_generations = 0\t# selects default based on effort #geqo_selection_bias = 2.0\t# range 1.5-2.0 #geqo_seed = 0.0\t# range 0.0-1.0 # - Other Planner Options - #default_statistics_target = 100\t# range 1-10000 #constraint_exclusion = partition\t# on, off, or partition #cursor_tuple_fraction = 0.1\t# range 0.0-1.0 #from_collapse_limit = 8 #join_collapse_limit = 8\t# 1 disables collapsing of explicit # JOIN clauses #force_parallel_mode = off #jit = on\t# allow JIT compilation #plan_cache_mode = auto\t# auto, force_generic_plan or # force_custom_plan #------------------------------------------------------------------------------ # REPORTING AND LOGGING #------------------------------------------------------------------------------ # - Where to Log - #log_destination = 'stderr'\t# Valid values are combinations of # stderr, csvlog, syslog, and eventlog, # depending on platform. csvlog # requires logging_collector to be on. # This is used when logging to stderr: logging_collector = on\t# Enable capturing of stderr and csvlog # into log files. Required to be on for # csvlogs. # (change requires restart) # These are only used if logging_collector is on: log_directory = 'log'\t# directory where log files are written, # can be absolute or relative to PGDATA log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\t# log file name pattern, # can include strftime() escapes log_file_mode = 0600\t# creation mode for log files, # begin with 0 to use octal notation #log_truncate_on_rotation = off\t# If on, an existing log file with the # same name as the new log file will be # truncated rather than appended to. # But such truncation only occurs on # time-driven rotation, not on restarts # or size-driven rotation. Default is # off, meaning append to existing files # in all cases. #log_rotation_age = 1d\t# Automatic rotation of logfiles will # happen after that time. 0 disables. #log_rotation_size = 10MB\t# Automatic rotation of logfiles will # happen after that much log output. # 0 disables. # These are relevant when logging to syslog: #syslog_facility = 'LOCAL0' #syslog_ident = 'postgres' #syslog_sequence_numbers = on #syslog_split_messages = on # This is only relevant when logging to eventlog (win32): # (change requires restart) #event_source = 'PostgreSQL' # - When to Log - #log_min_messages = warning\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # info # notice # warning # error # log # fatal # panic #log_min_error_statement = error\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # info # notice # warning # error # log # fatal # panic (effectively off) #log_min_duration_statement = -1\t# -1 is disabled, 0 logs all statements # and their durations, \u0026gt; 0 logs only # statements running at least this number # of milliseconds #log_min_duration_sample = -1\t# -1 is disabled, 0 logs a sample of statements # and their durations, \u0026gt; 0 logs only a sample of # statements running at least this number # of milliseconds; # sample fraction is determined by log_statement_sample_rate #log_statement_sample_rate = 1.0\t# fraction of logged statements exceeding # log_min_duration_sample to be logged; # 1.0 logs all such statements, 0.0 never logs #log_transaction_sample_rate = 0.0\t# fraction of transactions whose statements # are logged regardless of their duration; 1.0 logs all # statements from all transactions, 0.0 never logs # - What to Log - #debug_print_parse = off #debug_print_rewritten = off #debug_print_plan = off #debug_pretty_print = on #log_checkpoints = off #log_connections = off #log_disconnections = off #log_duration = off #log_error_verbosity = default\t# terse, default, or verbose messages #log_hostname = off #log_line_prefix = '%m [%p] '\t# special values: # %a = application name # %u = user name # %d = database name # %r = remote host and port # %h = remote host # %b = backend type # %p = process ID # %t = timestamp without milliseconds # %m = timestamp with milliseconds # %n = timestamp with milliseconds (as a Unix epoch) # %i = command tag # %e = SQL state # %c = session ID # %l = session line number # %s = session start timestamp # %v = virtual transaction ID # %x = transaction ID (0 if none) # %q = stop here in non-session # processes # %% = '%' # e.g. '\u0026lt;%u%%%d\u0026gt; ' #log_lock_waits = off\t# log lock waits \u0026gt;= deadlock_timeout #log_parameter_max_length = -1\t# when logging statements, limit logged # bind-parameter values to N bytes; # -1 means print in full, 0 disables #log_parameter_max_length_on_error = 0\t# when logging an error, limit logged # bind-parameter values to N bytes; # -1 means print in full, 0 disables log_statement = 'all'\t# none, ddl, mod, all #log_replication_commands = off #log_temp_files = -1\t# log temporary files equal or larger # than the specified size in kilobytes; # -1 disables, 0 logs all temp files log_timezone = 'UTC' #------------------------------------------------------------------------------ # PROCESS TITLE #------------------------------------------------------------------------------ #cluster_name = ''\t# added to process titles if nonempty # (change requires restart) #update_process_title = on #------------------------------------------------------------------------------ # STATISTICS #------------------------------------------------------------------------------ # - Query and Index Statistics Collector - #track_activities = on #track_counts = on #track_io_timing = off #track_functions = none\t# none, pl, all #track_activity_query_size = 1024\t# (change requires restart) #stats_temp_directory = 'pg_stat_tmp' # - Monitoring - #log_parser_stats = off #log_planner_stats = off #log_executor_stats = off #log_statement_stats = off #------------------------------------------------------------------------------ # AUTOVACUUM #------------------------------------------------------------------------------ #autovacuum = on\t# Enable autovacuum subprocess? 'on' # requires track_counts to also be on. #log_autovacuum_min_duration = -1\t# -1 disables, 0 logs all actions and # their durations, \u0026gt; 0 logs only # actions running at least this number # of milliseconds. #autovacuum_max_workers = 3\t# max number of autovacuum subprocesses # (change requires restart) #autovacuum_naptime = 1min\t# time between autovacuum runs #autovacuum_vacuum_threshold = 50\t# min number of row updates before # vacuum #autovacuum_vacuum_insert_threshold = 1000\t# min number of row inserts # before vacuum; -1 disables insert # vacuums #autovacuum_analyze_threshold = 50\t# min number of row updates before # analyze #autovacuum_vacuum_scale_factor = 0.2\t# fraction of table size before vacuum #autovacuum_vacuum_insert_scale_factor = 0.2\t# fraction of inserts over table # size before insert vacuum #autovacuum_analyze_scale_factor = 0.1\t# fraction of table size before analyze #autovacuum_freeze_max_age = 200000000\t# maximum XID age before forced vacuum # (change requires restart) #autovacuum_multixact_freeze_max_age = 400000000\t# maximum multixact age # before forced vacuum # (change requires restart) #autovacuum_vacuum_cost_delay = 2ms\t# default vacuum cost delay for # autovacuum, in milliseconds; # -1 means use vacuum_cost_delay #autovacuum_vacuum_cost_limit = -1\t# default vacuum cost limit for # autovacuum, -1 means use # vacuum_cost_limit #------------------------------------------------------------------------------ # CLIENT CONNECTION DEFAULTS #------------------------------------------------------------------------------ # - Statement Behavior - #client_min_messages = notice\t# values in order of decreasing detail: # debug5 # debug4 # debug3 # debug2 # debug1 # log # notice # warning # error #search_path = '\u0026quot;$user\u0026quot;, public'\t# schema names #row_security = on #default_tablespace = ''\t# a tablespace name, '' uses the default #temp_tablespaces = ''\t# a list of tablespace names, '' uses # only default tablespace #default_table_access_method = 'heap' #check_function_bodies = on #default_transaction_isolation = 'read committed' #default_transaction_read_only = off #default_transaction_deferrable = off #session_replication_role = 'origin' #statement_timeout = 0\t# in milliseconds, 0 is disabled #lock_timeout = 0\t# in milliseconds, 0 is disabled #idle_in_transaction_session_timeout = 0\t# in milliseconds, 0 is disabled #vacuum_freeze_min_age = 50000000 #vacuum_freeze_table_age = 150000000 #vacuum_multixact_freeze_min_age = 5000000 #vacuum_multixact_freeze_table_age = 150000000 #vacuum_cleanup_index_scale_factor = 0.1\t# fraction of total number of tuples # before index cleanup, 0 always performs # index cleanup #bytea_output = 'hex'\t# hex, escape #xmlbinary = 'base64' #xmloption = 'content' #gin_fuzzy_search_limit = 0 #gin_pending_list_limit = 4MB # - Locale and Formatting - datestyle = 'iso, mdy' #intervalstyle = 'postgres' timezone = 'UTC' #timezone_abbreviations = 'Default' # Select the set of available time zone # abbreviations. Currently, there are # Default # Australia (historical usage) # India # You can create your own file in # share/timezonesets/. #extra_float_digits = 1\t# min -15, max 3; any value \u0026gt;0 actually # selects precise output mode #client_encoding = sql_ascii\t# actually, defaults to database # encoding # These settings are initialized by initdb, but they can be changed. lc_messages = 'en_US.utf8'\t# locale for system error message # strings lc_monetary = 'en_US.utf8'\t# locale for monetary formatting lc_numeric = 'en_US.utf8'\t# locale for number formatting lc_time = 'en_US.utf8'\t# locale for time formatting # default configuration for text search default_text_search_config = 'pg_catalog.english' # - Shared Library Preloading - #shared_preload_libraries = ''\t# (change requires restart) #local_preload_libraries = '' #session_preload_libraries = '' #jit_provider = 'llvmjit'\t# JIT library to use # - Other Defaults - #dynamic_library_path = '$libdir' #------------------------------------------------------------------------------ # LOCK MANAGEMENT #------------------------------------------------------------------------------ #deadlock_timeout = 1s #max_locks_per_transaction = 64\t# min 10 # (change requires restart) #max_pred_locks_per_transaction = 64\t# min 10 # (change requires restart) #max_pred_locks_per_relation = -2\t# negative values mean # (max_pred_locks_per_transaction # / -max_pred_locks_per_relation) - 1 #max_pred_locks_per_page = 2 # min 0 #------------------------------------------------------------------------------ # VERSION AND PLATFORM COMPATIBILITY #------------------------------------------------------------------------------ # - Previous PostgreSQL Versions - #array_nulls = on #backslash_quote = safe_encoding\t# on, off, or safe_encoding #escape_string_warning = on #lo_compat_privileges = off #operator_precedence_warning = off #quote_all_identifiers = off #standard_conforming_strings = on #synchronize_seqscans = on # - Other Platforms and Clients - #transform_null_equals = off #------------------------------------------------------------------------------ # ERROR HANDLING #------------------------------------------------------------------------------ #exit_on_error = off\t# terminate session on any error? #restart_after_crash = on\t# reinitialize after backend crash? #data_sync_retry = off\t# retry or panic on failure to fsync # data? # (change requires restart) #------------------------------------------------------------------------------ # CONFIG FILE INCLUDES #------------------------------------------------------------------------------ # These options allow settings to be loaded from files other than the # default postgresql.conf. Note that these are directives, not variable # assignments, so they can usefully be given more than once. #include_dir = '...'\t# include files ending in '.conf' from # a directory, e.g., 'conf.d' #include_if_exists = '...'\t# include file only if it exists #include = '...'\t# include file #------------------------------------------------------------------------------ # CUSTOMIZED OPTIONS #------------------------------------------------------------------------------ # Add settings for extensions here 我只改了局部配置，如果需要知道改了哪些项，可以拿安装包中的配置文件的和该配置文件对比，或者参考教程。\n参考教程  postgres 查看历史sql执行记录  ","description":"","id":406,"section":"notes","tags":null,"title":"PostgreSQL配置显示SQL执行记录","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/postgresql%E9%85%8D%E7%BD%AE%E6%98%BE%E7%A4%BAsql%E6%89%A7%E8%A1%8C%E8%AE%B0%E5%BD%95/"},{"content":"使用新的环境变量方案，旧的环境变量都需要删除：\n再网上找了一圈没有找到删除的方案，最后自己给试出来了。\n","description":"","id":407,"section":"notes","tags":null,"title":"Postman删除环境变量","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%88%A0%E9%99%A4%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"之所以研究这个技术，主要我通过EasyYapi导出到Postman的频率太高了，每次导出都需要重新填写Header，不是很舒服。我开发了如下脚本：\n pm.request.headers.remove(\u0026quot;Sdtc-Tenant-Id\u0026quot;) pm.request.headers.add({ key: \u0026quot;token\u0026quot;, value: \u0026quot;{{token}}\u0026quot; }) pm.request.headers.add({ key: \u0026quot;Sdtc-Tenant-Id\u0026quot;, value: \u0026quot;12345678910\u0026quot; }) 参考资料  Scripting with request data  ","description":"","id":408,"section":"notes","tags":null,"title":"Postman发起请求前自动添加Header","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%8F%91%E8%B5%B7%E8%AF%B7%E6%B1%82%E5%89%8D%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0header/"},{"content":"左右布局用起来非常的不方便，就莫名其妙的变成了左右布局！！！\n参考资料  postman界面变成了左右结构怎么办  ","description":"","id":409,"section":"notes","tags":null,"title":"Postman变成了左右布局","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%8F%98%E6%88%90%E4%BA%86%E5%B7%A6%E5%8F%B3%E5%B8%83%E5%B1%80/"},{"content":"如图，Content-Type的值为application/x-www-form-urlencoded时，会提示json无法解析。\n","description":"","id":410,"section":"notes","tags":null,"title":"Postman因传递错误的Content-Type导致传递的json无法正常解析","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%9B%A0%E4%BC%A0%E9%80%92%E9%94%99%E8%AF%AF%E7%9A%84content-type%E5%AF%BC%E8%87%B4%E4%BC%A0%E9%80%92%E7%9A%84json%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E8%A7%A3%E6%9E%90/"},{"content":"应用场景不用多说吧，只是可惜了，导出来的curl在windows上执行不了。\n这个code按钮还是有很多东西可以研究的，我之后研究下：\n20211008后续 新版本的导出按钮移动到了这块：\n参考资料  Postman 导出 curl命令 到命令行运行 Mac OS  ","description":"","id":411,"section":"notes","tags":null,"title":"Postman导出curl指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E5%AF%BC%E5%87%BAcurl%E6%8C%87%E4%BB%A4/"},{"content":"我机器出现这个问题的原因是因为我的内存不足，公司为我分配的开发主机内存位16G，但是真正能够使用的是有60%，一旦到了60%就无法正常分配内存了，具体表现为：\n Chrome总是报内存分配错误，且会出现黑屏 Idea无法正常启动服务，也会报内存错误，即使为其设置了近20G的堆大小 Postman打开后总是灰屏  ","description":"","id":412,"section":"notes","tags":null,"title":"Postman总是灰屏","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E6%80%BB%E6%98%AF%E7%81%B0%E5%B1%8F/"},{"content":"场景是这样的，我们local和dev共用一套token，之前的脚本中我将通过如下方法设置到了当前环境中，所以当我切换环境的时候我不得不重新运行一次登录脚本。\n1 2 3  postman.setEnvironmentVariable(\u0026#39;token\u0026#39;, token)   因为我需要高频率的在local和dev环境间切换，所以我希望我的登录脚本能够将获取的token信息保存在全局变量中，然后在当前环境中通过一个变量中引用全局变量，从而实现一次登录应用不同的环境。\n我登录脚本代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  var token var login_address const loginRequestDev = { url: \u0026#39;http://dev.4dshoetech.local/backend/authcenter/login/login\u0026#39;, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;junjie001@qq.com\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;Hello123\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } const loginRequestSit = { url: \u0026#39;http://sit.4dshoetech.local/backend/authcenter/login/login\u0026#39;, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;502\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;123456\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } pm.sendRequest(loginRequestDev,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token pm.globals.set(\u0026#34;dev_token\u0026#34;, token); console.log(response.data.token); } }); pm.sendRequest(loginRequestSit,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token pm.globals.set(\u0026#34;sit_token\u0026#34;, token); console.log(response.data.token); } });   我global和local、dev、sit配置如下：\n在使用token时，只需要如下配置，就可以实现只运行一次登录脚本，不同环境中使用：\n参考资料  Postman配置全局变量与环境变量详细教程 postman 设置全局变量  ","description":"","id":413,"section":"notes","tags":null,"title":"Postman用脚本设置全局变量","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E7%94%A8%E8%84%9A%E6%9C%AC%E8%AE%BE%E7%BD%AE%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F/"},{"content":"升级内存到32G后，Postman几乎没有出现过任何问题\n我把这路径记一记，因为我感觉我随时要去整它，Postman好几个版本在我公司电脑上老是出问题，糟心。\nC:\\Users\\wujj\\AppData\\Local\\Postman\n","description":"","id":414,"section":"notes","tags":null,"title":"Postman的安装路径","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/%E4%BD%9C%E5%BA%9F/postman%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/"},{"content":"这个功能结合Chrome的Copy As Curl使用，非常的赞：\n","description":"","id":415,"section":"notes","tags":null,"title":"Postman的导入功能","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E7%9A%84%E5%AF%BC%E5%85%A5%E5%8A%9F%E8%83%BD/"},{"content":"问题描述  完成了一个postman的脚本（可以在该分类下找到该脚本源码），用于在请求时自动计算签名，使用该脚本时发现绝大多数请求的签名校验成功，部分签名校验失败 将这个请求的data部分替换掉，则签名校验成功（我们签名验证部分是需要将data计算在内的）  解决流程  postman打印所所有用于签名的字段，用java中的方法进行md5计算，计算结果与postman计算结果一致 网关断点调试，发现计算出来的签名与postman计算出来的请求不一致 截取网关请求，截取postman请求，截取计算签名时用的data的请求，发现data与postman处不一致  原因分析  postman脚本中拿data计算签名时，用到了JSON.parse(request.data)，JSON.parse()反序列化时存在精度丢失的问题 而我们的请求中，memberId的字段太长了，且是数字类型，就刚好撞到这个问题上  解决方案  将memberId字段换成String，或者截断一点（我采用的方案） 不使用JSON.parse()，使用JsonPath直接拿数据（Postman貌似不支持引入JsonPath模块） 不使用JSON.parse()，使用正则表达式提取data部分（不是很想搞，太麻烦了，哈哈）  ","description":"","id":416,"section":"notes","tags":null,"title":"Postman解决使用签名脚本，部分接口签名校验失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8%E7%AD%BE%E5%90%8D%E8%84%9A%E6%9C%AC%E9%83%A8%E5%88%86%E6%8E%A5%E5%8F%A3%E7%AD%BE%E5%90%8D%E6%A0%A1%E9%AA%8C%E5%A4%B1%E8%B4%A5/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  var token const loginRequest = { url: login_url, method: \u0026#39;POST\u0026#39;, header: \u0026#39;Content-Type: application/json\u0026#39;, body: { mode: \u0026#39;raw\u0026#39;, raw: JSON.stringify({\u0026#34;account\u0026#34;:\u0026#34;junjie001@qq.com\u0026#34;,\u0026#34;pass\u0026#34;:\u0026#34;Hello123\u0026#34;,\u0026#34;level\u0026#34;:1,\u0026#34;inviteId\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;type\u0026#34;:0}) } } pm.sendRequest(loginRequest,function(err,res){ if(err) { console.log(err) } else { var response = JSON.parse(res.text()); token = response.data.token postman.setEnvironmentVariable(\u0026#39;token\u0026#39;, token) console.log(response.data.token); } });   参考教程  Postman脚本中发送请求 js字符串转换为对象格式 Postman：脚本应用_预请求脚本  ","description":"","id":417,"section":"notes","tags":null,"title":"Postman请求前获取Token","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%AF%B7%E6%B1%82%E5%89%8D%E8%8E%B7%E5%8F%96token/"},{"content":"相关操作  如图，点击Postman的Pre-request Script选项卡:  填写如下代码：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  var CryptoJS = require(\u0026#34;crypto-js\u0026#34;); // select channel_app_id,sign_secret from mmp_brand_channel_app; var channelIdToAppSecret = { \u0026#34;11111111\u0026#34;:\u0026#34;11111111111111111111111111111111\u0026#34;, \u0026#34;300000001\u0026#34;:\u0026#34;300000001300000001300000001300000001\u0026#34;, \u0026#34;300000002\u0026#34;:\u0026#34;300000002300000002300000002300000002\u0026#34;, \u0026#34;300000003\u0026#34;:\u0026#34;300000003300000003300000003300000003\u0026#34;, \u0026#34;300000004\u0026#34;:\u0026#34;300000004300000004300000004300000004\u0026#34; } var body = JSON.parse(request.data) var appId = body.appId var appSecret = channelIdToAppSecret[appId] var timestamp = Date.parse(new Date()) / 1000 var data = JSON.stringify(body.data) var sign = CryptoJS.MD5(appId + appSecret + timestamp + data).toString().toUpperCase() console.log(appId) console.log(appSecret) console.log(timestamp) console.log(sign) console.log(data) postman.setEnvironmentVariable(\u0026#39;timestamp\u0026#39;, timestamp); postman.setEnvironmentVariable(\u0026#39;sign\u0026#39;, sign);   改写请求的body（请求参数和Header也支持双大括号语法）  1 2 3 4 5 6 7 8 9 10  { \u0026#34;brandId\u0026#34;: 100000001, \u0026#34;channelId\u0026#34;: 200000001, \u0026#34;appId\u0026#34;: 300000001, \u0026#34;timestamp\u0026#34;: \u0026#34;{{timestamp}}\u0026#34;, \u0026#34;sign\u0026#34;: \u0026#34;{{sign}}\u0026#34;, \u0026#34;data\u0026#34;:{\u0026#34;cardId\u0026#34;:\u0026#34;1400000002\u0026#34;,\u0026#34;outTradeNo\u0026#34;:\u0026#34;123555\u0026#34;,\u0026#34;appUserId\u0026#34;:\u0026#34;zhenye\u0026#34;} }   相关教程  使用postman生成md5签名 postman 发送MD5加密签名请求  ","description":"","id":418,"section":"notes","tags":null,"title":"Postman请求时自动完成md5计算","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/postman%E8%AF%B7%E6%B1%82%E6%97%B6%E8%87%AA%E5%8A%A8%E5%AE%8C%E6%88%90md5%E8%AE%A1%E7%AE%97/"},{"content":"这个东西用的比较少，今天看书时遇到了，整理一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public static void main(String[] args) throws IOException { ServerSocket serverSocket = new ServerSocket(7000); Socket clientSocket = serverSocket.accept(); BufferedReader br = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); PrintWriter pw = new PrintWriter(clientSocket.getOutputStream(), true); String request, response; while ((request = br.readLine()) != null) { if (\u0026#34;Done\u0026#34;.equals(request)) { break; } response = request; pw.println(response); } }   ","description":"","id":419,"section":"notes","tags":null,"title":"PrintWriter用法案例","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/printwriter%E7%94%A8%E6%B3%95%E6%A1%88%E4%BE%8B/"},{"content":"我之前启动服务时使用不同的配置使用的profiles.profiles.active，但是我最近发现这个配置的不便之处，我的每个测试类都需要配置（如果使用的不是默认的配置文件），如果我需要修改Spring的profile，我还得为每个测试类进行修改，但是使用Maven的profile配置就不存在这个问题。\n","description":"","id":420,"section":"notes","tags":null,"title":"Profile配置在实践中使用起来很舒服","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/profile%E9%85%8D%E7%BD%AE%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%B5%B7%E6%9D%A5%E5%BE%88%E8%88%92%E6%9C%8D/"},{"content":"操作步骤  准备编译工具   apt update \u0026amp;\u0026amp; apt install pve-headers-$(uname -r) build-essential 从如下地址下载驱动源码   https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software 解压并编译   tar xvf r8125-9.004.01.tar cd r8125-9.004.01 make 安装驱动   cd src mkdir -p /lib/modules/5.4.78-2-pve/kernel/drivers/net/ethernet/realtek/ install -m 644 -o root r8125.ko /lib/modules/5.4.78-2-pve/kernel/drivers/net/ethernet/realtek/ # 20211011 mkdir -p /lib/modules/5.11.22-5-pve/kernel/drivers/net/ethernet/realtek/ install -m 644 -o root r8125.ko /lib/modules/5.11.22-5-pve/kernel/drivers/net/ethernet/realtek/ /sbin/depmod `uname -r` /sbin/modprobe r8125 检验安装结果并重启   lsmod | grep r8125 modinfo r8125 reboot 个人小结 1.我贴出来的代码，是在我的机器上实际使用的代码（除了驱动版本号与代码中的不符合），教程中提到了装dkms，但是我无法安装该工具，遂放弃。\n参考教程  给PVE6添加Realtek 8125 2.5G网卡驱动  ","description":"","id":421,"section":"notes","tags":null,"title":"Promox VE 6.3装Realtek 8125 2.5G网卡驱动","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/promox-ve-6.3%E8%A3%85realtek-8125-2.5g%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"content":"SpringBoot集成MyBatis-Plus后，启动时报如下错误：\n org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'userMapper' defined in file [D:\\Project\\Mybatis\\target\\classes\\fun\\junjie\\mybatis\\mapper\\UserMapper.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1794) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:516) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:324) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:322) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:878) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) ~[spring-context-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:405) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226) [spring-boot-2.3.7.RELEASE.jar:2.3.7.RELEASE] at fun.junjie.mybatis.MybatisApplication.main(MybatisApplication.java:12) [classes/:na] Caused by: java.lang.IllegalArgumentException: Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required at org.springframework.util.Assert.notNull(Assert.java:201) ~[spring-core-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.mybatis.spring.support.SqlSessionDaoSupport.checkDaoConfig(SqlSessionDaoSupport.java:122) ~[mybatis-spring-2.0.6.jar:2.0.6] at org.mybatis.spring.mapper.MapperFactoryBean.checkDaoConfig(MapperFactoryBean.java:73) ~[mybatis-spring-2.0.6.jar:2.0.6] at org.springframework.dao.support.DaoSupport.afterPropertiesSet(DaoSupport.java:44) ~[spring-tx-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1853) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1790) ~[spring-beans-5.2.12.RELEASE.jar:5.2.12.RELEASE] ... 16 common frames omitted 经过分析发现，是我依赖引入错误：\n 原来： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 改为： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 参考资料  java.lang.IllegalArgumentException: Property \u0026lsquo;sqlSessionFactory\u0026rsquo; or \u0026lsquo;sqlSessionTemplate\u0026rsquo; are require  ","description":"","id":422,"section":"notes","tags":null,"title":"Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/property-sqlsessionfactory-or-sqlsessiontemplate-are-required/"},{"content":"简单的实验 proto如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  syntax = \u0026#34;proto3\u0026#34;;message SearchRequest3 { enum Corpus{ UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } string query = 1; int32 page_number = 2; int32 result_per_page = 3; Corpus corpus = 4;}  java代码如下：\n1 2 3 4 5 6 7 8  SearchRequest3OuterClass.SearchRequest3.newBuilder() .setQuery(\u0026#34;query\u0026#34;) .setPageNumber(1) .setResultPerPage(1) .setCorpusValue(SearchRequest3OuterClass.SearchRequest3.Corpus.UNIVERSAL.getNumber()) .build();   （感觉代码不是很优雅，还需要持续的学习，寻找更优雅的编码方案）\n为值定义别名 可以通过为不同的枚举常量分配相同的值来定义别名，为此需要经applow_alias选项设置为true，否则协议编辑器将在找到别名时生成错误消息：\n1 2 3 4 5 6 7 8 9 10  message MyMessage1 { enum EnumAllowingAlias { option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1; }}  我是知道java的枚举时不支持修改original的值的，我很好奇这个别名时如何实现的，发现如下源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public enum EnumAllowingAlias implements com.google.protobuf.ProtocolMessageEnum { /** * \u0026lt;code\u0026gt;UNKNOWN = 0;\u0026lt;/code\u0026gt; */ UNKNOWN(0), /** * \u0026lt;code\u0026gt;STARTED = 1;\u0026lt;/code\u0026gt; */ STARTED(1), ; /** * \u0026lt;code\u0026gt;RUNNING = 1;\u0026lt;/code\u0026gt; */ public static final EnumAllowingAlias RUNNING = STARTED; }   有点意思，这是非常巧妙的一种实现方式。\n","description":"","id":423,"section":"notes","tags":null,"title":"Protobuf枚举类型的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/protobuf%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"如下代码，会无限循环，知道堆栈移除：\n1 2 3 4 5 6 7  StudentPOJO.Student item = StudentPOJO.Student.newBuilder() .setId(1) .setName(\u0026#34;100\u0026#34;) .build(); Object o = JSON.toJSON(item);   我使用的jar包版本分别为：\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.protobuf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.76\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":424,"section":"notes","tags":null,"title":"Protobuf生成的实体作为JSON.toJSON的参数时会无限循环","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/protobuf%E7%94%9F%E6%88%90%E7%9A%84%E5%AE%9E%E4%BD%93%E4%BD%9C%E4%B8%BAjson.tojson%E7%9A%84%E5%8F%82%E6%95%B0%E6%97%B6%E4%BC%9A%E6%97%A0%E9%99%90%E5%BE%AA%E7%8E%AF/"},{"content":"ProtoBuf的字段编号 消息定义中的每个字段都有一个唯一的编号。这些字段编号用于在消息二进制格式中标识您的字段，一旦您的消息类型被使用，就不应更改（消息类型被使用了，更改字段编码会影响已有数据的编解码）。\n1到15范围内的字段编号占用一个字节进行编码，包括字段编号和字段类型（您可以在协议缓冲区编码中找到更多相关信息）。16到2047范围内的字段编号占用两个字节。因此，您应该为非常频繁出现的消息元素保留数字1到15。可以为将来可能添加的频繁出现的元素留出一些空间（可以这么理解吧，必填字段用1~15，选填字段使用16~2047）。\n不能使用数字19000到19999，因为它们是为Protocol Buffers实现保留的。同样，也不能使用任何以前保留的字段编号。\n保留字段 保留字段存在的必要性：如果只通过注释或删除字段来更新消息类型，可能导致删除或注释的字段被复用，从而使用新的消息类型解析已有的消息时，会带来困惑。\n确保不会发生这种情况的一种方法是指定已删除字段的字段编号、名称（之所以保留名称，是担心JSON序列化的问题），如果任何未来的用户尝试使用这些字段标识符，协议缓冲区编译器会报错。\n1 2 3 4 5 6  message Foo { reserved 2, 15, 9 to 11; reserved \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;; }   不可以在同一个reserved中混合使用字段名称和字段编号。\n默认值 解析消息时，如果编码的消息不包含特定的singular元素（不是很理解这个前提），则解析对象中的相应字段将设置为该字段的默认值。这些默认值是特定于类型的：\n 对于字符串，默认值为空字符串。 对于字节，默认值为空字节。 对于bool，默认值为false。 对于数字类型，默认值为零。 对于enums，默认值是第一个定义的enum value，它必须是 0。 对于消息字段，未设置该字段。它的确切值取决于语言。有关详细信息，请参阅生成的代码指南。 重复字段的默认值为空（通常是相应语言的空列表）。  请注意，对于标量消息字段，一旦消息被解析，就无法判断字段是否明确设置为默认值（例如，布尔值是否设置为false）或根本没有设置：您应该记住这一点在定义消息类型时。例如，false如果您不希望默认情况下也发生该行为，则不要设置一个布尔值来开启某些行为。还要注意的是，如果一个标消息字段被设置为默认值，该值将不会在电线上连载。\n有关默认值如何在生成的代码中工作的更多详细信息，请参阅所选语言的生成代码指南。\n枚举类型 每个枚举定义都必须包含一个零的常量作为其第一个元素，这是因为：\n 必须有一个零值，以便我们可以使用0作为数字默认值 零值需要是第一个元素，以便与proto2语义兼容，其中第一个枚举值始终是默认值  需要注意的事项：\n 枚举常量必须在32位整数范围内。 由于enum值在线路上使用varint编码，负值效率低下，因此不推荐使用。 可以在消息类型内部或者消息外部定义枚举，这些枚举当前proto文件中的任何消息类型复用。 可以使用_MessageType_._EnumType_使用其他消息内部定义的枚举。  不是很理解的知识 在反序列化期间，无法识别的枚举值将保留在消息中，尽管在反序列化消息时如何表示取决于语言。在支持值超出指定符号范围的开放枚举类型的语言（例如 C++ 和 Go）中，未知枚举值只是作为其底层整数表示存储。在 Java 等具有封闭枚举类型的语言中，枚举中的 case 用于表示无法识别的值，并且可以使用特殊访问器访问底层整数。在任何一种情况下，如果消息被序列化，无法识别的值仍将与消息一起序列化。\n使用其他消息类型作为字段类型 很好理解，看代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  syntax = \u0026#34;proto3\u0026#34;;message SearchResponse { repeated Result results = 1;}message Result { string url = 1; string title = 2; repeated string snippets = 3;}  嵌套类型 代码如下：\n1 2 3 4 5 6 7 8 9 10  message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1;}  要在其父消息类型之外重用此消息类型，类似如下代码：\n1 2 3 4 5  message SomeOtherMessage { SearchResponse.Result result = 1;}  嵌套消息没有层数限制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  message Outer { // Level 0  message MiddleAA { // Level 1  message Inner { // Level 2  int64 ival = 1; bool booly = 2; } } message MiddleBB { // Level 1  message Inner { // Level 2  int32 ival = 1; bool booly = 2; } }}  未知字段 未知字段是格式良好的协议缓冲区序列化数据，表示解析器无法识别的字段。例如，当旧二进制文件用新字段解析新二进制文件发送的数据时，这些新字段将成为旧二进制文件中的未知字段。\n最初，proto3消息在解析过程中总是丢弃未知字段，但在 3.5 版本中，我们重新引入了未知字段的保留以匹配 proto2 行为。在 3.5 及更高版本中，未知字段在解析过程中保留并包含在序列化输出中。\n","description":"","id":425,"section":"notes","tags":null,"title":"Protobuf的基础知识","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/protobuf%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"content":"操作步骤  修改/etc/network/interfaces：   # network interface settings; autogenerated # Please do NOT modify this file directly, unless you know what # you're doing. # # If you want to manage parts of the network configuration manually, # please utilize the 'source' or 'source-directory' directives to do # so. # PVE will preserve these directives, but will NOT read its network # configuration from sourced files, so do not attempt to move any of # the PVE managed interfaces into external files! source /etc/network/interfaces.d/* auto lo iface lo inet loopback iface enx00e04c36028c inet dhcp iface enp2s0 inet manual iface enp3s0 inet manual iface enp4s0 inet manual iface enp5s0 inet manual auto vmbr2 iface vmbr2 inet manual bridge-ports enp2s0 bridge-stp off bridge-fd 0 auto vmbr3 iface vmbr3 inet manual bridge-ports enp3s0 bridge-stp off bridge-fd 0 auto vmbr4 iface vmbr4 inet manual bridge-ports enp4s0 bridge-stp off bridge-fd 0 # 修改的部分在这块，主要修改为该manual为static，增加address、netmask、gateway段 auto vmbr5 iface vmbr5 inet static address 192.168.31.218 netmask 255.255.255.0 gateway 192.168.31.1 bridge-ports enp5s0 bridge-stp off bridge-fd 0 修改/etc/issue（提示文件，随便你改）：   ------------------------------------------------------------------------------ Welcome to the Proxmox Virtual Environment. Please use your web browser to configure this server - connect to: https://192.168.31.218:8006/ ------------------------------------------------------------------------------ 修改etc/hosts：   127.0.0.1\tlocalhost # 改动主要在这块 192.168.31.218\tj4125.home\tj4125 # The following lines are desirable for IPv6 capable hosts ::1 localhost ip6-localhost ip6-loopback ff02::1 ip6-allnodes ff02::2 ip6-allrouters 重启网络   /etc/init.d/networking restart 参考教程   proxmox ve（PVE）修改管理IP地址\n  Proxmox Virtual Environment（PVE）完美的更改IP地址\n  为 Proxmox 配置私有网络\n  ","description":"","id":426,"section":"notes","tags":null,"title":"Proxmox VE修改管理员IP地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/proxmox-ve%E4%BF%AE%E6%94%B9%E7%AE%A1%E7%90%86%E5%91%98ip%E5%9C%B0%E5%9D%80/"},{"content":"这个问题我在4月份的时候已经注意到了，当时折腾的一段时间后没有结果，最后选择了先安装Debian，然后安装PVE 6.x。\n经过一段时间的考虑，我决定大面积的使用PVE（试验机、工具机、J4215都走这套方案），所以我开始系统学习PVE。但是当我开始使用U盘安装该系统的时候，出现了问题，我始终无法进入到安装界面，一致显示如下错误：\n 我原本将问题定位在我的U盘，或官方提供的镜像。经过在群里询问，了解到其他人没有类似的问题，我同时已经尝试了足够多品牌的U盘了，我不想再购买新的U盘进行实验。\n这个时候，我注意到我下载ISO文件的SHA256值和官方提供的SHA256值并不一样，我重新在中文论坛下载ISO文件后，并计算SHA256值，与官网的一致，该问题修复了。\n没有玄学 这个问题已经超出了我的认知范围，为什么官网下载的ISO文件竟然和它自己提供的SHA256值不一样呢。再发现这个问题后，我使用我的下载器又下载了一次该镜像，计算出来的值和前一次、官网的都不一样。我将问题定位到时官网提供的资源有问题。\n实际上这个答案不能让我信服，我又进行了如下实现：在公司，使用浏览器下载该ISO文件，使用下载器下载该ISO文件，分别计算SHA256值，最后发现浏览器下载的和官网提供的一样，而下载器下载的不一样。我不认为是我的下载器出了问题，我更多的是认为，从官网下载页面Copy的链接是不支持在下载器下载的。\n这个问题到此告一段落了。\n小结 我从解决这个问题收获了什么？\n 关注下载的制品的SHA256值，我以前是无条件信任官网下载的东西的，这次好好的给我上了一课，我至少有3~5天的时间，都浪费在这个问题上（当然，解决这个问题时，我在其他方面也是有一定收获的）。  ","description":"","id":427,"section":"notes","tags":null,"title":"PVE 6.x无法U盘安装","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve-6.x%E6%97%A0%E6%B3%95u%E7%9B%98%E5%AE%89%E8%A3%85/"},{"content":"R8125这张网卡，真的可以把我折磨的死去活来的，我甚至都考虑换一个I210网卡的机子了，不过今天可能真的一劳永逸的解决这个问题了。\n之前将CentOS系统配置成网关服务器时，就遇到了很多R8125网卡的问题，使用过程中，如果断开连接就无法重连了，我当时已经查出来该问题是ARP报文出错，我最后解决该问题的方案是降低CentOS的内核版本。实际上，我当时对此问题的研究还不够，没有充分的获取信息。\n最近又在我的PVE系统中出现了类似的情况，当我的PVE系统运行一段时间后，再开启我的笔记本，那么我的笔记本可能无法连接到网络（90%的几率），表现为无法正确的获取到IP地址（得到了一个保留地址），这和我之前配置CentOS时遇到的情况一模一样。我PVE的内核已经升级到了5.11，而R8125官方提供的驱动只支持到5.6，PVE的内核升级是直接从5.4跳到5.11的，所以我放弃了之前降级内核的方案。\n我需要记录一下我解决这个问题的心理路程，这会为我之后解决问题提供经验（实际上，在解决这个问题时我非常的沮丧，之前在CentOS系统上解决问题的挫败感压得我很窒息）。\n第一阶段 第一个阶段，我是尝试降级PVE的内核版本，正如上文所说，因为PVE的内核版本是跳着走的，我没有办法降级到5.6。我找到了如下的博客，博主和我的情况几乎是一样的，他也是想通过降级内核来避免R8125驱动的问题，不过他解决的是速度问题，我解决的是不好用的问题（还没到解决速度的阶段，哈哈）：\nLinux内核版本升级或降级\n我不想直接降到5.4，感觉版本跨度是在是太大了，而且我是从5.4升上来的，家中两台设备都已经升级到了5.11，而且5.4时编译R8125的驱动时，也会遇到一些问题。\n第二阶段 这个时候我考虑换机器了，我想购买一条I210的机器，最后放弃了，之所以放弃是因为不想委曲求取全，万兆肯定会比千兆有更多玩的空间（虽然我目前就这一个万兆设备），而且我也不知道换成I210后还会遇到什么奇奇怪怪的问题，最重要的是，我还得花费1000个大洋，糟心。\n第三阶段 既然官方不提供5.11的驱动，或许有大神提供，所以第三个阶段，我开始尝试寻找大神提供的版本。我之前看到过说有大神自己改了驱动文件，从而跑满这款网卡。于是我在GitHub上用R8125做关键字进行搜索，结果找到了如下的项目：\nawesometic/realtek-r8125-dkms\n于是我按照这个项目的Readme执行了起来，但是最终没有解决我的问题，但是Reame的最后面给我解决我的问题埋下了种子：\n这是说：如果存在R8169的驱动和R8125的驱动，可能会导致默认使用R8169的驱动，但是当是我只是按照教程简单执行了一下，没有任何效果，我就放弃了。我当时并没有办法判断我的网卡使用的是R8169还是R8125。\n第四阶段：逼进真相 就在这个时候，我偶然发现了如下的一篇问题贴：\nNo network with Realtek RTL8125 2.5GbE R8169/R8125\n我按照问题中的指令一一进行查看，发现贴主和我的几乎一模一样，那么我们的问题是同一个：网卡驱动默认选择了R8169而不是R8125（和第三阶段一样的，但是有方法可以确认的我用的是R8169的驱动了）：\n root@J4125:~# lspci -knn | grep Eth -A4 02:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8169 Kernel modules: r8169, r8125 03:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8169 Kernel modules: r8169, r8125 04:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8169 Kernel modules: r8169, r8125 05:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8169 Kernel modules: r8169, r8125 定位问题后，我又尝试用如下的方案来让我的网卡使用R8125驱动：\n  按照教程将R8169添加到黑名单中，但是始终不起作用\n  卸载R8169模块，我尝试的方案如下，这些方案都没有效果：\n 用modprode -r r8169指令，重启后依然存在 删除/lib/modules/5.11.22-5-pve/kernel/drivers/net/ethernet/realtek/下的r8169.ko，然后重启 用rmmod r8169指令，重启后依然存在 修改/lib/modules/5.11.22-5-pve/modules.dep文件，将r8169相关的行删掉 修改/lib/modules/*/modules.dep文件，将r8169相关的行删掉    在尝试了上面所有的方案后，我又开始思考，为什么pve中设置的blacklist不起作用，最后找如下教程：\n  Proxmox VE: Installation and configuration\n这篇文章解决了blacklist不生效的问题，可能没有人能猜到，我用什么关键字搜索到了这篇文章，我使用的是：R8169 /etc/modprobe.d/pve-blacklist.conf。\n最终我lspci -knn | grep Eth -A4有了如下的输入：\n root@J4125:/lib/modules/5.11.22-5-pve# lspci -knn | grep Eth -A4 02:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8125 Kernel modules: r8125 03:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8125 Kernel modules: r8125 04:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8125 Kernel modules: r8125 05:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:8125] (rev 04) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller [10ec:0123] Kernel driver in use: r8125 Kernel modules: r8125 真的很开心啊，今天状态并不是很好，这件事让人很舒服。现在我的笔记本，可以很正常的重连到我的PVE系统了，这是我家庭网络中最重要的一环，非常的开心。\n存在的问题 本次解决问题的过程中，存在的最大问题就是没有控制好变量。我在CentOS时代，我不知道是不是同样是因为网卡使用了R8169驱动，导致我断线重连时无法正常重连；同样，我并不知道默认使用R8169是在我编译安装好R8125驱动后，还是在我按照Readme文档，安装了Dpks后（我倾向于前者）；最后移除R8169的驱动时，我尝试了各种方案，但是方案开始前没有备份，结束后没有还原现场，虽然问题不是很大，但是可能存在影响实验结果的可能。\n小结 我需要将我所做的操作重新整理一下，方便下次使用：\n 编译、安装R8125模块（参考Proxmox VE下的其他文档） 检查网卡当前使用的驱动：   ethtool eno1 lshw -class network lspci -knn | grep Eth -A4 将R8169添加到黑名单，并让黑名单生效（这部分没有控制变量，不知道是否正确）：   echo “blacklist r8169” \u0026gt;\u0026gt; /etc/modprobe.d/pve-blacklist.conf update-initramfs -u 参考资料 核心参考的资料如下：\n No network with Realtek RTL8125 2.5GbE R8169/R8125 Proxmox VE: Installation and configuration  ","description":"","id":428,"section":"notes","tags":null,"title":"PVE与R8125网卡","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E4%B8%8Er8125%E7%BD%91%E5%8D%A1/"},{"content":"我本意是不想升级的，但是我编译R8125的驱动时下载不到相应的headers，所以只好升级PVE到7.x。\n整个过程让我无法理解的是，我按照官方的教程操作始终无法完成升级，我只能搜索博客，寻找偏方。\n6.x升级到6.4  编辑/etc/apt/sources.list（这份文件我其实没动）：  1 2 3 4 5 6 7 8  deb http://deb.debian.org/debian buster main contrib deb http://deb.debian.org/debian buster-updates main contrib # security updates deb http://security.debian.org buster/updates main contrib   添加一份新的源（非常重要）  1 2 3  echo \u0026#34;deb http://download.proxmox.com/debian/pve buster pve-no-subscription\u0026#34; \u0026gt; /etc/apt/sources.list.d/pve-install-repo.list   下载gpg文件（非常重要，但是现在还不是太理解）  1 2 3  wget http://download.proxmox.com/debian/proxmox-ve-release-6.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-6.x.gpg   开始升级   apt update \u0026amp;\u0026amp; apt dist-upgrade reboot pveversion -v 从6.4升级到7.x 从6.4到7.x我都是从6.x升级到6.4举一反三的，我比较喜欢用一致的方案解决问题。\n 检查一下是否可以升级   pve6to7 --full 修改buster为bullseye   sed -i 's/buster\\/updates/bullseye-security/g;s/buster/bullseye/g' /etc/apt/sources.list sed -i 's/buster\\/updates/bullseye-security/g;s/buster/bullseye/g' /etc/apt/sources.list.d/pve-install-repo.list 下载gpg文件（非常重要，但是现在还不是太理解）   wget http://download.proxmox.com/debian/proxmox-release-bullseye.gpg -O /etc/apt/trusted.gpg.d/proxmox-release-bullseye.gpg 这儿有一个技巧，不能直接将6.x换成7.x，所以要去http://download.proxmox.com/debian/看一下，哪个gpg该下载。\n开始升级   apt update \u0026amp;\u0026amp; apt dist-upgrade reboot pveversion -v 参考资料  Proxmox PVE 6.3 升级 6.4 Downloads Upgrade from 6.x to 7.0  ","description":"","id":429,"section":"notes","tags":null,"title":"PVE从6.x升级到7.x","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E4%BB%8E6.x%E5%8D%87%E7%BA%A7%E5%88%B07.x/"},{"content":"已知xterm.js是个好东西，支持copy和paste，但是配置起来太麻烦了，性价比太低，所以我不想搞。资料如下：\n Serial Terminal PVE 5.1 設定 KVM 虛擬機能夠使用 xterm.js  ","description":"","id":430,"section":"notes","tags":null,"title":"PVE使用xterm.js","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E4%BD%BF%E7%94%A8xterm.js/"},{"content":"事情的起因是这样的，我创建Ubuntu虚拟机时没有调整硬盘大小，结果磁盘只有32G，这个孔家大小在编译OpenWrt时完全不够用。按照我以往的做法，我会直接重新一个新的虚拟机，并调整硬盘大小为100G。但是，在接触PVE的过程中，我对Linux的磁盘有些熟悉了，我想尝试这自己将这个磁盘调整为我想要的大小。于是有了这篇文章。\n操作步骤   在PVE上将虚拟机的磁盘大小调整为132G。\n  查看磁盘信息：我在查看磁盘信息的时候，终端显示了一些红色的提示信息，大致就是说部分空间没有用上，下面的一步可以修改该问题：\n   fdisk -l 修复fdisk -l指令中的提示信息。完成该步后，fdisk -l就不会有任何错误提示信息，我也是偶然发现可以用这个修复的。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # 我的输入 root@junjie:~# parted /dev/sda GNU Parted 3.3 Using /dev/sda Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. # 我的输入 (parted) print Warning: Not all of the space available to /dev/sda appears to be used, you can fix the GPT to use all of the space (an extra 209715200 blocks) or continue with the current setting? # 我的输入 Fix/Ignore? fix Model: QEMU QEMU HARDDISK (scsi) Disk /dev/sda: 142GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 1076MB 1074MB ext4 3 1076MB 34.4GB 33.3GB   为分区增加空间，完成该不，通过fdisk -l指令已经可以看到分区的大小发生了变化。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # 我的输入 root@junjie:~# parted /dev/sda GNU Parted 3.3 Using /dev/sda Welcome to GNU Parted! Type \u0026#39;help\u0026#39; to view a list of commands. # 我的输入 (parted) print Model: QEMU QEMU HARDDISK (scsi) Disk /dev/sda: 142GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 2097kB 1049kB bios_grub 2 2097kB 1076MB 1074MB ext4 3 1076MB 34.4GB 33.3GB # 我的输入 (parted) resizepart 3 100% # 我的输入 (parted) quit Information: You may need to update /etc/fstab.   修改物理卷大小（这一步我没有看出任何变化信息）   pvresize /dev/sda2 修改逻辑卷大小（ubuntu\u0026ndash;vg-ubuntu\u0026ndash;lv文件视各自情况而定，你的文件可能不叫这个名字）   lvresize --extents +100%FREE --resizefs /dev/mapper/ubuntu--vg-ubuntu--lv 这一步带来的变化如图所示：\n最后重启验证下  参考资料  proxmox ve (PVE) 调整虚拟机(VM)的磁盘大小  ","description":"","id":431,"section":"notes","tags":null,"title":"PVE修改Ubuntu虚拟机的硬盘大小","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E4%BF%AE%E6%94%B9ubuntu%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E7%A1%AC%E7%9B%98%E5%A4%A7%E5%B0%8F/"},{"content":"vgremove pve2\n使用的场景是不小心动了pve的卷组设置。\n该方案需要结合下面的教程使用，否则的话无法删除PVE界面上的pve2\nProxmox 删除local-lvm 操作步骤\n参考资料  Linux LVM-删除卷组逻辑卷物理卷  ","description":"","id":432,"section":"notes","tags":null,"title":"PVE删除lvm卷组","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E5%88%A0%E9%99%A4lvm%E5%8D%B7%E7%BB%84/"},{"content":"我觉得这篇文章给的方法最优雅，我采用的也是这样方案。\n参考资料  Proxmox VE（PVE）如何添加多块硬盘  ","description":"","id":433,"section":"notes","tags":null,"title":"PVE添加一块硬盘作为存储","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E6%B7%BB%E5%8A%A0%E4%B8%80%E5%9D%97%E7%A1%AC%E7%9B%98%E4%BD%9C%E4%B8%BA%E5%AD%98%E5%82%A8/"},{"content":"实际上，我现在不需要这个技术了，甚至在研究这个技术时，我悟出了一个人生道理：最优解不一定是最适合的解。\nBIOS层面的东西我不讲了，因为我老早前就配置过，所以这次实验没有做任何改动。\n 查看已有网卡信息   lspci | grep -i ethernet 修改引导文件/etc/default/grub   GRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet\u0026quot; GRUB_CMDLINE_LINUX_DEFAULT=\u0026quot;quiet intel_iommu=on\u0026quot; 更新引导   update-grub 验证有效性（我没有做这一步）：执行如下指令，如果没有输出，则出现问题。   dmesg | grep -e DMAR -e IOMMU 新增所需要的模块：/etc/modules   vfio vfio_iommu_type1 vfio_pci vifo_virqfd 执行命令来更新initramfs（我没有执行这一步，我直接重启了）   update-initramfs -u -k all. 在Web管理页面添加PCI设备（虚拟机的设备页面）  参考资料   Proxmox VE(PVE) 进行网卡直通\n这个教程干货还很多，又很多我目前还没有接触到。\n  ","description":"","id":434,"section":"notes","tags":null,"title":"PVE网卡直通","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/pve%E7%BD%91%E5%8D%A1%E7%9B%B4%E9%80%9A/"},{"content":"截图如下：\n第三张图中，需要选到本地的一个exe文件。\n","description":"","id":435,"section":"notes","tags":null,"title":"Pycharm设置sdk","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pycharm%E8%AE%BE%E7%BD%AEsdk/"},{"content":"一个字：非常爽。之前需要每次编辑完后，删除shell已有的问题件，然后将新的文件拖到shell中，然后手动执行，现在不需要这样做了，大大提升了编码的幸福度。\n唯一的一个缺点是，不是所有现象都是一模一样的，比如我开发的脚本启动了子进程，在Linux中执行的话，这个后台的进程会保留下来，但是通过PyCharm远程调试的时候，这些子进程都会跟着父进程一起死。\n方法如下：\n后面就很简单了，添加完成后需要将Interpretor设置成这个SSH Interceptor。\n参考资料  pycharm远程连接linux服务器环境开发调试  ","description":"","id":436,"section":"notes","tags":null,"title":"Pycharm远程调试","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/pycharm%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"content":"我执行的指令如下：\n yum search python | grep devel yum install python3-devel.x86_64 参考资料  解决Python.h找不到问题  ","description":"","id":437,"section":"notes","tags":null,"title":"Python.h找不到","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/python.h%E6%89%BE%E4%B8%8D%E5%88%B0/"},{"content":"犯傻了，在Ubuntu上运行urllib2，意味要安装urllib2，花了很多时间去查找资料，最后发现根本不需要安装。\n","description":"","id":438,"section":"notes","tags":null,"title":"Python2不需要安装urllib2","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/python2%E4%B8%8D%E9%9C%80%E8%A6%81%E5%AE%89%E8%A3%85urllib2/"},{"content":"我之前使用的方式是一行一行的读取文件，然后调用update方法，需要写好多行代码，下面的写法更简洁一些：\n1 2 3 4 5 6 7 8  import hashlib fd=open(\u0026#34;1.jpg\u0026#34;,\u0026#34;r\u0026#34;) fcont=fd.read() fmd5=hashlib.md5(fcont) print fmd5.hexdigest() #get 32 value   ","description":"","id":439,"section":"notes","tags":null,"title":"Python计算md5（更新版）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/python%E8%AE%A1%E7%AE%97md5%E6%9B%B4%E6%96%B0%E7%89%88/"},{"content":"安装Rancher  执行如下指令   docker run -d --restart=unless-stopped -p 80:80 -p 443:443 --privileged rancher/rancher:latest 导入集群  首先在Cluster选项卡下选择Add Cluster。因为我已经配置过了，这个按钮不见了。   在第一栏的Register Existing Cluster里选择Other。我看有的教程选择的是GKE，我这个是最新版，选择GKE不行。\n  之后会让你执行三条指令，我是如下处理的：\n   # 换[USER_ACCOUNT]为root kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user root # 不执行 kubectl apply -f https://192.168.13.68/v3/import/x26bbfhcn855gd4h24n59jdcd84l2xvjvv28n2t6fgpt4f77dkrfpf_c-whs58.yaml # 执行（在node1节点上执行的） curl --insecure -sfL https://192.168.13.68/v3/import/x26bbfhcn855gd4h24n59jdcd84l2xvjvv28n2t6fgpt4f77dkrfpf_c-whs58.yaml | kubectl apply -f - 遇到的问题  我执行第二条的时候，报了如下的错误：   Unable to connect to the server: x509: certificate is valid for 127.0.0.1, 172.17.0.2, 172.17.0.4, not 192.168.13.68 我猜想是因为我的集群里证书都是我自己造的，所以有这个问题。\n我执行第三条的时候，也遇到了问题，大意说没有给kubectl传递任何东西。我还是怀疑是证书的问题。所以我选择了在浏览器中下载，推到node1上，然后执行（这个可能是个例，不一定都存在这个问题）。  参考资料  Rancher部署并导入K8S集群  ","description":"","id":440,"section":"notes","tags":null,"title":"Rancher的安装与导入K8S集群（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/rancher%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AF%BC%E5%85%A5k8s%E9%9B%86%E7%BE%A4%E5%BA%9F%E5%BC%83/"},{"content":"t_raw_data\nid\nrawData # 用户提交的json数据\ntransferData # 根据langKey转换后的json数据\njsonStructure # 当前json的结构\nt_datasource\nid # 自增主键\nname # 数据源的名称全局唯一\ntype # 取值Get、Post，前端按照该值发送http请求（目前主要为Get，Post用于开发高度自定义）\n# 新增一种Fixed，Fixed代表的是由rawData生成的\nparams # 前端按照该值提供参数，存储为对象数组：[{\u0026ldquo;paramName\u0026rdquo;:\u0026ldquo;tmp\u0026rdquo;,\u0026ldquo;paramType\u0026rdquo;:\u0026ldquo;JString\u0026rdquo;}]\nrequestUrl # 前端将请求发送到该地址\nreturnType # 表单编排器通过该字段判断该数据源能够绑定到某个组件的某个属性声明（系统定义的类型JList、JBoolean、JMap）\n","description":"","id":442,"section":"notes","tags":null,"title":"rawData数据源如何工作","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/rawdata%E6%95%B0%E6%8D%AE%E6%BA%90%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C/"},{"content":"过于无用，故作废\n这个纯粹是用来玩的。用Netty开发了一个简单的时间服务，然后想用rdate去访问这个服务：\n rdate -p 192.168.28.118 # 输出 rdate: [192.168.28.118]\tSat Aug 21 04:03:48 2021 Netty核心代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { final ByteBuf time = ctx.alloc().buffer(4); time.writeInt((int) (System.currentTimeMillis() / 1000L + 2208988800L)); ChannelFuture writeFuture = ctx.writeAndFlush(time); writeFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { assert writeFuture == future; ctx.close(); } }); }   这里面遇到的问题是：貌似我Linux上的rdate不能指定端口，所以我需要监听在37号端口。\n参考资料  Writing a Time Server 写个时间服务器  ","description":"","id":444,"section":"notes","tags":null,"title":"rdate指令的使用","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%BD%9C%E5%BA%9F/rdate%E6%8C%87%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"content":"因为产品坚持将字段和组件绑定在一起，拖动字段，便可以实现组件的添加，故，该方案作废了。\n开发该项目时，我总结的经验就是不要重复的造轮子，很多时候很多需求都是可以找到优秀的开源的软件的。\n","description":"","id":445,"section":"notes","tags":null,"title":"READE","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/reade/"},{"content":"我购买了群晖，故研究该系列的技术没有任何的意义，但是平心而论，我觉得群晖买的不是很值得，因为我买的群晖只使用了一些极其基础的功能。\n","description":"","id":446,"section":"notes","tags":null,"title":"READE","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BD%9C%E5%BA%9F/openmediavault/reade/"},{"content":"\u0026ndash;recursive用于选款克隆git子项目：\n git clone git://github.com/ansible/ansible.git --recursive ","description":"","id":447,"section":"notes","tags":null,"title":"recursive参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/recursive%E5%8F%82%E6%95%B0/"},{"content":"用telnet连接的时候有如下提示信息：\n -DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside. 我自己琢磨出来的方法如下：\n1 2 3 4 5 6 7 8 9  mkdir ~/Config/Redis/ tee ~/Config/Redis/redis.conf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; protected-mode no EOF redis-server ~/Config/Redis/redis.conf   ","description":"","id":448,"section":"notes","tags":null,"title":"redis-server启动的Redis处于保护模式下","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/redis-server%E5%90%AF%E5%8A%A8%E7%9A%84redis%E5%A4%84%E4%BA%8E%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E4%B8%8B/"},{"content":"一个临时的功能：当用户登录系统时，如果用户不存在，则为该用户初始化一些身份信息。在入库的时候发现存在一些并发行为，可能会初始化两条用户信息，这种问题需要规避，所以我决定用锁。\n因为初始化信息的时候，是插入操作，所以行锁是用不了的，我需要用表锁，但是用表锁又会印象到其他接口的查询功能（是这样的吧？我这块学的还不透彻）。所以，我最终决定用Redis实现一个简单的分布式锁。\n分布式锁原理比较简单，就是利用了Redis的单线程性，我直接找了一个线程的Jar包，操作步骤如下：\n 引入Jar包  1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   进行配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  @Configuration public class RedissonConfig { @Value(\u0026#34;${spring.redis.host}\u0026#34;) private String host; @Value(\u0026#34;${spring.redis.port}\u0026#34;) private Integer port; @Value(\u0026#34;${spring.redis.password}\u0026#34;) private String password; @Value(\u0026#34;${spring.redis.lettuce.pool.max-idle}\u0026#34;) private int maxPoolSize; private String cluster; @Bean public RedissonClient redissonClient() { return loadRedisson(); } public RedissonClient loadRedisson() { RedissonClient redisson; Config config = new Config(); //单节点  if (!StringUtils.isEmpty(host)) { config.useSingleServer() .setAddress(\u0026#34;redis://\u0026#34; + host + \u0026#34;:\u0026#34; + port) .setPassword(StringUtils.isEmpty(password) ? null : password) .setConnectionPoolSize(maxPoolSize) .setDnsMonitoringInterval(-1) //最小空闲连接  .setConnectionMinimumIdleSize(0); } else { //集群节点  String[] nodes = cluster.split(\u0026#34;,\u0026#34;); //redisson版本是3.5，集群的ip前面要加上“redis://”，不然会报错，3.2版本可不加  for (int i = 0; i \u0026lt; nodes.length; i++) { nodes[i] = \u0026#34;redis://\u0026#34; + nodes[i]; } //这是用的集群server  config.useClusterServers() //设置集群状态扫描时间2000  .setScanInterval(2000) .addNodeAddress(nodes) .setPassword(password) .setMasterConnectionPoolSize(maxPoolSize) .setDnsMonitoringInterval(-1) //最小空闲连接  .setMasterConnectionMinimumIdleSize(0); } redisson = Redisson.create(config); return redisson; } public RedissonClient retryGetRedisson() { return loadRedisson(); } }   编写代码  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  RLock lock = redissonClient.getLock(String.format(\u0026#34;SRM:inviteFromMaterialPlatform:%s_%s\u0026#34;, tenantId, request.getSupplierId())); try { lock.lock(); // do something  return inviteInsert.getId(); } finally { if (lock.isLocked()) { lock.unlock(); } }   遇到的问题：\n 因为我使用了Proxifier代理java.exe的所有流量，从而让我本地的服务可以直接访问K8S集群中的服务。但是，使用该工具的时候，会一直报redis不可解析，我已经在我的代码服务器中设置了该host条目。最后解决该问题的方法是：我在我本机的host文件中加上了该host条目，我感觉这种解决问题的方式不是很优雅。  ","description":"","id":449,"section":"notes","tags":null,"title":"Redis一个简易的分布式锁","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/redis%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"content":" 启动Redis服务   redis-server redis-server 配置文件 连接Redis服务   redis-cli redis-cli -p 6379 # 可连接到服务后执行shutdown指令 redis-cli shutdown redis-cli -p 6379 shtudown 数据库的管理   # 切换到DB库 select DB # 查看当前数据库的key的数量 dbsize # 清除当前库和清除全部库 flushdb flushall 键的管理   # 查看当前库中得所有key keys * # 判断某个key是否存在 exist key # 查看你的key是什么类型 type key # 删除指定的key del key # 根据value选择非阻塞删除 unlink key # 给定的key设置过期时间 expire key # 查看给定的key的过期时间 ttl key pttl key ","description":"","id":450,"section":"notes","tags":null,"title":"Redis中常用指令","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/redis%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"参考资料  查看 redis 请求日志  ","description":"","id":451,"section":"notes","tags":null,"title":"Redis查看日志执行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/redis%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97%E6%89%A7%E8%A1%8C/"},{"content":"这个比较简单，我直接上代码了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  private String getSn(String typeId, String typePrefix) { String key = String.format(\u0026#34;CommonMaterialService:createCommonMaterial:%s\u0026#34;, typePrefix); String sn = String.format(\u0026#34;%s-%06d\u0026#34;, typePrefix, stringRedisTemplate.opsForValue().increment(key, 1)); LambdaQueryWrapper\u0026lt;CommonMaterial\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;CommonMaterial\u0026gt;() .eq(CommonMaterial::getTypeId, typeId) .eq(CommonMaterial::getSn, sn); List\u0026lt;CommonMaterial\u0026gt; commonMaterials = commonMaterialMapper.selectList(queryWrapper); while (commonMaterials != null \u0026amp;\u0026amp; commonMaterials.size() != 0) { sn = String.format(\u0026#34;%s-%06d\u0026#34;, typePrefix, stringRedisTemplate.opsForValue().increment(key, 1)); queryWrapper.eq(CommonMaterial::getSn, sn); commonMaterials = commonMaterialMapper.selectList(queryWrapper); } return sn; }   参考资料  Redis生成唯一递增序列号~  ","description":"","id":452,"section":"notes","tags":null,"title":"Redis递增序列的实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/redis%E9%80%92%E5%A2%9E%E5%BA%8F%E5%88%97%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"content":"今天我在Feign Client中增加了如下的代码：\n1 2 3 4 5 6 7  /** * 全量获取材料平台供应商列表（SRM） */ @GetMapping(\u0026#34;getSupplierById\u0026#34;) SupplierResponse getSupplierById(@RequestParam String supplierId);   结果本地安装后，会导致依赖该Client的项目始终启动不起来，说无法找到该Client。最后在对比以往的代码后，进行了如下代码调整：\n1 2 3 4 5 6 7  /** * 全量获取材料平台供应商列表（SRM） */ @GetMapping(\u0026#34;getSupplierById\u0026#34;) SupplierResponse getSupplierById(@RequestParam(\u0026#34;supplierId\u0026#34;) String supplierId);   该客户端可以被正确的扫描。\n","description":"","id":453,"section":"notes","tags":null,"title":"RequestParam缺少参数，导致FeignClient注入失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/requestparam%E7%BC%BA%E5%B0%91%E5%8F%82%E6%95%B0%E5%AF%BC%E8%87%B4feignclient%E6%B3%A8%E5%85%A5%E5%A4%B1%E8%B4%A5/"},{"content":"使用如下代码：\n1 2 3 4 5 6 7 8 9 10 11  syntax = \u0026#34;proto3\u0026#34;;message SearchRequest2 { reserved 1, 2; reserved \u0026#34;result_per_page\u0026#34;; string query = 1; repeated int32 page_number = 2; repeated int32 result_per_page = 3;}  编辑器会报错，且无法正常编译：\n小结 需要思考一下，如何在实践中应用相关的技术。删除一行消息字段是一件非常简单的事情，根本就没有办法约束开发在删除一个字段的定义时补上一个reserved。所以为了让开发未来想起该消息类型需要补上一个reserved，我们需要一定需要进行版本管理（这是必要会进行版本管理的）。\n但是即使是使用了版本管理，我们也大多数情况是在事故发生后才知道需要补上这个字段，这个时候已经给我们的生产环境带来了影响。我趋于怎么做，我趋于开发脚本，结合版本管理工具，自动完成reserver字段的添加和管理。\n大致思路是这样的，我们每次提交proto文件，我们CI工具将会拉取当前的代码和和上一个版本（由CI工具记录，并非严格意义上的上一次提交）的代码，分析删除了哪些字段，然后进行自动添加上reserved字段，再编译成需要的代码文件。\n最后，我还需要思考下，protoBuf是否新旧协议的兼容，如果兼容，我又该如何做，我又该如何管理我的项目。\n对消息类型进行更新 添加新字段时，旧消息可以被新代码解析，解析时旧消息中没有的字段将会被设置为默认值。旧代码也可以解析新的消息，在解析的过程中会自动忽略新增加的字段。所以在解析的过程中，我们需要注意字段的默认值。删除字段的原理类似。\n字段名似乎不会影响最终的解析结果，所以针对要删除的字段，我们可以将其重命名为OBSOLETE_fieldName，或者直接删除该字段，并使用reverse保留字段名和编号。\nint32、uint32、int64、uint64和bool都兼容，可以从一种类型改为另一种，不会破坏向前向后的兼容性。如果解析出来的数据不适合该类型，在编程语言中将会进行强制类型转换。\n。。。\n后面知识太多了，感觉目前都用不到，往后再整理。\n","description":"","id":454,"section":"notes","tags":null,"title":"reserved的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/reserved%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"其实这个问题的原因很简单，就是传递给restTemplate.getForObject的类，没有Getter和Setter。\n其实这种问题完全没有必要记录，一旦发现了这个问题后，简单的尝试后就能获得这样的知识。\n但是的但是，快速定位这个问题是需要一些基础设施的，比如我在这次定位的过程中，就是因为我配置了restTemplate打印请求的信息，才能够快速获取一部分信息。\n","description":"","id":455,"section":"notes","tags":null,"title":"restTemplate.getForObject执行后的返回值字段全部为空","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate.getforobject%E6%89%A7%E8%A1%8C%E5%90%8E%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC%E5%AD%97%E6%AE%B5%E5%85%A8%E9%83%A8%E4%B8%BA%E7%A9%BA/"},{"content":"RestTemplate上传文件其实是一个非常简单的操作，这次之所以踩坑一方面是自己给自己挖的，一方面是接口提供方给我挖的。\n我给自己挖的坑是我在配置RestTemplate时，清除了所有默认的HttpMessageConverter，然后只设置了一个FastJsonHttpMessageConverter，结果针对上传操作，这个HttpMesageConverter无法进行转换，就报了一个错出来。不过还好，因为RestTemplate是我自己配置的，所以我很快就定位了这个问题，最后将配置代码中清理HttpMessageConverter的代码清除了。\n第二个问题是接口提供方的编码中应该写死要求上传时的文件名为file，而用RestTemplate上传时准备的MultiValueMap太具备迷惑性，到时我一直以为该参数的key就是上传时的文件名，所以用这种写法时接口一直报500。最后找到了一篇博文，抱着试一试的想法，尝试了一下，解决了我的问题（实际上我去接口提的后台查看了接口报错，猜到了其写法）。\n我最终的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  public String uploadPictureBytes(byte[] bytes) { // 计算md5值，作为文件名  String fileName = md5_32Encrypt(bytes); // 设置请求体  MultiValueMap\u0026lt;String, Object\u0026gt; bodyParams = new LinkedMultiValueMap\u0026lt;\u0026gt;(); bodyParams.add(\u0026#34;file\u0026#34;, new ByteArrayResource(bytes) { @Override public String getFilename() { return \u0026#34;file\u0026#34;; } }); // 设置请求头  HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.MULTIPART_FORM_DATA); // 封装整个报文  HttpEntity\u0026lt;MultiValueMap\u0026lt;String, Object\u0026gt;\u0026gt; requestEntity = new HttpEntity\u0026lt;\u0026gt;(bodyParams, headers); // 发送请求  ResponseForUpload response = restTemplate.postForObject( String.format(URL_FOR_UPLOAD, fileName), requestEntity, ResponseForUpload.class); // 处理返回结果  if (response != null \u0026amp;\u0026amp; response.getCode() == 200) { return response.getData().getPath(); } throw new BusinessException(PICTURE_UPLOAD_WRONG); }   参考资料  spring restTemplate 上传文件流  ","description":"","id":456,"section":"notes","tags":null,"title":"RestTemplate上传文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/"},{"content":"今天在一个没有配置RestTemplate的项目中使用RestTemplate，所以我需要自己配置一下，按照我之前的方式配置好了后，发现报了如下错误：\n org.springframework.web.client.RestClientException: No HttpMessageConverter for com.sdstc.show.controller.external.DynamicFormController$PostDataRequest at org.springframework.web.client.RestTemplate$HttpEntityRequestCallback.doWithRequest(RestTemplate.java:961) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:737) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:674) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.client.RestTemplate.postForObject(RestTemplate.java:418) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at com.sdstc.show.controller.external.DynamicFormController.postData(DynamicFormController.java:49) ~[classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_281] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_281] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_281] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_281] at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:523) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:590) ~[jakarta.servlet-api-4.0.3.jar:4.0.3] at io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:74) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:129) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at com.sdstc.core.configuration.web.RequestBodyFilter.doFilter(RequestBodyFilter.java:39) ~[sdstc-core-1.1.4.jar:?] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE] at io.undertow.servlet.core.ManagedFilter.doFilter(ManagedFilter.java:61) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler$FilterChainImpl.doFilter(FilterHandler.java:131) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.FilterHandler.handleRequest(FilterHandler.java:84) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:62) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletChain$1.handleRequest(ServletChain.java:68) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.RedirectDirHandler.handleRequest(RedirectDirHandler.java:68) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:132) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletAuthenticationCallHandler.handleRequest(ServletAuthenticationCallHandler.java:57) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:46) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.ServletConfidentialityConstraintHandler.handleRequest(ServletConfidentialityConstraintHandler.java:64) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AuthenticationMechanismsHandler.handleRequest(AuthenticationMechanismsHandler.java:60) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:77) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.security.handlers.AbstractSecurityContextAssociationHandler.handleRequest(AbstractSecurityContextAssociationHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:43) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:269) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$100(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:133) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$2.call(ServletInitialHandler.java:130) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.core.ServletRequestContextThreadSetupAction$1.call(ServletRequestContextThreadSetupAction.java:48) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.core.ContextClassLoaderSetupAction$1.call(ContextClassLoaderSetupAction.java:43) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:249) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:78) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:99) ~[undertow-servlet-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.Connectors.executeRootHandler(Connectors.java:376) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830) ~[undertow-core-2.0.29.Final.jar:2.0.29.Final] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_281] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_281] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_281] HttpMessageConverter这东西我还是有点熟悉的，我立刻对RestTemplate加了如下配置：\n FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); restTemplate.getMessageConverters().add(fastConverter); 结果又报错说无法找不到MediaType，额，还好我最近看过这部分知识，于是我进行了如下配置：\n FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); List\u0026lt;MediaType\u0026gt; supportedMediaTypes = new ArrayList\u0026lt;\u0026gt;(); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.APPLICATION_ATOM_XML); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_OCTET_STREAM); supportedMediaTypes.add(MediaType.APPLICATION_PDF); supportedMediaTypes.add(MediaType.APPLICATION_RSS_XML); supportedMediaTypes.add(MediaType.APPLICATION_XHTML_XML); supportedMediaTypes.add(MediaType.APPLICATION_XML); supportedMediaTypes.add(MediaType.IMAGE_GIF); supportedMediaTypes.add(MediaType.IMAGE_JPEG); supportedMediaTypes.add(MediaType.IMAGE_PNG); supportedMediaTypes.add(MediaType.TEXT_EVENT_STREAM); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_MARKDOWN); supportedMediaTypes.add(MediaType.TEXT_PLAIN); supportedMediaTypes.add(MediaType.TEXT_XML); fastConverter.setSupportedMediaTypes(supportedMediaTypes); restTemplate.getMessageConverters().add(fastConverter); 我们的框架高度定制化，有很多默认存在的东西，都因为定制的原因已经不叫原来的名字了，所以我们无法使用到这些bean，最后就导致出现了问题。\n","description":"","id":457,"section":"notes","tags":null,"title":"RestTemplate更高级配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate%E6%9B%B4%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"content":"代码如下：\nRestTemplateConfig类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  @Configuration public class RestTemplateConfig { @Bean public RestTemplate restTemplate(ClientHttpRequestFactory httpRequestFactory) { RestTemplate restTemplate = new RestTemplate(httpRequestFactory); // 设置拦截器，答应请求信息，方便Debug  List\u0026lt;ClientHttpRequestInterceptor\u0026gt; interceptors = new ArrayList\u0026lt;\u0026gt;(); interceptors.add(new LoggingClientHttpRequestInterceptor()); restTemplate.setInterceptors(interceptors); //提供对传出/传入流的缓冲,可以让响应body多次读取(如果不配置,拦截器读取了Response流,再响应数据时会返回body=null)  restTemplate.setRequestFactory(new BufferingClientHttpRequestFactory(httpRequestFactory)); return restTemplate; } @Bean public ClientHttpRequestFactory simpleClientHttpRequestFactory() { SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); factory.setConnectTimeout(15000); factory.setReadTimeout(5000); return factory; } }   LoggingClientHttpRequestInterceptor 类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  @Slf4j public class LoggingClientHttpRequestInterceptor implements ClientHttpRequestInterceptor { @Override public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException { traceRequest(request, body); ClientHttpResponse response = execution.execute(request, body); traceResponse(response); return response; } private void traceRequest(HttpRequest request, byte[] body) { log.info(\u0026#34;=========================== request begin ===========================\u0026#34;); log.info(\u0026#34;uri : {}\u0026#34;, request.getURI()); log.info(\u0026#34;method : {}\u0026#34;, request.getMethod()); log.info(\u0026#34;headers : {}\u0026#34;, request.getHeaders()); log.info(\u0026#34;request body : {}\u0026#34;, new String(body, StandardCharsets.UTF_8)); log.info(\u0026#34;============================ request end ============================\u0026#34;); } private void traceResponse(ClientHttpResponse httpResponse) throws IOException { StringBuilder inputStringBuilder = new StringBuilder(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(httpResponse.getBody(), StandardCharsets.UTF_8)); String line = bufferedReader.readLine(); while (line != null) { inputStringBuilder.append(line); inputStringBuilder.append(\u0026#39;\\n\u0026#39;); line = bufferedReader.readLine(); } log.info(\u0026#34;============================ response begin ============================\u0026#34;); log.info(\u0026#34;Status code : {}\u0026#34;, httpResponse.getStatusCode()); log.info(\u0026#34;Status text : {}\u0026#34;, httpResponse.getStatusText()); log.info(\u0026#34;Headers : {}\u0026#34;, httpResponse.getHeaders()); log.info(\u0026#34;Response body: {}\u0026#34;, inputStringBuilder.toString()); log.info(\u0026#34;============================= response end =============================\u0026#34;); } }   这个功能不是手到擒来的（如果你按照上面的配置去搞，就是傻瓜版开启了这个功能），我开启这个功能时遇到了哪些问题？我找到教程前，已经有了自己的一份关于RestTemplate的配置，我不想对我的配置进行太大的改动，所以我只复制了我觉得重要的配置，即没有复制该行：restTemplate.setRequestFactory(new BufferingClientHttpRequestFactory(httpRequestFactory));\n结果就导致了，日志信息明明看到了返回体有相关的信息，但是得到的对象总是为空。我仔细阅读了教程中的代码，发现漏了上面的一行。实际上我对底层的实现还是有点不太理解，目前先记录下来，把这些知识积累起来，这种知识积累多了后，可能就可以学习到更多的知识。\n参考资料  Spring RestTemplate配置拦截器打印请求URL和响应结果 Spring RestTemplate配置拦截器打印请求URL和响应结果  ","description":"","id":458,"section":"notes","tags":null,"title":"RestTemplate配置打印请求的详细信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/resttemplate%E9%85%8D%E7%BD%AE%E6%89%93%E5%8D%B0%E8%AF%B7%E6%B1%82%E7%9A%84%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF/"},{"content":"ResultMap标签类似于定义了一个变量，然后在select标签中使用：\n因为目前使用MyBatis-Plus多一点，这个技术暂时就不研究了。\n","description":"","id":459,"section":"notes","tags":null,"title":"resultMap标签","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/resultmap%E6%A0%87%E7%AD%BE/"},{"content":"如下图，搜索NUnit即可：\n感觉NuGet没有Maven好用。\n","description":"","id":460,"section":"notes","tags":null,"title":"Rider下载NUnit的包","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/rider/rider%E4%B8%8B%E8%BD%BDnunit%E7%9A%84%E5%8C%85/"},{"content":"我的需求是这样的，我需要拉下一个仓库，然后删除这个仓库中除.git外的所有文件，然后在这个仓库中放入我的新文件，在提交到远程仓库中。\n我最后使用的代码如下：\n1 2 3  cd GitRepo \u0026amp;\u0026amp; find . | grep -v .git | xargs rm -rf   这个方案要求我必须进入我下载的仓库里执行，我在外部执行的时候，不能很好的工作（我能理解产生这种现象的原因）\n我尝试过rm !(.git)的方案，结果提示我不存在!指令。\n参考资料  Linux rm 删除指定文件外的其他文件 方法汇总  ","description":"","id":461,"section":"notes","tags":null,"title":"rm指令在移除的时候排除一些文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/rm%E6%8C%87%E4%BB%A4%E5%9C%A8%E7%A7%BB%E9%99%A4%E7%9A%84%E6%97%B6%E5%80%99%E6%8E%92%E9%99%A4%E4%B8%80%E4%BA%9B%E6%96%87%E4%BB%B6/"},{"content":"Strust2是基于Filter实现的，而SpringMVC是Servlet的扩展。我很好奇Filter和Servlet究竟有什么区别，查了了该资料，已经能比较清晰的了解Servlet和Filter的区别了。\n我想到了一些问题，我之前的一家公司测试方面做的比较细心，需要做防SQL注入、XSS攻击方面的测试，我们的代码没有注意到这些问题，所以需要开发相应的工具来解决这个问题。由于当时我对Spring底层知识了解的并不是太多，我选择了基于反射开发一个工具类，将Request对象传入到这个工具类中，工具类将会判断字段的类型，当字段的类型为String时，则执行SQL、JS代码清理工作。如果现在让我实现这个功能，我想我会选择使用过滤器实现（我当时查的资料基本都是基于过滤器的）。\n我们目前的项目中有这样的一个功能：我们在返回Response时，针对图片、文件等OSS里存放的资料，打上一个标记，则会有个Filter计算出该资源的url（携带了签名、鉴权等信息），我去寻找源码时，并没有找到相关的源码，我想这个功能应该是通过某种特别的方式实现的吧，我SpringBoot相关的知识还不够，需要继续学习。\n后续：\n在和同时的讨论中，我知道了我们代码中处理OSS字段的类：ResponseBodyAdvice。从命名上看，这个应该是切面技术，而并非过滤器技术，我目前没有系统的学习相关的知识，所以保持观望状态。\n","description":"","id":462,"section":"notes","tags":null,"title":"Servlet和Filter的区别","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/servlet%E5%92%8Cfilter%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"content":"ShardingSphere-Jdbc研究告一段落，目前总结的配置文件和增加的类已经基本能够满足我们的业务需求。而且我已经对我使用到的每个技术点都进行了相对充分的测试，确保了我的理解是正确的。我将对ShardingSphere-Jdbc的研究总结如下。\n业务需求 我们的业务上只有分表需求，并没有分库需求，所以主要研究了在分表方面的使用。\n在分表方面，我们的需求为：\n 按照某个字段的模进行分表 按照创建时间进行分表（这个地方需要注意，存在创建表的需求）  研究时编写的代码我已提交到：shardingsphere-jdbc，有兴趣的同学可以自行查看\n发现或解决的问题 截止目前，发现的和解决的问题如下所列，并不是所有的问题都解决了，但是眼下的方案能让我们的以下在一定时间内正常运行：\n 分页问题（使用临时方案解决） 查询时不包括分表键的问题（使用临时方案解决） 绑定表 按时间分表及相关定时任务  分页问题 使用ShardingSphere-Jdbc时，有分页需求时，需要从多个数据源中拿数据，然后再拼接为最终的结果。很直观的，不可能从每个数据节点（数据节点：一个数据库 + 表名定义唯一一个数据节点）执行一次limit，然后将结果拼接再一次，选出目标范围内的数据。ShardingSphere-Jdbc也的确不是这样做的，它做了一些SQL的改写。\nShardingSphere-Jdbc如何改写：举个例子，如果我们要得到第3页的10个数据，原始limit的写法为limit 3, 10。ShardingSphere-Jdbc对其的改写为：limit 0, 33，它从每个数据节点拿到前33个数据，拼接后，再显示按照需求显示第3页的10个数据。\n我们不必担心这个过程中内存会使用量会非常高，按照官方文档的说法，其底层采用了流式处理方案，并不是将各个数字节点的数据缓存到内存后再做分页。\n不过，如果分页偏移量很大，则可能引发新的问题，那就是网络开销，按照ShardingSphere-Jdbc的实现，如果我们有三个数据节点，需求为要第一万页的数据，则其至少需要传输三万乘以每页大小个数据。\nShardingSphere-Jdbc官方文档中简单提到了一个解决方案，分别如下：\n 构建行记录数量与行偏移量  这个方案我并没有查到相关的资料，也不知道如何实践。\n通过某个可排序的字段完成分页  代码演示如下：\n1  SELECT*FROMt_orderWHEREid\u0026gt;100000ANDid\u0026lt;=100010ORDERBYid  其实这个是没有办法在我们生产中实践的，因为我们生产中的id是由雪花算法产生的，并且和行不是一一对应的，所以100010 \u0026gt;= id \u0026gt; 100000在分页层面并没有任何含义。\n我认为我们可以使用一个row字段，来模拟这种解决方案，但又会引入新的问题，那就是在微服务架构中，我们还需要确保row字段全局唯一而且还要递增，这本身就是一个技术难题（我们的项目中，目前没有积累解决这种问题的方案）。这个方案还存在一个问题，那就是应用面窄，一旦增加了排序的需求，row字段就没有任何意义的，又会回归到ShardingSphere默认的解决方法。\n不过我们的项目实际上只采用了分表，没有采用分库，甚至整个微服务都是用同一个库（我们再尽量避免分布式事务方面的问题）。所以通过一些技巧，还是有办法拿到全局唯一的row值。\n我们项目一直不愿意引入新的技术方案，怕增加研发成本，这限制了我们解决问题的思路。这个问题应该可以使用ES解决，但是没有机会进行探索这个方案。\n查询时不包括分表键的问题 我们分表策略为按照某个字段，进行模运算。但是我们实际业务中，不一定按照这个字段进行查询，这就导致了会出现按照非分表键进行查询的问题，按照文档所说，这个查询将会遍历全部的分表。\n该如何解决了，我们采用的方案为：对这些非分表键加索引。这个方案看上去不是很优雅，但是可以在一定程度上环节这个问题。\n还有一种高大上的解决方案，我们可以使用多个键进行分表，且算法需要保证单独使用各个键、使用全部这些键时能够定位到同一张表，关于这个算法如何实现能不能实现，其实我是不知道的。\n或许业务精心设计后，这个问题也是可以避免的，但是在我们的项目中，这样做的成本会非常高。\n绑定表 绑定表是指指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。\n这儿挪用一下官方的案例，一个查询如下：\nSELECT i.* FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 那么按照笛卡尔积，则应该改写SQL为：\nSELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 配置了绑定表关系后，改写所得的SQL为：\nSELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); 在我们的业务中有相关的需求，所以我们需要使用到绑定表。\n按时间分表及相关定时任务 我们一些记录表，是按照时间分片的，在ShardingSphere-Jdbc中，我们需要自行提供分片算法，思路清晰时，这个算法实现起来比较简单。\n这儿说说我在实现时遇到的一个坑：因为我们的schedule项目需要操作分表，故项目引入了ShardingSphere-JDBC，同时我想在执行建表语句前，检查一下该表是否存在，故我使用了show tables like \u0026lsquo;'，解决发现返回的结果为空。后来经过实验，我发现，原生的数据源的的确确支持show语句，但是ShardingSphere-JDBC配置的数据源是不支持这个语句的。（官方文档也有谈到对各种语句的支持，我没有深入研究）\n最后我的解决方案为，创建一张纯记录表，记录目前定时任务已经创建了哪些表，这样使用select语句就可以知道表是否创建了。\n值得研究的方向  与Liquibase的结合  我是比较感兴趣这个技术点的，但是，我对Liquibase的掌握，目前也仅仅限制与一些简单的Demo。\n为什么我会对这两者的结合感兴趣了，ShardingSphere-Jdbc支持插入语句，我们可以从旧表中读取数据，然后再插入到新表中，完成数据的迁移。而完成这个工作的最好工具就是Liquibase。\n系统的使用这款工具  我们的业务需求真的只使用了这个工具的很小一部分功能，它还提供了很多非常强大的功能。我们对这款工具的使用是存在隐患的，如前文所述，有很多业务场景下的解决方案都不是很优雅，而且，很多生产中可能会遇到的问题，我们都没有进行假设，并准备应对方案（这本来应该是DBA干的，我们开发客串了）。\n参考资料  Apache ShardingSphere apache/shardingsphere  ","description":"","id":463,"section":"notes","tags":null,"title":"ShardingSphere-Jdbc研究日志","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/shardingsphere-jdbc/shardingsphere-jdbc%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"},{"content":"shell定义变量和使用变量  first_name=\u0026quot;Bob\u0026quot; second_name=\u0026quot;bob\u0026quot; your_name=\u0026quot;$first_name $second_name\u0026quot; your_name2='Bob bob' ","description":"","id":464,"section":"notes","tags":null,"title":"shell定义变量和使用变量","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/shell%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E5%92%8C%E4%BD%BF%E7%94%A8%E5%8F%98%E9%87%8F/"},{"content":"我的需求是这样的，我需要序列化一个对象成yaml文档，序列化时要求驼峰转下划线，且保持字段声明顺序。我原本计划通过自定义snakeyaml的Representer实现这个需求，但是发现并不是很好这么搞（我没有充分研究，我觉得投入和产出不成比例），所以我决定绕一绕解决问题。\n我最终选择的方案是，将对象通过fastjson转换成一个json字符串，转换的过程中保持字段声明顺序，且驼峰转下滑线。然后再用fastjson将json字符串转换成一个LinkedHashMap，再使用snakeyaml的dump方法导出该map。具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /** * 将对象序列化成Yaml文件，序列化时保持字段顺序与声明一致 */ public static void dumpObject(TableRoot sourceObj, Path dirPath, String fileName) { try { if (!Files.exists(dirPath)) { Files.createDirectory(dirPath); } // 将原始的对象序列化成json（字段按照原对象的声明顺序）  JSON.DEFAULT_GENERATE_FEATURE \u0026amp;= ~SerializerFeature.SortField.getMask(); SerializeConfig serializeConfig = new SerializeConfig(true); serializeConfig.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase; String jsonWithFieldOrder = JSON.toJSONString(sourceObj, serializeConfig); // 将jsonWithFieldOrder转换成Map，并输出到yaml文件  FileWriter fileWriter = new FileWriter(Paths.get(dirPath.toString(), fileName).toString()); Yaml yaml = new Yaml(); fileWriter.write(yaml.dumpAsMap(JSON.parseObject(jsonWithFieldOrder, LinkedHashMap.class, Feature.OrderedField))); fileWriter.close(); } catch (IOException e) { throw new RuntimeException(\u0026#34;Dump Wrong...\u0026#34;); } }   这种解决问题的方案，成本非常的高，不过我用于工具的开发，问题倒不是很大。反序列话相对比较简单，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  /** * 将多个Yaml文件反序列化成对象列表 */ public static List\u0026lt;TableRoot\u0026gt; loadObject() { File outputDir = new File(Paths.get(ToolsConfig.TABLES_INFO_DIR, ProjectConfig.getProjectName()).toString()); if (!outputDir.isDirectory()) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } File[] yamlFiles = outputDir.listFiles(); if (yamlFiles == null) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } try { List\u0026lt;TableRoot\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (File file : yamlFiles) { String jsonMiddle = JSON.toJSONString(new Yaml().load(new FileReader(file))); TableRoot tableRoot = JSONObject.parseObject(jsonMiddle, TableRoot.class); result.add(tableRoot); } return result; } catch (FileNotFoundException e) { throw new RuntimeException(\u0026#34;Load Wrong...\u0026#34;); } }   参考资料   【需求】支持按照成员变量声明顺序，做序列化字段排序\n  Keep tags order using SnakeYAML\n针对该需求，这篇教程中似乎提到了更高级的解决方案，但是我目前没有使用该方案的需求。\n  JAVA使用SnakeYAML解析与序列化YAML\n这篇文章里有些高级的知识需要理解下。\n  ","description":"","id":465,"section":"notes","tags":null,"title":"snakeyaml驼峰与下滑线转化","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/snakeyaml/snakeyaml%E9%A9%BC%E5%B3%B0%E4%B8%8E%E4%B8%8B%E6%BB%91%E7%BA%BF%E8%BD%AC%E5%8C%96/"},{"content":"我的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Data @NoArgsConstructor public class TableRoot { private String tblName; private String tblDesc; private List\u0026lt;ColumnRoot\u0026gt; columns; public TableRoot(String tblName, String tblDesc) { this.tblName = tblName; this.tblDesc = tblDesc; this.columns = new ArrayList\u0026lt;\u0026gt;(); } @Data @SuppressWarnings(\u0026#34;WeakerAccess\u0026#34;) private static class ColumnRoot { private String colName; private String colDesc; @JSONField(deserializeUsing = JavaTypeCodec.class, serializeUsing = JavaTypeCodec.class) private JavaType javaType; } }   序列化TableRoot对象时发现无法正常序列化，提示权限不足，需要将ColumnRoot改为public。我ColumnRoot其实没有暴露到外部的需求，但是因为snakeyaml的特性不得不暴露到外部，不是很爽。\n我目前没有找到资料解决这个问题。\n参考资料  can not access a member of class with modifiers \u0026ldquo;public\u0026rdquo;  ","description":"","id":466,"section":"notes","tags":null,"title":"snakyaml序列化时，类必须为public","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/snakeyaml/snakyaml%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E7%B1%BB%E5%BF%85%E9%A1%BB%E4%B8%BApublic/"},{"content":"需求很少的，作废该笔记了\n我的工具监听的是socks协议，socks协议的dns请求仍然会通过原来的网络进行解析，而我们的工具中只能指定socks5://不能指定socks5h://，所以我们的dns无法被正确解析。于是我想将socks协议转换为http协议，我找到了polipo工具。\n安装polipo 指令如下：\n1 2 3 4 5 6 7 8  git clone https://github.com/jech/polipo.git cd polipo git checkout polipo-1.1.1 make all su -c \u0026#39;make install\u0026#39;   最后一步我遇到了一个关于text的报错，我执行下面的指令修复了这个问题：\n1 2 3  yum install texinfo   后续：\n新开的虚拟机安装时遇到如下问题：\n cc -Os -g -Wall -fno-strict-aliasing -DLOCAL_ROOT=\\\u0026quot;/usr/share/polipo/www/\\\u0026quot; -DDISK_CACHE_ROOT=\\\u0026quot;/var/cache/polipo/\\\u0026quot; -c -o util.o util.c make: cc: Command not found 我选择把常用的编译库都安装一遍：\n1 2 3 4  yum -y install gcc automake autoconf libtool make yum install gcc gcc-c++   配置并启动polipo 配置指令如下（有时间改为echo版）：\n1 2 3 4 5 6 7 8 9 10  mkdir /opt/polipo vim /opt/polipo/config proxyAddress = \u0026#34;0.0.0.0\u0026#34; socksParentProxy = \u0026#34;127.0.0.1:2223\u0026#34; socksProxyType = socks5 proxyPort = 12345 dnsQueryIPv6 = no   使用如下指令进行启动：\n polipo -c /opt/polipo/config 参考资料  centos7 安装polipo Linux socks5转http  ","description":"","id":467,"section":"notes","tags":null,"title":"socks协议转http协议","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%BD%9C%E5%BA%9F/socks%E5%8D%8F%E8%AE%AE%E8%BD%AChttp%E5%8D%8F%E8%AE%AE/"},{"content":"我第一尝试的方案如下：\n1 2 3 4 5 6 7  stringRedisTemplate.multi(); stringRedisTemplate.opsForValue().set(\u0026#34;name\u0026#34;, \u0026#34;qinyi\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;gender\u0026#34;, \u0026#34;male\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;age\u0026#34;, \u0026#34;19\u0026#34;); System.out.println(stringRedisTemplate.exec());   但是这种写法会报错，具体的原因是Spring Data Redis执行multi和exec时使用的不是同一个Connection。查找资料说可以使用如下写法：\n1 2 3 4 5 6 7 8  redisTemplate.setEnableTransactionSupport(true) stringRedisTemplate.multi(); stringRedisTemplate.opsForValue().set(\u0026#34;name\u0026#34;, \u0026#34;qinyi\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;gender\u0026#34;, \u0026#34;male\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;age\u0026#34;, \u0026#34;19\u0026#34;); System.out.println(stringRedisTemplate.exec());   在实践中该方法没有任何作用，我最终选择使用如下写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13  stringRedisTemplate.execute(new RedisCallback\u0026lt;Object\u0026gt;() { @Override public Object doInRedis(RedisConnection connection) throws DataAccessException { stringRedisTemplate.multi(); stringRedisTemplate.opsForValue().set(\u0026#34;name\u0026#34;, \u0026#34;qinyi\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;gender\u0026#34;, \u0026#34;male\u0026#34;); stringRedisTemplate.opsForValue().set(\u0026#34;age\u0026#34;, \u0026#34;19\u0026#34;); System.out.println(stringRedisTemplate.exec()); return \u0026#34;\u0026#34;; } });   20220121后续：\n在学习Spring Data Redis的事务部分时，发现官方的写法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  List\u0026lt;Object\u0026gt; txResults = redisTemplate.execute(new SessionCallback\u0026lt;List\u0026lt;Object\u0026gt;\u0026gt;() { @Override public List\u0026lt;Object\u0026gt; execute(RedisOperations operations) throws DataAccessException { operations.multi(); operations.opsForSet().add(\u0026#34;key\u0026#34;, \u0026#34;values\u0026#34;); return operations.exec(); } }); System.out.println(\u0026#34;Number of items add to set: \u0026#34; + txResults.get(0));    Spring Data Redis提供了SessionCallback接口，供需要在同一个连接上执行多个操作时使用。\n 参考资料  How to implement Redis Multi-Exec by using Spring-data-Redis  ","description":"","id":468,"section":"notes","tags":null,"title":"Spring Data Redis中使用Multi Exec","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/spring-data-redis%E4%B8%AD%E4%BD%BF%E7%94%A8multi-exec/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  @Slf4j @RestController public class FileUploadController { @PostMapping(\u0026#34;/upload\u0026#34;) private ResponseVo upload( @RequestPart(\u0026#34;file\u0026#34;) MultipartFile file, @RequestPart(\u0026#34;files\u0026#34;) MultipartFile[] files) throws IOException { log.info(\u0026#34;上传的信息: file={}, files={}\u0026#34;, file.getSize(), files.length); if (!file.isEmpty()) { file.transferTo(Paths.get( \u0026#34;C:\\\\Users\\\\wujj\\\\Desktop\\\\Tmp5\\\\\u0026#34;, file.getOriginalFilename())); } if (files.length \u0026gt; 0) { for (MultipartFile multipartFile : files) { if (!multipartFile.isEmpty()) { multipartFile.transferTo(Paths.get( \u0026#34;C:\\\\Users\\\\wujj\\\\Desktop\\\\Tmp5\\\\\u0026#34;, multipartFile.getOriginalFilename())); } } } return new ResponseVo(\u0026#34;00000\u0026#34;, \u0026#34;成功\u0026#34;); } }   Postman上传时配置如下：\nMultipartFile应用 说起来有点糟心，Spring MVC的MultipartFile非常的好用，但是我们代码使用这个工具的方式真的不是很优雅：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public ResponseVo\u0026lt;Object\u0026gt; importCompany( @RequestAttribute(value = APICons.REQUEST_USER, required = false) JSONObject user, MultipartHttpServletRequest request) throws IOException { Map\u0026lt;String, MultipartFile\u0026gt; fileMap = request.getFileMap(); List\u0026lt;String\u0026gt; msgList = new ArrayList\u0026lt;\u0026gt;(); for (Map.Entry\u0026lt;String, MultipartFile\u0026gt; stringMultipartFileEntry : fileMap.entrySet()) { Sheet sheet = new Sheet(1, 1, CompanyRequestMode.class); EasyExcelFactory.readBySax( stringMultipartFileEntry.getValue().getInputStream(), sheet, new ExcelCompanylistener(this.companyService, this.packageService, user.getString(\u0026#34;id\u0026#34;), user.getString(\u0026#34;name\u0026#34;), msgList)); } return ResponseVo.ok(msgList); }   我们没有在参数中接受MultipartFile类型的参数，而是从request中获取了一个Map类型的，感觉这样编码并不是很优雅。\n","description":"","id":469,"section":"notes","tags":null,"title":"Spring MVC如何上传文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/spring-mvc%E5%A6%82%E4%BD%95%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/"},{"content":"表单支持Delete、PUT参数 为了让表单支持DELETE、PUT等参数，我们需要配置HiddenHttpMethodFilter，配置了该Bean后，表单可以增加_method的隐藏域，来支持DELETE、PUT等参数。我们可以对HiddenHttpMethodFilter进行定制：\n1 2 3 4 5 6 7 8  @Bean public HiddenHttpMethodFilter hiddenHttpMethodFilter(){ HiddenHttpMethodFilter methodFilter = new HiddenHttpMethodFilter(); methodFilter.setMethodParam(\u0026#34;_m\u0026#34;); return methodFilter; }   HiddenHttpMethodFilter的原理是这样的：\n Post请求，且带有_method参数，会被HiddenHttpMethodFilter拦截 拦截后返回一个RequestWrapper对象，该对象的getMethod将会返回_method对应的方法  请求映射的原理 Dispatcher的doDispatch方法会找一个正确的一个Handler处理当前的请求，程序运行的过程中，有如下的Handler：\n其中WelcomePageHandlerMapping可以访问index.html，RequestMappingHandlerMapping在请求进来时，挨个尝试所有的HandlerMapping看是否有请求信息。如果有就找到这个请求对应的Handler，如果没有就是尝试一个HandlerMapping。\n我们可以通过给容器注入HandlerMapping，来自定义映射处理（我评估了一下，暂时没有相关需求，所以就不研究了）\n在处理Controller中的方法时，我们使用RequestMappingHandlerMapping。RequestMappingHandlerMapping包含了当前SpringBoot实例中所有@RequestMapping和handler的映射规则：\n（整理到这块，我突然意识到RequestMappingHandlerMapping和最开始的@RequestMapping注解好像啊，RequestMappingHandlerMapping应该就是@RequestMapping真实处理类）\n普通参数与基本注解 基本注解有如下几个：@PathVariable、@RequestHeader、@ModleAttribute、@RequestParam、@MatrixVariable、@CookieValue、@RequestBody，其中@PathVariable、@ModleAttribute、@MatrixVariable、@CookieValue这几个我用的比较少。\n支持的Servlet参数有：WebRequest、ServletRequest、MultipartRequest、HttpSession、PushBuilder、Principal、InputStream、Reader、HttpMethod、Locale、TimeZone、ZoneId。由ServletRequestMethodArgumentResolver提供对这些\n支持的复杂参数有：Map、Model（map、model里面的数据会被放在request的请求域request.setAttribute）、Errors/BindingResult、RedirectAttributes（重定向携带数据）、ServletResponse、SessionStatus、UriComponentsBuilder、ServletUriComponentsBuilder\n对矩阵变量的理解 （我不想整理这部分笔记了，矩阵变量的使用概率非常的底）\n对Map、Modle的理解 （这部分用的比较少了，仅记录一下）\nMap、Model类型的参数，会返回mavContainer.getModel();\u0026mdash;\u0026gt;BindingAwareModelMap是Model也是Map。\n对自定义对象的理解 ServletModelAttributeMethodProcessor\n（我们很少用对象去接受请求的参数，故此处不深入研究。）\n参数处理原理  HandlerMapping中找到能处理请求的Handler（Controller.method()） 为当前Handler找一个适配器HandlerAdapter（RequestMappingHandlerAdapter） 适配器执行目标方法，并确定方法参数的每一个值  数据相应与内容协商 （暂时不整理这部分了）\n","description":"","id":470,"section":"notes","tags":null,"title":"Spring MVC对请求参数处理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/spring-mvc%E5%AF%B9%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E5%A4%84%E7%90%86/"},{"content":"为了编写配置方便，我们引入了如下的jar包：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   如果进行如上配置，则该jar包会打入我们最终可运行的jar包中，这样会浪费一丢丢我们的内容空间：\n官方文档给了如下配置建议：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.7.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt;fun.junjie.mybatis.MybatisApplication\u0026lt;/mainClass\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;repackage\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt;   参考资料   Configuring the Annotation Processor\n我只找到了低版本的文档，高版本的文档中没有提到这一块。\n  ","description":"","id":471,"section":"notes","tags":null,"title":"spring-boot-configuration-processor包与构建插件的配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/spring-boot-configuration-processor%E5%8C%85%E4%B8%8E%E6%9E%84%E5%BB%BA%E6%8F%92%E4%BB%B6%E7%9A%84%E9%85%8D%E7%BD%AE/"},{"content":"是这样的，我在合并分支的时候，删除了原来的源码，从Git上拉取了一份新的代码，然后再Idea导入该源码并启动该项目，结果再启动的过程中一致报如下错误：\n *************************** APPLICATION FAILED TO START *************************** Description: The bean 'http://metadata.FeignClientSpecification' could not be registered. A bean with that name has already been defined and overriding is disabled. Action: Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true 之前运气比较好，我在启动项目时一定会指定spring.profiles.active=local，所以我也是第一看到这个错误。我之前的项目中也从来没有进行过spring.main.allow-bean-definition-overriding=true配置，所以我主观上也不会想到在配置文件中进行该项配置。\n我在什么时候意识到是我自己出了问题，我在发现我昨天成功运行的分支突然也运行不了，后来才发现是自己忘记配置spring.profiles.active=local了（经过同事提醒）。在这次定位问题的过程中我也接触了一些新的东西，比如：\n实际上我是不需要配置spring.profiles.active=local的，我可以在profiles中选择local，就可以使用到local环境。经过同事了解到其原理：当选择了local后，我们在运行时会自动给带上spring.profiles.active=local参数。其实我是有点不理解的是，我运行的时候是通过Idea上的运行按钮，profiles配置属于Maven的配置，这两者之间是如何联系在一起的呢？\n","description":"","id":472,"section":"notes","tags":null,"title":"spring.main.allow-bean-definition-overriding配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/spring.main.allow-bean-definition-overriding%E9%85%8D%E7%BD%AE/"},{"content":"SpringBoot Actuator默认的地址是在server.servlet.context-path的基础上加上actuator/*，这个细节，我之前一直没有关注到。management.endpoints.web.base-path配置实际上只会影响到actuator段。\n举一个例子，如果项目按如下配置了context-path，那么actuator的地址就为：localhost:50001/demo/actuator\n server: port: 50001 servlet: context-path: /demo 此时如果修改了management.endpoints.web.base-path且值为tmp-actuator，那么actuator的地址就为：localhost:50001/demo/tmp-actuator\n这样其实挺好的，这样的话我们的actuator请求可以非常轻松的通过网关，不需要在额外配合什么东西了。\n参考资料 好东西，慢慢消化~~~\nSpring Boot (十九)：使用 Spring Boot Actuator 监控应用\n","description":"","id":473,"section":"notes","tags":null,"title":"SpringBoot Actuator的base-path配置项","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/springboot-actuator%E7%9A%84base-path%E9%85%8D%E7%BD%AE%E9%A1%B9/"},{"content":" 脚本如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  local key = KEYS[1] local value = ARGV[1] local expire = ARGV[2] if redis.call(\u0026#34;get\u0026#34;, key) == false then if redis.call(\u0026#34;set\u0026#34;, key, value) then if tonumber(expire) \u0026gt; 0 then redis.call(\u0026#34;expire\u0026#34;, key, expire) end return true end end return false   1 2 3 4 5 6 7 8 9 10 11 12  local key = KEYS[1] local current_value = ARGV[1] local expect_value = ARGV[2] if redis.call(\u0026#39;GET\u0026#39;, key) == current_value then redis.call(\u0026#39;SET\u0026#39;, key, expect_value) return true end return false   配置如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Configuration public class LuaConfiguration { @Bean public RedisScript\u0026lt;Boolean\u0026gt; lua02() { return RedisScript.of(new ClassPathResource(\u0026#34;scripts/lua02.lua\u0026#34;), Boolean.class); } @Bean public DefaultRedisScript\u0026lt;Boolean\u0026gt; lua01() { DefaultRedisScript\u0026lt;Boolean\u0026gt; redisScript = new DefaultRedisScript\u0026lt;\u0026gt;(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\u0026#34;scripts/lua01.lua\u0026#34;))); redisScript.setResultType(Boolean.class); return redisScript; } }   测试代码如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  @SpringBootTest public class Test05_RedisScripting { @Autowired private RedisScript\u0026lt;Boolean\u0026gt; lua02; @Autowired private DefaultRedisScript\u0026lt;Boolean\u0026gt; lua01; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void lua01() { Boolean execute = stringRedisTemplate.execute(lua01, Collections.singletonList(\u0026#34;lua01_key\u0026#34;), \u0026#34;lua01_value\u0026#34;, \u0026#34;1000\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } @Test public void lua02() { stringRedisTemplate.opsForValue().set(\u0026#34;lua02_key\u0026#34;, \u0026#34;2\u0026#34;); Object execute = stringRedisTemplate.execute(lua02, Collections.singletonList(\u0026#34;lua02_key\u0026#34;), \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } }   注意事项   Lua脚本的bug特别可怕，由于Redis的单线程特点，一旦Lua脚本出现不会返回（不是返回值）得问题，那么这个脚本就会阻塞整个redis实例。\n  Lua脚本应该尽量短小实现关键步骤即可。（原因同上）\n  Lua脚本中不应该出现常量Key，这样会导致每次执行时都会在脚本字典中新建一个条目，应该使用全局变量数组KEYS和ARGV, KEYS和ARGV的索引都从1开始（这个提醒非常好，因为我习惯去定义变量）\n  传递给lua脚本的的键和参数：传递给lua脚本的键列表应该包括可能会读取或者写入的所有键。传入全部的键使得在使用各种分片或者集群技术时，其他软件可以在应用层检查所有的数据是不是都在同一个分片里面。另外集群版redis也会对将要访问的key进行检查，如果不在同一个服务器里面，那么redis将会返回一个错误。（决定使用集群版之前应该考虑业务拆分），参数列表无所谓。（感觉Redis集群服务还是有很多技术点需要研究的，我们现在的应用还停留在表皮）\n  lua脚本跟单个redis命令和事务段一样都是原子的已经进行了数据写入的lua脚本将无法中断，只能使用SHUTDOWN NOSAVE杀死Redis服务器，所以lua脚本一定要测试好。\n  参考资料  SpringBoot使用Lua脚本操作Redis  ","description":"","id":474,"section":"notes","tags":null,"title":"SpringBoot使用Redis脚本","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/scripts/springboot%E4%BD%BF%E7%94%A8redis%E8%84%9A%E6%9C%AC/"},{"content":"因为开发需求，引入了如下一些包：\n1 2 3 4 5 6 7 8 9  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.sdstc.starter\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elasticjob-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   结果项目无法正常启动，报如下错误：\n *************************** APPLICATION FAILED TO START *************************** Description: An attempt was made to call a method that does not exist. The attempt was made from the following location: com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter.persistEphemeral(ZookeeperRegistryCenter.java:246) The following method did not exist: org.apache.curator.framework.api.CreateBuilder.creatingParentsIfNeeded()Lorg/apache/curator/framework/api/ProtectACLCreateModePathAndBytesable; The method's class, org.apache.curator.framework.api.CreateBuilder, is available from the following locations: jar:file:/home/usr/updacnce/srm.jar!/BOOT-INF/lib/curator-framework-4.0.1.jar!/org/apache/curator/framework/api/CreateBuilder.class It was loaded from the following location: jar:file:/home/usr/updacnce/srm.jar!/BOOT-INF/lib/curator-framework-4.0.1.jar!/ Action: Correct the classpath of your application so that it contains a single, compatible version of org.apache.curator.framework.api.CreateBuilder 同事提示，项目中存在包冲突，需要加入上下配置。加上配置后，问题确实解决了，但是我认为这不是优雅的解决方案，优雅的方案不是应该升级一下elasticjob-spring-boot-starter么。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.dangdang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elastic-job-lite-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.dangdang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;elastic-job-lite-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-framework\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.10.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/com.google.guava/guava --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.guava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guava\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;20.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;   ","description":"","id":475,"section":"notes","tags":null,"title":"SpringBoot依赖版本被覆盖","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E4%BE%9D%E8%B5%96%E7%89%88%E6%9C%AC%E8%A2%AB%E8%A6%86%E7%9B%96/"},{"content":"代码如下：\n1 2 3 4 5 6  @PostConstruct void setDefaultTimezone() { TimeZone.setDefault(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); }   需要注意的是如下的写法并不会生效：\n1 2 3 4 5 6  public static void main(String[] args) { TimeZone.setDefault(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); SpringApplication.run(MybatisApplication.class, args); }   查看当前实例的时区，可用如下代码：\n1 2 3 4  ZoneId defaultZone = ZoneId.systemDefault(); System.out.println(defaultZone);   参考资料  springboot项目设置时区 java关于时区的获取的几种方式  ","description":"","id":476,"section":"notes","tags":null,"title":"SpringBoot修改默认的时区","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84%E6%97%B6%E5%8C%BA/"},{"content":"方案都挺不优雅的，尤其是在激活多个profiles时，先收集一下，下次用的时候再整理吧。\n参考资料  SpringBoot获取当前运行环境三种方式  ","description":"","id":477,"section":"notes","tags":null,"title":"SpringBoot在代码中获取profiles信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E5%9C%A8%E4%BB%A3%E7%A0%81%E4%B8%AD%E8%8E%B7%E5%8F%96profiles%E4%BF%A1%E6%81%AF/"},{"content":"使用场景是这样的，一个记录配置信息的类，想使用静态方法、静态字段记录一些存储在配置文件中的信息。我选择定义这些静态的字段，然后再定义一些需要注入的字段，然后在一个方法中实现注入的字段往静态的字段中赋值的操作。\n大概代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Component public class Config{ @Autowire private String configItem1; @Autowire private String configItem2; public static String CONFIG_ITEM_1; public static String CONFIG_ITEM_2; @PostConstruct public void init(){ CONFIG_ITEM_1 = configItem1; CONFIG_ITEM_2 = configItem2; } }   目前这种写法我觉得非常的不优雅，原因有下：\n 我定义了两种含义一样的字段，只是一个是静态的，一个是对象的  如何解决这个问题了，我想到的方案是使用将@Autowire放置在set方法上，这样甚至可以免去init方法的开发，但是这样不是没有问题的：目前我的编码风格已经习惯性使用构造函数注入，最不济也是将@Autowire写在字段上，为了使用静态的信息，我需要将@Autowire写在方法上，这样非常不符合我的编码习惯。\n参考资料  Spring 容器启动完成后，执行初始化加载工作 SpringBoot使用@Value给静态变量注入值  ","description":"","id":478,"section":"notes","tags":null,"title":"SpringBoot容器初始化后执行回调","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%90%8E%E6%89%A7%E8%A1%8C%E5%9B%9E%E8%B0%83/"},{"content":"@Configuration的proxyBeanMethods参数 entity包\nUser.java\n1 2 3 4 5 6 7  @NoArgsConstructor @AllArgsConstructor public class User { private String name; }   Pet.java\n1 2 3 4 5 6 7  @NoArgsConstructor @AllArgsConstructor public class Pet { private String name; }   TmpConfiguration.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Configuration(proxyBeanMethods = false) public class TmpConfigration { @Bean public User user() { return new User(\u0026#34;张三\u0026#34;); } @Bean public Pet pet() { return new Pet(\u0026#34;旺财\u0026#34;); } }   三段测试代码：\n1 2 3 4 5 6  // 实验一 for (String name : configurableApplicationContext.getBeanDefinitionNames()) { System.out.println(name); }   实验一主要验证了加了@Bean注解的方法名，将会作为该Bean在容器中的名字。\n1 2 3 4 5 6 7 8 9 10 11  // 实验二 System.out.println(configurableApplicationContext.getBean(TmpConfigration.class)); System.out.println(configurableApplicationContext.getBean(TmpConfigration.class)); System.out.println(configurableApplicationContext.getBean(User.class)); System.out.println(configurableApplicationContext.getBean(User.class)); System.out.println(configurableApplicationContext.getBean(Pet.class)); System.out.println(configurableApplicationContext.getBean(Pet.class));   实验二验证了proxyBeanMethods无论是true或者false，都不会影响从容器中通过get方法获取Bean（这些Bean始终都是单例）\n1 2 3 4 5 6 7 8 9 10 11 12  // 实验三 TmpConfigration tmpConfigration = configurableApplicationContext.getBean(TmpConfigration.class); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.user()); System.out.println(tmpConfigration.pet()); System.out.println(tmpConfigration.pet()); System.out.println(tmpConfigration.pet());   实验三验证了如果proxyBeanMethods设置为true，则即使通过Configuration Bean的方法获取Bean，这些Bean都是单例的。如果proxyBeanMethods设置为false，则通过Configuration Bean的方法获取Bean，这些Bean不是单例的。\n小结 proxyBeanMethods代表了两种不同的SpringBoot模式：\n FULL(proxyBeanMethod = true)，每个@Bean方法别调用多次时，返回的组件都是单实例的 LITE(proxyBeanMethod = false)，每个@Bean方法被调用多次时，返回的组件都是新创建的  如果存在组件间的依赖（Bean之间存在依赖），则需要使用FULL模式，否则可以使用Lite模式。\n","description":"","id":479,"section":"notes","tags":null,"title":"SpringBoot的@Configuration配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E7%9A%84configuration%E9%85%8D%E7%BD%AE/"},{"content":"其实相关的技术我很早前就用在了项目中，但是一直没有整理笔记，最近在重构我工具包的代码时，又使用到了相关的技术，所以顺便整理一下。我工具包有个工具类，其中的方法都是静态方法，但是这些静态方法会根据配置文件呈现出不同的功能。\n配置文件的配置的获取我还是使用的是传统的方法，使用一个@ConfigurationProperties(prefix = \u0026quot;xxx\u0026quot;)注解，那么我工具类中需要只用配置类的时候，我就需要先注入其中，我之前的写法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Component @RequiredArgsConstructor public class YamlUtils { private final ToolsConfig toolsConfig; private final ProjectConfig projectConfig; private static ToolsConfig toolsConfigStatic; private static ProjectConfig projectConfigStatic; @PostConstruct public void init() { toolsConfigStatic = toolsConfig; projectConfigStatic = projectConfig; } }   我觉得非常的怪异，不是很满意。经过调整后，我的写法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @Component @RequiredArgsConstructor public class YamlUtils { private final ApplicationContext applicationContext; private static ToolsConfig toolsConfig; private static ProjectConfig toolsConfig; @PostConstruct public void init() { projectConfig = applicationContext.getBean(ProjectConfig.class); toolsConfig = applicationContext.getBean(ToolsConfig.class); } }   这种写法相对于之前的写法稍微优雅一点点，不需要同时提供一个对象字段和类字段了，而且两者的含义是一样的。但是其实我还是不太满意，我更期待的是ApplicationContext都不需要注入，而是通过一个工具类获取，或者存在支持静态字段注入的注解（目前没有找到相关的资料）。\n参考资料   从Spring 应用上下文获取 Bean 的常用姿势\n  spring项目中获取ApplicationContext对象，然后手动获取bean\n提到了一个继承ApplicationContextAware的方案，感觉很高级，但是在实践中获取到的bean为null，我也不知道为什么。\n  ","description":"","id":480,"section":"notes","tags":null,"title":"SpringBoot获取Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E8%8E%B7%E5%8F%96bean/"},{"content":"我们一部分接口在local环境并调不通，我将这些接口写在了manage层，我希望我有个开关当我在本地环境运行的时候，这些接口可以不被调用，我想到了使用SpringBoot的环境。\n如下代码：\n1 2 3 4 5 6 7 8 9 10  @Value(\u0026#34;${spring.profiles.active}\u0026#34;) private String env; public void test(){ if(\u0026#34;local\u0026#34;.equal(env)){ return; } }   我最后放弃这么搞了，因为这种方案在我们项目组中并不是很流行，我担心会给其他同事带来困惑。\n参考资料  SpringBoot获取当前运行环境三种方式  ","description":"","id":481,"section":"notes","tags":null,"title":"SpringBoot获取当前运行环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springboot%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/"},{"content":"我没有系统的学习Apollo，仅记录一下我在开发中遇到的问题，如下，我们在sit环境中的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  apollo:bootstrap:enabled:truenamespaces:application,mybatis-plus,datasource,redis,spring,ossapp:id:srmspring:main:allow-bean-definition-overriding:true  如果在本地想使用Apollo中sit环境的配置文件，则需要增加如下启动参数：\n -Dapollo.meta=http://192.168.19.107:8080 我打算有时间研究一下，如何把这个配置放在配置文件中，这样更利于我文件的CV。\n20211011后续 我最终决定不修改配置文件，虽然修改配置文件利于我CV，但是这份配置文件毕竟要上SIT环境的，所以在SIT环境中也会使用到我配置的配置中心地址，这样就不支持通过环境变量配置了（其实是支持的，但是有优先级问题，存在优先级问题，出现错误时不利于排查）。所以我决定使用环境变量的方式，参考我们SIT环境，我需要进行如下环境变量的配置：\n APOLLO_CLUSTER=default APOLLO_META=http://192.168.19.107:8080 这儿需要注意的是，我将点号换成了下滑线（但是有趣的是，在linux系统中，配置成点好也是可以正常使用的，这也许只是个例）。如果用点号的话，配置是不会生效的。另外配置后需要重新启动Idea，Idea新配置的环境变量不会立即生效，这个问题我很久前就注意到了。\n其实还可以使用修改hosts文件的方案，因为我注意到，不进行环境变量的配置时，会请求http://apollo.meta/，所以在hosts文件中配置apollo.meta的地址就可以了，但是我不是很喜欢这种方式，感觉和SIT环境的配置不一致，不是很优雅。\n参考资料   apollo 在 spring-boot 中的加载过程解析\n我是在该文中找到一段关于环境变量如何配置的讲解：\n  ","description":"","id":483,"section":"notes","tags":null,"title":"SpringBoot项目配置apollo访问地址","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/apollo/springboot%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AEapollo%E8%AE%BF%E9%97%AE%E5%9C%B0%E5%9D%80/"},{"content":"操作步骤   如图两个项目mmp-wuid和mmp-member-brand项目\n  mmp-wuid项目下有如下module，其中admin、api、fiegn都依赖于feign\n   mmp-global-admin-api mmp-global-api mmp-global-dmain mmp-global-api-feign  mmp-global-brand项目下，需要远程与mmp-wuid项目通信，所以mmp-global-admin-api模块依赖了mmp-wuid项目下mmp-global-api-feign项目  ","description":"","id":484,"section":"notes","tags":null,"title":"SpringCloud使用Feign方案","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/springcloud%E4%BD%BF%E7%94%A8feign%E6%96%B9%E6%A1%88/"},{"content":"Spring团队原本不打算支持OAuth授权服务器，因为他们认OAuth授权服务器并不是一个高频的需求，但是因为社区中有大量的人提出了该需求，所以他们打算实现一个授权服务器。Spring是直接开了一个新的项目来支持OAuth授权服务器，且这个新项目是基于一个叫做Nimbus的SDK。\n在学习OAuth的过程中，我可能不会使用Spring的授权服务器了，因为相关的资料会比较少。\n参考资料   Announcing the Spring Authorization Server\n  Spring Authorization Server 全新授权服务器整合使用\n  ","description":"","id":485,"section":"notes","tags":null,"title":"Spring与OAuth授权服务器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/spring%E4%B8%8Eoauth%E6%8E%88%E6%9D%83%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"content":"代码如下：\n1 2 3 4  ConfigurableEnvironment environment = applicationContext.getEnvironment(); environment.getProperty(\u0026#34;os.name\u0026#34;);   冷知识，第一次接触。\n","description":"","id":486,"section":"notes","tags":null,"title":"Spring获取操作系统信息","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/spring%E8%8E%B7%E5%8F%96%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF/"},{"content":"我对Spring的接触是直接从SpringBoot开始的，直接导致我没有接触一些原理层的东西，比如我们引入了starter-web后，SpringBoot到底做了哪些配置，这些配置的意义何在。所以我打算整理一下使用Spring配置Spring MVC的资料，从而更了解Spring MVC具体有哪些组件，各个组件的作用。这个整理的过程中我并不会进行任何实践，更多的是去理解。\n依赖的jar包   spring.jar\n  spring-core.jar\n 包含了Spring框架基本的核心工具类 Spring其它组件要都要使用到这个包里的类 可以在自己的应用系统中使用这些工具类    spring-beans.jar\n 这个jar文件是所有应用都要用到的， 它包含访问配置文件、创建和管理bean，以及进行IoC/DI操作相关的所有类。 如果应用只需基本的IoC/DI支持，引入spring-core.jar及spring-beans.jar文件就可以了。    spring-aop.jar\n 这个jar文件包含在应用中使用Spring的AOP特性时所需的类。 使用基于AOP的Spring特性，如声明型事务管理，也要在应用里包含这个jar包。    spring-context.jar　  这个jar文件为Spring核心提供了大量扩展。\n  可以找到使用Spring ApplicationContext特性时所需的全部类，JDNI所需的全部类，UI方面的用来与模板引擎如Velocity、FreeMarker、JasperReports集成的类，以及校验Validation方面的相关类。\n    spring-dao.jar　 这个jar文件包含Spring DAO、Spring Transaction进行数据访问的所有类。 为了使用声明型事务支持，还需在自己的应用里包含spring-aop.jar。    spring-hibernate.jar　 这个jar文件包含Spring对Hibernate 2及Hibernate 3进行封装的所有类。    spring-jdbc.jar　 这个jar文件包含对Spring对JDBC数据访问进行封装的所有类。    spring-orm.jar\n  这个jar文件包含Spring对DAO特性集进行了扩展，使其支持 iBATIS、JDO、OJB、TopLink，因为Hibernate已经独立成包了，现在不包含在这个包里了。\n  这个jar文件里大部分的类都要依赖spring-dao.jar里的类，用这个包时你需要同时包含spring-dao.jar包。\n    spring-remoting.jar\n 这个jar文件包含支持EJB、JMS、远程调用Remoting（RMI、Hessian、Burlap、Http Invoker、JAX-RPC）方面的类。    spring-support.jar\n 这个jar文件包含支持缓存Cache（ehcache）、JCA、JMX、邮件服务（Java Mail、COS Mail）、任务计划Scheduling（Timer、Quartz）方面的类。    spring-web.jar\n 这个jar文件包含Web应用开发时，用到Spring框架时所需的核心类， 包括自动载入WebApplicationContext特性的类、Struts与JSF集成类、文件上传的支持类、Filter类和大量工具辅助类。    spring-webmvc.jar\n 这个jar文件包含Spring MVC框架相关的所有类。 包含国际化、标签、Theme、视图展现的FreeMarker、JasperReports、Tiles、Velocity、XSLT相关类。 当然，如果你的应用使用了独立的MVC框架，则无需这个JAR文件里的任何类。    spring-mock.jar\n 这个jar文件包含Spring一整套mock类来辅助应用的测试。 Spring测试套件使用了其中大量mock类，这样测试就更加简单。 模拟HttpServletRequest和HttpServletResponse类在Web应用单元测试是很方便的。    我在我最新的一个SpringBoot项目中也发现了如上所述的一些jar包：\n这些包还有一些依赖包，我不整理这部分了，我核心只需要知道Spring的包做了什么。\nweb.xml配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  \u0026lt;display-name\u0026gt;SpringMVC\u0026lt;/display-name\u0026gt; \u0026lt;welcome-file-list\u0026gt; \u0026lt;welcome-file\u0026gt;/login.jsp\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring/spring-core.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!-- 配置ContextLoaderListener --\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;!-- 配置DispatcherServlet --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring/spring-servlet.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springMVC\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt;   ContextLoaderListener指定了IOC容器初始化的方法。\nDispatcherServlet则定义了mvc的相关内容，并配置拦截的URL。\n为了方便理解，如下提供了另一份关于servlet和servlet-mapping的配置，在该配置中，所有以/example开头的请求都会被名字为example的DispatcherServlet处理。\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;example\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;example\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/example/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt;   DispatcherServlet的初始化过程中，Spring MVC会在Web应用的WEB-INF目录下查找一个名为[servlet-name]-servlet.xml的配置文件，并创建其中所定义的Bean。如果在全局上下文中存在相同名字的Bean，则它们将被新定义的同名Bean覆盖。\n配置spring-servlet.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;!-- 开启注解 --\u0026gt; \u0026lt;!-- 这块配置了一个HttpMessageConverter，看样子HttpMessageConverter是在切面中发挥作用 --\u0026gt; \u0026lt;mvc:annotation-driven\u0026gt; \u0026lt;mvc:message-converters register-defaults=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\u0026#34; p:supportedMediaTypes=\u0026#34;text/html; charset=UTF-8\u0026#34; /\u0026gt; \u0026lt;/mvc:message-converters\u0026gt; \u0026lt;/mvc:annotation-driven\u0026gt; \u0026lt;context:annotation-config /\u0026gt; \u0026lt;!-- 开启AOP自动代理功能 --\u0026gt; \u0026lt;aop:aspectj-autoproxy proxy-target-class=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 事务（注解 ）--\u0026gt; \u0026lt;tx:annotation-driven transaction-manager=\u0026#34;transactionManager\u0026#34; proxy-target-class=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;!-- 视图解释器 --\u0026gt; \u0026lt;bean id=\u0026#34;viewResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.InternalResourceViewResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;prefix\u0026#34; value=\u0026#34;/WEB-INF/pages/\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;suffix\u0026#34; value=\u0026#34;.jsp\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- 静态资源访问 --\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/js/**\u0026#34; location=\u0026#34;/resources/js/\u0026#34;/\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/css/**\u0026#34; location=\u0026#34;/resources/css/\u0026#34;/\u0026gt;   注解与BeanPostProcessor 如果使用@Autowired注解，则必须配置AutowiredAnnotationBeanPostProcessor的Bean，如果使用@Required注解，则必须配置RequiredAnnotationBeanPostProcessor的Bean。类似地，使用@Resource、@PostConstruct、@PreDestroy等注解就必须声明CommonAnnotationBeanPostProcessor，使用@PersistenceContext注解，就必须声明PersistenceAnnotationBeanPostProcessor的Bean。\n这样的声明不太优雅，Spring提供了一种极为方便的注册这些BeanPostProcessor的方法，即使用\u0026lt;context:annotation- config/\u0026gt;向Spring容器注册AutowiredAnnotationBeanPostProcessor、RequiredAnnotationBeanPostProcessor、CommonAnnotationBeanPostProcessor、PersistenceAnnotationBeanPostProcessor\n如果配置了\u0026lt;context:component-scan/\u0026gt;，其包含了自动注入上述processor的功能，此时可以省去\u0026lt;context:component-scan/\u0026gt;配置。\n（PostProcessor是Spring生命周期中的一个周期，我之前有简单的接触过这个东西）\n参考资料  springMVC各个包下的作用 Spring SpringMVC配置  ","description":"","id":487,"section":"notes","tags":null,"title":"Spring配置Spring MVC","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/spring%E9%85%8D%E7%BD%AEspring-mvc/"},{"content":"操作步骤  如下代码生成秘钥对，可以一致按回车，使用默认值（我设置了密码）   ssh-keygen 执行如下指令，将生成的pub秘钥添加到信任名单，并检查文件权限正确（权限太高，无法正常登录）   cd .ssh cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys chmod 600 authorized_keys chmod 700 ~/.ssh 通过/etc/ssh/sshd_config文件配置ssh服务器（我服务器上没有找到RSAAuthentication，我只配置了PubkeyAuthentication），完成配置后，使用service sshd restart指令重启ssh服务。   RSAAuthentication yes PubkeyAuthentication yes #PasswordAuthentication yes service sshd restart  完成配置后，可以尝试用秘钥登录一次，具体操作为：下载id_rsa文件到本地，然后导入到XShell中，在登录的时候选择秘钥登录，然后设置秘钥的密码，就可以完成登录了。\n  完成登录后，配置ssh服务器，禁止用户用密码登录。\n   PasswordAuthentication no service sshd restart 参考教程  设置 SSH 通过密钥登录  ","description":"","id":488,"section":"notes","tags":null,"title":"SSH 配置只允许秘钥登录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/ssh-%E9%85%8D%E7%BD%AE%E5%8F%AA%E5%85%81%E8%AE%B8%E7%A7%98%E9%92%A5%E7%99%BB%E5%BD%95/"},{"content":"官方的starter命名：spring-boot-starter-*\n第三方的starter命名：*-spring-boot-starter\nMyBatis-Plus的starter命名：\n \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 遵循某种习惯，可以让代码和设计意图更容易被人理解。\n","description":"","id":489,"section":"notes","tags":null,"title":"Starter的命名习惯","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/starter%E7%9A%84%E5%91%BD%E5%90%8D%E4%B9%A0%E6%83%AF/"},{"content":"操作步骤  只用如下指令：   # 相比教程中的指令，增加了一个local参数（是因为我local-lvm不存在的原因） ./img2kvm openwrt.img 100 vm-100-disk-1 local ","description":"","id":490,"section":"notes","tags":null,"title":"storage 'local-lvm' does not exists","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/storage-local-lvm-does-not-exists/"},{"content":"两个大括号代表大括号本身，感觉不是很优雅。\n我本来准备了一段案例代码，案例代码和hugo有冲突，导致无法编译，所以我就清理掉了。\n","description":"","id":491,"section":"notes","tags":null,"title":"str.format输出大括号本身","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/str.format%E8%BE%93%E5%87%BA%E5%A4%A7%E6%8B%AC%E5%8F%B7%E6%9C%AC%E8%BA%AB/"},{"content":"写Demo时，StringReader可以让你不用新开一份文件，而是直接通过String实现相同的效果：\n Reader reader = new StringReader(\u0026quot;hhhhhh\u0026quot;); 参考资料  String 、InputStream、Reader 之间的转换  ","description":"","id":492,"section":"notes","tags":null,"title":"StringReader非常利于测试文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/stringreader%E9%9D%9E%E5%B8%B8%E5%88%A9%E4%BA%8E%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6/"},{"content":"StringUtils.trim()仅去除控制字符，且字符编码需要小于32\nStringUtils.strip()可以去除\\t\\r\\n等\nStringUtils.deleteWhitespace将删除所有的空白\n另外trim和strip还有xxxToNull和xxxToEmpty方法，如果字符串全部都为控制字符，则将得到Null或者空字符串。\ntrim和strip的区别在于能否去除全角和半角的空格字符。\n参考资料  StringUtils 去除空白 Java: trim()方法和strip()方法之间的区别  ","description":"","id":493,"section":"notes","tags":null,"title":"StringUtils去除文本首位空白","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/stringutils%E5%8E%BB%E9%99%A4%E6%96%87%E6%9C%AC%E9%A6%96%E4%BD%8D%E7%A9%BA%E7%99%BD/"},{"content":"tar不支持创建目录 tar使用-C参数时，如果目录不存在，是没有办法创建的，不要在徒劳的去寻找解压并创建目录的方法了，我感觉我已经尝试做这件事情好几次了！！！\n","description":"","id":494,"section":"notes","tags":null,"title":"tar在解压时不支持创建目录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/tar%E5%9C%A8%E8%A7%A3%E5%8E%8B%E6%97%B6%E4%B8%8D%E6%94%AF%E6%8C%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95/"},{"content":"这个方案目前还有很多问题，我个人认为是因为我还有很多细节处没有参透，所以结果很怪异。\n先说明一下我的需求，当我开发了一个分页接口，我需要测试其中的几个时间相关的字段，比如记录创建时间在某个范围，我一般会先看看我库中有哪些数据，然后直接把根据这些数据造测试数据：\n但是，由于我的接口是用时间戳的，而我直接查库得到的是一个时间，所以在使用的时候并不是很方便，我需要找另一个转换工具将这个时间转换为时间戳。\n我目前找到了如下查询语句的写法，可以稍微简化一下我的步骤：\n1 2 3 4 5  selectEXTRACT(epochFROMgmt_create_time)fromt_common_materialorderbygmt_create_time;  但是查询结果仍然不是太满意，我需要拷贝整数部分，然后手动加上三个零，才能得到一个稍微可以用的时间戳：\n该方案目前存在的问题有下：\n  查询的即使是时间，也是不准确的，我11左右插入的记录，但是查出来的数据显示是3点，我怀疑是我DataGrip的时间设置的有问题。\n  整数部分精确到了秒，但是我实际上需要的是一个精确到毫秒的时间戳。\n  问题一 确实是DataGrip时区设置的问题，相关的笔记我会整理在DataGrip分类下。\n问题二（我暂时还没验证，大概看了一下差不多） 优化一下查询语句：\n1 2 3 4  selectfloor(extract(epochfrom((gmt_create_time-timestamp\u0026#39;1970-01-01 00:00:00\u0026#39;)*1000)))fromt_common_material;  参考资料   postgresql获取系统当前时间毫秒数的sql，以及秒级时间戳\n  Postgresql中时间戳与日期的相互转换(同样适用于GreenPlum)\n  ","description":"","id":495,"section":"notes","tags":null,"title":"timestamptz查询结果用时间戳显示","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/timestamptz%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E7%94%A8%E6%97%B6%E9%97%B4%E6%88%B3%E6%98%BE%E7%A4%BA/"},{"content":"对timestamptz的研究，是为了项目内部时间戳的统一。统一时间戳可以有如下好处：\n  统一的认知层次，大家都清晰的知道，前端、后端、数据库中的时间戳意味着什么（主要是时区问题）\n  统一的工具类，我们可以用通一的时间戳工具类，完成我们所有的时间戳需求\n  利于框架层面统一处理时间戳，请求进入服务、返回到前端、服务内部的反序列化时我们时间戳都能正确的表达我们想要的数据。\n  理解timestamp和timestamptz timestamp数据类型可以同时存储日期和事件，但它不存储时区，这意味着修改了数据库服务器所在的时区时，它里面存储的值不会改变。timestamptz数据类型在存储日期和事件的同时还能正确处理时区。\nPostgreSQL使用UTC值来存储Timestamptz数据。在想timestamptz字段插入值的时候，PostgreSQL会自动将值转换成UTC值，并保存到表里。当从一个timestamptz字段查询数据的时候，postgreSQL会把存储在其中的utc值转换成数据库服务器、用户或当前链接所在的时区（如何理解用户、点前链接所在的时区）。\n重要提示：timestamptz并不会存储时区，它只是存储了utc值，然后会和当前时区进行转换。\n参考资料  PostgreSQL TIMESTAMP类型  ","description":"","id":496,"section":"notes","tags":null,"title":"timestamptz类型的研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/timestamptz%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%A0%94%E7%A9%B6/"},{"content":"需求描述 随机或按指定条件将玩家匹配到一起玩游戏。\n需求分析 条件可能是由我们玩家指定的，也可能是隐形的。比如我们的游戏有多个模式：双人协作、双人竞技。玩家指定了要双人协作模式，所以我们必须匹配这个模式。隐形条件是怎样的，有的玩家总是中途挂机、喜欢开麦、喜欢开麦克风、游戏中表现比较好，我们期待这样的玩家组队在一起玩，而那些表现的比较差的玩家，我不想让他们影响到表现好的玩家的游戏体验。\n随机在实现方面比较简单，考虑的因素会非常的小。\n但是眼下我可能会选择随机算法，然后再一次一次的迭代中优化这个算法，上来就选择最复杂的，会浪费非常多的精力在非核心的功能上。\n","description":"","id":497,"section":"notes","tags":null,"title":"tmp","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E6%88%BF%E9%97%B4%E6%9C%8D%E5%8A%A1/tmp/"},{"content":"我是有需求将type-handler-package配置成字符串数组，但是官方给的文档中，该处只能配置成字符串，我觉得查看源码肯定可以找到配置成字符串数组的方案，只是这样做成本太高了，并不值得这么做。\n20210621后续：\n我在网上有看到type-handler-package配置成多个值，值之间用分号隔开，我没有验证过这个方案。\n参考资料   typehandlerspackage官方文档\n  spring boot 与mybatis整合，type-aliases-package、type-handlers-package等配置不起作用,导致类加载失败\n这篇文章似乎在讲源码怎么看，我简单看了下，目前不想花精力去研究这个。\n  ","description":"","id":498,"section":"notes","tags":null,"title":"typeHandlersPackage只能配置成字符串","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/typehandlerspackage%E5%8F%AA%E8%83%BD%E9%85%8D%E7%BD%AE%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"content":"我在开发新功能时发现如下的问题，我代码编写如下：\n在运行时候value字段的值是：\n是一个LinkedTreeMap，而不是我期待的Language对象。\n我意识到肯定是JsonbTypeHandler影响了我最终的结果，但是，当我将JsonbTypeHandler换成ObjectTypeHandler时，依旧无法达到我想要的效果。\n我还未开始系统研究MyBatis-Plus，这块的问题只能先放置。我最终选择的是通过FastjsonTypeHandler先绕开这个问题（FastJsonTypeHandler也不能很好的符合我的需求）。\n20210520后续：\n我后来开发的处理该问题的方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_option\u0026#34;, autoResultMap = true) public class OptionPo extends BasePo { private static final long serialVersionUID = 1L; private String orgId; private String fieldCode; private Integer sort; @TableField(typeHandler = LanguageTypeHandler.class) private List\u0026lt;Language\u0026gt; value; @Data @NoArgsConstructor @AllArgsConstructor public static class Language { private String languageCode; private String languageValue; } @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public static class LanguageTypeHandler extends AbstractJsonTypeHandler\u0026lt;Object\u0026gt; { private final Class\u0026lt;?\u0026gt; type = Language.class; @Override protected Object parse(String json) { JSON.parseObject(\u0026#34;\u0026#34;, type); Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;数据库数据格式错误\u0026#34;); } } @Override protected String toJson(Object obj) { return JSON.toJSONString(obj, SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullStringAsEmpty); } } }   考虑到后面需要开发自动化工具，所以我将Handler提取到了框架中，新代码如下：\nJsonTypeHandler.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class JsonTypeHandler extends AbstractJsonTypeHandler\u0026lt;Object\u0026gt; { protected Class\u0026lt;?\u0026gt; type = Object.class; @Override protected Object parse(String json) { JSON.parseObject(\u0026#34;\u0026#34;, type); Object jsonObj = JSON.parse(json); if (jsonObj instanceof JSONObject) { return ((JSONObject) jsonObj).toJavaObject(type); } else if (jsonObj instanceof JSONArray) { return ((JSONArray) jsonObj).toJavaList(type); } else { throw new RuntimeException(\u0026#34;json数据格式错误\u0026#34;); } } @Override protected String toJson(Object obj) { return JSON.toJSONString(obj, SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullStringAsEmpty); } }   OptionPo.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package com.sdstc.dyf.admin.core.po; import com.sdstc.dyf.admin.core.handler.JsonTypeHandler; import com.sdstc.scdp.mybatis.plus.handler.JsonbTypeHandler; import com.baomidou.mybatisplus.annotation.TableName; import java.util.List; import com.sdstc.scdp.mybatis.plus.po.BasePo; import com.baomidou.mybatisplus.annotation.TableField; import lombok.*; import lombok.extern.slf4j.Slf4j; import org.apache.ibatis.type.JdbcType; import org.apache.ibatis.type.MappedJdbcTypes; import org.apache.ibatis.type.MappedTypes; /** * \u0026lt;p\u0026gt; * * \u0026lt;/p\u0026gt; * * @author wujj * @since 2021-05-17 */ @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_option\u0026#34;, autoResultMap = true) public class OptionPo extends BasePo { private static final long serialVersionUID = 1L; private String orgId; private String fieldCode; private Integer sort; @TableField(typeHandler = LanguageTypeHandler.class) private List\u0026lt;Language\u0026gt; value; @Data @NoArgsConstructor @AllArgsConstructor public static class Language { private String languageCode; private String languageValue; } @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public static class LanguageTypeHandler extends JsonTypeHandler { public LanguageTypeHandler() { this.type = Language.class; } } }   目前的实现上肯定不是非常的优雅，比如用FastJson解析的时候，一定需要先判断是Array还是Object，但是能达到我们想要的效果。\n自动化工具遇到类型为jsonb的字段时，会自动生成相应的对象和Handler。\n参考资料   MyBatis通过TypeHandler自动编解码对象的Json属性\n  关于mybatis中typeHandler的两个案例\n  【Mybatis】用TypeHandler将数据库中存储的json字符串处理为对象，包括对象含List以及复杂对象的情况, 并满足泛型可转成多种对象\n没有用到该资料，先记录在这块。\n  ","description":"","id":499,"section":"notes","tags":null,"title":"Typehandler转换出来的对象运行时状态和定义状态不符","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/typehandler%E8%BD%AC%E6%8D%A2%E5%87%BA%E6%9D%A5%E7%9A%84%E5%AF%B9%E8%B1%A1%E8%BF%90%E8%A1%8C%E6%97%B6%E7%8A%B6%E6%80%81%E5%92%8C%E5%AE%9A%E4%B9%89%E7%8A%B6%E6%80%81%E4%B8%8D%E7%AC%A6/"},{"content":"操作步骤  关闭用户图形界面，使用tty登录   sudo systemctl set-default multi-user.target sudo reboot 开启用户图形界面   sudo systemctl set-default graphical.target sudo reboot 参考资料  Ubuntu18.04 关闭和开启图形界面  ","description":"","id":500,"section":"notes","tags":null,"title":"Ubunt 18.04关闭和开启图形界面","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubunt-18.04%E5%85%B3%E9%97%AD%E5%92%8C%E5%BC%80%E5%90%AF%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2/"},{"content":"该教程为我工具机在公司访问网络用到的\n操作步骤  代码如下：  1 2 3 4 5 6 7  nmcli con edit CONNECTION_NAME nmcli\u0026gt; set ipv4.method auto nmcli\u0026gt; set 802-1x.eap peap nmcli\u0026gt; set 802-1x.identity sadegh.k@atu.com nmcli\u0026gt; set 802-1x.phase2-auth mschapv2 nmcli\u0026gt; save nmcli\u0026gt; quit   参考教程  Ubuntu 18.04终端802.1X认证设置？ 802.1x with NetworkManager using nmcli Ubuntu上通过802.1x认证联网  ","description":"","id":501,"section":"notes","tags":null,"title":"Ubuntu 18.04使用802.1x协议登录网络","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E4%BD%BF%E7%94%A8802.1x%E5%8D%8F%E8%AE%AE%E7%99%BB%E5%BD%95%E7%BD%91%E7%BB%9C/"},{"content":"操作步骤 准备基础环境：  克隆我的个人项目，启动三台虚拟机  1 2 3 4 5  git clone https://github.com/junjie2018/vagrant.git cd vagrant/cluster/ssh_kubernetes/kubernetes vagrant up   关闭工具机的防火墙，使开发机能直接访问虚拟机：  1 2 3  sudo ufw disable    开发机挂VPN，连接到三台虚拟机，并更新三台虚拟机的软件源为国内源\n  为三台虚拟机安装docker，并设置Docker容器加速\n  1 2 3  sudo apt-get install -y docker.io   安装Kubernetes  关闭swap，并测试关闭是否成功  1 2 3 4  sudo swapoff -a free -h   为三台虚拟机必要的基础工具（kubeadm需要用到的）  1 2 3 4  sudo apt update \u0026amp;\u0026amp; sudo apt install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -   配置镜像kubeadm仓库地址  1 2 3 4 5 6  sudo tee /etc/apt/sources.list.d/kubernetes.list \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF sudo apt update   安装 kubelet、kubeadm、kubectl并验证安装是否成功  1 2 3 4  sudo apt install -y kubelet kubeadm kubectl kubelet --version   初始化Kubernetes集群  1 2 3 4 5 6 7  kubeadm init \\  --image-repository registry.aliyuncs.com/google_containers \\  --kubernetes-version v1.18.2 \\  --pod-network-cidr=10.244.0.0/16 \\  --apiserver-advertise-address=172.17.30.101    安装flannel组件：  1 2 3 4 5  # 需要外网，可以在浏览器上下载下来，再传到虚拟机上 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml   漫长的等待后，验证是否成功：  1 2 3  kubectl get pods --all-namespaces   其他知识  忘记了node添加到master时的指令，可以通过如下指令获取  1 2 3  kubeadm token create --print-join-command --ttl 0   相关教程  ubuntu18.04安装kubernetes ubuntu18.04搭建 kubernetes（k8s）集群 Kubernetes集群的简单搭建（flannel.yml文件，及相关内容） Docker 镜像加速 kubenetes使用kubeadm查询添加节点到集群的命令  后记  我以为apiserver-advertise-address参数可以帮我解决双网卡的问题，没想到我还是踩到了双网卡的坑，见相关教程。  ","description":"","id":502,"section":"notes","tags":null,"title":"Ubuntu 18.04搭建Kubernetes（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ubuntu-18.04%E6%90%AD%E5%BB%BAkubernetes%E5%BA%9F%E5%BC%83/"},{"content":"处理步骤  三台虚拟机上运行如下指令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  sudo tee -a /etc/resolvconf/resolv.conf.d/head \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; nameserver 172.17.30.1 nameserver 114.114.114.114 nameserver 114.114.115.115 EOF sudo tee -a /etc/resolvconf/resolv.conf.d/head \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; nameserver 192.168.31.1 nameserver 8.8.8.8 EOF    重启所有虚拟机  相关教程   Kubernetes中的Pod无法访问外网-Ubuntu16.04 LTS\n  完美解决K8s中的Pod无法解析外网域名问题（该方案行不通，给了思路）\n  ","description":"","id":503,"section":"notes","tags":null,"title":"Ubuntu 18.04永久替换resolve.conf文件的方法","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E6%B0%B8%E4%B9%85%E6%9B%BF%E6%8D%A2resolve.conf%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95/"},{"content":"操作步骤  编辑/etc/netplan/01-network-manager-all.yaml（你的机器上可能不是这个文件名，也有可能有多个文件，需要注意观察，并自行分析修改哪个文件），代码如下：  1 2 3 4 5 6 7 8 9 10 11  network:version:2renderer:NetworkManagerethernets:enp34s0:dhcp4:noaddresses:[192.168.31.29/24]optional:truegateway4:192.168.31.1nameservers:addresses:[114.114.114.114,8.8.8.8]  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  sudo tee -a 00-installer-config.yaml \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; network: version: 2 renderer: NetworkManager ethernets: ens18: dhcp4: no addresses: [192.168.31.136/24] optional: true gateway4: 192.168.31.4 nameservers: addresses: [192.168.31.4, 8.8.8.8] EOF    运行如下指令：  1  sudo netplan apply   个人总结   整个过程其实并没有那么顺利，前几次试验都失败了，我意识到可能是路由和主机的接口出现了问题，我调整了一个路由器接口后发现enp34s0网口动态的获取到一个ip地址。\n  我尝试过新起一份文件，同时修改网关的名称为ens33，我期待重新配置一个端口出来，结果并没有生效（我觉着这块我对底层理解的不太到位）。\n  网卡的名称一定要与ifconfig查到的一致。\n  20211017后续：\n第三点，很重要，因为我今天配置的时候又猜到了这个坑里。\n参考教程  ubuntu 18.04 设置静态ip方法  ","description":"","id":504,"section":"notes","tags":null,"title":"Ubuntu 18.04配置静态地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-18.04%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80/"},{"content":"我使用的方法  禁用ssytemd-resolved（不用犹豫，这东西占用我53号端口，是肯定不行的）   sudo systemctl disable systemd-resolved sudo systemctl stop systemd-resolved 修改/etc/NetworkManager/NetworkManager.conf文件   [main] dns=127.0.0.1 删除符号链接   rm /etc/resolv.conf 下载network-manager并重新启动   apt install -y network-manager sudo systemctl restart NetworkManager 我认为可行的方法（实践证明，这种方法可行） 实际上我觉得，关闭systemd-resolved后，删除/etc/resolv.conf符号链接，然后手动创建一份/etc/resolv.conf也是可行的。\n参考资料  如何在Ubuntu中禁用systemd-resolved？ 怎么安装network-manager  ","description":"","id":505,"section":"notes","tags":null,"title":"Ubuntu 20.04网络调整","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu-20.04%E7%BD%91%E7%BB%9C%E8%B0%83%E6%95%B4/"},{"content":"操作步骤  https://jdk.java.net/java-se-ri/7下载openJDK 7安装包  解压，设置环境变量  1 2 3 4 5 6 7 8 9  tar -zxvf openjdk-7u75-b13-linux-x64-18_dec_2014.tar.gz sudo tee -a /etc/profile \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; JAVA_HOME=/home/vagrant/software/openjdk/java-se-7u75-ri PATH=${JAVA_HOME}/bin:${PATH} EOF source /etc/profile   ","description":"","id":506,"section":"notes","tags":null,"title":"Ubuntu18.04装OpenJDK 7","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu18.04%E8%A3%85openjdk-7/"},{"content":" 安装gcc、make工具  1 2 3  sudo apt install -y gcc make   官网下载源码，解压源码文件  1 2 3 4  tar redis-6.2.6.tar.gz cd redis-6.2.6   指定安装目录并进行编译、安装  1 2 3  sudo make PREFIX=/usr/local/redis6 install   检查安装结果  1 2 3 4  ls /usr/local/redis6 ls /usr/local/redis6/bin   配置环境变量  1 2 3 4 5 6 7  sudo tee -a ~/.bashrc \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; REDIS_HOME=/usr/local/redis6 PATH=${REDIS_HOME}/bin:${PATH} EOF source ~/.bashrc   参考资料  linux(ubuntu20.10) :编译安装redis6.0.9  ","description":"","id":507,"section":"notes","tags":null,"title":"Ubuntu上安装Redis6（废弃）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85redis6%E5%BA%9F%E5%BC%83/"},{"content":"最近按照教程配置了一份environment文件，在里面配置了代理，发现apt、curl都可以使用代理了，之前的方案是使用all_proxy，而且apt需要单独配置，先关注下这个问题。\n执行后需要使用source /etc/environment生效\n","description":"","id":508,"section":"notes","tags":null,"title":"Ubuntu中的environment文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E4%B8%AD%E7%9A%84environment%E6%96%87%E4%BB%B6/"},{"content":"如图官网下载脚本文件：\n然后执行如下代码（一路默认）：\n bash Anaconda3-2021.05-Linux-x86_64.sh 最后的最后，执行下如下代码：\n source ~/.bashrc 参考资料   Ubuntu18.04 安装 Anaconda3\n简单参考了一下，看看该下载那个文件。\n  ","description":"","id":509,"section":"notes","tags":null,"title":"Ubuntu安装Anaconda3","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/anaconda3/ubuntu%E5%AE%89%E8%A3%85anaconda3/"},{"content":"操作步骤  安装openssh服务端  sudo apt-get install openssh-server 编辑配置文件/etc/ssh/sshd_config改PermitRootLogin为yes   # Authentication: LoginGraceTime 120 PermitRootLogin yes StrictModes yes  重启服务   /etc/init.d/ssh restart 相关资料  ubuntu 16.0 安装openssh和启动 Ubuntu如何开启SSH服务 Ubuntu ssh开机自动启动的设置方法  ","description":"","id":510,"section":"notes","tags":null,"title":"Ubuntu安装并配置OpenSSH","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E5%AE%89%E8%A3%85%E5%B9%B6%E9%85%8D%E7%BD%AEopenssh/"},{"content":"这些是凭记忆写的，以后用到时还会更新：\n1 2 3 4 5 6 7 8 9 10  # ifconfig apt install -y net-tools # ip apt install -y iputils-ping # traceroute apt install traceroute   ","description":"","id":511,"section":"notes","tags":null,"title":"Ubuntu容器安装常用工具","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/ubuntu%E5%AE%B9%E5%99%A8%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"content":"sudo systemctl disable systemd-resolved\nsudo systemctl stop systemd-resolved\nsudo systemctl enable systemd-resolved\nsudo systemctl start systemd-resolved\n","description":"","id":512,"section":"notes","tags":null,"title":"Ubuntu设置systemd-resolved","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/ubuntu%E8%AE%BE%E7%BD%AEsystemd-resolved/"},{"content":"这个问题应该属于我们项目中的问题，我按照要求继承项目后，在mapper包下开发自己的Mapper，结果在启动的时候发现Mapper无法被注入。\n后来参考了案例代码后判断，应该要把包名改为dao，我之前有搞过类似的东西，通过ComponentScan组件完成指定包扫描路径，有点意思，哈哈。\n20210616后续：\n哈哈，这个框架已经被废弃了，我们项目不再使用这个新框架。\n","description":"","id":513,"section":"notes","tags":null,"title":"Unsatisfied dependency expressed through field 'baseMapper'","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/unsatisfied-dependency-expressed-through-field-basemapper/"},{"content":"我刚接触Vagrant时，官方Box搜索页面是不提供任何下载按钮的，需要一些特殊的技巧得到下载链接。我最近发现官方提供了下载按钮，满心欢喜的去尝试，结果下载到一半的时候速度降到非常低，而且还出现400错误，头疼。\n下面的教程我目前使用时，目前没有任何问题的。\n操作步骤  在Discover Vagrant Boxes搜索你需要的box，然后进入该box的详情页，随便选择一个版本，进入该版本的详情页，如下所示：  在地址栏中加上/providers/virtualbox.box，得到下载地址（virtualbox.box可以换成你自己的虚拟机），可以将下载地址复制到自己的下载器中下载。   https://app.vagrantup.com/generic/boxes/centos8/versions/3.2.14/providers/virtualbox.box 下载文件拖动到Centos中，改一个名字，然后执行如下代码加载：   vagrant box add --name BOX_NAME FILE_NAME ","description":"","id":514,"section":"notes","tags":null,"title":"Vagrant下载自己需要的Box","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/vagrant%E4%B8%8B%E8%BD%BD%E8%87%AA%E5%B7%B1%E9%9C%80%E8%A6%81%E7%9A%84box/"},{"content":"Vagrant会默认创建一个nat的网卡，这个网卡要是删除了，主机就无法通过vagrant ssh虚拟上了（但是我认为主机可以通过我配置的私有ip地址，ssh到这台虚拟机上，我需要尝试一下）。\n我踩过了这个坑，因为我通过ifconfig看到了一个不是我手动配置的ip地址，这让我非常的不舒服，所以我手动删除了它，结果导致我无法建立ssh链接。\n参考资料  Vagrant (三) - 网络配置  ","description":"","id":515,"section":"notes","tags":null,"title":"Vagrant创建的虚拟机有两个网卡","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/vagrant%E5%88%9B%E5%BB%BA%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%9C%89%E4%B8%A4%E4%B8%AA%E7%BD%91%E5%8D%A1/"},{"content":" Vagrant的同步目录，在虚拟机内是无法修改所有者和所属组的。且可以对其进行如下配置：   device.vm.synced_folder \u0026quot;./share_dir\u0026quot;, # 配置本地共享目录 \u0026quot;/vagrant\u0026quot;, # 配置虚拟机对应的挂载目录 create: true, # 如果虚拟机上对应的文件夹不存在, 则创建 owner: \u0026quot;root\u0026quot;, # 指定目录的所有者 group: \u0026quot;root\u0026quot;, # 指定目录的所属组 mount_options: [\u0026quot;dmode=755\u0026quot;, \u0026quot;fmode=644\u0026quot;], # 指定文件夹权限和文件权限 type: \u0026quot;rsync\u0026quot; # 指定文件同步方式, 一般让系统选择, 不指定 参考资料  同步目录的用户权限  ","description":"","id":516,"section":"notes","tags":null,"title":"Vagrant无法修改同步目录的权限","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/vagrant%E6%97%A0%E6%B3%95%E4%BF%AE%E6%94%B9%E5%90%8C%E6%AD%A5%E7%9B%AE%E5%BD%95%E7%9A%84%E6%9D%83%E9%99%90/"},{"content":"简单研究了下这个技术，有了一些心得，我实践未必按照这个方案走的，但是如果下次搞，我肯定用这套方案。\n从Vagrant官方仓库下载一个最新的CentOS7 Box。加载到Vagrant中，启动起来。我们在这个虚拟机上实现各种定制化。\n 首先需要下载一个ssh的key，我已经做过实验了，如果不存在这个key，新制作的box在启动阶段是无法进行ssh的，也就导致无法启动成功。   wget https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub cat vagrant.pub \u0026gt;\u0026gt; .ssh/authorized_keys 为root用户设置密码，并为root用户准备免密登录的文件key（这里面用了些我之前准备的文件）   sudo passwd root su root cd /vagrant/software/ssh chmod +x init.sh ./init.sh 完成这些工作后，用XShell测试下，能否能行免密登录。\n我这套方案其实有些复杂了，但是我也忘记我当时为什么需要通过ssh key来实现免密登录了，如果嫌麻烦，可以为root设置密码，然后通过xshll记录密码实现免密登录。\n 设置/etc/resolve.conf。因为我用到了透明代理，所以这个地方应该配置成我主机的ip地址。如果直接配置/etc/resolve.conf文件，新虚拟机中不会生效，所以需要配置/etc/NetworkManager/NetworkManager.conf，具体操作我还没有实践，我计划等我下次实践的时候再整理这部分。\n  退出虚拟机，制作box，并加载box，然后进行测试。\n   vagrant box package --base master --output centos7_docker vagrant box add --name centos7_docker centos7_docker vagrant box list 参考资料  vagrant制作box  ","description":"","id":517,"section":"notes","tags":null,"title":"Vagrant自制Box","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/vagrant%E8%87%AA%E5%88%B6box/"},{"content":"先记录一下，暂时用不到这些，暂时不打算深入研究这些。\n参考资料  VirtualBox命令行VBoxManage创建与管理虚拟机教程 使用命令操作VirtualBox Manage VirtualBox machines from CLI  ","description":"","id":518,"section":"notes","tags":null,"title":"VirtualBox常用命令行操作","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/virtualbox%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/"},{"content":"看资料时看到了一个volumeClaimTemplates字段的配置，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  apiVersion:apps/v1kind:StatefulSetmetadata:name:webspec:selector:matchLabels:app:nginxserviceName:\u0026#34;nginx\u0026#34;replicas:3template:metadata:labels:app:nginxspec:terminationGracePeriodSeconds:10containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80name:webvolumeMounts:- name:wwwmountPath:/usr/share/nginx/htmlvolumeClaimTemplates:- metadata:name:wwwspec:accessModes:[\u0026#34;ReadWriteOnce\u0026#34;]storageClassName:\u0026#34;my-storage-class\u0026#34;resources:requests:storage:1Gi  ~~~ yaml kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim annotations: volume.beta.kubernetes.io/storage-class: \u0026quot;managed-nfs-storage\u0026quot; spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi --- kind: Pod apiVersion: v1 metadata: name: test-pod spec: containers: - name: test-pod image: busybox:1.24 command: - \u0026quot;/bin/sh\u0026quot; args: - \u0026quot;-c\u0026quot; - \u0026quot;touch /mnt/SUCCESS \u0026amp;\u0026amp; exit 0 || exit 1\u0026quot; volumeMounts: - name: nfs-pvc mountPath: \u0026quot;/mnt\u0026quot; restartPolicy: \u0026quot;Never\u0026quot; volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim 学习这几份配置文件，有如下疑惑点：\n  StatefulSet定义中得volumeMounts下并没有persistentVolumeClaim属性，而貌似是直接写了volumeClaimTemplates中的name。\n  PersistentVolumeClaim定义中的StorageClass是通过注解写出来的，而不是像volumeClaimTemplates使用一个字段。\n  其实我现在还不知道StatefulSet这份配置能不能正常的运行，而且几份配置文件针对的是不同版本的Kubernetes，所以这种差异不知道是不是版本的差异。\nKubernetes为每一个VolumeClaimTemplate创建一份PV\n","description":"","id":519,"section":"notes","tags":null,"title":"volumeClaimTemplates与PersistentVolumeClaim","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/volumeclaimtemplates%E4%B8%8Epersistentvolumeclaim/"},{"content":" 切换命名空间  我发现切换了命名空间后，我在CentOS系统上的Kubectl工具也会受到影响。\n","description":"","id":520,"section":"notes","tags":null,"title":"VS Code上K8S插件应用笔记","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/vs-code%E4%B8%8Ak8s%E6%8F%92%E4%BB%B6%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0/"},{"content":"意义不大，我最后选择了在Linux提供上开一个smb服务，然后映射到Windows上，故作废该笔记\nSFTP插件，真的是大大提升幸福感的一个插件呀，我VIM用不惯，还是比较喜欢用VS Code多一点，所以配置文件我基本都sz到我Windows机器上进行修改，然后再rz回去，rz回去的时候还需要删除旧文件，总之体验极差。\n之前使用过git，结果windows机器和Linux机器都需要高频率的Pull和Push，操作起来有点繁琐，而且偶尔还会造成冲突，解决冲突大大影响了体验。\n使用SFTP，这些问题都解决了，我在Windows上编辑，一个Ctrl + S，就将文件同步会Linux了，非常的舒服。\nSSH开启SFTP 按照如下方式编辑/etc/ssh/sshd_config文件：\n # 注释下面这一行 # Subsystem sftp /usr/libexec/openssh/sftp-server # 新增下面这一行 Subsystem sftp internal-sftp 重新启动sshd服务：\n service sshd restart VSCode配置SFTP插件   安装sftp插件，安装的是liximomo的版本\n  编辑.vscode\\sftp.json为如下内容：\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  { \u0026#34;name\u0026#34;: \u0026#34;node1\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;192.168.23.60\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;port\u0026#34;: 22, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;remotePath\u0026#34;: \u0026#34;/root/Kubernetes/\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34;, \u0026#34;uploadOnSave\u0026#34;: true, \u0026#34;syncOption\u0026#34;: { \u0026#34;update\u0026#34;: true }, \u0026#34;watcher\u0026#34;: { \u0026#34;files\u0026#34;: \u0026#34;**/*\u0026#34;, \u0026#34;autoUpload\u0026#34;: false, \u0026#34;autoDelete\u0026#34;: false }, \u0026#34;ignore\u0026#34;: [ \u0026#34;.vscode\u0026#34;, \u0026#34;.git\u0026#34;, \u0026#34;.DS_Store\u0026#34; ] }   新建一个文件保存测试一下  遇到的问题  autoUpload不要配置成true，否则可能将一些半成品的文件同步到服务器上 /root/Kubernetes/最后的斜杠一定好些，否则会提示找不到该文件  方案总结 这个方案并不是很完美，它不能自动双向同步，所以我决定我只进行VS Code到Linux的单向同步，绝对不从Linux上同步到VS Code上。如果以后有时间，我还会研究一些其他更好用的方案，比如挂载之类的（其实我已经掌握了Windows挂载Linux文件夹的技术）。\n参考资料  CentOS7配置SFTP（root用户登录版） 工具篇-vscode sftp代码同步  20211230后续 放弃这个方案了，感觉不是很好用，最后走了目录挂载。\n","description":"","id":521,"section":"notes","tags":null,"title":"VS Code使用sftp插件（废弃）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/%E4%BD%9C%E5%BA%9F/vs-code%E4%BD%BF%E7%94%A8sftp%E6%8F%92%E4%BB%B6%E5%BA%9F%E5%BC%83/"},{"content":"3种场景：\n alt+鼠标左键（光标点中一行算一行） alt+鼠标左键拖动（多次）（每次拖动选中一块内容） shift+alt+鼠标左键拖动（光标同时出现在多行）  这东西有需求的时候，实践下就可以掌握了。\n参考资料  VS Code 列编辑功能说明  ","description":"","id":522,"section":"notes","tags":null,"title":"vs code同时处理多行","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/vs-code%E5%90%8C%E6%97%B6%E5%A4%84%E7%90%86%E5%A4%9A%E8%A1%8C/"},{"content":"不小心误触了键盘，打开了VS Code的全屏，我不是很需要这个功能，简单查了一下，F11键快速打开或关闭全屏。\n","description":"","id":523,"section":"notes","tags":null,"title":"VS Code开启和关闭全屏","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/vs-code%E5%BC%80%E5%90%AF%E5%92%8C%E5%85%B3%E9%97%AD%E5%85%A8%E5%B1%8F/"},{"content":"踩了一些坑，所以记录一下：\n我踩的坑：我在配置为Power Shell时，按Ctrl + Shift + ~打开过一次终端，更新了配置后，即使是重启都还是Power Shell，除非再按一次Ctrl + Shift + ~。\n在编辑器里直接使用中断，大大提升了我编码的幸福感，哈哈。\ntodo 如果找不到默认的Git Bash怎么办 ","description":"","id":524,"section":"notes","tags":null,"title":"VS Code设置默认终端为Git bash","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/vs-code%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E7%BB%88%E7%AB%AF%E4%B8%BAgit-bash/"},{"content":"下载该插件，重启即可：\nIntelliJ IDEA Keybindings\n","description":"","id":525,"section":"notes","tags":null,"title":"VS Code配置使用Idea快捷键","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/vscode/vs-code%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8idea%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"content":"问题现象  执行hexo generate时出现了如下警告，且首页无法访问（空白的）   WARN No layout: 404.html WARN No layout: categories/index.html WARN No layout: search/index.html WARN No layout: post/Git客户端修改默认的编辑器.html WARN No layout: post/使用Docker快速启动一个MySQL实例.html WARN No layout: post/使用Docker快速启动一个RabbitMQ实例.html WARN No layout: post/设置Docker容器加速及允许通过http协议拉取镜像.html 解决方法  检查themes下的主题目录与_config.yml配置文件中的theme的值是否对应 检查themes下的主题文件夹中的内容是否完成（我的项目中是因为这个问题导致的）  问题小结 这是一个很有趣的问题，我在我Windows机器上在themes文件夹拉下了主题文件，然后将这个项目提交到git仓库中。然后我去到我Linux机器中拉下代码，hexo generate该项目，结果就出现了这个问题。\n真正的问题在于，我提交项目时，从GitHub拉下来的主题文件并没有正常的提交到仓库，甚至使用git status时，总是提示没有任何文件更新。\n发现问题后，解决问题反倒变得简单，我删除了该主题文件，然后使用git add -A \u0026amp;\u0026amp; git commit -m \u0026ldquo;\u0026ldquo;重新提交了一次（即目录下增加了文件，git感知不到的规避办法）。然后重新拉取主题文件，并删除其中的.git文件夹（这一步，我不确实是否必须这么做）。\n相关教程  目录下增加了文件，git感知不到的规避办法 hexo本地测试运行重启后页面空白,提示 : WARN No layout: index.html?  其他资源  thinkerchan/hexo-theme-greyshade 有哪些好看的 Hexo 主题？ 修改git默认的编辑器  ","description":"","id":526,"section":"notes","tags":null,"title":"WARN  No layout index.html","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/hexo/warn-no-layout-index.html/"},{"content":"WebApplicationContext继承自ApplicationContext，它提供了一些web应用经常需要用到的特性。WebApplicationContext被绑定在ServletContext中。如果需要获取它，你可以通过RequestContextUtils工具类中的静态方法来拿到这个web应用的上下文WebApplicationContext。\nRequestContextUtils RequestContextUtils类是Spring提供的用于从HttpServletRequest上下文中获取特殊对象的工具类。该工具类虽然是属于Spring的一部分，但是如果在应用中我们有需要直接获取相关信息的需求，我们也可以直接使用。\n1 2 3 4 5 6 7 8 9 10 11 12  // 获取WebApplicationContext RequestContextUtils.getWebApplicationContext(request); // 获取LocaleResolver或Locale RequestContextUtils.getLocaleResolver(request); RequestContextUtils.getLocale(request); // 获取ThemeResolver或Theme（这个概念非常陌生） RequestContextUtils.getThemeResolver(request); RequestContextUtils.getTheme(request);   备注：这个request是ServletRequest类，所以我们日常用的Request DTO应该是没有办法获取到这些信息的，先记录一下，以后再慢慢研究。\n参考资料   Spring MVC DispatcherServlet详解\n  SpringMVC之RequestContextUtils工具类\n  ","description":"","id":527,"section":"notes","tags":null,"title":"WebApplicationContext是什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/webapplicationcontext%E6%98%AF%E4%BB%80%E4%B9%88/"},{"content":"目前先整理一下这部分资料，以后要深入学习的。\nWebApplicationInitializer是Spring MVC提供的一个接口，它会查找你所有基于代码的配置，并应用它们来初始化Servlet 3版本以上的Web容器。\n它有一个抽象的实现AbstractDispatcherServletInitializer，用以简化DispatcherServlet的注册工作：你只需要指定其Servlet映射即可。\n参考资料  Spring MVC DispatcherServlet详解  ","description":"","id":528,"section":"notes","tags":null,"title":"WebApplicationInitializer接口","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/webapplicationinitializer%E6%8E%A5%E5%8F%A3/"},{"content":"PVE突然WEBUI不可访问了，无论是本地还是远程。但是SSH访问还是正常的，在网上找了一圈方案，没有很好的解决办法，最后选择重启整个系统解决该问题了。\n","description":"","id":529,"section":"notes","tags":null,"title":"WebUI无法打开","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/webui%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/"},{"content":"WHERE标签 WHERE标签：只有一个以上的IF条件有值得情况下才去插入WHERE子句，而且，如果开头的内容是AND或OR开头，WHERE标签知道如何进行剔除。\nTRIM标签 四个属性：\n prefix：在trim包裹的SQL前添加指定内容 suffix：在trim包裹的SQL尾添加指定内容 prefixOverrides：去掉（覆盖）trim包裹的SQL的指定首部内容 suffixOverrides：去掉（覆盖）trim包裹的SQL的指定尾部内容  prefixOverrides和suffixOverrides支持匹配多个字段：\n1 2 3 4 5  \u0026lt;trim prefix=\u0026#34;where\u0026#34; prefixOverrides=\u0026#34;and|or\u0026#34;\u0026gt; \u0026lt;/trim\u0026gt;   ","description":"","id":530,"section":"notes","tags":null,"title":"WHERE标签、TRIM标签","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/where%E6%A0%87%E7%AD%BEtrim%E6%A0%87%E7%AD%BE/"},{"content":"这是总结目前遇到问题总结出来的方案。这个方案主要分为三层，\n","description":"","id":531,"section":"notes","tags":null,"title":"Win 10使用KT Connect（稳定版）（待完成）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/win-10%E4%BD%BF%E7%94%A8kt-connect%E7%A8%B3%E5%AE%9A%E7%89%88%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"我都忘记了需求场景，故作废\n指令如下：\n ipconfig /all ","description":"","id":532,"section":"notes","tags":null,"title":"Win 10查看mac地址","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/win-10%E6%9F%A5%E7%9C%8Bmac%E5%9C%B0%E5%9D%80/"},{"content":"放弃折腾这个了，J4125顶不住\n在我J4125上装了Win10，用作下载器，但是内存占用太高了，吃了我6G的内存，所以需要进行一下优化，优化流程如下：\n  激活Window系统\n  关闭Windows的自动更新\n  关闭Windows Defender（我安装了火绒）\n  （这个时候远程操作已经比较流程了）\n关闭所有的动画效果，有点不好找，截图如下：   借用360，再进行一下优化\n  借用驱动精灵，再进行一些优化\n  （系统已经不卡了，内存占用显示为20%，但是PVE上始终显示的是使用了5。14G内存）\n参考资料  全站最强Windows11/win10优化，内存占用暴降，无需重装！  ","description":"","id":533,"section":"notes","tags":null,"title":"Win10优化内存占用","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E4%BC%98%E5%8C%96%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8/"},{"content":"懒的整理，这种东西就是十年半个月用不到一次：\nhttps://jingyan.baidu.com/article/e73e26c01bc1c364acb6a734.html\n20210928后续：\nwindows图标经常莫名其妙的缩回去，没想到这个教程使用频率这么高。\n20211008h后续：\n好煞笔，右下角的图标是可以直接拖的，缩回去也可能是因为我不小心拖进去了。\n","description":"","id":534,"section":"notes","tags":null,"title":"win10右下角图表显示","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E5%8F%B3%E4%B8%8B%E8%A7%92%E5%9B%BE%E8%A1%A8%E6%98%BE%E7%A4%BA/"},{"content":"另外需要说一下，win家庭版不支持远程桌面，打消这个念头吧。\n参考资料  win10怎么开启远程桌面  ","description":"","id":535,"section":"notes","tags":null,"title":"Win10开启远程桌面","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"},{"content":"打开控制面板，搜索程序，选择启用或者关闭Window功能：\n选择Telnet客户端，点击确定：\n参考资料  在windows10下面打开TELNET功能  ","description":"","id":536,"section":"notes","tags":null,"title":"win10打开telnet服务","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%89%93%E5%BC%80telnet%E6%9C%8D%E5%8A%A1/"},{"content":"用的少，但是又不得不用，截图如下：\n20210630后续:\n额，没想到这个东东我用的挺多的，我老是忘记打卡。\n","description":"","id":537,"section":"notes","tags":null,"title":"Win10查看关机事件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E5%85%B3%E6%9C%BA%E4%BA%8B%E4%BB%B6/"},{"content":"我将家庭内部网络切换成了172.20.11网段，避免内网穿透时与其他网络环境中的网段冲突。切换后我需要知道我网络中的所有新Ip地址，故找到了这些相关的资料。\n for /L %i IN (1,1,254) DO ping -w 2 -n 1 172.20.11.%i arp -a 参考资料  windows 查看局域网内所有已使用的IP  ","description":"","id":538,"section":"notes","tags":null,"title":"win10查看局域网中ip","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E5%B1%80%E5%9F%9F%E7%BD%91%E4%B8%ADip/"},{"content":"netstat -ano | findstr \u0026ldquo;192.168.13.113\u0026rdquo;\n一个指令多种使用场景。\n参考资料  Windows 下查看网络连接  ","description":"","id":539,"section":"notes","tags":null,"title":"win10查看活动的网络连接","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E6%B4%BB%E5%8A%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5/"},{"content":"指令如下：\n tree /F 如果不要/F的话，则只显示目录。\n","description":"","id":540,"section":"notes","tags":null,"title":"win10查看目录树","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E7%9B%AE%E5%BD%95%E6%A0%91/"},{"content":"和Linux需求一致，有时候服务启动起来了，需要检查是否正在监听着：\n netstat -aon | findstr \u0026quot;9050\u0026quot; 参考资料  windows下查看端口监听情况  ","description":"","id":541,"section":"notes","tags":null,"title":"win10查看端口占用情况","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/"},{"content":"这个解决方案是我看教程的时候自己猜出来的，我没有找到很清晰的描述这个问题的解决方案。解决方法如下：\n pip config set global.proxy http://127.0.0.1:1080 我在整理笔记时发现，我之前解决过类似的问题，嗯，下次有问题先找一下自己的笔记。\n参考教程  【python】python3.x 在Windows 10 下的环境配置——pip永久换源成国内镜像  ","description":"","id":542,"section":"notes","tags":null,"title":"win10设置pip3代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/win10%E8%AE%BE%E7%BD%AEpip3%E4%BB%A3%E7%90%86/"},{"content":"route print\nroute delete 192.168.31.1 mask 255.255.255.0\n","description":"","id":543,"section":"notes","tags":null,"title":"Win10路由表常用操作（待完善）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win10%E8%B7%AF%E7%94%B1%E8%A1%A8%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%BE%85%E5%AE%8C%E5%96%84/"},{"content":"Windows打头的快捷键用的不是太顺手，故作废\nWindows + E：非常好用的快捷键，之前我是在任务栏里固定一个文件夹~\n先记录一下，以后一起整理。\n","description":"","id":544,"section":"notes","tags":null,"title":"Windows+E快速打开文件浏览器","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/windows+e%E5%BF%AB%E9%80%9F%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"content":"谷歌都比找笔记快，故作废\n挺简单的，如图：\n","description":"","id":545,"section":"notes","tags":null,"title":"Windows关闭右下角的天气","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/windows%E5%85%B3%E9%97%AD%E5%8F%B3%E4%B8%8B%E8%A7%92%E7%9A%84%E5%A4%A9%E6%B0%94/"},{"content":"不敢搞这些骚操作了，故作废该笔记\n越来越讨厌Windows系统了！！！\n20211011实践 实践中，我是通过火绒剑关闭相关进程的。关闭进程后，文件夹才可以删除，我直接用git bash删除文件夹，但是这个删除貌似是假的。感觉没有一定能成功的方案，但是总结如下：\n 关闭进程 禁用相关服务 删除注册表（计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\下Uni打头的） 删除文件夹  参考资料  如何使uniaccess agent监控软件失能？  ","description":"","id":546,"section":"notes","tags":null,"title":"Windows卸载安全助手","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/windows%E5%8D%B8%E8%BD%BD%E5%AE%89%E5%85%A8%E5%8A%A9%E6%89%8B/"},{"content":"Windows安装ElasticSearch，用于学习环境\n  下载二进制文件，解压后进入bin目录\n  使用管理员身份运行elasticsearch.bat文件\n  浏览器访问localhost:9200，看到如下内容，则成功：\n   { \u0026quot;name\u0026quot; : \u0026quot;WUJJ\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;5XBz9P4ZQXy-CBIqzZbCSw\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.12.1\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;zip\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;3186837139b9c6b6d23c3200870651f10d3343b7\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2021-04-20T20:56:39.040728659Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.8.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } ","description":"","id":547,"section":"notes","tags":null,"title":"Windows安装ElasticSearch","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/elasticsearch/windows%E5%AE%89%E8%A3%85elasticsearch/"},{"content":"用的非常少，作废了\n目前还不能评价，还在试用中：\n","description":"","id":548,"section":"notes","tags":null,"title":"Windows带历史功能的剪贴板","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/windows%E5%B8%A6%E5%8E%86%E5%8F%B2%E5%8A%9F%E8%83%BD%E7%9A%84%E5%89%AA%E8%B4%B4%E6%9D%BF/"},{"content":"谷歌都比找笔记快，故作废\n这个指令之前查过，给忘记了，现在整理一下：\n tskill pid ","description":"","id":549,"section":"notes","tags":null,"title":"Windows杀死一个进程","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/windows%E6%9D%80%E6%AD%BB%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B/"},{"content":"操作步骤  指令如下  route print route print | findstr \u0026quot;172\u0026quot; route delete 172.17.0.0 route add 172.17.0.0 MASK 255.255.0.0 172.17.30.1 route add 172.17.0.0 MASK 255.255.0.0 10.8.0.1 route delete 172.17.0.0 route add 172.17.0.0 MASK 255.255.0.0 172.17.0.1 ","description":"","id":550,"section":"notes","tags":null,"title":"Windows查看路由信息","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/ubuntu/windows%E6%9F%A5%E7%9C%8B%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF/"},{"content":"如下代码可直接进入非C盘的目录：\n1 2 3  cd /D D:\\Blogs   如不不用/D参数，则该指令无法正常进入该目录。\n参考资料  bat文件直接进入某个盘符目录  ","description":"","id":551,"section":"notes","tags":null,"title":"win上进入非C盘的文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win%E4%B8%8A%E8%BF%9B%E5%85%A5%E9%9D%9Ec%E7%9B%98%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"使用指令如下：\n set Java中查看所有环境变量，使用如下代码：\n1 2 3 4 5  public static void main(String[] args) { Map\u0026lt;String, String\u0026gt; getenv = System.getenv(); }   ","description":"","id":552,"section":"notes","tags":null,"title":"win查看所有的环境变量","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"content":"测试自己接口用的，我使用的指令如下：\n curl --proxy socks5h://192.168.27.15:12345 -H token:1374675177769156610:web:8085e1bc1d7b3325cae1bcd6684f853b http://dyf/dyf/field ","description":"","id":553,"section":"notes","tags":null,"title":"win版本的curl设置代理及请求头","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/win%E7%89%88%E6%9C%AC%E7%9A%84curl%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%8F%8A%E8%AF%B7%E6%B1%82%E5%A4%B4/"},{"content":" WireGuard使用最初创建WireGuard接口的网络命名空间发送和接收加密数据包。这意味着您可以在可以访问Internet的主网络名称空间中创建WireGuard接口，然后将其移动到属于Docker容器的网络名称空间中，作为该容器的唯一接口。这确保了容器能够访问网络的唯一可能方式是通过安全加密的WireGuard隧道。\n 我感觉我Linux学习的还是不够深入，上面的知识理解起来还是有一定的困难的。\n参考资料  wireguard  ","description":"","id":554,"section":"notes","tags":null,"title":"Wireguard与Docker（记录）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/wireguard%E4%B8%8Edocker%E8%AE%B0%E5%BD%95/"},{"content":"（这是我读官方文档时的简单理解）\nWireguard使用UDP封装IP数据包。在使用的过程中，需要创建一个WireGuard接口，使用自己的私钥和对等方的公钥进行配置，访问对等方网络时的所有数据包将通过该接口发送。\nWireguard可以通过添加多个网络接口来工作，可以使用ifconfig、ip-address等工具配置这些网络接口，可以使用route、ip-route为这些接口添加和删除路由，而WireGuard方面的配置需要使用wg工具完成。这些接口充当隧道接口。\nWireGuard将隧道IP地址与公钥和远端端点相关联，当接口向对等方发送数据包时，会执行如下操作：\n 判断数据包发送给哪个对等方，如果不属于任何已配置的对等方，则丢弃该数据包 使用对等方的公钥加密整个IP数据包 通过UDP将数据包发送给对等方  当对等方接受到数据包时，会执行如下操作：\n 解密收到的数据包 记录对等方最新的Internet端点数据 判断该数据包的发送者是否是允许的，如果不允许则丢弃数据包  参考资料  wireguard  ","description":"","id":555,"section":"notes","tags":null,"title":"Wireguard的原理知识","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/wireguard%E7%9A%84%E5%8E%9F%E7%90%86%E7%9F%A5%E8%AF%86/"},{"content":"  wireguard 安装与组网\n过年在外怎么访问家庭内网,wireguard组网！\n很重要的资料，通过该资料，我知道了如果需要访问我内网环境，则需要配置SNAt。\n  个人办公用 wireguard 组网笔记\n学习了一种拓补结构，学习了配置端口转发，这篇教程还有一些高级知识，我暂时不用到，所以就不研究了。\n  OpenWRT 配置 WireGuard 服务端及客户端配置教程\n该教程提出了另一种iptables的配置方式，如下：\n iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -o br-lan -j MASQUERADE   ","description":"","id":556,"section":"notes","tags":null,"title":"WireGuard重要资料整理","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/wireguard%E9%87%8D%E8%A6%81%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"我在本地测试Dockerfile时，习惯性的将ENTRYPOINT写成如下形式：\n1 2 3  ENTRYPOINT [\u0026#34;./entrypoint.sh\u0026#34;]  但是如果这样写，在GitHub Actions中将会报错：\n1 2 3  docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: \u0026#34;./entrypoint.sh\u0026#34;: stat ./entrypoint.sh: no such file or directory: unknown.  需要用如下的写法：\n1 2 3  ENTRYPOINT [\u0026#34;/entrypoint.sh\u0026#34;]  原因分析 如下Github Actions在启动Docker容器时会传递如下的参数，而我使用的python:3.8.6镜像的默认位置是根目录，所以就无法使用相对路径找到我的脚本文件。\n","description":"","id":557,"section":"notes","tags":null,"title":"workdir参数导致docker启动时无法找到脚本","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/workdir%E5%8F%82%E6%95%B0%E5%AF%BC%E8%87%B4docker%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0%E8%84%9A%E6%9C%AC/"},{"content":"我也不知道误触了什么案件，XShell突然变透明了，通过如下方式改回来：\n我评估了下，感觉这个功能没有什么适用场景。\n","description":"","id":558,"section":"notes","tags":null,"title":"XShell不小心变透明了","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/xshell/xshell%E4%B8%8D%E5%B0%8F%E5%BF%83%E5%8F%98%E9%80%8F%E6%98%8E%E4%BA%86/"},{"content":"一图胜千言万语\n","description":"","id":559,"section":"notes","tags":null,"title":"XShell导出配置文件","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/xshell/xshell%E5%AF%BC%E5%87%BA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"content":"我也是第一次遇到这种情况，我拿一台虚拟机帮同事开KT Connect的代码，并开启了一个端口转发，如下代码所示：\n nohup ktctl --namespace=dev connect --method=socks5 --dump2hosts \u0026gt; ktctl.log 2\u0026gt;\u0026amp;1 \u0026amp; nohup polipo -c /opt/polipo/config \u0026gt; polipo.log 2\u0026gt;\u0026amp;1 \u0026amp; 此时查看端口占用：\n [root@node ~]# netstat -ntlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:2223 0.0.0.0:* LISTEN 5214/ktctl tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 873/sshd tcp 0 0 0.0.0.0:12345 0.0.0.0:* LISTEN 5224/polipo tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1028/master tcp 0 0 127.0.0.1:2222 0.0.0.0:* LISTEN 5226/kubectl tcp6 0 0 :::22 :::* LISTEN 873/sshd tcp6 0 0 ::1:25 :::* LISTEN 1028/master tcp6 0 0 ::1:2222 :::* LISTEN 5226/kubectl 端口都正常开启，且同事能够正常使用，我退出了xshell再进入，结果程序都被杀掉了。\n最后网上说通过exit可以退出xshell而不影响通过nohup开启的进程。我目前不知道什么原因，先记录一下\n参考资料  nohup \u0026amp;不挂断运行之后退出xshell客户端会杀死nohup进程  ","description":"","id":560,"section":"notes","tags":null,"title":"xshell退出时关闭了通过nohup启动的应用","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/xshell%E9%80%80%E5%87%BA%E6%97%B6%E5%85%B3%E9%97%AD%E4%BA%86%E9%80%9A%E8%BF%87nohup%E5%90%AF%E5%8A%A8%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"不用再在跳板机上手动ssh生产机了，还能往生产机上传文件，不使用该技术，则需要先ssh跳板机，然后在ssh到生产机，而且还不能向生产机传文件\n原理部分   该方案至少要两个会话，一个会话需要登录跳板机并配置隧道，我叫它为跳板机会话。另一个会话就是我们日常使用的会话，我称为它为目标会话\n  如图，测试环境下跳板机就是我所说的跳板机会话，而192.168.52.157、192.168.52.168、192.168.52.169就是我所说的目标会话\n  使用的时候，需要先打开跳板机会话，然后再打开你需要的目标会话  操作步骤 配置跳板机会话   xshell上创建一个跳板机会话（这块不截图了，两部分，ip地址和登录信息，其中ip地址是跳板机的ip地址，登录信息为跳板机的用户名和密码）\n  跳板机会话设置登录脚本，设置登录脚本是为了防止跳板机长时间没有输入，给自动掉线了\n  跳板机会话设置隧道，添加两台生产机（观察两张截图，可以总结需要设置哪些内容）  配置目标会员  添加目标会员（右键，新建会话，登录信息部分是常规设置，需要注意主机部分）  完美收工，使用时需要先连接跳板机  ","description":"","id":561,"section":"notes","tags":null,"title":"XShell隧道技术的利用","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/xshell/xshell%E9%9A%A7%E9%81%93%E6%8A%80%E6%9C%AF%E7%9A%84%E5%88%A9%E7%94%A8/"},{"content":"账号：admin@admin.com\n密码：ymfe.org\n参考资料  我想问下默认超级管理员的账号密码是啥  ","description":"","id":562,"section":"notes","tags":null,"title":"yapi默认账号密码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/yapi%E9%BB%98%E8%AE%A4%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81/"},{"content":"我感觉youtube-dl下载BiliBili的分P视频时不是很好处理，所以又找到了you-get工具。\n you-get -o . --playlist url 参考资料  使用youtube-dl下载B站视频  ","description":"","id":563,"section":"notes","tags":null,"title":"you-get下载b站分批视频","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/youtube-dl/you-get%E4%B8%8B%E8%BD%BDb%E7%AB%99%E5%88%86%E6%89%B9%E8%A7%86%E9%A2%91/"},{"content":"当目录过程，展开的时候超过了一屏的高度时，页面会出现抖动的情况，抖动的原因是因为超过一屏时浏览器右侧会出现滚动条，该滚动条影响了屏幕的宽度，会导致body标签左移，所以呈现页面抖动。\n我选择解决这个问题的办法是，让右侧的滚动条一直存在，这样就不存在宽度的变化了。\n操作步骤  准备如下css文件，放置在asserts/css/custom.css下：  1 2 3  body { overflow-y: scroll; }   配置config/_default/params.toml，增加如下配置   custom_css = [\u0026quot;css/custom.css\u0026quot;] 参考资料  解决因出现滚动条导致页面抖动 CSS  ","description":"","id":564,"section":"notes","tags":null,"title":"ZDoc主题抖动的问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/zdoc%E4%B8%BB%E9%A2%98%E6%8A%96%E5%8A%A8%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"恶意应用软件让浏览器向已完成身份认证的网站发起请求，执行有害的操作，这就是CSRF。这是怎么发生的呢？记住主要的一点，浏览器可以向任何源发送请求（带有cookie），并执行所请求的特定操作。如果用户登录某个网站，并且该网站允许用户执行一系列任务，而攻击者诱导浏览器向这些任务对应的某个URL发送请求，就可以以登录用户的身份执行该任务。通常，攻击者会将恶意的HTML或者JavaScript代码嵌入邮件或者网页中（也可能是用户主动浏览了带有恶意代码的网页），在用户不知情的情况下向某个特定的URI发送请求。\n对书中案例的分析 下图为OAuth的授权码模式的示意图：\n第7步，浏览器带着授权服务器返回的code去访问客户端服务器，客户端服务器因而可以获取到code信息。\n那么攻击者是怎么做的呢？我先单纯的从文字表述的角度描述一下整个攻击的过程，攻击者也可以开启一个OAuth过程，但是它终止在了获取了权限码后向授权服务器请求ACCESS_TOKEN的过程（攻击者可以有很多方式开始这个过程，我推荐使用代码），此时攻击者手中拥有一个授权码，它接下来怎么做了？\n攻击者提供了一个页面，当访问这访问这个页面的时候会自动的向正常的客户端服务器发送一个URL，攻击者想方设法的让资源拥有者访问到这个页面，邮件、钓鱼网站等。\n当资源拥有者访问了这个页面后，就向正常的客户端服务器发送了请求。客户端服务器按照流程，就会去请求授权服务器，然后获取ACCESS_TOKEN。即使客户端服务器判断一下当前是否已经有ACCESS_TOKEN，也最多只能延迟一下被攻陷的时间，最终在ACCESS_TOKEN过期的时候，还是会被攻击到。\n客户端服务器为什么不能开启CSRF，仅让授权服务器下的域名可访问呢？这个就跟业务有关了，获取我们的客户端服务器提供的服务是可以分享到各个社交平台的，这样就没有办法做到万无一失。\n我真正不理解的是：最终调用资源服务器的代码始终写在客户端的，即使做了这样的攻击，放开了可以调用的权限，攻击者可以获取的数据还是有限的呀。其实有这种可能性的，就是客户端服务器其实申请了三项权限，但是资源拥有者只授权了其中的一项，现在攻击者想通过这种攻击方式获取另外两种权限下的数据。\n书中提到了与OAuth不能做身份认证，我还没有体会到这个层面。\n参考资料  《OAuth 2实战》 7.2 针对客户端服务器的CSRF攻击  ","description":"","id":565,"section":"notes","tags":null,"title":"【笔记】CSRF攻击","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/%E7%AC%94%E8%AE%B0csrf%E6%94%BB%E5%87%BB/"},{"content":"Pod的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  apiVersion:v1kind:Podmetadata:name:init-demolabels:name:init-demospec:containers:- name:nginximage:nginxresources:limits:memory:\u0026#34;128Mi\u0026#34;cpu:\u0026#34;500m\u0026#34;ports:- containerPort:80volumeMounts:- name:workdirmountPath:/usr/share/nginx/htmlinitContainers:- name:installimage:busyboxcommand:- wget- \u0026#34;-O\u0026#34;- \u0026#34;/work-dir/index.html\u0026#34;- https://kuboard.cnvolumeMounts:- name:workdirmountPath:\u0026#34;/work-dir\u0026#34;dnsPolicy:Defaultvolumes:- name:workdiremptyDir:{}  该段配置中，Pod中初始化容器和应用程序容器共享一个数据卷。初始化容器将该共享数据卷挂载到/work-dir路径下，应用程序容器将共享数据卷挂载到/usr/share/nginx/html路径下。\n初始化容器执行如下指令，执行该直接会将wget的结果写入应用程序容器Nginx服务器对应的html根路径下得index.html。\n1 2 3  wget -O /work-dir/index.html https://kuboard.cn   创建Pod，获取该Pod的集群Ip，然后使用curl进行测试。\n1 2 3  curl http://10.244.1.2   ","description":"","id":566,"section":"notes","tags":null,"title":"一个关于InitContainer的小实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8Einitcontainer%E7%9A%84%E5%B0%8F%E5%AE%9E%E9%AA%8C/"},{"content":"需求是这样的，一个字段它在创建的时候是允许多选的，然后再分页的时候，用户传递的条件它也是多选的，所以我们需要判断一个集合中得元素是否全部属于另一个集合。\n举例来说，就是判断[\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;]是否属于[\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;, \u0026quot;D\u0026quot;]，在PG中，该需求可以通过如下SQL实现：\n1 2 3  select*fromt_trend_modelwherecompany_view_allow::jsonb?\u0026amp;array[\u0026#39;83\u0026#39;,\u0026#39;42\u0026#39;];  但是该SQL是不能直接移植到MyBatis中使用了，问题一是\u0026amp;符号要转义，问题二是?要写成??，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182  \u0026lt;select id=\u0026#34;pageTrendModel\u0026#34; resultType=\u0026#34;com.sdstc.tmp.server.entity.TrendModel\u0026#34;\u0026gt; select * from t_trend_model trm \u0026lt;!-- 登录状态，且搜索条件中包含收藏 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.collect == 1\u0026#34;\u0026gt; join t_favorite tf on trm.id = tf.trend_model_id \u0026lt;/if\u0026gt; \u0026lt;!-- 登录状态，且搜索条件中包含浏览 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.viewed == 1\u0026#34;\u0026gt; join t_viewed tv on trm.id = tv.trend_model_id \u0026lt;/if\u0026gt; where trm.is_delete = 0 \u0026lt;!-- 登录状态，且搜索条件中包含收藏 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.collect == 1\u0026#34;\u0026gt; and tf.is_delete = 0 and tf.creator = #{userId} \u0026lt;/if\u0026gt; \u0026lt;!-- 登录状态，且搜索条件中包含浏览 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.viewed == 1\u0026#34;\u0026gt; and tv.is_delete = 0 and tv.creator = #{userId} \u0026lt;/if\u0026gt; \u0026lt;!-- 关键字 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.lang3.StringUtils@isNotBlank(condition.keyword)\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;keyword\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + condition.keyword + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; and (trm.theme like #{keyword} or trm.design_points like #{keyword}) \u0026lt;/if\u0026gt; \u0026lt;!-- 趋势主题 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.themes)\u0026#34;\u0026gt; AND trm.theme in \u0026lt;foreach collection=\u0026#34;condition.themes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;themes\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{theme} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 适用品牌 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.brands)\u0026#34;\u0026gt; AND trm.brand in \u0026lt;foreach collection=\u0026#34;condition.brands\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;brand\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{brand} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 允许预览 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.allowView == 1\u0026#34;\u0026gt; AND (trm.personal_allow_view = 1 or trm.company_view_allow::jsonb ??\u0026amp;amp; array[#{tenantId}]) \u0026lt;/if\u0026gt; \u0026lt;!-- 发布状态 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.publishStatus)\u0026#34;\u0026gt; AND trm.publish_status in \u0026lt;foreach collection=\u0026#34;condition.publishStatus\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;publishStatusItem\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{publishStatusItem} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 型体号 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.modelNumbers)\u0026#34;\u0026gt; AND trm.model_number in \u0026lt;foreach collection=\u0026#34;condition.modelNumbers\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;modelNumber\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{modelNumber} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 鞋底 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.soles)\u0026#34;\u0026gt; AND trm.sole in \u0026lt;foreach collection=\u0026#34;condition.soles\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;sole\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{sole} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 跟型 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.heelTypes)\u0026#34;\u0026gt; AND trm.heel_type in \u0026lt;foreach collection=\u0026#34;condition.heelTypes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;heelType\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{heelType} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 跟高 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.heelHeights)\u0026#34;\u0026gt; AND trm.heel_height in \u0026lt;foreach collection=\u0026#34;condition.heelHeights\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;heelHeight\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{heelHeight} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 款式类型 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.shapeTypes)\u0026#34;\u0026gt; AND trm.shape_type in \u0026lt;foreach collection=\u0026#34;condition.shapeTypes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;shapeType\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{shapeType} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 流行趋势 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.trendTags)\u0026#34;\u0026gt; AND trm.trend_tags::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.trendTags\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;trendTag\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{trendTag} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 流行地区 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.regions)\u0026#34;\u0026gt; AND trm.regions::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.regions\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;region\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{region} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 场景风格 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.styles)\u0026#34;\u0026gt; AND trm.styles::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.styles\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;style\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{style} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 面料元素 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.materialElements)\u0026#34;\u0026gt; AND trm.material_elements::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.materialElements\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;materialElement\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{materialElement} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 装饰元素 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.decorativeElements)\u0026#34;\u0026gt; AND trm.decorative_elements::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.decorativeElements\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;decorativeElement\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{decorativeElement} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 工艺 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.crafts)\u0026#34;\u0026gt; AND trm.crafts::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.crafts\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;craft\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{craft} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 适用季节 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.seasons)\u0026#34;\u0026gt; AND trm.seasons::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.seasons\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;season\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{season} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 色系 --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(condition.colors)\u0026#34;\u0026gt; AND trm.colors::jsonb ??\u0026amp;amp; \u0026lt;foreach collection=\u0026#34;condition.colors\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;color\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{color} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 是否推荐 --\u0026gt; \u0026lt;if test=\u0026#34;condition.isRecommend != null\u0026#34;\u0026gt; AND trm.is_recommend = #{condition.isRecommend} \u0026lt;/if\u0026gt; \u0026lt;!-- 设计师Id --\u0026gt; \u0026lt;if test=\u0026#34;@org.apache.commons.lang3.StringUtils@isNotBlank(condition.designerId)\u0026#34;\u0026gt; AND trm.designer_id = #{condition.designerId} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt;   参考资料  PostgreSQL JSONB 使用入门 Mybatis特殊字符转义以及sql中带有问号(?)的处理方式  ","description":"","id":567,"section":"notes","tags":null,"title":"一个列表为另一个列表的子集的SQL如何编写，及在MyBatis中如何处理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E4%B8%BA%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E7%9A%84%E5%AD%90%E9%9B%86%E7%9A%84sql%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E5%8F%8A%E5%9C%A8mybatis%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/"},{"content":"SQL如下：\n1 2 3  SELECT*FROMt_common_materialwhereimg_json::jsonb?|\u0026#39;normalMap\u0026#39;=falseandis_delete=0ANDis_shelf=1andrender_version!=1  ","description":"","id":568,"section":"notes","tags":null,"title":"一个列表和另一个列表的交集不为空集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E5%92%8C%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E7%9A%84%E4%BA%A4%E9%9B%86%E4%B8%8D%E4%B8%BA%E7%A9%BA%E9%9B%86/"},{"content":"初始化K8S集群的时候，有如下报错：\n [root@node-template ~]# kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=172.20.11.201 [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \u0026quot;cgroupfs\u0026quot; as the Docker cgroup driver. The recommended driver is \u0026quot;systemd\u0026quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \u0026quot;/etc/kubernetes/pki\u0026quot; [certs] Generating \u0026quot;ca\u0026quot; certificate and key [certs] Generating \u0026quot;apiserver\u0026quot; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node-template] and IPs [10.96.0.1 172.20.11.201] [certs] Generating \u0026quot;apiserver-kubelet-client\u0026quot; certificate and key [certs] Generating \u0026quot;front-proxy-ca\u0026quot; certificate and key [certs] Generating \u0026quot;front-proxy-client\u0026quot; certificate and key [certs] Generating \u0026quot;etcd/ca\u0026quot; certificate and key [certs] Generating \u0026quot;etcd/server\u0026quot; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost node-template] and IPs [172.20.11.201 127.0.0.1 ::1] [certs] Generating \u0026quot;etcd/peer\u0026quot; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost node-template] and IPs [172.20.11.201 127.0.0.1 ::1] [certs] Generating \u0026quot;etcd/healthcheck-client\u0026quot; certificate and key [certs] Generating \u0026quot;apiserver-etcd-client\u0026quot; certificate and key [certs] Generating \u0026quot;sa\u0026quot; key and public key [kubeconfig] Using kubeconfig folder \u0026quot;/etc/kubernetes\u0026quot; [kubeconfig] Writing \u0026quot;admin.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;kubelet.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;controller-manager.conf\u0026quot; kubeconfig file [kubeconfig] Writing \u0026quot;scheduler.conf\u0026quot; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026quot;/var/lib/kubelet/kubeadm-flags.env\u0026quot; [kubelet-start] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026quot;/etc/kubernetes/manifests\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-apiserver\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-controller-manager\u0026quot; [control-plane] Creating static Pod manifest for \u0026quot;kube-scheduler\u0026quot; [etcd] Creating static Pod manifest for local etcd in \u0026quot;/etc/kubernetes/manifests\u0026quot; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026quot;/etc/kubernetes/manifests\u0026quot;. This can take up to 4m0s [kubelet-check] Initial timeout of 40s passed. Unfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - 'systemctl status kubelet' - 'journalctl -xeu kubelet' Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - 'docker ps -a | grep kube | grep -v pause' Once you have found the failing container, you can inspect its logs with: - 'docker logs CONTAINERID' error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster To see the stack trace of this error execute with --v=5 or higher 这个问题导致的原因是我将--apiserver-advertise-address=172.20.11.201写错了，应该写成--apiserver-advertise-address=172.20.11.202，好蠢。\n","description":"","id":569,"section":"notes","tags":null,"title":"一个蠢问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%B8%80%E4%B8%AA%E8%A0%A2%E9%97%AE%E9%A2%98/"},{"content":"最近在学习Netty，为了更好的查看方法调用顺序，开发了如下小工具：\n1 2 3 4 5 6 7 8 9 10 11  public class CommonUtils { public static void logCalling() { StackTraceElement[] mStacks = Thread.currentThread().getStackTrace(); if (mStacks.length \u0026gt;= 3) { System.out.printf(\u0026#34;Calling: %s.%s()\\n\u0026#34;, mStacks[2].getClassName(), mStacks[2].getMethodName()); } } }   这个工具可以打印当前是谁在调用这个方法，如果不使用调用栈的方案，我们就需要传入一个object，感觉很low。\n如果在SpringBoot中，可以考虑开发相应的注解。\n参考资料  java怎么看某个方法被谁调用  ","description":"","id":570,"section":"notes","tags":null,"title":"一个骚气的小工具，查看方法调用轨迹","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E4%B8%80%E4%B8%AA%E9%AA%9A%E6%B0%94%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7%E6%9F%A5%E7%9C%8B%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E8%BD%A8%E8%BF%B9/"},{"content":"写入时自动释放Buffer 如下代码：\n1 2 3 4 5 6 7 8 9 10  public class DiscardServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ctx.write(msg); ctx.flush(); } }   此处在ChannelInboundHandlerAdapter中并没有释放接受到的消息，这是因为当写入的时候Netty会帮助我们释放。\n（我简单的理解为：调用ctx的write方法，可以自动将我们的buffer的引用减一）\n换一个角度理解ChannelFuture 一个 ChannelFuture 代表了一个还没有发生的IO操作。\n预定义监听器代码 这个东西我在用，但是一直不知道它叫做预定义监听器：\n1 2 3  writeFuture.addListener(ChannelFutureListener.CLOSE);   ByteToMessageDecoder陷阱 关于Sharable的问题我已经了解了，但是下面还有一个小问题。\n一些方法如ByteBuf.readBytes(int)，如果返回的缓冲区没有被释放或者添加到out List中，将会导致内存泄漏。使用像ByteBuf.readSlice(int)这样的派生缓冲区来避免内存泄漏。\n（我目前Netty的代码写的还不够多，对这个问题理解的还不够深入）\n ","description":"","id":571,"section":"notes","tags":null,"title":"一些小的知识点","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C/%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"content":"刚才整理笔记的时候，突然迸发出来了一些灵感。如果我想让我的文件管理工具更灵活，我就不应该设计我在什么场景使用它。\n可是我又如何实现这个想法呢？我做了如下的设计（初步）：\n 假如每个文件都对应如下的属性，其中比较特殊的tags字段，tags字段的key为文件夹Id，值为该文件在该文件夹中的tag，其中key为root时表表示该文件在根目录中的tag值。这些tag值会被如何设置，后面的内容会讲到。  1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;fileName\u0026#34;: \u0026#34;这是一个测试文件夹\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;134324832478\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;134324832478\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;root\u0026#34;: [\u0026#34;root_1\u0026#34;, \u0026#34;root_2\u0026#34;, \u0026#34;root_3\u0026#34;], \u0026#34;DirId_1\u0026#34;: [\u0026#34;tag_1_1\u0026#34;,\u0026#34;tag_1_2\u0026#34;,\u0026#34;tag_1_3\u0026#34;], \u0026#34;DirId_2\u0026#34;: [\u0026#34;tag_2_1\u0026#34;,\u0026#34;tag_2_2\u0026#34;,\u0026#34;tag_2_3\u0026#34;] } }   假设每个文件夹都对应如下属性，这个比较特殊的是scripts字段，scripts中key是事件名，当该文件被删除子文件夹时触发什么事件，当该文件夹被移动文件时执行什么事件。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  { \u0026#34;fileName\u0026#34;: \u0026#34;这是一个测试文件夹\u0026#34;, \u0026#34;createTime\u0026#34;: \u0026#34;134324832478\u0026#34;, \u0026#34;updateTime\u0026#34;: \u0026#34;134324832478\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;root\u0026#34;: [\u0026#34;root_1\u0026#34;, \u0026#34;root_2\u0026#34;, \u0026#34;root_3\u0026#34;], \u0026#34;DirId_1\u0026#34;: [\u0026#34;tag_1_1\u0026#34;,\u0026#34;tag_1_2\u0026#34;,\u0026#34;tag_1_3\u0026#34;], \u0026#34;DirId_2\u0026#34;: [\u0026#34;tag_2_1\u0026#34;,\u0026#34;tag_2_2\u0026#34;,\u0026#34;tag_2_3\u0026#34;] }, \u0026#34;scripts\u0026#34;: { \u0026#34;onDeleteFile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onDeleteDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onCreateFile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onCreateDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onFileDragToDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onFileDragToFile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onDirDragToFile\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;onDirDragToDir\u0026#34;: \u0026#34;\u0026#34; } }     事件接受的参数有哪些呢？当前文件夹的所有属性信息、被移动文件的所有属性信息。事件的输出有哪些呢？输出新的文件属性信息的tags字段。\n  Explore本身也是有属性的，属性结构没想好。\n  Explore可以配置全局的事件。\n这些都是初步设计，数据机构还有优化和丰富，数据结构转换也需要再精心设计以下。\n还需要提供Explore相关的API。\n我们让真正的文件操作也在这些事件中完成吧。\n我现在在这套架构下实现我目前的需求：\n 文件顺序可以任意调整，这个应该是文件夹级别的，就是说每个文件夹都会有自己的方案。我在文件夹A的每个事件中都加一行代码，得到当前Explore视图（随便造的概念），然后进行排序，ra  ","description":"","id":572,"section":"notes","tags":null,"title":"一些灵感","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E4%B8%80%E4%BA%9B%E7%81%B5%E6%84%9F/"},{"content":" 查看视频的所有类型，只看不下载   youtube-dl -F url youtube-dl -F url youtube-dl -F url  下载1080P视频+音频（仅针对YouTuBe）   youtube-dl -f 137+140 url ","description":"","id":573,"section":"notes","tags":null,"title":"一些重要的参数","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/youtube-dl/%E4%B8%80%E4%BA%9B%E9%87%8D%E8%A6%81%E7%9A%84%E5%8F%82%E6%95%B0/"},{"content":"今天在整理框架的时候，看到了一段很奇怪的maven插件配置代码，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-jar-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;classifier\u0026gt;base\u0026lt;/classifier\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/configuration/error/**\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/configuration/web/Interceptor/**\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/configuration/web/InterceptorConfig.*\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/base/controller/**\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/configuration/web/response/ControllerResponseBodyAdvice.*\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/configuration/web/UnderTowConfiguration.*\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/storage/**\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt;   这一段代码，在配置org.apache.maven.plugins.maven-jar-plugin插件，我们让这个插件在打包的时候，忽略指定的.class文件。为什么会有这样的需求呢？因为我们的部分项目将FeignClient的代码和Application的代码写在了一起，所以我们在打包的手需要将一些文件给exclude出去。\n我首先是不支持将FeignClient的代码和Application的代码写在一起的，我会开两个Module隔离这些代码；其次，我是不主张这部分过度依赖旧框架的项目升级到新框架的，我主张的是将框架直接推到重写，我们的目标就单纯的是新项目。\n","description":"","id":574,"section":"notes","tags":null,"title":"一段插件配置代码与这样配置的原因","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E4%B8%80%E6%AE%B5%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%99%E6%A0%B7%E9%85%8D%E7%BD%AE%E7%9A%84%E5%8E%9F%E5%9B%A0/"},{"content":"核心写法如下：\n1 2 3 4  @Resource(name = \u0026#34;redisTemplate\u0026#34;) private HashOperations\u0026lt;String, byte[], byte[]\u0026gt; hashOperations;   教程中的解释是：HashOperations是RedisTemplate的众多操作视图之一，要使用其中一个视图，必须将该视图声明为依赖项，然后注入RedisTemplate（我对这段话理解的不是很深入）。\n参考资料  Redis HashOperations dependency not found?  ","description":"","id":575,"section":"notes","tags":null,"title":"一种注入Operations的写法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E4%B8%80%E7%A7%8D%E6%B3%A8%E5%85%A5operations%E7%9A%84%E5%86%99%E6%B3%95/"},{"content":"实际上我没有找到这样的功能，所以使用Postman的Api，自己开发了一个Python脚本，脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import requests, json get_all_collections_url = \u0026#34;https://api.getpostman.com/collections\u0026#34; delete_collection_url = \u0026#34;https://api.getpostman.com/collections/\u0026#34; headers = {\u0026#39;X-Api-Key\u0026#39;: \u0026#39;\u0026#39;} protect = [\u0026#34;SpringBoot Actuator\u0026#34;, \u0026#34;Login\u0026#34;] result = requests.get(get_all_collections_url, headers=headers) if result.status_code == 200: for item in json.loads(str(result.content, encoding=\u0026#34;utf-8\u0026#34;))[\u0026#34;collections\u0026#34;]: if item[\u0026#34;name\u0026#34;] in protect: continue requests.delete(delete_collection_url + item[\u0026#34;id\u0026#34;], headers=headers) print(\u0026#34;delete {}success\u0026#34;.format(item[\u0026#34;name\u0026#34;]))   如果你要使用，需要将X-Api-Key换成你自己的。\n参考资料  Postman API - Postman Public Workspace  ","description":"","id":576,"section":"notes","tags":null,"title":"一键清理掉所有无用的Collection","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/%E4%B8%80%E9%94%AE%E6%B8%85%E7%90%86%E6%8E%89%E6%89%80%E6%9C%89%E6%97%A0%E7%94%A8%E7%9A%84collection/"},{"content":"额，说Excel默认支持255项，结果我导出的Excel只要超过了20项，就会报上面的错误，最后我自己写了一个Handler处理该问题，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113  package com.sdstc.anta.material.utils.excel.handlers_with_new_scheme; import com.alibaba.excel.metadata.CellData; import com.alibaba.excel.metadata.Head; import com.alibaba.excel.util.StyleUtil; import com.alibaba.excel.write.handler.CellWriteHandler; import com.alibaba.excel.write.handler.SheetWriteHandler; import com.alibaba.excel.write.metadata.holder.WriteSheetHolder; import com.alibaba.excel.write.metadata.holder.WriteTableHolder; import com.alibaba.excel.write.metadata.holder.WriteWorkbookHolder; import com.alibaba.excel.write.metadata.style.WriteCellStyle; import com.alibaba.excel.write.metadata.style.WriteFont; import lombok.extern.slf4j.Slf4j; import org.apache.commons.collections4.CollectionUtils; import org.apache.poi.ss.usermodel.*; import org.apache.poi.ss.util.CellRangeAddressList; import org.apache.poi.xssf.usermodel.XSSFDataValidation; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; @Slf4j public class DropDownSheetHandler implements SheetWriteHandler { private static final String DROP_BOX_HIDDEN_SHEET = \u0026#34;DROP_BOX_HIDDEN_SHEET\u0026#34;; // 下拉框值  private final HashMap\u0026lt;Integer, String[]\u0026gt; dropDownMap; public DropDownSheetHandler(HashMap\u0026lt;Integer, String[]\u0026gt; dropDownMap) { this.dropDownMap = dropDownMap; } @Override public void beforeSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { } @Override public void afterSheetCreate(WriteWorkbookHolder writeWorkbookHolder, WriteSheetHolder writeSheetHolder) { Workbook workbook = writeWorkbookHolder.getWorkbook(); // region 在另一张Sheet中准备下拉数据  // 因为行只能创建一次，所以需要计算出最大行  int maxRows = Integer.MIN_VALUE; for (String[] arr : dropDownMap.values()) { if (arr.length \u0026gt; maxRows) { maxRows = arr.length; } } Sheet dropBoxHiddenSheet = workbook.createSheet(DROP_BOX_HIDDEN_SHEET); for (int i = 0; i \u0026lt; maxRows; i++) { Row row = dropBoxHiddenSheet.createRow(i); for (Map.Entry\u0026lt;Integer, String[]\u0026gt; entry : dropDownMap.entrySet()) { if (i \u0026lt; entry.getValue().length) { row.createCell(entry.getKey()).setCellValue(entry.getValue()[i]); } } } // 隐藏Sheet  if (!workbook.isSheetHidden(workbook.getSheetIndex(DROP_BOX_HIDDEN_SHEET))) { workbook.setSheetHidden(workbook.getSheetIndex(DROP_BOX_HIDDEN_SHEET), true); } // endregion  DataValidationHelper helper = writeSheetHolder.getSheet().getDataValidationHelper(); for (Map.Entry\u0026lt;Integer, String[]\u0026gt; entry : dropDownMap.entrySet()) { String excelTag = getExcelTag(entry.getKey(), entry.getValue().length); DataValidationConstraint dataValidationConstraint = helper.createFormulaListConstraint( String.format(\u0026#34;%s!%s\u0026#34;, DROP_BOX_HIDDEN_SHEET, excelTag)); CellRangeAddressList cellRangeAddressList = new CellRangeAddressList(1, 65536, entry.getKey(), entry.getKey()); DataValidation dataValidation = helper.createValidation(dataValidationConstraint, cellRangeAddressList); // 设置错误提示  dataValidation.setErrorStyle(DataValidation.ErrorStyle.STOP); dataValidation.setShowErrorBox(true); dataValidation.setSuppressDropDownArrow(true); dataValidation.createErrorBox(\u0026#34;错误提示\u0026#34;, \u0026#34;请选择下拉框内选项!\u0026#34;); writeSheetHolder.getSheet().addValidationData(dataValidation); } } private String getExcelTag(int row, int length) { if (row \u0026lt; 0) { throw new RuntimeException(\u0026#34;Wrong RowIndex Show Bigger Then 0\u0026#34;); } int leftRow = row / 26; int rightRow = row % 26; String leftRowChar = leftRow == 0 ? \u0026#34;\u0026#34; : String.valueOf((char) (65 + leftRow - 1)); String rightRowChar = String.valueOf((char) (65 + rightRow)); return String.format(\u0026#34;$%s%s$%d:$%s%s$%d\u0026#34;, leftRowChar, rightRowChar, 1, leftRowChar, rightRowChar, length); } }   参考资料    ","description":"","id":577,"section":"notes","tags":null,"title":"下拉项过多，导致文档无法打开","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/%E4%B8%8B%E6%8B%89%E9%A1%B9%E8%BF%87%E5%A4%9A%E5%AF%BC%E8%87%B4%E6%96%87%E6%A1%A3%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/"},{"content":"这个方案并不直观，步骤如下：\n  进入官网下载页面\n  按F12，设置成手机模式，然后刷新页面\n  完成两个多选框后，会弹出选择32位还是64位的页面  我遇到的哪些问题：\n 找不到这种下载方案，我也是尝试了很多次才知道可以这样下载的 使用Windows工具下载ISO，下载的ISO根本无法安装 F12后，不知道要两个单选框（选完第一个，第二个才出现）都选择后才会出现版本选择页面  参考资料    ","description":"","id":578,"section":"notes","tags":null,"title":"下载Win10镜像","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%B8%8B%E8%BD%BDwin10%E9%95%9C%E5%83%8F/"},{"content":"you-get貌似没有维护了，所以没有研究价值了\n用pip3 install you-get后，执行you-get，提示找不到这条指令，花了一点时间解决这个问题，所以记录一下。\n下载后会给一个提示，说放置在了~/.local/xxx的某个目录下，实际上这个目录下得东西只是Python的一些包，可执行文件并不在这个目录下，可执行文件位于：~/.local/bin\n参考资料  Ubuntu怎么安装you-get  ","description":"","id":579,"section":"notes","tags":null,"title":"下载you-get及遇到的问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/youtube-dl/%E4%BD%9C%E5%BA%9F/%E4%B8%8B%E8%BD%BDyou-get%E5%8F%8A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我决定不再研究Ansible，故系列笔记不再维护。\n我之前决定学习Ansible，是因为我计划深度学习Redis、Kafka等软件，在学习这些软件之前，我需要一个配置管理工具，用来记录我对这些软件的配置。我当时之所以不选择K8s是因为我发现生产实践中，这些软件是不适合安装在K8s中的。所以我计划研究Ansible，同时研究使用Ansible配置这些工具，期待回来也能掌握在生产中使用Ansible配置这些软件的技能。\n我为什么又放弃研究Ansible呢？我现在使用PVE、使用Anaconda等工具、使用容器等，我发现我已经无法接受一个会影响到真实系统环境的工具了。Ansible的每一步操作都最终会影响到我的系统，且我无法很好的逆向操作，来取消这些影响。那么这就存在一个问题，一旦我操作失误了，我的系统环境就会被污染，最终不得不重装系统，或者给我埋下一些隐患，影响我其他操作。\n其次，我是一个开发人员，我不想花费太多精力去深度研究各个软件的部署、优化，Ansible让我过于接触到一些底层的东西了，增加了我学习的成本。我觉得，如果只是对软件的学习，我使用K8s就足够了。\n","description":"","id":580,"section":"notes","tags":null,"title":"不再研究Ansible","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/%E4%B8%8D%E5%86%8D%E7%A0%94%E7%A9%B6ansible/"},{"content":"其实这个问题不值得记录，但是实在是太巧合了，我刚修复好这个问题，另一个同事也遇到了，所以我就直接告诉他怎么修复了，他解决这个问题所花费的时间不到一分钟。\n我们框架中有一个ResponseBodyAdvice\u0026lt;Object\u0026gt;，它会在在我们返回的内容中遍历这个字符串找到一些我们打了标记的内容，然后为这些内容计算oss的签名，结果我的新项目这个功能都使用不了了，经过阅读源码发现，我们的切面中使用了Feign客户端，所以我们需要如下的注解，开启我们项目的客户端功能：\n1 2 3  @EnableFeignClients({\u0026#34;com.sdstc\u0026#34;})   ","description":"","id":581,"section":"notes","tags":null,"title":"不开启feign客户端，就无法使用oss签名功能","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E4%B8%8D%E5%BC%80%E5%90%AFfeign%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B0%B1%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8oss%E7%AD%BE%E5%90%8D%E5%8A%9F%E8%83%BD/"},{"content":"我一直有想法，让我的集群支持LoadBalancer类型，在看IngressNginx时看到了这方面的资料，所以计划试一试，但是发现并不是很顺利。\n认真思考一下，LoadBalancer的研究其实不是我的刚需，我之所以研究这个是为了让我的K8S集群和云上的行为完全保持一致，这样有利于我以后平滑的迁移到云上。但是现阶段研究这个，我基本功还不足，对很多底层知识理解不到位，研究效率非常的低，所以我决定暂时不研究了。\n在创建IngressNginx时，默认使用的是LoadBalancher类型，这个我会在研究完其Values.yaml后调整一下，使其默认使用NodePort。\n研究时用到的资料整理如下：\n Bare-metal considerations METALLB OpenELB OpenELB  ","description":"","id":582,"section":"notes","tags":null,"title":"不研究MetalLB、OpenELB的决定","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E4%B8%8D%E7%A0%94%E7%A9%B6metallbopenelb%E7%9A%84%E5%86%B3%E5%AE%9A/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  private List\u0026lt;Table\u0026gt; getOriginTableInfos() { if (this.jdbcTemplate.getDataSource() == null) { throw new RuntimeException(\u0026#34;数据库链接错误\u0026#34;); } try { Map\u0026lt;String, Table\u0026gt; tableName2TableMap = new HashMap\u0026lt;\u0026gt;(20); DatabaseMetaData dbMetaData = this.jdbcTemplate.getDataSource().getConnection().getMetaData(); // 处理表信息  // 此处抛出异常  ResultSet tables = dbMetaData.getTables( null, null, ProjectConfig.getTablePrefix() + \u0026#34;_%\u0026#34;, new String[]{\u0026#34;TABLE\u0026#34;}); while (tables.next()) { String tableName = tables.getString(\u0026#34;table_name\u0026#34;); String tableDesc = tables.getString(\u0026#34;remarks\u0026#34;); tableName2TableMap.put(tableName, new Table(tableName, tableDesc)); } // 处理列信息  ResultSet columns = dbMetaData.getColumns( null, null, ProjectConfig.getTablePrefix() + \u0026#34;%\u0026#34;, null); while (columns.next()) { String tableName = columns.getString(\u0026#34;table_name\u0026#34;); String columnName = columns.getString(\u0026#34;column_name\u0026#34;); String typeName = columns.getString(\u0026#34;type_name\u0026#34;); String remarks = columns.getString(\u0026#34;remarks\u0026#34;); Table table = tableName2TableMap.get(tableName); if (table == null) { throw new RuntimeException(\u0026#34;Data Wrong When Get Column Info\u0026#34;); } table.addColumn(new Column(columnName, remarks, typeName)); } return new ArrayList\u0026lt;\u0026gt;(tableName2TableMap.values()); } catch (Exception e) { throw new RuntimeException(\u0026#34;数据库获取数据错误\u0026#34;); } }   我在代码中注释了抛出异常的代码行，我之前一直以为是我的代码出错了，后来发现是传入的ProjectConfig.getTablePrefix() + \u0026quot;_%\u0026quot;参数，该参数的实现如下：\n1 2 3 4 5  public static String getTablePrefix() { return INSTANCE.tablePrefix; }   因为INSTANCE没有初始化，该字段应该为null，所以抛出来的异常应该为NullException，这个异常被捕获了，变成了一个迷惑我的数据库异常。\n","description":"","id":583,"section":"notes","tags":null,"title":"不要吞掉异常信息，否则只能自食其果","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E4%B8%8D%E8%A6%81%E5%90%9E%E6%8E%89%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF%E5%90%A6%E5%88%99%E5%8F%AA%E8%83%BD%E8%87%AA%E9%A3%9F%E5%85%B6%E6%9E%9C/"},{"content":"不会有这种想法了，故作废\n我计划自己将一个Linux系统变成路由器。\n为什么会有这样奇奇怪怪的需求呢？我原本是计划在J4125那台机器上做虚拟化，然后装OpenWRT外加一个CentOS系统的，但是用ESXI做虚拟化的过程中，并不是很顺利，这个工具问题太多了，经不起折腾。用PVE做虚拟化的时候，发现它本身也是一个Linux系统，我甚至只需要虚拟化出一个OpenWRT系统就可以满足我的需求了，其他的工具可以装在PVE上。我觉得花大量时间学习PVE，只为了维护一个OpenWRT实在是不值得，我决定寻找其他的方案。\n随着对OpenWRT的深入研究，我对自己需求也越来越清晰，我意识到自己可能并不需要OpenWRT，我需要的仅仅是一台机器做网关，实现对内网中流量的透明代理，同时我可以通过内网穿透工具暴露这台机器，使我在其他的网络环境中也可以连接到我的内网环境中。最好，整套方案不需要再引入其他的工具，增加我的学习成本。经过研究后我发现我的需求完全可以通过iptables实现，所以我决定自己动手，实现CentOS的路由化，这个过程中我还可以学习到大量的CentOS知识，非常划算。\n20210616后续：\n不要再有这种想法了，类似OpenWRT这种系统肯定是进行过内核级别的优化的，更适合做路由器的场景，我目前已经掌握了OpenWRT的编译技术，非常爽，哈哈。\n","description":"","id":584,"section":"notes","tags":null,"title":"不要尝试将一个Linux系统配置成网关服务器","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%BD%9C%E5%BA%9F/%E4%B8%8D%E8%A6%81%E5%B0%9D%E8%AF%95%E5%B0%86%E4%B8%80%E4%B8%AAlinux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%88%90%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"content":"之前有考虑研究GitPython、PyGit，然后在python脚本中操作Git仓库，但是最近在使用的过程中发现相关资料有点少，而且运行的时候会出现一些我无法理解的问题，所以决定暂时不研究这些技术了。\n可能等我系统学习了Git后，我可能会再次研究相关技术。所以这也影响了我对python脚本的定位，我之前是期待python脚本为主，完全取代shell脚本，甚至在代码中都不调用shell脚本。可能这之后还是shell脚本为主，python脚本用于处理一些业务逻辑比较复杂的东西。\n","description":"","id":585,"section":"notes","tags":null,"title":"不计划对GitPython等技术进行研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%B8%8D%E8%AE%A1%E5%88%92%E5%AF%B9gitpython%E7%AD%89%E6%8A%80%E6%9C%AF%E8%BF%9B%E8%A1%8C%E7%A0%94%E7%A9%B6/"},{"content":"问题描述  # # There is insufficient memory for the Java Runtime Environment to continue. # Native memory allocation (malloc) failed to allocate 949216 bytes for Chunk::new # An error report file with more information is saved as: # D:\\Project\\dyf\\hs_err_pid20632.log [thread 15576 also had an error] # # Compiler replay data is saved as: # D:\\Project\\dyf\\replay_pid20632.log Disconnected from the target VM, address: '127.0.0.1:63994', transport: 'socket' Process finished with exit code 1 Idea在执行程序的时候，报如上的错误，处理过程如下：\n这个方案实际上并没有帮到我，我每次设置后都会重启，重启后就不会出现该问题了。但是该设置仍然是700M。\n20210615后续：\n后来已经证明是我操作系统出现了问题，当内存超过60%时，就无法正常的分配内存。\n","description":"","id":586,"section":"notes","tags":null,"title":"为Idea配置内存不足导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E4%B8%BAidea%E9%85%8D%E7%BD%AE%E5%86%85%E5%AD%98%E4%B8%8D%E8%B6%B3%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3  sudo passwd root   ","description":"","id":587,"section":"notes","tags":null,"title":"为root用户添加密码","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%B8%BAroot%E7%94%A8%E6%88%B7%E6%B7%BB%E5%8A%A0%E5%AF%86%E7%A0%81/"},{"content":"说明  这不是一个优雅的方案，只是为了临时用一下 我感觉阿里云也是用的这个方案，但是可能它用的层次更高一些，我只是简单的照搬  操作步骤 master  切换到root用户，执行如下指令：  1 2 3 4 5  mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config   node  vagrant用户，指令如下  1 2 3 4  cd ~ \u0026amp;\u0026amp; mkdir .kube scp vagrant@172.17.30.101:~/.kube/config ~/.kube/config    root用户，指令如下  1 2 3 4 5  cd ~ \u0026amp;\u0026amp; mkdir .kube cp /home/vagrant/.kube/config ~/.kube/ sudo chown $(id -u):$(id -g) $HOME/.kube/config   相关教程   ubuntu18.04安装kubernetes(用于查看安装Kubernetes后，如何保证master机器能够使用kubectl)\n  通过kubectl连接Kubernetes集群(我的方案就是阿里云方案的照搬)\n  更多研究资料（我没有用这些，但是我认为这些方案更好一些）  kubectl客户端工具远程连接k8s集群（有关于证书的资料） 配置kubectl在Mac(本地)远程连接Kubernetes集群 使用 kubectl 连接远程 Kubernetes 集群(有kubectl配置资料) 使用 kubectl 连接远程 Kubernetes 集群(有kubectl配置资料) 配置远程工具访问kubernetes集群(有kubectl配置资料)  ","description":"","id":588,"section":"notes","tags":null,"title":"为root用户配置kubectl","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%B8%BAroot%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AEkubectl/"},{"content":"因为我现在用Anaconda3比较多，且笔记中有些地方表述不清晰，故不在维护该笔记\n我使用频率较高的是Python3，但是Yum工具又必须使用Python2打开，所以我不得不频繁的切换Python软连接的指向。\n我尝试过将/usr/bin/yum脚本头部执行Python2，结果在下载依赖时，还是有一定的概率报错，所以我将/usr/bin下所有的yum打头的脚本的头部都改成了Python2。\n1 2 3 4 5 6 7 8 9 10 11 12  ls /usr/bin | grep yum # 输出为 yum yum-builddep yum-config-manager yum-debug-dump yum-debug-restore yumdownloader yum-groups-manager   另外我在一篇教程中发现似乎只需要改三个文件就可以了，按照这份教程，我也修改了/usr/libexec/urlgrabber-ext-down脚本的头部。\n","description":"","id":589,"section":"notes","tags":null,"title":"为Yum指定Python2","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/%E4%B8%BAyum%E6%8C%87%E5%AE%9Apython2/"},{"content":"在写Demo时，一旦引入第三方组件，再次启动该Demo的动力就会减少80%，尤其是数据库之类的第三方组件，所以我决定好好研究一下H2数据库。考虑到我目前使用的Navicat 12不支持H2数据库（貌似Navicat没有支持H2数据库的计划），所以我决定开始接触DataGrip工具。\n","description":"","id":590,"section":"notes","tags":null,"title":"为什么决定学习H2及DataGrip","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/datagrip-h2/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%86%B3%E5%AE%9A%E5%AD%A6%E4%B9%A0h2%E5%8F%8Adatagrip/"},{"content":"核心原因在于Date、SimpleDateFormat等是非线程安全的，而LocalDataTime是线程安全的。\n参考资料  为什么建议使用你LocalDateTime，而不是Date？  ","description":"","id":591,"section":"notes","tags":null,"title":"为什么要使用LocalDateTime","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8localdatetime/"},{"content":"增加字段 1 2 3 4 5  ALTERTABLEt_company_package_manageADDCOLUMNaudit_opinionvarchar;COMMENTONCOLUMN\u0026#34;auth\u0026#34;.\u0026#34;t_company_package_manage\u0026#34;.\u0026#34;audit_opinion\u0026#34;IS\u0026#39;审核意见\u0026#39;;  删除字段 1 2 3  ALTERTABLEt_company_package_manageDROPCOLUMNaudit_opinionCASCADE;  修改字段 1 2 3 4 5 6 7 8 9 10 11  altertablet_taskalterCOLUMNmaterial_typetypevarchar(32);-- 删除或新增非空约束 altertabletable_namealtercolumn_namedropnotnull;altertabletable_namealtercolumn_namesetnotnull;-- 删除或设置默认值 altertabletable_namealterCOLUMNcolumn_nameDROPDEFAULT;altertabletable_namealterCOLUMNcolumn_nameSETDEFAULTdefault_value;  备注 1 2 3 4 5 6 7 8 9  -- PG中貌似不支持这种写法，没有找到很好的方案 ALTERTABLEt_color_altaADDCOLUMNcommit_qualilty_manvarchar(32)beforequality_man;ALTERTABLEt_color_altaADDCOLUMNcommit_qualilty_timetimestamptzbeforequality_man;COMMENTONCOLUMNt_color_alta.commit_qualilty_manIS\u0026#39;提交质检人\u0026#39;;COMMENTONCOLUMNt_color_alta.commit_qualilty_manIS\u0026#39;提交质检时间\u0026#39;;  ","description":"","id":592,"section":"notes","tags":null,"title":"为已存在的表删除、增加、修改一个字段","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E4%B8%BA%E5%B7%B2%E5%AD%98%E5%9C%A8%E7%9A%84%E8%A1%A8%E5%88%A0%E9%99%A4%E5%A2%9E%E5%8A%A0%E4%BF%AE%E6%94%B9%E4%B8%80%E4%B8%AA%E5%AD%97%E6%AE%B5/"},{"content":"我采用的方案比较简单：\n ls /dev/sd* // 进行分区 fdisk /dev/sdb n p 转折（使用默认） 转折（使用默认） w // 创建文件系统 mkfs -t ext4 /dev/sdb1 // 将硬盘信息写入/etc/fstab echo /dev/sdb1 /mnt/sdc1 ext4 defaults 1 2 \u0026gt;\u0026gt; /etc/fstab 参考资料  Proxmox VE（PVE）如何添加多块硬盘 Linux/VPS开机启动自动挂载分区的方法 linux中lost+found目录的作用  ","description":"","id":593,"section":"notes","tags":null,"title":"为系统新加一块硬盘","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%B8%BA%E7%B3%BB%E7%BB%9F%E6%96%B0%E5%8A%A0%E4%B8%80%E5%9D%97%E7%A1%AC%E7%9B%98/"},{"content":"我这个需求产生于修复EasyApi的官方提供的渲染服务的Bug。就是我按照官方说明做了镜像后，无法正常启动，所以我决定先在本地试试能否正常启动该服务。\n 首先确保你的容器处于正在运行的状态，如果没有办法保证，可以使用如下指令：   docker run -it --entrypoint top yapi-markdown-render:v3 --name tmp-for-test 使用如下指令，完成copy   docker cp vibrant_joliot:/easyyapi . 参考资料  docker中宿主机与容器（container）互相拷贝传递文件的方法 docker cmd 能够代替 entrypoint 的所有功能  ","description":"","id":594,"section":"notes","tags":null,"title":"从Docker容器内拷贝资料到宿主机","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E4%BB%8Edocker%E5%AE%B9%E5%99%A8%E5%86%85%E6%8B%B7%E8%B4%9D%E8%B5%84%E6%96%99%E5%88%B0%E5%AE%BF%E4%B8%BB%E6%9C%BA/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 硬件校准信息上报 */ @PostMapping(\u0026#34;/client/calibration/report\u0026#34;) @PassToken public ResponseVo\u0026lt;Object\u0026gt; clientCalibrationReport( @RequestHeader(value = \u0026#34;terminal\u0026#34;) Integer terminal, @Valid @RequestBody ClientCalibrationReportRequest request) { clientCalibrationReportService.saveClientCalibrationReport(terminal, request); return ResponseVo.createSuccess(); }   参考资料  java 获取HttpRequest Header 的几种方法  ","description":"","id":595,"section":"notes","tags":null,"title":"从Header中获取值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E4%BB%8Eheader%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%80%BC/"},{"content":"20210420后续：\n实际上我有点不想用Python去开发一些小工具了，Python好久不摸，API忘得太快了，Ide又给不到什么有用的信息，在观望一下吧。\n小小说明 这是我个人很久以前开发的一个辅助开发工具，最近有遇到类似的需求了，故记录下来。\n事情的起因是这样的：我们业务上经常需要和第三方对接，第三方提供的往往是一个json文件。我们在编写代码时，可能会构建一个map，然后把各个字段填充进去，我并不是很喜欢这种方案，感觉并不是太优雅。我比较喜欢用@Builder的方案，这样代码段落会比较清晰，看上去也很优雅。\n所以我就完成了这个辅助工具，这个工具可以解析一份json文件，然后输出类的定义代码。我在实现的时候，考虑了嵌套关系，所以生成的代码和实际情况是比较符合的，可以直接copy到项目中使用。\n这儿需要说明的是，因为当时编写的时候，只考虑了服务于接口开发，代码中充斥了很多和我们应用场景细细相关的东西，比如我解析时，是从data层开始解析的；最后生成的对象，也是很多个小对象包含在一个大的Data对象中；同时，我这边只考虑了String的场景。如果你有需求，可以自行调整一下代码。\n代码展示 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  import json outer_class = [] inner_class = {} class Field: def __init__(self, field_tame, field_type, is_list=False): self.fieldName = field_tame self.fieldType = field_type self.is_list = is_list def outer_dispose(data_element): for key in data_element: if isinstance(data_element[key], list): # 暂时不考虑list嵌套的问题 if len(data_element[key]) \u0026gt; 0: if isinstance(data_element[key][0], dict): outer_class.append(Field(key, key, True)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, data_element[key][0]) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;, True)) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;, True)) elif isinstance(data_element[key], dict): outer_class.append(Field(key, key)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, data_element[key]) else: outer_class.append(Field(key, \u0026#39;string\u0026#39;)) def inner_dispose(class_name, element): for key in element: if isinstance(element[key], list): if len(element[key]) \u0026gt; 0: if isinstance(element[key][0], dict): inner_class[class_name].append(Field(key, key, True)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, element[key][0]) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;, True)) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;, True)) elif isinstance(element[key], dict): inner_class[class_name].append(Field(key, key)) # 处理内部类型 inner_class[key] = [] inner_dispose(key, element[key]) else: inner_class[class_name].append(Field(key, \u0026#39;string\u0026#39;)) def generateLine(prefix, field): result = \u0026#39;\u0026#39; if field.is_list: result += \u0026#39;%sprivate List\u0026lt;%s\u0026gt; %s;\\n\u0026#39; % (prefix, field.fieldType.capitalize(), field.fieldName) else: result += \u0026#39;%sprivate %s%s;\\n\u0026#39; % (prefix, field.fieldType.capitalize(), field.fieldName) return result def generateOuterClass(outer_class, inner_class_content): result = \u0026#39;\u0026#39; result += \u0026#39;@Data\\n\u0026#39; result += \u0026#39;@NoArgsConstructor\\n\u0026#39; result += \u0026#39;@AllArgsConstructor\\n\u0026#39; result += \u0026#39;public class %s{\\n\u0026#39; % \u0026#39;Temp\u0026#39; for field in outer_class: result += generateLine(\u0026#39;\\t\u0026#39;, field) result += \u0026#39;\\n\\n\u0026#39; result += inner_class_content result += \u0026#39;}\\n\u0026#39; return result def generateInnerClass(inner_class): result = \u0026#39;\u0026#39; for class_name in inner_class: result += \u0026#39;\\t@Data\\n\u0026#39; result += \u0026#39;\\t@Builder\\n\u0026#39; result += \u0026#39;\\t@NoArgsConstructor\\n\u0026#39; result += \u0026#39;\\t@AllArgsConstructor\\n\u0026#39; result += \u0026#39;\\tpublic static class %s{\\n\u0026#39; % class_name.capitalize() for field in inner_class[class_name]: result += generateLine(\u0026#39;\\t\\t\u0026#39;, field) result += \u0026#39;\\t}\\n\\n\u0026#39; return result if __name__ == \u0026#39;__main__\u0026#39;: with open(\u0026#39;input.json\u0026#39;, encoding=\u0026#39;utf8\u0026#39;) as file: root_element = json.load(file) data_element = root_element[\u0026#39;data\u0026#39;] if isinstance(data_element, list): if len(data_element) \u0026gt; 0: outer_dispose(data_element[0]) elif isinstance(data_element, dict): outer_dispose(data_element) else: raise Exception() inner_class_content = generateInnerClass(inner_class) print(generateOuterClass(outer_class, inner_class_content))   这份代码目前收录在python，如果你有兴趣，可以关注该项目最新的动态，或许我已经对这份代码进行了调整，且调整后更符合你的需求。\n","description":"","id":596,"section":"notes","tags":null,"title":"从json文件生成java对象的小工具","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%BB%8Ejson%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"content":"代码如下（该代码未执行，未在编辑器中编辑，纯粹记录使用）：\n1 2 3 4 5 6 7  // beans.xml ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026#34;beans.xml\u0026#34;); // xxxConfiguration.class ApplicationContext applicationContext = new AnnotationConfigApplicationContext(xxxConfiguration.class)   ","description":"","id":597,"section":"notes","tags":null,"title":"从xml配置文件到基于注解的配置文件的演进","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BB%8Exml%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E6%BC%94%E8%BF%9B/"},{"content":"RBAC，一个用户可以有多个角色，一个角色可以有多个控制。\n在K8S中，有（省略了部分配置）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:name:ingress-nginxrules:# 对namespaces资源的控制- apiGroups:- \u0026#39;\u0026#39;resources:- namespacesverbs:- get# 对configmaps、pods、secrets、endpoints资源的配置- apiGroups:- \u0026#39;\u0026#39;resources:- configmaps- pods- secrets- endpointsverbs:- get- list- watch---# 类似用户角色关联表，但是它是角色到用户一对多，而传统的是用户到角色一对多apiVersion:rbac.authorization.k8s.io/v1kind:RoleBinding# 关联的角色（角色Id）roleRef:apiGroup:rbac.authorization.k8s.iokind:Rolename:ingress-nginx# 绑定到的用户（用户Id）subjects:- kind:ServiceAccountname:ingress-nginxnamespace:ingress-nginx  假如我现在有一个需求，我需要为一个用户配置多个角色，在传统的方案中我会怎么做，我会在用户角色关联表里插入多条记录；在K8S的方案中，我需要怎么做呢？我需要创建多个RoleBinding，这个显然不是很优雅的解决方案，不如专门创建一个角色，然后绑定到这个用户上。\n现在我发现很多时候，Service、Role、ClusterRole、RoleBinding、ClusterBinding都是谁需要谁自己准备好清单文件，然后由集群管理员创建出来，假如一个恶意的服务，它完全可以准备一份拥有非常高权限的清单文件，然后获取集群的信息，做一些攻击行为，我不知道这种事情现在该如何避免。\n其实这个问题时普遍存在的，比如我们手机APP，它就是知道自己要哪些权限，然后申请这些权限，我们再赋予给它。假如我们赋权时不仔细甄别，可能就被APP拿去很高的权限，然后做一些攻击行为了。\n","description":"","id":598,"section":"notes","tags":null,"title":"从传统RBAC的角度理解K8S的RBAC","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%BB%8E%E4%BC%A0%E7%BB%9Frbac%E7%9A%84%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3k8s%E7%9A%84rbac/"},{"content":"核心的目标是，用户传递的某个字段的值，在@RequestBody转换后，自动转换成枚举，因为枚举是全局的，所以可以直接赋值给entity的相应字段，然后调用mapper的方法进行入库。\n这个过程核心需求解决的问题如下：\n 用户提交数据时，需要将用户提交的值转换成一个枚举 controller方法是，需要将entity中的枚举的值返回回去 entity写入到库中时，需要完成枚举到值的转换 从库中读取数据到entity时，自动完成值到枚举的转换  提交、查询阶段 request类如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  @Data public class CreateDomainModelRequest { /** * 领域ID */ private String domainId; /** * 模型名 */ private String modelName; /** * 类型 * @see com.sdstc.dyf.meta.common.constant.enums.ModelType#value */ @JSONField(serializeUsing = EnumCodec.class, deserializeUsing = EnumCodec.class) private ModelType modelType; /** * 组织ID */ private String orgId; /** * 注意事项 */ private String note; }   其中ModelType枚举的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  package com.sdstc.dyf.meta.common.constant.enums; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.AccessLevel; /** * 类型 */ @AllArgsConstructor(access = AccessLevel.PROTECTED) public enum ModelType { /** * 系统 */ SYSTEM(\u0026#34;1\u0026#34;), /** * 自定义 */ CUSTOM(\u0026#34;3\u0026#34;), ; @Getter private String value; public static ModelType convert(String inputValue) { for (ModelType enumItem : ModelType.values()) { if (enumItem.getValue().equals(inputValue)) { return enumItem; } } throw new RuntimeException(\u0026#34;Enum Transfer Wrong.\u0026#34;); } }   入库、出库阶段 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  @Data @Builder @NoArgsConstructor @AllArgsConstructor @EqualsAndHashCode(callSuper = false) @TableName(value = \u0026#34;t_dyf_domain_model\u0026#34;, autoResultMap = true) public class DomainModelPo extends BasePo { /** * 领域ID */ private String domainId; /** * 模型名 */ private String modelName; /** * 类型 */ @TableField(typeHandler = ModelTypeTypeHandler.class) private ModelType modelType; /** * 组织ID */ private String orgId; /** * 注意事项 */ private String note; }   其中ModelTypeTypeHandler.java的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  @Slf4j @MappedTypes({Object.class}) @MappedJdbcTypes(JdbcType.VARCHAR) public class ModelTypeTypeHandler extends AbstractEnumTypeHandler\u0026lt;ModelType\u0026gt; { @Override protected ModelType parseValue(String inputParam) { return ModelType.convert(inputParam); } @Override protected String toValue(ModelType isModelRequired) { return isModelRequired.getValue(); } }   其中AbstractEnumTypeHandler.java的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public abstract class AbstractEnumTypeHandler\u0026lt;T\u0026gt; extends BaseTypeHandler\u0026lt;T\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException { ps.setObject(i, toValue(parameter)); } @Override public T getNullableResult(ResultSet rs, String columnName) throws SQLException { final Object inputParam = rs.getObject(columnName); return parseValue(String.valueOf(inputParam)); } @Override public T getNullableResult(ResultSet rs, int columnIndex) throws SQLException { final Object inputParam = rs.getObject(columnIndex); return parseValue(String.valueOf(inputParam)); } @Override public T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { final Object inputParam = cs.getObject(columnIndex); return parseValue(String.valueOf(inputParam)); } protected abstract T parseValue(String inputParam); protected abstract String toValue(T enumObject); }   参考资料   MybatisPlus中@TableField注解的使用\n  https://blog.csdn.net/intersting/article/details/93768803\n  深入解析Spring使用枚举接收参数和返回值机制并提供自定义最佳实践\n这部分内容包含了一些知识，但是我这次解决问题并没有使用到这些知识。\n  自定义fastjson对枚举类型的序列化及反序列化过程\n有参考该份文档。\n  ","description":"","id":599,"section":"notes","tags":null,"title":"从请求到入库都使用枚举","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E4%BB%8E%E8%AF%B7%E6%B1%82%E5%88%B0%E5%85%A5%E5%BA%93%E9%83%BD%E4%BD%BF%E7%94%A8%E6%9E%9A%E4%B8%BE/"},{"content":"这些依赖高频率的使用在我写Demo时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":600,"section":"notes","tags":null,"title":"代码开发常用依赖","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91%E5%B8%B8%E7%94%A8%E4%BE%9D%E8%B5%96/"},{"content":"Raw数据  shoeLastGenderAndFootTypeAndSize:{\u0026quot;男\u0026quot;:{\u0026quot;EURO\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;UK\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;US\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;CM\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5]},\u0026quot;女\u0026quot;:{\u0026quot;EURO\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;UK\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;US\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5],\u0026quot;CM\u0026quot;:[40.5,41,41.5,42,42.5,43,43.5,44,44.5]}} 数据源  shoeLastGender type:fixed params:null returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize.keys() shoeLastFootType type:fixed params: shoeLastGender JJString returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize[shoeLastGender].keys() shoeLastSize type:fixed params: shoeLastGender JJString shoeLastFootType JJString returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize[shoeLastGender][shoeLastFootType] 表单编排  下拉框组件： 字段名称: 鞋楦男女 绑定的属性: shoeLastGender 数据源: shoeLastGender 下拉框组件： 字段名称: 鞋楦脚型 绑定的属性: shoeLastFootType 数据源: shoeLastFootType params: shoeLastGender: content.shoeLastGender 下拉框组件： 字段名称: 鞋楦码数 绑定的属性: shoeLastSize 数据源: shoeLastSize params: shoeLastGender: content.shoeLastGender shoeLastFootType: content.shoeLastGender 我的思考 目前我设计数据源的时候设计了一种类型为fixed的数据源，该数据源的适用场景是下拉菜单数据写死的场景。但是，我觉得这种方法会增加表单渲染器的开发难度，不如所有数据来源于服务端干净利索。不仅如此，该方案也会增加后端数据校验器的开发难度。\n我认为创建表单、编辑表单并不是一件高频率的工作，我们让这个接口的所有数据源、检查器都从服务端获取数据，也并不是不可以接受。我的意思是，即使一个简单的男女的下拉选项，我们都从服务端获取，同时验证用户输入的是否为男女选项，我们也可以交给服务端验证。在我的记忆中，很久以前的Web开发，走的就是这样的一套流程，我们适当的返璞归真，可以更利于我们系统的设计。\n谈到便利性，不得不谈一下用户理解这个东西的成本，fixed类型数据源虽然利用前端存储数据，减少了和后端的交互，但是它增加了用户的理解成本，学习成本，可能不利用推广。\n","description":"","id":601,"section":"notes","tags":null,"title":"企业库中的案例","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/%E7%BB%84%E4%BB%B6%E9%80%89%E6%8B%A9/%E4%B8%8B%E6%8B%89%E6%A1%86/%E4%BC%81%E4%B8%9A%E5%BA%93%E4%B8%AD%E7%9A%84%E6%A1%88%E4%BE%8B/"},{"content":"数据源  shoeLastGender type:get params:null returnType:JList requestUrl:www.baidu.com shoeLastFootType type:fixed params: shoeLastGender JString returnType:JList requestUrl:www.baidu.com shoeLastSize type:get params: shoeLastGender JString shoeLastFootType JString returnType:JList requestUrl:www.baidu.com 检查器  shoeLastGendercheckerer type:post params: shoeLastGender JString result:JBollean resultMsg:JString url:www.baiduchecker.com shoeLastFootTypecheckerer type:post params: shoeLastGender JString shoeLastFootType JString result:JBollean resultMsg:JString url:www.baiduchecker.com shoeLastSize type:post params: shoeLastGender JString shoeLastFootType JString shoeLastSize JString result:JBollean resultMsg:JString url:www.baiduchecker.com 表单编排 对于下拉框组件，前端是没有任何必要做校验的，我之所以写这个东西在这儿，是因为我们的数据引擎也需要做校验。数据引擎校验的时候，会拿到用户提交的表单内容，然后拿到相关key绑定的校验器，然后按照校验器定义向这个校验器传递参数，从而实现校验工作。\n 下拉框组件： 字段名称: 鞋楦男女 绑定的属性: shoeLastGender 数据源: shoeLastGender 检查器: shoeLastGenderchecker params: shoeLastGender: context.shoeLastGender 下拉框组件： 字段名称: 鞋楦脚型 绑定的属性: shoeLastFootType 数据源: shoeLastFootType params: shoeLastGender: content.shoeLastGender 检查器: shoeLastFootTypechecker params: shoeLastGender: context.shoeLastGender shoeLastFootType: context.shoeLastFootType 下拉框组件： 字段名称: 鞋楦码数 绑定的属性: shoeLastSize 数据源: shoeLastSize params: shoeLastGender: content.shoeLastGender shoeLastFootType: content.shoeLastGender 检查器: shoeLastSizechecker params: shoeLastGender: context.shoeLastGender shoeLastFootType: context.shoeLastFootType shoeLastSize: context.shoeLastSize 我的思考 我比较喜欢这种设计，用户在使用的时候，并不需要知道太多的概念，他只需要知道，在表单编排页面，将一个组件拖动到设计区域，然后为这个组件绑定上属性、数据源、检查器就好了。我们规定如果你绑定的数据源包含参数，那么你就必须提供这些参数，这些参数，一般是从表单上下文中获取。同样的，检查器有参数，用户也必须提供参数。\n那么前端如何开发这个下拉组件呢？组件的名称为用户提供的字段名称，组件在用户完成数据后将值绑定到用户设置的属性上。当用户点击了这个组件，那么这个组件将会从服务端获取数据，然后用来渲染下拉框（这一部分可以在表单渲染器打开页面的时候，提取所有不带参数的数据源的数据，从而提升用户体验）。同时，组件会调用检查器，向后端询问该数据是否正确。\n后端的数据引擎又该如何工作呢？表单编排结束后，会生成一份校验指导文件，这份文件大概格式如下：\n { \u0026quot;shoeLastGender\u0026quot;:[ \u0026quot;SYS:NOT_NULL\u0026quot;, \u0026quot;SYS:Number\u0026quot;, \u0026quot;CUS:shoeLastGenderchecker\u0026quot; ], \u0026quot;shoeLastFootType\u0026quot;:[ \u0026quot;SYS:NOT_NULL\u0026quot;, \u0026quot;SYS:Number\u0026quot;, \u0026quot;CUS:shoeLastFootTypechecker\u0026quot; ], \u0026quot;shoeLastSize\u0026quot;:[ \u0026quot;SYS:NOT_NULL\u0026quot;, \u0026quot;SYS:String\u0026quot;, \u0026quot;CUS:shoeLastSizechecker\u0026quot; ] } 我来解释下这份文件如何指导数据校验器工作，当校验器读到shoeLastGender的所有校验规则时，他会一条一条的去执行：\n SYS:NOT_NULL代表系统定义的，非空的校验，校验器可以使用StringUtils工具来进行判断。 SYS:Number带包系统定义的，数字的的校验，校验器会使用Number之类的工具类完成。 CUS:shoeLastGenderchecker是我们自定义的校验器，数据引擎会去检索出该校验器的数据定义，然后按照该校验器定义，从表单的提取数据找找到所有的参数，并拼接出校验请求，去访问相应的服务，进行校验工作。  我接下来的工作只提供这种纯服务版的设计，因为我真的解决这种方案更具备可实践性。\n","description":"","id":602,"section":"notes","tags":null,"title":"企业库中的案例（服务端版）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/%E7%BB%84%E4%BB%B6%E9%80%89%E6%8B%A9/%E4%B8%8B%E6%8B%89%E6%A1%86/%E4%BC%81%E4%B8%9A%E5%BA%93%E4%B8%AD%E7%9A%84%E6%A1%88%E4%BE%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%89%88/"},{"content":"本次优化的目标：\n  Request、Response中不需要标注JSONField，序列化和反序列化时可自动完成Long类型到LocalDateTime类型的转换\n  当用对象接受参数中的传递的对象信息时，自动完成Long类型到LocalDateTime类型的转换，如下代码：\n  1 2 3 4 5 6  @Controller(/user) public void postUser(User user){ // todo something }    实现调用fastjson的序列化和反序列化化方法是，自动完成LocalDateTime类型到Long类型的转换\n  实体类上无需标注typeHandler，即可完成在数据出库入库时自动完成Long类型和LocalDateTime类型的转换（只需配置mybatis-plus的type-handler-packages，技术含量不好，所以不整理了）\n  Feign中的时间转换（临时加的这个目标，我只是将Fiegn的HttpMessageConverts换成了FastjsonHttpMessageConvert，我对Feign的了解还不深入，所以暂时不整理了）。\n  实现目标一 为了让实验环境了我们项目环境一致，我们进行如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { // 清除掉默认的HttpMessageConvert  converters.clear(); FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); fastJsonHttpMessageConverter.setSupportedMediaTypes(Arrays.asList( MediaType.APPLICATION_JSON, MediaType.ALL)); converters.add(fastJsonHttpMessageConverter); } }   并准备如下的测试类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @RestController public class TestController { @Data public static class User { private String username; private String password; private LocalDateTime time; } @PostMapping(\u0026#34;/createUser\u0026#34;) public User createUser(@RequestBody User user) { return user; } }   接下来进行如下实验：\n  Request中不加JSONField，完成用户输入的Long型到LocalDateTime类型的转换（实验中不需要任何配置，即可完成该目标）。\n  Response中不加入JSONFiled，可以将LocalDateTime类型转换成Long型。\n  第二个小实验 实验中，我们的请求和返回值分别如下：\n请求：\n1 2 3 4 5 6 7  { \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;time\u0026#34;: 1626696114000 }   返回值：\n1 2 3 4 5 6 7  { \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-07-19T20:01:54\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34; }   很显然time字段的返回目标并不符合我们的需求，我们期待该字段为number类型的时间戳。因此，我进行了如下配置（此处代码并不代表我最终的编码）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { // 清除掉默认的HttpMessageConvert  converters.clear(); FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); fastJsonHttpMessageConverter.setSupportedMediaTypes(Arrays.asList( MediaType.APPLICATION_JSON, MediaType.ALL)); SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器  serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; // 针对1.2.79进行的调整  if (object == null) { serializer.writeNull(); return; } ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); }); FastJsonConfig fastJsonConfig = new FastJsonConfig(); fastJsonConfig.setSerializeConfig(serializeConfig); converters.add(fastJsonHttpMessageConverter); }   实验结果表明，response中的LocalDateTime能够按照我们的需求，序列化成long型的时间戳（这段代码写的并不是很好，很容易看出来，写这段代码对Fastjson理解不足）。\n实现目标二 目标二和目标一看似是一样的，实际上千差万别。目标一中，请求数据放在请求体中，所以我们接受的时候必须使用@RequestBody，controller层方法由RequestMappingHandlerAdapter进行包装（我目前接触的几乎都是有这个适配器包装的），在RequestMappingHandlerAdapter中，经过层层处理后，我们寻找到了RequestResponseBodyMethodProcessor作为我们的参数处理器，然后由RequestResponseBodyMethodProcessor完成将请求体中的参数解析成我们方法中要的User对象。具体实现是根据MediaType寻找一个合适的HttpMessageConvert，所以我们只需要想办法在HttpMessageConvert做文章，就可以完成我们的目标。\n目标二中，我们构建实体的数据都是通过请求参数传递进来的。前面大部分内容时和实现目标一时一致的，但是到了参数绑定阶段，我们寻找到的是ServletModeAttributeMethodProcessor。在这个处理器的resolveArgument方法中，会寻找一些convert或者formatter完成String类型到目标类型的转换（我还没有找到相应的源码，但是原理上应该是这样的）。所以解决这个问题的方案就是增加一些我们自己的Convert或者Formatter，为了将所有MVC的配置集中在一起，我选择了实现Formatter，具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  @Override public void addFormatters(FormatterRegistry registry) { registry.addFormatter(new Formatter\u0026lt;LocalDateTime\u0026gt;() { @Override public String print(LocalDateTime object, Locale locale) { ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(object); return String.valueOf(object.toInstant(offset).toEpochMilli()); } @Override public LocalDateTime parse(String text, Locale locale) throws ParseException { long timestamp = Long.parseLong(text); Instant instant = Instant.ofEpochMilli(timestamp); ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone); } }); WebMvcConfigurer.super.addFormatters(registry); }   在我实际开发中，通过请求参数构建一个请求对象的需求比较少，可能只有刚接触SpringBoot的同学会不小心忘记写@RequestBody导致用参数接受数据。\n实现目标三 在进行目标一时，我已经很好的完成了该目标。在这个过程中，我意识到我对Fastjson的配置是全局的，所以不应该写在对MVC的配置类中，所以我仅仅进行了一些代码的重构，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @Configuration public class FastjsonConfig { @PostConstruct public void configFastjson() { SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器  serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; // 针对1.2.79进行的调整  if (object == null) { serializer.writeNull(); return; } ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); }); } }   我选择了用PostConstruct对Fastjson进行配置。实际上，这种全局配置我一直在担心一个问题，如果哪位同学在业务代码中不小心进行了该类的配置，那么这个功能类后续的表现将都不是我们想要的，这该怎么办呢？\n实现目标四 目标四的实现也非常的简单，我们仅仅只需要将MyBatis-Plus的配置项中增加如下配置即可：\n1 2 3 4  mybatis-plus:type-handlers-package:fun.junjie.mybatis.type  这时候，只要我们的字段为LocalDateTime类型，则会自动调用该TypeHandler，非常的优雅和舒服。\n20220106后续 因为公司将fastjson的版本从1.2.60升级到1.2.79，导致原来的代码出现了错误，所以我也相应做了一些调整，调整已经呈现在代码中了，主要为如下内容：\n1 2 3 4 5 6 7  // 针对1.2.79进行的调整 if (object == null) { serializer.writeNull(); return; }   完整的代码 完整的配置代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  package com.sdstc.core.configuration.web; import com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter; import lombok.RequiredArgsConstructor; import org.springframework.context.annotation.Configuration; import org.springframework.format.Formatter; import org.springframework.format.FormatterRegistry; import org.springframework.http.MediaType; import org.springframework.http.converter.HttpMessageConverter; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; import javax.validation.constraints.NotNull; import java.text.ParseException; import java.time.Instant; import java.time.LocalDateTime; import java.time.ZoneId; import java.time.ZoneOffset; import java.util.Arrays; import java.util.List; import java.util.Locale; /** * 对Spring MVC进行配置： * 1.配置HttpMessageConverts * 2.配置针对LocalDateTime的转换器 */ @Configuration @RequiredArgsConstructor public class WebConfig implements WebMvcConfigurer { private final FastJsonHttpMessageConverter fastJsonHttpMessageConverter; /** * 配置HttpMessageConverts * * @param converters 当前SpringBoot实例已有的转换器 */ @Override public void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { // 这部分代码还需要斟酌，需要确认下会不会影响到文件上传  converters.clear(); converters.add(fastJsonHttpMessageConverter); } /** * 配置针对LocalDateTime的转换器 * * @param registry formatter注册中心 */ @Override public void addFormatters(FormatterRegistry registry) { registry.addFormatter(new Formatter\u0026lt;LocalDateTime\u0026gt;() { @Override public String print(LocalDateTime localDateTime, Locale locale) { ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(localDateTime); return String.valueOf(localDateTime.toInstant(offset).toEpochMilli()); } @Override public LocalDateTime parse(String text, Locale locale) throws ParseException { long timestamp = Long.parseLong(text); Instant instant = Instant.ofEpochMilli(timestamp); ZoneId zone = ZoneId.systemDefault(); return LocalDateTime.ofInstant(instant, zone); } }); WebMvcConfigurer.super.addFormatters(registry); } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  package com.sdstc.core.configuration.fastjson; import com.alibaba.fastjson.serializer.JSONSerializer; import com.alibaba.fastjson.serializer.SerializeConfig; import com.alibaba.fastjson.serializer.SerializerFeature; import com.alibaba.fastjson.support.config.FastJsonConfig; import com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter; import com.sdstc.core.utils.FastJsonUtil; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.http.MediaType; import javax.annotation.PostConstruct; import java.lang.reflect.Type; import java.time.LocalDateTime; import java.time.ZoneId; import java.time.ZoneOffset; import java.util.Arrays; /** * 对Fastjson进行全局配置，使用其可以自动将LocalDateTime类型转换成Number类型时间戳 * * @author wujj */ @Configuration public class FastjsonConfiguration { @PostConstruct public void configFastjson() { SerializeConfig serializeConfig = SerializeConfig.globalInstance; // 添加处理LocalDateTime的处理器  serializeConfig.put(LocalDateTime.class, (JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) -\u0026gt; { LocalDateTime fieldValue = (LocalDateTime) object; // 针对1.2.79进行的调整  if (object == null) { serializer.writeNull(); return; } ZoneId systemDefaultZoneId = ZoneId.systemDefault(); ZoneOffset offset = systemDefaultZoneId.getRules().getOffset(fieldValue); serializer.write(fieldValue.toInstant(offset).toEpochMilli()); }); } @Bean public FastJsonHttpMessageConverter fastJsonHttpMessageConverter() { FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); // 配置FastJsonConfig  FastJsonConfig config = new FastJsonConfig(); config.setSerializerFeatures( SerializerFeature.WriteMapNullValue, SerializerFeature.WriteNullListAsEmpty, SerializerFeature.WriteNullStringAsEmpty, SerializerFeature.WriteDateUseDateFormat, SerializerFeature.DisableCircularReferenceDetect); fastJsonHttpMessageConverter.setFastJsonConfig(config); fastJsonHttpMessageConverter.setSupportedMediaTypes(Arrays.asList( MediaType.APPLICATION_JSON, MediaType.ALL)); return fastJsonHttpMessageConverter; } }   ","description":"","id":603,"section":"notes","tags":null,"title":"优化项目中LocalDateTime类型的应用","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/%E4%BC%98%E5%8C%96%E9%A1%B9%E7%9B%AE%E4%B8%ADlocaldatetime%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8/"},{"content":"@Value注解我们平时用于从application.yml中获取配置，给到类中的字段，我一直以为这是这个字段存在的价值，知道最近才知道，这个注解其实是模拟的bean.xml配置文件中的属性注入配置。\n使用@Value支持三种赋值方式：\n 基本数值 使用SpEL：#{} 获取配置文件中的配置：${}  ","description":"","id":604,"section":"notes","tags":null,"title":"使用@Value赋值","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BD%BF%E7%94%A8value%E8%B5%8B%E5%80%BC/"},{"content":"安装Anaconda的时候，我只修改了一些安装路径，其他选项都操持了默认。结果完成安装后，我发现我输入conda --version没有任何反应，且我输入python时，出现的仍然时我系统之前安装的python。于是，我做了如下的调整：\n 删除了原来的python的所有相关的环境变量配置 新增了anaconda相关的环境变量配置：   %ANACONDA3_HOME%\\ %ANACONDA3_HOME%\\Scripts %ANACONDA3_HOME%\\Library\\bin 截止到这块，我应该已经解决了所有的问题，但是我发现我在cmd窗口输入python时，会跳出应用商店，所以，我又做了如下调整：\n 删除%USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps 删除C:\\User\\Junjie\\AppData\\Local\\Microsoft\\WindowsApps  参考资料  win10 anaconda python环境，cmd输入python弹出应用商店问题 win10+python3下Anaconda的安装及环境变量配置  ","description":"","id":605,"section":"notes","tags":null,"title":"使用Anaconda遇到的一些问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/anaconda3/%E4%BD%BF%E7%94%A8anaconda%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7  sudo docker pull docker.io/rabbitmq:3.8-management sudo docker run \\  --name rabbitmq -d \\  -p 15672:15672 -p 5672:5672 \\  docker.io/rabbitmq:3.8-management   添加账号  1 2 3 4 5 6 7  sudo docker exec -i -t rabbitmq bin/bash rabbitmqctl add_user root 123456 rabbitmqctl set_permissions -p / root \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; rabbitmqctl set_user_tags root administrator rabbitmqctl list_users   管理页面   http://192.168.30.174:15672 相关教程  docker安装RabbitMq  ","description":"","id":606,"section":"notes","tags":null,"title":"使用Docker快速启动一个RabbitMQ实例","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E4%BD%BF%E7%94%A8docker%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AArabbitmq%E5%AE%9E%E4%BE%8B/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public class MyFactoryBean implements FactoryBean { @Override public Object getObject() throws Exception { return null; } @Override public Class\u0026lt;?\u0026gt; getObjectType() { return null; } @Override public boolean isSingleton() { return false; } }   getObject：方法返回了用户创建的实例\ngetObjectType：指明了创建的实例的类型\nisSingleton：指明了创建的实例是否是单例\n具体使用时将FactoryBean注入到Spring上下文即可。注入后，通过id获取该FactoryBean得到的并不是该FactoryBean，而是getObject创建的Bean。如果在bean的名称前加一个\u0026amp;符号，则可以获得到该工厂的bean。\n1 2 3 4  run.getBean(\u0026#34;myFactoryBean\u0026#34;); // 获取的是getObject创建的bean run.getBean(\u0026#34;\u0026amp;myFactoryBean\u0026#34;); // 获取的是myFactoryBean    据说MyBatis等框架都是通过这种方式注入的。\n","description":"","id":607,"section":"notes","tags":null,"title":"使用FactoryBean注入Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E4%BD%BF%E7%94%A8factorybean%E6%B3%A8%E5%85%A5bean/"},{"content":"常用指令  常用指令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  sudo docker pull nginx:alpine sudo docker tag nginx:alpine 192.168.30.174:80/test/nginx:alpine sudo docker push 192.168.30.174:80/test/nginx:alpine sudo docker tag jenkins/jenkins:lts 192.168.30.174:80/test/jenkins:lts sudo docker push 192.168.30.174:80/test/jenkins:lts sudo docker tag jenkins/jenkins:lts 192.168.30.174:80/test/jenkins:lts2 sudo docker push 192.168.30.174:80/test/jenkins:lts2 sudo docker tag cnych/jenkins:jnlp6 192.168.30.174:80/test/jenkins:jnlp6 sudo docker push 192.168.30.174:80/test/jenkins:jnlp6 sudo docker tag sonatype/nexus3:3.25.0 192.168.30.174:80/test/nexus3:3.25.0 sudo docker push 192.168.30.174:80/test/nexus3:3.25.0 sudo docker tag jenkinsci/jnlp-slave:latest 192.168.30.174:80/test/jnlp-slave:v1 sudo docker push 192.168.30.174:80/test/jnlp-slave:v1 sudo docker tag python:3.8.5 192.168.30.174:80/test/python:3.8.5 192.168.30.174:80/test/python:3.8.5 sudo docker tag busybox:latest 192.168.30.174:80/test/busybox:v1 sudo docker push 192.168.30.174:80/test/busybox:v1 sudo docker tag maven:alpine 192.168.30.174:80/test/maven:alpine sudo docker push 192.168.30.174:80/test/maven:alpine sudo docker tag google/cadvisor:latest 192.168.30.174:80/test/cadvisor:v1 sudo docker push 192.168.30.174:80/test/cadvisor:v1 sudo docker tag prom/prometheus:v2.1.0 192.168.30.174:80/test/prometheus:v2.1.0 sudo docker push 192.168.30.174:80/test/prometheus:v2.1.0   常用指令2  1 2 3 4 5 6 7  # junjie sudo docker tag jenkins/inbound-agent:4.3-4 192.168.30.174:80/test/inbound-agent:4.3-4 sudo docker push 192.168.30.174:80/test/inbound-agent:4.3-4 # 虚拟机 sudo docker pull 192.168.30.174:80/test/inbound-agent:4.3-4 sudo docker tag 192.168.30.174:80/test/inbound-agent:4.3-4 jenkins/inbound-agent:4.3-4   ","description":"","id":608,"section":"notes","tags":null,"title":"使用Harbor时的常用指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/harbor/%E4%BD%BF%E7%94%A8harbor%E6%97%B6%E7%9A%84%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"废弃理由：Kubernetes升级到1.20后不再支持selflink（其实这个我也不是很懂），导致创建pvc时会报如下错误：\n I0117 03:07:49.409564 1 controller.go:987] provision \u0026quot;default/test-claim\u0026quot; class \u0026quot;nfs-client\u0026quot;: started E0117 03:07:49.484879 1 controller.go:1004] provision \u0026quot;default/test-claim\u0026quot; class \u0026quot;nfs-client\u0026quot;: unexpected error getting claim reference: selfLink was empty, can't make reference I0117 03:20:19.438488 1 controller.go:987] provision \u0026quot;default/test-claim\u0026quot; class \u0026quot;nfs-client\u0026quot;: started E0117 03:20:19.441774 1 controller.go:1004] provision \u0026quot;default/test-claim\u0026quot; class \u0026quot;nfs-client\u0026quot;: unexpected error getting claim reference: selfLink was empty, can't make reference 相关讨论资料如下：\n Kubernetes 创建 pvc error getting claim reference: selfLink was empty, can‘t make refere Kubernetes nfs provider selfLink was empty   指令如下：  1 2 3 4 5 6 7 8 9 10  # 添加存储库 helm repo add azure http://mirror.azure.cn/kubernetes/charts/ # 搜索nfs-client-provisioner helm search repo nfs-client-provisioner # 拿到其values.yaml文件 helm inspect values azure/nfs-client-provisioner \u0026gt; values.yaml   修改vaues.yaml文件，暂时只修改如下内容：  1 2 3 4 5  nfs:server:192.168.23.60path:/root/NFSDirectory  安装nfs-client  1 2 3 4 5 6  helm install nfs-client azure/nfs-client-provisioner \\  --values values.yaml \\  --namespace nfs-client \\  --create-namespace   我目前使用的是别人的Chart，未来我可能会开发自己的Chart。\n进行测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14  kind:PersistentVolumeClaimapiVersion:v1metadata:name:test-claimannotations:volume.beta.kubernetes.io/storage-class:\u0026#34;nfs-client\u0026#34;spec:accessModes:- ReadWriteManyresources:requests:storage:1Mi  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  kind:PodapiVersion:v1metadata:name:test-podspec:containers:- name:test-podimage:busybox:1.24command:- \u0026#34;/bin/sh\u0026#34;args:- \u0026#34;-c\u0026#34;- \u0026#34;touch /mnt/SUCCESS \u0026amp;\u0026amp; exit 0 || exit 1\u0026#34;volumeMounts:- name:nfs-pvcmountPath:\u0026#34;/mnt\u0026#34;restartPolicy:\u0026#34;Never\u0026#34;volumes:- name:nfs-pvcpersistentVolumeClaim:claimName:test-claim  参考资料  k8s中级篇-Helm安装nfs-client-provisioner  ","description":"","id":609,"section":"notes","tags":null,"title":"使用Helm安装nfs-provisioner","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%AE%9E%E9%AA%8C/%E4%BD%BF%E7%94%A8helm%E5%AE%89%E8%A3%85nfs-provisioner/"},{"content":"参考步骤 需求产生于如下的场景：\n 使用网卡桥接时因为上级网络配置，但是无法分配到IP地址 使用网卡桥接时，需求使用静态IP地址，又担心造成IP地址冲突  在虚拟机的网络设置中，设置虚拟机的网络为Host Only，然后在宿主机的网络适配器选择当前上网的适配器，右键属性，选择共享选项卡，勾选允许其他网络用户通过此计算机的Internet链接来链接。\n需要注意的细节：\n 如果你现在有超过两个的适配器，则需要选择你共享给哪个适配器 共享后，会将共享的目标适配器IP地址改为192.168.137.1，你需要去手动改下（也可以在VirtualBox的主机网络管理器中改） 如果你的宿主机开启了防火墙，虚拟机中是ping不同的，但是你可以ping通虚拟机  20210414后续：\n这个方案出现了一个问题，我发现当我重启后，我的虚拟机就无法正常的上网了，这个问题在我的笔记本上从来没有出现过。我没有办法定位这个问题，相关的资料太少了，我决定放弃这个方案。\n参考资料  VirtualBox网络之仅主机(Host-Only)网络  ","description":"","id":611,"section":"notes","tags":null,"title":"使用Host Only网络的技巧","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/%E4%BD%BF%E7%94%A8host-only%E7%BD%91%E7%BB%9C%E7%9A%84%E6%8A%80%E5%B7%A7/"},{"content":"这块核心在于要调用一下matches或者find才能获取group中的值，我目前没有系统化的去研究这些Java中的正则，未来会系统研究一下。\n参考资料  Java写爬虫的时候，matcher.groupCount()返回为1，但是matcher.group(1)却抛异常  ","description":"","id":612,"section":"notes","tags":null,"title":"使用java正则时需要注意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E4%BD%BF%E7%94%A8java%E6%AD%A3%E5%88%99%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"keytool工具位于%JAVA_HOME%/bin，我之前从来没有意识到过这个工具的存在，最近在进行CAS相关的实验，发现了这个工具。按照书中的提示进行了实验，将实验过程整理如下：\n制作本地秘钥库 用如下指令生成本地秘钥库\n keytool -genkey -alias casserver -keyalg RSA -keystore D:\\keystore 在交互的过程中会涉及两个口令：密钥库口令和密钥口令。如果在生成秘钥时，keystore参数指定的秘钥库已经存在，那么新生成的秘钥会添加到该密钥库，否则将生成一个新的密钥库用于存放新生成的密钥。所以，当指定的密钥库已经存在时，必须填写密钥库的口令；如果密钥库不存在，则可以设定一个新的口令。\n在您的名字与姓式是什么一项，应当填写CAS Server的域名，否则在后续的单点登录过程中会遇到问题。如果只是用于本地开发测试，则域名可以随意填写，并通过配置hosts的方式使其生效。其他参数可以根据个人情况填写，或者直接跳过。制作成功之后就可以在对应的路径下找到密钥库了。\n其他操作 删除一个entry 从一个keystore中删除某个entry：\n keytool -delete -alias tomcat5 -keystore D:\\keystore 生成一个证书 生成一个自签名的证书：\n keytool -genkey \\ -dname \u0026quot;CN=fingki,OU=server,O=server,L=bj,ST=bj,C=CN\u0026quot; \\ -alias myca \\ -keyalg RSA \\ -keysize 1024 \\ -keystore D:\\keystore \\ -keypass 654321 -storepass 123456 -validity 3650 修改密码 修改密码：\n keytool -genkey -alias duke -keypass dukekeypasswd -keystore D:\\keystore keytool -keypasswd -alias duke -keypass dukekeypasswd -new newpass -keystore D:\\keystore 查看一个keystore中的所有条目  keytool -list -v -keystore D:\\keystore 将keystore中的某条entry导出到一个文件  keytool -export -alias duke -keystore D:\\keystore -rfc -file testkey # 将证书库monitor.keystore中的别名为monitor的证书导出到monitor.cer证书文件中 # 它包含证书主体的信息及证书的公钥，不包括私钥，可以公开 kektool -export -alias monitor -keystore monitor.keystore -file monitor.cer 输入证书到一个新的truststore  # 我觉得这个指令应该是将文件中的证书导入到keystore中 keytool -import -alias dukecert -keystore truststore -file testkey # 想Java默认证书中导入Rapa.cert keytool -import -alias RapaServer -keystore cacerts -file Rapa.cert 其他概念 签署 服务器产生了一个证书之后，用这个证书签署Applet等，以表明这个Applet确实是来源于这个服务器，而不是其他，以实现其真实性，如果你信任这个服务器，那么你就可以信任这个Applet。比如你可以通过jarsigner工具，用keystore中的某个key entry来签署一个jar文件（这个操作我还未进行过）。\nkeytool Keytool可以用来创建数字证书，所有的数字证书是以一条一条（采用别名区分）的形式存入证书库中，证书库中的一条证书包含该证书的私钥、公钥和对应的数字证书的信息。证书的一条证书可以导出数字证书文件，数字证书文件只包含主体信息和对应的公钥。\nKeytool把要是和证书存储到一个keystore中，keystore默认的实现是一个文件，用一个密码保护秘钥（和上面的知识开始印证起来了）。\n证书 一个证书是一个实体的数字签名，还包含这个实体的公共秘钥值。\n公共钥匙：是一个详细的实体的数字关联，并有意让所有想通这个实体发生信任关系的其他实体知道，公共钥匙是用来校验签名的。\n数字签名：是实体信息用实体的私有秘钥签名（加密）后的数据，这条数据可以用这个实体的公共钥匙来检验签名（解密）出实体信息，以鉴别实体的身份（目前是谁拿到了这个证书都可以校验实体是不是自己想要的）。\n私有钥匙：是一些数字，私有和共有钥匙存在所有用公共秘钥加密的系统的钥匙对中。公共钥匙用来加密数据、私有钥匙用来计算签名，公钥加密的信息，只能用私钥解密。私钥签名的消息只能用公钥检验签名。\n实体：一个实体可以是一个人、一个组织、一个程序、一台计算机、一个商业、一个银行，或其他你想信任的东西。\nkeystore 所有的keystore entry（钥匙和信任证书入口）是通过唯一的别名访问的，别名不区分大小写。可以在使用-genkey参数的时候指定别名，也可以使用-import参数加一个证书或证书链到信任证书（这个又是什么概念）。\nkeystore和truststore区别 一个web应用如果需要走https协议，需要一个数字证书，这个证书的配置是在apache的配置文件或者其他web容器的配置文件中进行配置。当然这个可以保存在keystore中。\nkeystore和truststore主要是针对应用本身的需求来的，keystore和truststore从其文件格式来看其实是一个东西，只是为了方便管理将其分开。keystore中一般保存的是我们的私钥，用来加密或者为别人做签名。truststore中保存的是一些可信任的证书，主要是java在代码中访问某个https的时候对访问者进行认证的，以确保其是可信任的（好奇怪的说，访问某个https的时候，对访问这进行认证，应该是被访问者吧）。\ntruststore是必须的，如果我们没有显示地指定，那么java会默认指定为$JAVA_HOME/lib/security/cacerts这个文件（这个知识我也是第一次接触）。可以在java的参数中进行指定：\n -Djavax.net.ssl.keyStore=clientKeys -Djavax.net.ssl.keyStorePassword=password -Djavax.net.ssl.trustStore=clientTrust -Djavax.net.ssl.trustStorePassword=password 参考资料  Keystore密钥库  ","description":"","id":613,"section":"notes","tags":null,"title":"使用keytool生成秘钥对","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/cas/%E4%BD%BF%E7%94%A8keytool%E7%94%9F%E6%88%90%E7%A7%98%E9%92%A5%E5%AF%B9/"},{"content":"这是一篇整理笔记，我很久前就开始使用这个技术了，但是一直没有整理。最近同事需要用，所以我简单整理一下，笔记中需要用到的资料我暂时去整理下载地址了，等以后有时间了，我在详细补充一下这份资料。\n准备二进制文件及K8S配置文件，并配置配置环境变量 如图，准备必要的二进制文件：\n然后配置环境变量，配置后，需要确保在命令行执行ktctl有输出（很基本的常识）。整个过程需要注意一点：不要修改者两个二进制文件的位置，如果你的系统里已经有了kubectl则可以删除kubectl这个二进制文件。因为ktctl中是直接调用kubectl，如果kubectl不在环境变量中，则无法启动。\n下一步是在你的home目录下建一个.kube目录，将kubernetes的config文件放在里面，这个大家都知道，是kubectl用来链接集群的配置文件，包含了用户名、密码，或者token之类的信息。\n启动二进制文件 下一步是在终端（终端需要管理员权限，因为需要修改host文件）运行如下如下指令：\n ktctl --namespace=dev connect --method=socks5 --dump2hosts 这条指令有两层含义：\n 去dump一下host文件， 使用的是socks代理（windows只支持socks代理）  下载Proxifier，并进行配置 如图，我只做了如下简单配置，便可以使用了（我把KT Connection运行在了我Linux服务器上，建议运行在自己本地）：\n我没有采用官网上建议的JVM Inject方案，因为这个方案在Windows上成功率非常的低。\n使用过程中遇到的各种离奇的问题  使用CMD无法dump下host文件（CMD已经在管理员身份下运行），我目前定位了一例是因为host文件设置成只读的了  ","description":"","id":614,"section":"notes","tags":null,"title":"使用KT Connect（探索版）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/%E4%BD%BF%E7%94%A8kt-connect%E6%8E%A2%E7%B4%A2%E7%89%88/"},{"content":"技术研究后发现不符合我的需求，故作废\n使用这个方案的难点是下载LCX模板，如图，找到模板资源：\n如果直接点击下载是非常非常慢的，我这边6个小时都没有下载下来：\n该怎么做了？方案有很多，走透明代理、换模板源、设置代理都可以，我选择的方案是，拿到下载用的url，在我的Windows机器上开代理下载后，在传到PVE中。地址是从下面拿到的：\n上传后如下图：\n最后具体的创建NextCloud容器，我就不整理了，真的非常的简单。我在使用PVE的LCX之前，有尝试过使用Ubuntu、CentOS部署NextCloud都失败，使用LCX是一次性成功的，非常的棒。\n这次也是第一次用PVE的LCX技术，感觉非常的不错，不过貌似PVE使用的不是Docker技术，有时间需要去研究一下，这样以后一些简单的服务，我完全可以使用LCX代替，而不需要自己在虚拟机中部署，哈哈。\n参考资料  【PVE系列】使用Proxmox VE部署自己的私有网盘  ","description":"","id":615,"section":"notes","tags":null,"title":"使用LCX模板安装NextCloud","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E4%BD%9C%E5%BA%9F/%E4%BD%BF%E7%94%A8lcx%E6%A8%A1%E6%9D%BF%E5%AE%89%E8%A3%85nextcloud/"},{"content":"由于Nginx不知道NodePort服务操作的端口转换，后端应用程序负责生成重定向URL，该URL考虑到外部客户端使用的URL，包括NodePort。\n（我现在还不是很清楚该如何处理这个问题）\n","description":"","id":616,"section":"notes","tags":null,"title":"使用NodePort类型时，重定向需要注意的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E4%BD%BF%E7%94%A8nodeport%E7%B1%BB%E5%9E%8B%E6%97%B6%E9%87%8D%E5%AE%9A%E5%90%91%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"  github里下载安装包，并进行安装\n  常用指令：\n   nvm v # 安装最新版的node nvm install latest # 安装指定版本的node nvm install 16.4.0 # 卸载指定版本的node nvm uninstall 16.4.0 # 使用指定版本的nvm nvm use 16.4.0 # 查看已安装的node版本 nvm list 解决nvm下载慢的问题：在程序安装目录下找到settings.txt，添加下面两行：（我没有使用该方案，我使用的方案是为npm设置代理）   node_mirror: https://npm.taobao.org/mirrors/node/ npm_mirror: https://npm.taobao.org/mirrors/npm/ nvm安装路径，及下载的node.js保存路径（两者在同一个路径下）   C:\\Users\\wujj\\AppData\\Roaming\\nvm 小结 nvm技术和Anaconda3好像还不一样，Anaconda3是通过环境变量，让程序永远优先找到用户配置的Python环境，而nvm是在程序安装目录建立一个快捷方式，然后环境变量始终指向这个快捷方式，从而实现不同node.js版本的切换的。\nnvm这种方案对我的影响时，一旦切换了不同的node.js环境，就全局切换成该环境了，你在任意地方使用，都是该版本的node.js，这也包括webstorm（知识点不够准确）。\n我刚发现，似乎不同的版本的node.js会将模块安装在同一个目录，这个是我不想看到的\n参考教程  Windows 下安装 nvm 管理 nodejs 版本  ","description":"","id":617,"section":"notes","tags":null,"title":"使用nvm安装多版本的node.js","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/%E4%BD%BF%E7%94%A8nvm%E5%AE%89%E8%A3%85%E5%A4%9A%E7%89%88%E6%9C%AC%E7%9A%84node.js/"},{"content":"我们一个使用量非常小的小系统，不知道抽什么疯，突然出现了几起并发插入的问题，插入时上锁，好像只能上表锁，表锁会影响其他用户的使用，所以打算用Redis实现一个小小的分布式锁。\n引入依赖如下：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  @Configuration public class RedissonConfig { @Value(\u0026#34;${spring.redis.host}\u0026#34;) private String host; @Value(\u0026#34;${spring.redis.port}\u0026#34;) private Integer port; @Value(\u0026#34;${spring.redis.password}\u0026#34;) private String password; @Value(\u0026#34;${spring.redis.lettuce.pool.max-idle}\u0026#34;) private int maxPoolSize; private String cluster; @Bean public RedissonClient redissonClient() { return loadRedisson(); } public RedissonClient loadRedisson() { RedissonClient redisson; Config config = new Config(); //单节点  if (!StringUtils.isEmpty(host)) { config.useSingleServer(). setAddress(\u0026#34;redis://\u0026#34; + host + \u0026#34;:\u0026#34; + port) .setPassword(StringUtils.isEmpty(password) ? null : password) .setConnectionPoolSize(maxPoolSize) .setDnsMonitoringInterval(-1) //最小空闲连接  .setConnectionMinimumIdleSize(0); } else { //集群节点  String[] nodes = cluster.split(\u0026#34;,\u0026#34;); //redisson版本是3.5，集群的ip前面要加上“redis://”，不然会报错，3.2版本可不加  for (int i = 0; i \u0026lt; nodes.length; i++) { nodes[i] = \u0026#34;redis://\u0026#34; + nodes[i]; } //这是用的集群server  config.useClusterServers() //设置集群状态扫描时间2000  .setScanInterval(2000) .addNodeAddress(nodes) .setPassword(password) .setMasterConnectionPoolSize(maxPoolSize) .setDnsMonitoringInterval(-1) //最小空闲连接  .setMasterConnectionMinimumIdleSize(0); } redisson = Redisson.create(config); return redisson; } public RedissonClient retryGetRedisson() { return loadRedisson(); } }   业务逻辑代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // 根据supplierId、tenantId上锁 RLock lock = redissonClient.getLock(String.format(\u0026#34;SRM:inviteFromMaterialPlatform:%s_%s\u0026#34;, tenantId, supplierId); try { lock.lock(); return inviteInsert.getId(); } finally { if (lock.isLocked()) { lock.unlock(); } }   遇到的问题 因为配置文件中使用了一个奇怪的配置redis://192.168.11.1:2345，而我本机又在使用Proxifier，让我的java.exe流量始终走在代理下，导致这块始终报host解析失败。实际上我代理服务器已经设置了redis的域名解析。最后我解决这个问题的方法是在我们的本机配置hosts。\n","description":"","id":618,"section":"notes","tags":null,"title":"使用redisson的锁","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E4%BD%BF%E7%94%A8redisson%E7%9A%84%E9%94%81/"},{"content":"在Echo的案例中，为什么服务端使用的是ChannelInboundHandlerAdapter，而客户端使用的是SimpleChannelInboundHandler。这个问题和两个因素的相互作用有关：业务逻辑如何处理消息以及Netty如何管理资源。\n在客户端，当channelRead0方法完成时，你已经有了传入消息，并且已经处理完它了。当该方法返回时，SimpleChannelInboundHandler负责释放指向保存该消息的ByteBuf的内存引用。\n在服务端中，你需要将传入的消息回送给发送者（如下代码所示），而write()操作是异步的，知道channelRead()方法返回后可能仍然没有完成。为此，服务端扩展了ChannelInboundHandlerAdapter，其在这个事件点上不会释放消息。\n消息在EchoServerHandler的channelReadComplete()方法中，当writeAndFlush()方法被调用时被释放。\n1 2 3 4 5 6 7 8  @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf in = (ByteBuf) msg; System.out.println(\u0026#34;Server Received: \u0026#34; + in.toString(StandardCharsets.UTF_8)); ctx.write(in); }   对这段讲解不懂的两个点：\n SimpleChannelInboundHandler的channelRead0()方法完成之后，释放ByteBuf的操作我并没有看到 最后为什么说消息在writeAndFlush()方法被调用时被释放，不是很理解ByteBuf被释放的点  ","description":"","id":619,"section":"notes","tags":null,"title":"使用SimpleChannelInBoundHandler还是ChannelInBoundHandler","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E4%BD%BF%E7%94%A8simplechannelinboundhandler%E8%BF%98%E6%98%AFchannelinboundhandler/"},{"content":"之前使用SpringBoot较多，SpringBoot会自动帮忙引入slf4j-api，所以每次使用@Slf4j注解时，log变量都可以正常的使用。但是最近直接起一个Maven项目，加了lombok的依赖，但是没有加slf4j-api的依赖，结果无法使用log.info方法。后来加入了slf4j-api依赖后，该问题修复了。\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.32\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":620,"section":"notes","tags":null,"title":"使用了@Slf4j注解，但是没有引入slf4j-api包","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E4%BD%BF%E7%94%A8%E4%BA%86slf4j%E6%B3%A8%E8%A7%A3%E4%BD%86%E6%98%AF%E6%B2%A1%E6%9C%89%E5%BC%95%E5%85%A5slf4j-api%E5%8C%85/"},{"content":"需求描述 假设企业使用同一个集群作为开发环境和生产环境（注意：通常开发环境和生产环境是物理隔绝的）：\n开发团队期望有一个集群中的命名空间，以便他们可以查看查看和使用他们创建的Pod、Service、Deployment等。在此命名空间中，Kubernetes对象被创建又被删除，为了适应敏捷开发的过程，团队中的许多人都可以在此命名空间内做他们想做的事情。\n运维团队也期望有一个集群中的命名空间，在这里，将有严格的流程控制谁可以操作Pod、Service、Deployment等对象，因为这些对象都直接服务于生产环境。\n实验过程  创建development、production命名空间  1 2 3 4 5 6 7 8  apiVersion:v1kind:Namespacemetadata:name:developmentlabels:name:development  1 2 3 4 5 6 7 8  apiVersion:v1kind:Namespacemetadata:name:productionlabels:name:production  查看集群信息，并为kubectl定义上下文，以便在不同的名称空间中工作。  1 2 3 4 5 6 7 8 9 10 11 12 13 14  kubectl config view # cluster、user均来自kubectl config view kubectl config set-context development \\  --namespace=development \\  --cluster kubernetes \\  --user=kubernetes-admin kubectl config set-context production \\  --namespace=production \\  --cluster kubernetes \\  --user=kubernetes-admin    切换到不同的命名空间   kubectl config use-context development kubectl config current-context 参考资料  命名空间  ","description":"","id":621,"section":"notes","tags":null,"title":"使用命名空间切分集群的实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%AE%9E%E9%AA%8C/%E4%BD%BF%E7%94%A8%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E5%88%87%E5%88%86%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"我在使用自编译的python3执行pyinstaller时遇到了如下问题：\n [root@base launch]# pyinstaller -F launch.py 31 INFO: PyInstaller: 4.3 31 INFO: Python: 3.8.9 62 INFO: Platform: Linux-3.10.0-1160.el7.x86_64-x86_64-with-glibc2.17 62 INFO: wrote /root/Software/launch/launch.spec 63 INFO: UPX is not available. 64 INFO: Extending PYTHONPATH with paths ['/root/Software/launch', '/root/Software/launch'] 67 INFO: checking Analysis 67 INFO: Building Analysis because Analysis-00.toc is non existent 67 INFO: Initializing module dependency graph... 67 INFO: Caching module graph hooks... 72 INFO: Analyzing base_library.zip ... 1333 INFO: Processing pre-find module path hook distutils from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/pre_find_module_path/hook-distutils.py'. 1334 INFO: distutils: retargeting to non-venv dir '/usr/local/python3/lib/python3.8' 3008 INFO: Caching module dependency graph... 3101 INFO: running Analysis Analysis-00.toc 3110 INFO: Analyzing /root/Software/launch/launch.py 3169 INFO: Processing pre-safe import module hook urllib3.packages.six.moves from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/pre_safe_import_module/hook-urllib3.packages.six.moves.py'. 3907 INFO: Processing module hooks... 3907 INFO: Loading module hook 'hook-certifi.py' from '/usr/local/python3/lib/python3.8/site-packages/_pyinstaller_hooks_contrib/hooks/stdhooks'... 3910 INFO: Loading module hook 'hook-_tkinter.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3954 INFO: checking Tree 3954 INFO: Building Tree because Tree-00.toc is non existent 3954 INFO: Building Tree Tree-00.toc 3958 INFO: checking Tree 3958 INFO: Building Tree because Tree-01.toc is non existent 3958 INFO: Building Tree Tree-01.toc 3983 INFO: checking Tree 3984 INFO: Building Tree because Tree-02.toc is non existent 3984 INFO: Building Tree Tree-02.toc 3985 INFO: Loading module hook 'hook-difflib.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3987 INFO: Loading module hook 'hook-distutils.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3993 INFO: Loading module hook 'hook-distutils.util.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 3994 INFO: Loading module hook 'hook-encodings.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4026 INFO: Loading module hook 'hook-heapq.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4028 INFO: Loading module hook 'hook-lib2to3.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4053 INFO: Loading module hook 'hook-multiprocessing.util.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4054 INFO: Loading module hook 'hook-pickle.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-sysconfig.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-xml.etree.cElementTree.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4055 INFO: Loading module hook 'hook-xml.py' from '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks'... 4091 INFO: Looking for ctypes DLLs 4111 INFO: Analyzing run-time hooks ... 4114 INFO: Including run-time hook '/usr/local/python3/lib/python3.8/site-packages/PyInstaller/hooks/rthooks/pyi_rth_multiprocessing.py' 4116 INFO: Including run-time hook '/usr/local/python3/lib/python3.8/site-packages/_pyinstaller_hooks_contrib/hooks/rthooks/pyi_rth_certifi.py' 4120 INFO: Looking for dynamic libraries 4379 INFO: Looking for eggs 4379 INFO: Python library not in binary dependencies. Doing additional searching... Traceback (most recent call last): File \u0026quot;/usr/local/python3/bin/pyinstaller\u0026quot;, line 8, in \u0026lt;module\u0026gt; sys.exit(run()) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/__main__.py\u0026quot;, line 114, in run run_build(pyi_config, spec_file, **vars(args)) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/__main__.py\u0026quot;, line 65, in run_build PyInstaller.building.build_main.main(pyi_config, spec_file, **kwargs) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 737, in main build(specfile, kw.get('distpath'), kw.get('workpath'), kw.get('clean_build')) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 684, in build exec(code, spec_namespace) File \u0026quot;/root/Software/launch/launch.spec\u0026quot;, line 7, in \u0026lt;module\u0026gt; a = Analysis(['launch.py'], File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 242, in __init__ self.__postinit__() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/datastruct.py\u0026quot;, line 160, in __postinit__ self.assemble() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 476, in assemble self._check_python_library(self.binaries) File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/building/build_main.py\u0026quot;, line 581, in _check_python_library python_lib = bindepend.get_python_library_path() File \u0026quot;/usr/local/python3/lib/python3.8/site-packages/PyInstaller/depend/bindepend.py\u0026quot;, line 956, in get_python_library_path raise IOError(msg) OSError: Python library not found: libpython3.8mu.so.1.0, libpython3.8m.so.1.0, libpython3.8m.so, libpython3.8.so.1.0 This would mean your Python installation doesn't come with proper library files. This usually happens by missing development package, or unsuitable build parameters of Python installation. * On Debian/Ubuntu, you would need to install Python development packages * apt-get install python3-dev * apt-get install python-dev * If you're building Python by yourself, please rebuild your Python with `--enable-shared` (or, `--enable-framework` on Darwin) 我执行了如下指令：\n ./configure --prefix=/usr/local/python3 --enable-shared make clean \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 此时执行时，又有如下报错：\n [root@base launch]# pyinstaller -F launch.py /usr/local/python3/bin/python3.8: error while loading shared libraries: libpython3.8.so.1.0: cannot open shared object file: No such file or directory 我观察了Python3编译后的目录结构，发现了libpython3.8.so.1.0文件：\n我觉得很大可能性是make install指令没有将这个文件copy到相应的目录中，我手动完成了该操作：\n cp libpython3.8.so.1.0 /usr/lib64 同样的，因为编译安装的时候我已经设置了环境变量了，这块我不需要进行相应的配置。\n参考资料  Python打包方法——Pyinstaller CentOS下踩坑记录  ","description":"","id":622,"section":"notes","tags":null,"title":"使用自编译Python时执行pyinstaller时遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E4%BD%BF%E7%94%A8%E8%87%AA%E7%BC%96%E8%AF%91python%E6%97%B6%E6%89%A7%E8%A1%8Cpyinstaller%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"今天定位修复了一个比较难的问题。我们的项目将mybatis-plus升级到最新版后，发现了updateByBatch方法无效。最后层层排查下终于定位出这个问题：我们使用的hikari并将auto-commit配置成了false，而当我们使用updateByBatch方法时，有这样的一段逻辑判断：\n1 2 3 4 5 6 7  // PgStatement  if (connection.getAutoCommit()) { flags |= QueryExecutor.QUERY_SUPPRESS_BEGIN; }   这个时候得到的flags中就不包含自动提交的标记位，最终导致我们我们的executeBatch执行的sql最终没有提交。所以只需要将这个配置改为true就可以了。\n整个定位问题的过程发生了一些匪夷所思的问题，部分在定位的过程解决了，部分没有，先记录下来：\n  在同事的电脑上，我们步进的时候发现一行代码没有执行，直接跳过异常部分到了finally，这个很奇怪。以往的经验是我们使用的class文件和我们正在查看的class文件不一致才会导致这个问题，但是同事并没有手动配置class文件，完全是由Idea反编译的class文件。\n  我们使用了p6spy，但是只打印了select的sql语句，并没有打印update的语句（这直接导致我们认为update没有被执行，导致我寻找问题的重心一直是update为什么没有执行）。在定位问题的过程中，我发现，我们执行addBatch和executeBatch时，会直接跳过p6spy的Statement（甚至跳过了hikari的statement），这就是为什么p6spy没有打印执行的sql的原因。\n  还有一个问题，非常的迷惑，我在查看反射的时候，明明看到传入的是一个A的实例（A实例后面会跟一段描述：wrapping xxx），我在A实例的方法中断点，死活无法正常断到，我必须去wraping的实例中进行断点。甚至有些时候我去wrapping实例中断点，也无法成功的断点，我有点怀疑这些wrapping的实例时动态生成的。如果真的是这样，动态生成的实例，简直是调试的魔鬼。当然在这个场景下，我总结了一些定位问题的技巧，稍后会整理一下。\n  这次解决问题的过程中，我收获颇丰，整理如下：\n  学会了调式反射代码。\n  大致了解了MyBatis中整体架构，下次出问题了，知道该如何排查了。\n  因为了解了MyBatis的一些特点，所以我知道在定位问题中，不要被表象迷惑，可以直接在驱动器类上打断点。\n  简单了看了一下我们项目中MyBatis部分的架构，感觉功能挺丰富的，只是我在纠结，定制化过高，会不会不利于升级？\n  这次解决问题的过程中，我也产生了一些新的问题：\n 如果代码时动态生成了，我又该如何进行调试呢？  ","description":"","id":623,"section":"notes","tags":null,"title":"修复updateByBatch无法使用的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E4%BF%AE%E5%A4%8Dupdatebybatch%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我笔记中git和github文件夹，总是默认处于展开状态，我简单分析了一下，可能是作者直接从当前URL中进行分词，然后寻找目录结构，查看哪些目录需要展开。我的笔记发布在github page上，所以git和github目录就默认展开了。\n修复这个问题可以让这个功能从notes/后开始搜索，但是我觉得改js的成本太搞了（代码全部是压缩后的代码），所以我决定将我们目录名改一下。\n","description":"","id":624,"section":"notes","tags":null,"title":"修复Zoc主题自动展开问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/%E4%BF%AE%E5%A4%8Dzoc%E4%B8%BB%E9%A2%98%E8%87%AA%E5%8A%A8%E5%B1%95%E5%BC%80%E9%97%AE%E9%A2%98/"},{"content":"这个问题我之前从未遇到过，先说说我怎么发现这个问题的，我使用Helm安装chart时，发现Release一直处于Pending状态，所以我顺手查看了下nodes信息，发现除了Master节点，其他节点全部都处于NotReady状态。\n我采用如下方案修复了该问题，将所有节点重启，等待Master节点上的Kubectl指令可用（即Master上的服务启动成功）后，然后对所有从节点执行如下指令：\n systemctl restart docker systemctl restart kubelet 我分析是如下原因造成的，Master节点启动太慢了，导致从节点上的kubelet错误了连接时机。如果下次我重启PVE机器时该问题还会复现，我计划设置PVE的虚拟机启动延时。\n参考资料  k8s node节点重启后遇到的问题及解决 安全地清空一个节点  ","description":"","id":625,"section":"notes","tags":null,"title":"修复节点为NotReady的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%BF%AE%E5%A4%8D%E8%8A%82%E7%82%B9%E4%B8%BAnotready%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"修改/etc/kubernetes/manifests/kube-apiserver.yaml文件，在command下增加--service-node-port-range=30000-40000，然后等待api-server重启。\n参考资料  Kubernetes调整nodePort端口范围  ","description":"","id":626,"section":"notes","tags":null,"title":"修改NodePort的范围","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E4%BF%AE%E6%94%B9nodeport%E7%9A%84%E8%8C%83%E5%9B%B4/"},{"content":"我用的指令如下：\n alter table t_common_material alter column color_rgb type jsonb using color_rgb::jsonb; 参考资料  pgSql修改数据类型  ","description":"","id":627,"section":"notes","tags":null,"title":"修改字段类型","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E4%BF%AE%E6%94%B9%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B/"},{"content":"Redis关于AOF有auto-aof-rewrite-percentage和auto-aof-rewrite-min-size。假如用户对Redis设置了配置选项auto-aof-rewrite-percentage 100和auto-aof-rewrite-min-size 64mb，并且启用了AOF持久化，那么当AOF文件的体积大于64MB，并且AOF文件的体积比上一次重写之后的体积大了至少一倍的时候，Redis将执行BGREWRITEAOF命令。\n对于这两个配置，我疑惑的是auto-aof-rewrite-percentage配置，从书中的描述来看，我第一次重写是64mb，第二次重写是128mb，以此类推，直到aof文件已经远远大于内存，那么关于压缩的配置就没有任何意义了。其实我觉得书中的描述是有问题的，这个地方就应该已经为AOF文件的体积为上一次重写一倍的时候，Redis就执行BGREWRITEAOF命令。\n","description":"","id":628,"section":"notes","tags":null,"title":"关于AOF两个配置项的思考","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%85%B3%E4%BA%8Eaof%E4%B8%A4%E4%B8%AA%E9%85%8D%E7%BD%AE%E9%A1%B9%E7%9A%84%E6%80%9D%E8%80%83/"},{"content":" 在1.6以上版本中，您可以选择取消为ServiceAccount自动挂载API凭证，只需在ServiceAccount中设置automountServiceAccountToken: false（我已经进行了相关的实验，可以在相关类目下找到）\n 我设计了如下实验来验证该配置：\n 创建相关资源  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  apiVersion:v1kind:ServiceAccountmetadata:name:nfs-client-provisionernamespace:nfs---apiVersion:v1kind:ServiceAccountmetadata:name:nfs-client-provisioner2namespace:nfsautomountServiceAccountToken:false---apiVersion:v1kind:Podmetadata:name:nginxnamespace:nfslabels:name:nginxspec:serviceAccount:nfs-client-provisionercontainers:- name:nginximage:nginx:1.7.9resources:limits:memory:\u0026#34;128Mi\u0026#34;cpu:\u0026#34;500m\u0026#34;ports:- containerPort:80---apiVersion:v1kind:Podmetadata:name:nginx2namespace:nfslabels:name:nginx2spec:serviceAccount:nfs-client-provisioner2containers:- name:nginx2image:nginx:1.7.9resources:limits:memory:\u0026#34;128Mi\u0026#34;cpu:\u0026#34;500m\u0026#34;ports:- containerPort:80  实验创建了两个ServiceAccount、两个Pod，两个ServiceAccount一个设置了automountServiceAccountToken为false，两个Pod分别指定了这两个ServiceAccount。\n查看ServiceAccount相关的各个资源，发现ServiceAccount和相关的Secret都正确创建。  1 2 3 4  kubectl get sa -n nfs kubectl get secrects -n nfs   查看Pod的yaml格式定义如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # nginxspec:containers:- image:nginx:1.7.9volumeMounts:- mountPath:/var/run/secrets/kubernetes.io/serviceaccountname:kube-api-access-jbxhfreadOnly:truevolumes:- name:kube-api-access-jbxhfprojected:defaultMode:420sources:- serviceAccountToken:expirationSeconds:3607path:token- configMap:items:- key:ca.crtpath:ca.crtname:kube-root-ca.crt- downwardAPI:items:- fieldRef:apiVersion:v1fieldPath:metadata.namespacepath:namespace# nginx2（nginx2没有任何相关的配置）  结论 automountServiceAccountToken配置影响的是创建Pod时是否自动挂载一个可以访问APIServer的Secret。\n","description":"","id":629,"section":"notes","tags":null,"title":"关于automountServiceAccountToken配置的实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%85%B3%E4%BA%8Eautomountserviceaccounttoken%E9%85%8D%E7%BD%AE%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"透明零拷贝 这个零拷贝和我理解的零拷贝其实是两个东西。这个强调的是ByteBuf之间可以通过零拷贝而获取到一个新的ByteBuf，而我理解的零拷贝是内核级别的。\n1 2 3 4 5 6 7 8 9 10  // 复合类型与组件类型是兼容的 ByteBuf message = Unpooled.wrappedBuffer(header, body); // 可以通过混合符合类型与普通缓冲区来创建一个符合类型 ByteBuf messageWithFooter = Unpooled.wrappedBuffer(message, footer); // messageWithFooter.getUnsignedInt(messageWithFooter.readableBytes() - footer-readableBytes - 1);   我现在好奇的是这种符合类型的引用技术是如何处理的，哈哈。\nByteBuf是支持自动扩容的 1 2 3 4 5 6 7 8 9 10 11  ByteBuf b = Unpooled.buffer(4); b.writeByte(\u0026#39;1\u0026#39;); b.writeByte(\u0026#39;2\u0026#39;); b.writeByte(\u0026#39;3\u0026#39;); b.writeByte(\u0026#39;4\u0026#39;); // 当写入的字节数超过初始容量4时，内部缓冲区自动分配具有较大的容量 b.writeByte(\u0026#39;5\u0026#39;);   ","description":"","id":630,"section":"notes","tags":null,"title":"关于BuffByte研究","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E5%85%B3%E4%BA%8Ebuffbyte%E7%A0%94%E7%A9%B6/"},{"content":"问题描述 我们准备使用KT Connect，但是运维配置好了后，发现始终无法正常使用。我按照官方文档给的问题排查手册，发现最终报错为scoat，我自己搭建Istio时也遇到过关于socat的问题，但是当时没有深入研究，故对此理解并不够。\n我暂时依旧没有深入研究这些问题的计划，我计划等我有了稳定的实验环境时在系统研究这部分知识。\n","description":"","id":631,"section":"notes","tags":null,"title":"关于scoat的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%85%B3%E4%BA%8Escoat%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"手动创建ServiceAccount的API Token  如下配置创建资源：  1 2 3 4 5 6 7 8 9 10 11 12 13 14  apiVersion:v1kind:Namespacemetadata:name:practice01---apiVersion:v1kind:ServiceAccountmetadata:name:practice01namespace:practice01  查看各个资源  1 2 3 4 5 6 7  kubectl get sa -n practice01 kubectl get secrets -n practice01 # 此时只引用了一个Secret kubectl describe sa -n practice01   创建一个自定义的ServiceAccount Token  1 2 3 4 5 6 7 8 9 10  apiVersion:v1kind:Secretmetadata:name:practice01-token-customernamespace:practice01annotations:kubernetes.io/service-account.name:practice01type:kubernetes.io/service-account-token  查看各个资源  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  kubectl get sa -n practice01 kubectl get secrets -n practice01 # 此时引用了两个Secret kubectl describe sa -n practice01 # Name: default # Namespace: practice01 # Labels: \u0026lt;none\u0026gt; # Annotations: \u0026lt;none\u0026gt; # Image pull secrets: \u0026lt;none\u0026gt; # Mountable secrets: default-token-87gfr # Tokens: default-token-87gfr # Events: \u0026lt;none\u0026gt; # Name: practice01 # Namespace: practice01 # Labels: \u0026lt;none\u0026gt; # Annotations: \u0026lt;none\u0026gt; # Image pull secrets: \u0026lt;none\u0026gt; # Mountable secrets: practice01-token-sxkxf # Tokens: practice01-token-customer # practice01-token-sxkxf # Events: \u0026lt;none\u0026gt;   为ServiceAccount添加ImagePullSecret  创建一个imagePullSecret  1 2 3 4 5 6 7  kubectl create secret docker-registry practice01-image-pull-secret \\  --docker-server=DOCKER_REGISTRY_SERVER \\  --docker-username=DOCKER_USER \\  --docker-password=DOCKER_PASSWORD \\  --docker-email=DOCKER_EMAIL   我执行了上面的指令后得到如下内容，我比较喜欢使用yaml创建资源，方便笔记，但是该资源好像没有办法使用yaml创建（至少我现在还不了解）。\n需要注意的是Secret资源的type字段，这个字段说明了Secret资源的类型，我已经收集两个案例了。\n1 2 3 4 5 6 7 8 9 10 11 12 13  apiVersion:v1data:.dockerconfigjson:eyJhdXRocyI6eyJET0NLRVJfUkVHSVNUUllfU0VSVkVSIjp7InVzZXJuYW1lIjoiRE9DS0VSX1VTRVIiLCJwYXNzd29yZCI6IkRPQ0tFUl9QQVNTV09SRCIsImVtYWlsIjoiRE9DS0VSX0VNQUlMIiwiYXV0aCI6IlJFOURTMFZTWDFWVFJWSTZSRTlEUzBWU1gxQkJVMU5YVDFKRSJ9fX0=kind:Secretmetadata:creationTimestamp:\u0026#34;2022-01-06T08:28:15Z\u0026#34;name:practice01-image-pull-secretnamespace:nfsresourceVersion:\u0026#34;169211\u0026#34;uid:ab9eee1e-c5a9-4dd6-9f20-bbe2fde2c184type:kubernetes.io/dockerconfigjson  参考资料  ServiceAccount  ","description":"","id":632,"section":"notes","tags":null,"title":"关于ServiceAccount的API Token、ImagePullSecret的实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%85%B3%E4%BA%8Eserviceaccount%E7%9A%84api-tokenimagepullsecret%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"Docker镜像源真的是非常让人头疼的东西，想将它们全部塞到自己的Harbor里，然后实现本地环境的高速拉取！！！\n  让 K8S 在 GFW 内愉快的航行\n  docker拉取镜像太慢的解决办法\n  https://blog.csdn.net/alex_yangchuansheng/article/details/106088715\n这个方案很高大上，如果以后要往这个方向深入发展，需要研究这份资料。\n  国内拉取google kubernetes镜像\n里面提到了镜像同步神器，很感兴趣，但是不知道用于什么场景。除此之外，这篇文章还提到了很多高级的知识，很要研究价值。\n  我思考的一些问题：\n 如果我将我所有K8S结点的Docker镜像源都设置成我的Harbor地址，能不能实现使用kubectl apply -f指令的时候也从我的Harbor里拉取镜像呢？感觉有很多未知的东西等待验证，不过我真的很期待这个方案。  ","description":"","id":633,"section":"notes","tags":null,"title":"关于镜像源的一些方案","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%85%B3%E4%BA%8E%E9%95%9C%E5%83%8F%E6%BA%90%E7%9A%84%E4%B8%80%E4%BA%9B%E6%96%B9%E6%A1%88/"},{"content":"网络存在饱和的可能性，如何在异步框架中高效地写大块数据是一个特殊的问题。由于写操作是非阻塞的，所以即使没有写出所有的数据，写操作也会在完成时返回并通知ChannelFuture。当这种情况发生时，如果仍然不停额写入，就有内存耗尽的风险。所以在写大型数据时，需要准备好处理到远程节点的链接速度是慢速的情况，这种情况会导致内存释放的延迟。\n（额，不是十分理解这个写操作是非阻塞的说法）\n零拷贝发生在Netty的核心中，应用程序需要做的就是使用一个FileRegion的接口实现。\n1 2 3 4 5 6 7 8 9 10 11 12  FileInputStream in = new FileInputStream(file); FileRegion region = new DefaultFileRegion(in.getChannel(), 0, file.length()); channel.writeAndFlush(region).addListener(new ChannelFutureListener(){ @Override public void operationComplete(ChannelFuture future) throws Exception{ if(!future.isSuccess()) { // do something  } } })   在需要将数据从文件系统复制到用户内存中时，可以使用ChunkedWriterHandler，它支持异步写大型数据流，而又不会导致大量的内存消耗。\n","description":"","id":634,"section":"notes","tags":null,"title":"写大型数据","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E5%86%99%E5%A4%A7%E5%9E%8B%E6%95%B0%E6%8D%AE/"},{"content":"下载地址如下：\n  alibaba/kt-connect\n  在 Linux 系统中安装并设置 kubectl\n  ","description":"","id":635,"section":"notes","tags":null,"title":"准备必要的二进制文件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/%E5%87%86%E5%A4%87%E5%BF%85%E8%A6%81%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"},{"content":"先说现象：同事在Develop分支上删除了一些文件，我们将自己的特性分支合并到Develop时，不会感知到这些删除操作，所以没有报冲突，而是当做新文件给直接提交了。我们的特性分支是从Uat分支签出来的，按道理说这种现象应该不存在。\n具体分析的时候，发现如下情况：\n A同事将删除了文件的分支合并到了Develop分支，解决了冲突，并提交了代码。 B同事将自己的特性分支合并到了Uat，解决了冲突，并提交代码，进行发布进行功能验证 B同事将自己在Uat已经验证的分支合并到了Develoop、Sit分支，这个时候没有保任何冲突，同事直接提交 C同事（也就是我）拉Develop最新的分支，合并自己的特性分支，这个时候没有报任何冲突，同事直接提交  事情发生的根源在于B同事将Uat分支合并到Develop时的操作，但是此时，Git也并没有报任何冲突。我目前猜想的原因时，Uat分支已经和Develop分支失去了同步，也就是Develop分支和Uat分支只是某个父节点有关系，而两个分支的Head之间没有任何关系，所以Uat合并到Develop时，被视为了一次极其普通的合并。\n额，其实我们项目分支管理挺乱的，我们虽然有规范，但是没有专门的人负责这块，约束这些东西，所以大家都是按照自己的理解在处理问题。\n简单实验设计  master分支：a.txt child1 from master分支：delete a.txt child2 from master分支：change a.txt 合并child1分支到master 合并child2分支到master  合并时报冲突，提示a.txt被删除，所以，如果操作正确，Git肯定是会发现删除冲突的。\n解决问题时的思路   需要先确保是不是因为Git没有删除冲突的提示，导致我在合并代码时直接合并了。用了上面的小实验，发现Git会进行提示。\n  需要知道是不是删除操作有什么问题，导致跟踪丢失。我用了下面的指令进行查看，发现只要是删除的文件，都查不出来，所以从这个角度解决问题，没有太大的意义。\n   git ls-tree -r master --name-only  对比是否是因为Git命令行没有提示，而Idea的仓库管理工具会提示（同事认为是这样的），经过实验，发现两者的表现是一样的。\n  用git checkout COMMIT_ID直接到某次提交，然后用git merge COMMIT_ID，去复现开发时的操作，看没有提示。（这种操作拓展了我解决问题的思路，也正是这个操作让我发现了问题所在）\n  参考资料  如何让git显示正在跟踪的文件列表？  ","description":"","id":636,"section":"notes","tags":null,"title":"分支逆向提交，导致冲突不可见","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/%E5%88%86%E6%94%AF%E9%80%86%E5%90%91%E6%8F%90%E4%BA%A4%E5%AF%BC%E8%87%B4%E5%86%B2%E7%AA%81%E4%B8%8D%E5%8F%AF%E8%A7%81/"},{"content":"我始终记得我们之前做分页的时候是从零开始的，但是这个可能是我的错觉，因为我本身不是分页接口的消费者，所以我也不知道我开发的接口在被怎么传参（只有除了问题时我才会去关注细节），而且我采用的是模板方式写代码，所以所有的接口表现的都是一样的，消费者也用模板式的方式写代码（前端框架），所以出问题的概率很小，所以也就没有人提过这个问题。\n最近我发现了一些有趣的问题，我使用MyBatis的分页插件时，传入起始页为0和为1表现是一样的，都是查询第一页。我看了源码，是在构建Page对象的时候，只有传入的current大于1（或者零，忘了细节了）时才使用传入的current，否则就使用默认的current值1。\n","description":"","id":637,"section":"notes","tags":null,"title":"分页0和1的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E5%88%86%E9%A1%B50%E5%92%8C1%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我选择的是将自己创建的Actions和源码放在一起，因为这些Actions使用的复用性挺低的，放在一起避免了创建另一个仓库，非常舒服：\n目录结构如下：\n其中Dockerfile文件如下：\n1 2 3 4 5 6 7 8 9 10  FROMalpine:3.10# Copies your code file from your action repository to the filesystem path `/` of the containerCOPY entrypoint.sh /entrypoint.shRUN chmod +x entrypoint.sh# Code file to execute when the docker container starts up (`entrypoint.sh`)ENTRYPOINT [\u0026#34;/entrypoint.sh\u0026#34;]  action.yml文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # action.ymlname:\u0026#39;Hello World\u0026#39;description:\u0026#39;Greet someone and record the time\u0026#39;inputs:who-to-greet:# id of inputdescription:\u0026#39;Who to greet\u0026#39;required:truedefault:\u0026#39;World\u0026#39;outputs:time:# id of outputdescription:\u0026#39;The time we greeted you\u0026#39;runs:using:\u0026#39;docker\u0026#39;image:\u0026#39;Dockerfile\u0026#39;args:- ${{ inputs.who-to-greet }}  entrypoint.sh如下：\n1 2 3 4 5 6 7  #!/bin/sh -l echo \u0026#34;Hello $1\u0026#34; time=$(date) echo \u0026#34;::set-output name=time::$time\u0026#34;   Reademe.md没有太多营养，这儿就不呈现了。\ngithub-actions-demo.yml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  on:[push]jobs:hello_world_job:runs-on:ubuntu-latestname:A job to say hellosteps:- name:Checkoutuses:actions/checkout@v2- name:Hello world action stepid:hellouses:./.github/actions/AdjustPicturesInMDFileswith:who-to-greet:\u0026#39;Mona the Octocat\u0026#39;# Use the output from the `hello` step- name:Get the output timerun:echo \u0026#34;The time was ${{ steps.hello.outputs.time }}\u0026#34;  参考资料   创建 Docker 容器操作\n我参考了官方的案例，但是官方的案例中存在一点小小的错误，所以Dockerfile文件应该参考我的。\n  ","description":"","id":638,"section":"notes","tags":null,"title":"创建Docker Action","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/%E5%88%9B%E5%BB%BAdocker-action/"},{"content":"tunctl 安装tunctl工具 1 2 3 4 5 6 7 8 9 10 11 12  tee /etc/yum.repos.d/nux-misc.repo \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [nux-misc] name=Nux Misc baseurl=http://li.nux.ro/download/nux/misc/el7/x86_64/ enabled=0 gpgcheck=1 gpgkey=http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro EOF yum --enablerepo=nux-misc install tunctl   tunctl [OPTIONS] [ -u owner ] [ -g group ] [ -t device-name ]\n t：指定要创建的tap、tun设备名 g：指定一组用户 u：参数指定用户名，表明这个接口只受该用户控制，这个接口发生的事不会印象到系统的接口  OPTIONS:\n p：创建tap设备，默认创建该设备 n：创建tun设备 b：打印创建的接口名字 d：INTERFACE_NAME：删除指定接口 f：TUN_CLONE_DEVICE：指定tun设备对应的文件名，默认是/dev/net/tun，有些系统是/dev/misc/net/tun  创建、修改、删除该tap接口  创建指令如下   tunctl -p 该指令我执行了多次，分别生成了tap0、tap1、tap2，此时我使用ifconfig查看，是查看不到这些tapX的，当我执行下面的指令，为tap0设置了IP后，可以通过ifconfig查看，这使我想到我在另一篇教程中看到的说明：tapX设备文件会在该设备文件被使用的时候，由相应的驱动程序生成网口设备。\n为接口设置ip地址：   ifconfig tap0 192.168.0.154 up 可以使用如下的方式关闭该接口：   ifconfig tap down 为接口添加路由：   route add -host 192.168.0.1 dev tap0 删除该tap0接口：   tunctl -d tap0 我执行了多次该指令，甚至删除了本应该不存在的tapX，但是其返回值基本都是一样的。\nip taptun  创建tap/tun设备   ip tuntap add dev tap0 mod tap ip tuntap add dev tun0 mod tun 删除tap/tun设备   ip tuntap del dev tap0 mod tap ip tuntap del dev tun0 mod tun 参考资料  CentOS 7 安装tunctl Linux 网络工具详解之 ip tuntap 和 tunctl 创建 tap/tun 设备  ","description":"","id":639,"section":"notes","tags":null,"title":"创建自己的tap、tun设备（待深入研究）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%BE%85%E7%A0%94%E7%A9%B6/%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84taptun%E8%AE%BE%E5%A4%87%E5%BE%85%E6%B7%B1%E5%85%A5%E7%A0%94%E7%A9%B6/"},{"content":"我按教程简单的体验了一下JWT，我没有走完整的JWT流程，只走了一下加密部分，我的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  public class JWTUtils { private static final SystemProperties systemProperties = new SystemProperties(); public static String signature(Header header, Payload payLoad) throws Exception { switch (systemProperties.getEncryptionAlgorithm()) { case AES: /* 我疑惑的点：我看示意图，是需要对header和payload各自进行base64加密的 然后对加密结果用点号链接起来，然后再用 */ return AESUtils.encrypt( String.format(\u0026#34;%s.%s\u0026#34;, Base64.getEncoder().encodeToString(JSON.toJSONString(header).getBytes(StandardCharsets.UTF_8)), Base64.getEncoder().encodeToString(JSON.toJSONString(header).getBytes(StandardCharsets.UTF_8))), systemProperties.getPrivateKey()); case SM3: case SM4: default: throw new RuntimeException(\u0026#34;未准备的加密方式\u0026#34;); } } public static String token(Header header, Payload payLoad) throws Exception { return String.format(\u0026#34;%s.%s.%s\u0026#34;, Base64.getEncoder().encodeToString(JSON.toJSONString(header).getBytes(StandardCharsets.UTF_8)), Base64.getEncoder().encodeToString(JSON.toJSONString(payLoad).getBytes(StandardCharsets.UTF_8)), signature(header, payLoad)); } public static void main(String[] args) throws Exception { Header header = Header.builder() .alg(\u0026#34;HS256\u0026#34;) .typ(\u0026#34;JWT\u0026#34;) .build(); Payload payload = Payload.builder() .id(\u0026#34;100\u0026#34;) .name(\u0026#34;zhangsan\u0026#34;) .phone(\u0026#34;13579246810\u0026#34;) .expire(\u0026#34;200\u0026#34;) .build(); System.out.println(token(header, payload)); } }   参考资料   简单代码实现JWT(json web token)完成SSO单点登录\n  jwt.io\n  ","description":"","id":640,"section":"notes","tags":null,"title":"初次体验JWT","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/jwt/%E5%88%9D%E6%AC%A1%E4%BD%93%E9%AA%8Cjwt/"},{"content":"需求太少了，不再维护\nC盘炸了，只剩下3G了，我基本不在C盘装任何东西，经同时提示发现是hiberfil.sys、pagefile.sys、swapfile.sys文件占用太大空间，这些文件没有什么价值，可以清理掉。\n清理hiberfil.sys 打开cmd工具，执行powercfg -h off，然后去删除hiberfil.sys文件（此时hiberfil.sys就消失了）\n调整pagefile.sys文件的大小 截图如下：\n（这一步需要点击一下当前页面上的设置按钮，然后再点确认按钮，我之前的截图忘记操作这一步，让人很迷惑，退回到高级页面没有任何效果）\n至于swapfile.sys，我暂时懒得管了，C盘已经腾出来不少空间了~\n参考资料   hiberfil.sys 可以删吗？【C盘清理】\n  如何删除pagefile.sys\n  ","description":"","id":641,"section":"notes","tags":null,"title":"删除hiberfil.sys","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E5%88%A0%E9%99%A4hiberfil.sys/"},{"content":"这项技术用于开发一些自动化脚本：\n1 2 3 4 5 6 7  if [ -z \u0026#34;$(git status --porcelain)\u0026#34; ]; then # Working directory clean else # Uncommitted changes fi   参考资料   从脚本确定Git工作目录是否干净\n这篇文章中还有一些其他技术的应用，比如忽略未跟踪的文件，因为我目前没有需求，故不关注这些技术了。\n  linux shell:判断git工作文件夹是否干净(clean)\n这篇文章中也有相关技术的讨论，我没有实践。\n  ","description":"","id":642,"section":"notes","tags":null,"title":"判断工作区是否干净","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/%E5%88%A4%E6%96%AD%E5%B7%A5%E4%BD%9C%E5%8C%BA%E6%98%AF%E5%90%A6%E5%B9%B2%E5%87%80/"},{"content":"我没有打算用DockerCompose，直接使用指令的方式也挺简单的。\n机器环境  系统CentOS 7.9 两块硬盘，一块装系统，一块挂载在/data目录下  网络环境  # 创建自定义bridge docker network create ToolNet # 将已有的容器链接到创建的网络（我没有使用该指令） docker network connect ToolNet [容器名称] # 查看网络信息 docker network inspect ToolNet MySQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 准备配置文件 mkdir -p /root/Software/Configuration/MySQL/conf tee /root/Software/Configuration/MySQL/conf/my.cnf \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 [mysqld] sql-mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION character-set-server=utf8mb4 EOF # 启动Docker sudo docker run -d \\  --restart always -p 3306:3306 \\  --name mysql57 \\  --network ToolNet \\  -v /root/Software/Configuration/MySQL/conf/my.cnf:/etc/mysql/my.cnf \\  -v /data/MySQL/logs:/logs \\  -v /data/MySQL/data:/var/lib/mysql \\  -e MYSQL_ROOT_PASSWORD=HelloWorld \\  mysql:5.7.34   MongoDB 这个配置的细节处我还是不太了解，但是现在先这么搞着，方便使用\n docker run -d \\ --restart always -p 27017:27017 \\ --name mongodb \\ --network ToolNet \\ -v /data/MongoDB:/data/backup \\ -e MONGO_INITDB_ROOT_USERNAME=root \\ -e MONGO_INITDB_ROOT_PASSWORD=HelloWorld \\ mongo:4.4.6 docker run -d \\ --restart always -p 8081:8081 \\ --name mongodb-express \\ --network ToolNet \\ -e ME_CONFIG_MONGODB_SERVER=\u0026quot;mongodb\u0026quot; \\ -e ME_CONFIG_BASICAUTH_USERNAME=\u0026quot;junjie\u0026quot; \\ -e ME_CONFIG_BASICAUTH_PASSWORD=\u0026quot;junjie\u0026quot; \\ -e ME_CONFIG_MONGODB_ADMINUSERNAME=\u0026quot;root\u0026quot; \\ -e ME_CONFIG_MONGODB_ADMINPASSWORD=\u0026quot;HelloWorld\u0026quot; \\ mongo-express:0.54.0 YApi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  mkdir -p /root/Software/Configuration/YApi/conf tee /root/Software/Configuration/YApi/conf/config.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;port\u0026#34;: \u0026#34;3000\u0026#34;, \u0026#34;adminAccount\u0026#34;: \u0026#34;junjie2025@gmail.com\u0026#34;, \u0026#34;timeout\u0026#34;:120000, \u0026#34;db\u0026#34;: { \u0026#34;servername\u0026#34;: \u0026#34;mongodb\u0026#34;, \u0026#34;DATABASE\u0026#34;: \u0026#34;yapi\u0026#34;, \u0026#34;port\u0026#34;: 27017, \u0026#34;user\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;pass\u0026#34;: \u0026#34;HelloWorld\u0026#34;, \u0026#34;authSource\u0026#34;: \u0026#34;admin\u0026#34; } } EOF docker run -it \\  --restart always \\  --network ToolNet \\  --entrypoint npm \\  --workdir /yapi/vendors \\  -v /root/Software/Configuration/YApi/conf/config.json:/yapi/config.json \\  registry.cn-hangzhou.aliyuncs.com/anoyi/yapi \\  run install-server docker run -d \\  --name yapi \\  --network ToolNet \\  --workdir /yapi/vendors \\  -p 3000:3000 \\  -v /root/Software/Configuration/YApi/conf/config.json:/yapi/config.json \\  registry.cn-hangzhou.aliyuncs.com/anoyi/yapi \\  server/app.js   可选操作，删除builder容器，这个好像没有什么用\n docker container rm -f boring_faraday 最后登录YApi时的账号密码为：junjie2025@gmail.com、ymfe.org\nEasyYApi 使用如下我自己开发Dockerfile，为什么要使用我自己的仓库了，是因为官方提供的仓库中的package.json中有个插件的版本会导致Bug，需要升级一下。但是我没有找到通过命令行方式升级某个插件版本的方法，所以就自己fork的了一个仓库。\n我对我这份Dockerfile还挺满意，我计划将YApi的安装也通过这种自己编辑Dockerfile的方式实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  FROMnode:12-alpine as builderWORKDIR/easyyapiRUN apk add --no-cache gitRUN git clone https://github.com/junjie2018/yapi-markdown-render.git .RUN npm installFROMnode:12-alpineENV TZ=\u0026#34;Asia/Shanghai\u0026#34;WORKDIR/easyyapiCOPY --from=builder /easyyapi /easyyapiEXPOSE3001ENTRYPOINT [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;3001\u0026#34;]  使用如下指令，构建该镜像，并启动该镜像\n docker build -t yapi-markdown-render:v1 . # 我还没测试，因为我测试Dockerfile时，该服务已经启动起来了，我懒得重搞，哈哈 docker run -d \\ --name yapi-markdown-render \\ --network ToolNet \\ -p 3001:3001 \\ yapi-markdown-render:v1 PostgresSQL  sudo docker run -d \\ --restart always -p 5432:5432 \\ --name postgres13 \\ --network ToolNet \\ -v /data/PostgresSQL:/var/lib/postgresql/data \\ -e POSTGRES_PASSWORD=HelloWorld \\ postgres:13.3-alpine 踩坑记录  我之前有这么一行配置：  这行配置的意思是说，将容器的/var/lib/mysql目录挂载到主机的目录上，我在抄写的时候，少了一层目录，导致无法无法正常启动数据库。\n相关教程 MySQL教程   docker 安装 mysql5.7\n  MySQL5.7 启动报错:initialize specified but the data directory has files in it. Aborting.\n  Docker自定义网络和运行时指定IP\n  Docker容器间通信方法\n非常重要的教程，在这篇教程里学会了自定义网络的使用。\n  MongoDB教程   Docker 下的 MongoDB + Mongo-Express 环境搭建\n学习了四个账号密码环境变量的配置。\n  Docker搭建MongoDB\n  学习了-v /mnt/mongo/backup:/data/backup配置，但是并不是太满意\n  学习了docker exec mongo sh -c 'exec var=date +%Y%m%d%H%M \u0026amp;\u0026amp; mongodump -h localhost --port 27017 -u test -p test1 -d dbname -o /data/backup/$var_test1.dat'，实际使用中，没有满足我的需求\n    官方Mongo镜像说明\n  官方MongoExpress镜像说明\n  Docker 安装 MongoDB\n  YAPI教程   顶尖 API 文档管理工具 (YAPI)\n我主要参考的是这个教程。\n  官方GitHub\n  使用docker安装yapi\n顶尖 API 文档管理工具 (YAPI)\nRyan-Miao/docker-yapi\nfjc0k/docker-YApi\nsilsuer/yapi\njayfong/yapi\nfjc0k/docker-YApi\n基本只是参考，并没有走这个方案。\n  EasyYApi资料  官方：easyyapi/yapi-markdown-render 我改的：junjie2018/yapi-markdown-render Markdown配置部分资料 使用 Dockerfile 定制镜像  PostgreSQL教程   Docker安装PostgreSQL\n  DockerHub PostgreSQL文档\n  ","description":"","id":643,"section":"notes","tags":null,"title":"利用Docker快速启动开发环境","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%88%A9%E7%94%A8docker%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"content":"我们的项目中有这样的一个需求：我们存在oss中的数据，仅记录其相对位置，但是当我们将这些数据返回给前端的时候，我们需要将这些相对位置转换成带有签名鉴权等信息的url。我们之前是如何处理这个问题的呢？当我们的数据从数据库查查来后，将这个数据转换成JSONObject或者JSONArray，然后一个一个字段的处理（拿出来，处理后，放回去）。\n我不是很满意这种处理方法，感觉代码量非常的大，而且非常的不优雅，所以我开发了如下的工具：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  public class OSSTagUtils { public static \u0026lt;T\u0026gt; T tagByJsonPaths(T target, Class\u0026lt;T\u0026gt; clazz, String[] jsonPaths) { // todo 研究一下能不能提升JSONPath的性能  // todo 寻找性能更高的的jsonPath框架  // todo 完善工具的边界检查  if (jsonPaths.length == 0) { return target; } // 这种写法是因为已有的Bean深拷贝工具对Map类型支持并不是很好，所以不如转换成JSONObject处理  JSONObject toDispose = (JSONObject) JSON.toJSON(target); for (String jsonPath : jsonPaths) { if (JSONPath.contains(toDispose, jsonPath)) { Object jsonPathValue = JSONPath.eval(toDispose, jsonPath); if (!(jsonPathValue instanceof String)) { throw new RuntimeException(\u0026#34;该jsonPath指向的值不为字符串类型\u0026#34;); } String accessUrl = OssUtil.storage.getAccessUrl(\u0026#34;\u0026#34;, (String) jsonPathValue); JSONPath.set(toDispose, jsonPath, accessUrl); } } return toDispose.toJavaObject(clazz); } }   从设计的角度来说，我这个工具还不是非常的强大，我仅对jsonPath指向的字段的值是String时才进行处理，而且我还没有考虑传入的jsonPath定位到一个字符串时如何处理。但是的但，这个工具目前是符合我自己的需求的，倘若我之后有其他的需求，我可以添加上相关的代码。\n过度设计和实现，价值意义并不大。\n参考资料  JsonPath - 根据表达式路径解析Json jsonpath - 使用 JSONPath 解析 JSON 完整内容详解 fastJson 之 JSONPath使用  ","description":"","id":644,"section":"notes","tags":null,"title":"利用JSONPath简化工作","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/%E5%88%A9%E7%94%A8jsonpath%E7%AE%80%E5%8C%96%E5%B7%A5%E4%BD%9C/"},{"content":"我这儿只描述一下思路，具体的操作是可以在我Postman类目下找到的。\n快速调试接口，分为两个主要的场景：\n 新开发的接口 调试Chrome的Network中报错的接口  新开发的接口  Postman针对登录开发相应的Pre-request Script，使登录完成后，自动将token等信息保存到各个环境，及全局环境变量中 EasyYapi设置Postman的token，这样在Idea中导出接口时，在postman中可以立即看到 EasyYapi修改一些配置，这样可以导出接口时自动添加Pre-request Script脚本。 顺着这个方向研究，最终可以实现导出的接口，立即可调用  调试Chrome的Network中报错的接口  在Network中，针对报错接口，右键选择copy as curl 在Postman中导入该curl，然后就可以直接请求该curl 如果环境变量设计的好的话，修改请求的前缀，及可实现在不同环境中调用该请求  ","description":"","id":645,"section":"notes","tags":null,"title":"利用Postman快速调试接口","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/%E6%96%B9%E6%A1%88/%E5%88%A9%E7%94%A8postman%E5%BF%AB%E9%80%9F%E8%B0%83%E8%AF%95%E6%8E%A5%E5%8F%A3/"},{"content":"应用场景是这样的。我秉承的信念是，入库时每个字段都是需要被精细控制，所以我往往需要写一大堆setXXX方法，该工具就可以我快速生成这些代码：\n1 2 3 4 5 6 7 8 9 10 11  public static void main(String[] args) { for (Field field : FormPo.class.getDeclaredFields()) { System.out.println(String.format(\u0026#34;.%s(tmp.get%s())\u0026#34;, field.getName(), StringUtils.capitalize(field.getName()))); } }   有时间我会继续完善的。\n20210617后续：\n最近用Builder比较多，有时间改一下这个。\n","description":"","id":646,"section":"notes","tags":null,"title":"利用反射填充VO对象","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%88%A9%E7%94%A8%E5%8F%8D%E5%B0%84%E5%A1%AB%E5%85%85vo%E5%AF%B9%E8%B1%A1/"},{"content":"应用场景是这样的，你已经定义好的Request接受前端传递的参数，现在你需要测试下你的接口，你需要快速的生成一个可以被当前Request接受的json，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public static void main(String[] args) { for (Field field : PostFormRequest.class.getDeclaredFields()) { if (field.getType().equals(String.class)) { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%s\\\u0026#34;,\u0026#34;, field.getName(), \u0026#34;测试数据\u0026#34; + new Random().nextInt(100))); } else if (field.getType().equals(Integer.class)) { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%d\\\u0026#34;,\u0026#34;, field.getName(), new Random().nextInt(100000))); } else { System.out.println(String.format(\u0026#34;\\\u0026#34;%s\\\u0026#34;:\\\u0026#34;%s\\\u0026#34;,\u0026#34;, field.getName(), field.getType())); } } }   目前的这个我还不是太满意，我会花时间再优化这个工具的。\n","description":"","id":647,"section":"notes","tags":null,"title":"利用反射生成请求体","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%88%A9%E7%94%A8%E5%8F%8D%E5%B0%84%E7%94%9F%E6%88%90%E8%AF%B7%E6%B1%82%E4%BD%93/"},{"content":"用户完成了表单编排后，得到的是一个编排文件，这份文件说明了组件如何渲染，同时也说明了如何校验数据（需要考虑生成两份文件么）。\n","description":"","id":648,"section":"notes","tags":null,"title":"前后端数据校验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%89%8D%E5%90%8E%E7%AB%AF%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/"},{"content":"基础概念 组件 我不是很擅长阐述一个东西，所以我截取了金数据中我认为应该是一个组件的截图：\n同样的，在我们的项目中，如下截图也应该为一个组件：\n考虑到我们项目目前的动态表单的需求，我在第一阶段准备开发如下组件：\n 文本输入框（前后端支持非空、长度、整数、小数、小数位数、数范围校验） 单选下拉框（前后端支持非空、值是否属于正确范围校验） 多选下拉框（前后端支持非空、值是否属于正确范围校验） 二级联动下拉框（前后端支持非空、值是否属于正确范围校验） 三级联动下拉框（前后端支持非空、值是否属于正确范围校验）  数据源 数据源是个什么东西呢？单选下拉框需要显示一些下拉项，目前的常规实现方法大概有两种：一种是前端写死在代码中，一种是从服务端获取。\n在我的方案中，这些数据都将从服务端获取（避免过度设计，同时便于用户理解，可以在看完所有设计后再讨论这个问题），我们将这些提供下拉项数据的接口称做数据源。我们通过为同一个组件切换不同的数据源，从而可以使这个组件显示不同的下拉项。\n当然，我既然已经提到了数据源的概念，那么可想而知，我们一定是对提供数据的接口进行了一定的包装。我会将这些东西体现在我的详细设计中。\n检查器 前端在用户完成一个文本框的数据后，需要进行检查。后端在入库后，同样也需要进行输入检查；不同的数据源应该也搭配不同的输入检查器，如何实现统一呢？\n针对常规的检查（及不需要与服务端进行交互的检查），前后端各自独立的进行检查，只需要相同输入检查结果一致即可。针对需要与服务端进行交互的检查，我们通过检查源的概念实现服务端和前端检查方式统一。\n针对常规的检查，检查源就是一段正则表达式；针对与服务端交互的检查，我们的检查源其实是一个接口，前后端的处理逻辑相同，都是将数据按照这个接口声明的方式传递给这个接口，从而实现校验效果。\n同样的，检查器也是对提供检查功能的Url的包装，具体细节，我会体现在我的详细设计中。\n高级概念 rawData 为什么会有rawData概念的存在呢？想一想，我们将所有的下拉项都通过后端的接口提供了，后端的工作量有多大？如果用户需要临时调整某个下拉项里的项，我们至少还得为他修改配置文件，从而实现这个改动，这样实在是太低效了。\n我推出了rawData的概念，rawData就是一段json，用户将json提交到后台，我们解析这段json，判断这个json的结构是否符合我们的预设，如果属于的话，我们将自动为用户生成相应的数据源和检查器。因为我目前的设计是针对公司内部用户的，我不会假设我的用户不理解什么是json（如果不理解，我觉得我应该有办法教会他）。\n用户可以随时修改rawData，这些修改会立即体现到各个表单上。当然修改json影响到了数据结构是不允许的，除非目前没有表单正在使用当前的rawData生成的数据源。\n如果未来我们的动态表单将会面向普通用户，我是支持开发一个简单的rawData编辑器的，我无所谓，因为对我后端来说我都是存rawData，并且自动生成rawData数据源和rawData检查源。有时候用户体验真的很重要，我会在阶段三后将该功能纳入开发计划。\n这一期我支持的rawData结构有：\n # 适用于简单的下拉框 [\u0026quot;\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;\u0026quot;] # 适用于二级联动的下拉框 { \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[], \u0026quot;\u0026quot;:[], } # 适用于三级联动的下拉框 { \u0026quot;\u0026quot;:{ \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] }, \u0026quot;\u0026quot;:{ \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] \u0026quot;\u0026quot;:[] } } rawData数据源 rawData就是在用户提交了json后，自动生成的接口（其实不是接口，而是一个通用的接口可以出相应的rawData数据，会体现在详细设计中）及相应的数据库记录。这个东西的存在，是为了简化开发任务的，同时为了能够快速相应用户的需求。\nrawData检查器 rawData检查器同rawData数据源。\n表单上下文 表单上下文，存在的价值是什么呢？是为了实现组件间的联动，假如一个只声明了一个属性的组件，却绑定了需要两个参数的数据源，这个意味着什么呢？意味着我们的这个组件根本就无法提供足够的参数去查询这个组件需要的数据，那我们该如何处理呢？我们需要从表单的上下文，再获取一个参数，然后绑定到这个数据源的参数上。哈哈，其实这就实现了联动的效果。\n实际上，我做了很多便于理解的设计，让我们的组件复用性提高，这就是表单上下文存在的价值，通过表单上下文，我们能够实现组件间的联动。\n组件上下文 为什么我又提出了组件上下文的概念呢？组件上下文中只包含当前组件声明的属性，这主要是为了方便用户为数据源绑定参数。这些我都会在设计细节上体现。\n系统整体构成 系统整体由这些部分构成：\n数据源接口、检查器接口、rawData数据源接口、rawData检查器接口 各个服务提供数据源、检查源的接口，这个是很好理解的。rawData数据源和检查源接口，这个也是很好理解的，就是一个接口，用户传递什么参数，我们就返回什么值。\n检查器管理系统 叫做管理系统，实际上是开玩笑的，它仅仅就是用来包装这些检查器接口的页面，我将检查器分为了三种类型：\n rawData检查器：就是有rawData自动生成的检查器（向检查器表插入了记录）。 基础检查器：就是一些可以通过正则完成检查的检查器。 定制检查器，就是需要和服务端进行交互的检查器。  接口请求数据，往往是需要传递参数的，所以我们我们的检查器同样有参数的概念。我简单的设计的添加检查器的页面如下：\n检查器管理系统是高度服务于开发人员的，所以我需要测试无处不在，故我为每条条目设计了如下的选项卡：\n另外，检查器接口的错误码需要高度定制化，我发现我们目前的系统没有一套优雅的、全局的错误码处理方案，这个对我来说非常的尴尬，我必须想办法处理好这个问题。\n检查器管理系统可以新增、查看管理器，删除、修改、都必须在管理器未被使用的情况下进行。另外值得说明的是，检查器管理系统应该只有开发具有权限操作。\n数据源管理系统 数据源管理系统和检查器管理系统几乎一致，我这儿不想再赘述了。\n属性库、名词库 这个是为了国际化的\n组件库 这个也是为了方便我们开发调试的。同时也可以向用户展示我们组件库的效果。\n表单设计器 这个是重中之中\nrawData管理系统 单纯的一个json数据管理系统，其实没有多复杂的。\n","description":"","id":649,"section":"notes","tags":null,"title":"动态表单基础概念","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"content":"该工作安排，是在我的动态表单设计思路下实现的。\n阶段一：可配置组件的实现  **（已完成）**组件选择：选择一部分高使用频率的组件，最好能囊括目前的所有需求，作为实现配置化的目标（需要充分分析这些组件的需求）。 数据结构设计：后端负责收集整理这些组件的数据需求，针对这些组件设计数据结构 数据源，检查源的设计与实现：后端按照数据结构的设计，完成数据源、检查源设计与实现工作（Demo版） 组件设计：按照数据源、检查源的思路，设计组件伪代码，并与前端评审可行性，直到可行（可由前端主导） 按照数据源、检查源的思路，实现可配置的组件，并演示组件的可配置性（One By One）。 总结、优化，反复迭代，直到选择的组件的可配置化能够满足生产需求。  阶段二：表单编排的实现  设计表单编排产物的数据结构，评审这个数据结构是否满足表单渲染的需求。 前端设计并实现表单渲染器，并验证该表单渲染器能否完成表单渲染工作。 总结、优化，反复迭代，表单渲染器能够满足生产需求。 在生产中实践该表单渲染器，实践可配置化组件，确保能够在生产环境中正常工作（需要精心选择生产环境，确保实验开发的组件能满足需求）。  阶段三：组件库、属性库、表单编排器的设计与开发工作  这部分工作已经是尾声了，目标是将我们前面硬编码的组件配置、表单数据结构通过Web应用实现。  ","description":"","id":650,"section":"notes","tags":null,"title":"动态表单开发计划","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E5%BC%80%E5%8F%91%E8%AE%A1%E5%88%92/"},{"content":"万能表单的设计 说先说明下：我的设计是面向内部用户的，我想的更多的是：如何在多租户场景下，开发人员如何快速开发配置表单。至于用户使用的简易版，本身是开发人员使用的版本的一个子集，可以在思路成型后进行设计。\n我最想解决的问题是：在已经具备相关组件后，前端能够零代码实现一个表单的渲染。\n我觉得这个问题不能从属性的角度开始思考，实现一个表单是复杂的，表单中不单单是简单的文本输入框，还可能存在拥有复杂联动关系的组件，最简单的案例就是二级联动的下拉框。二级联动的下拉框，每个框的输入值都为我们需要的属性的值，我们现在的设计方案如何描述这种约束，如何解决这个需求呢？从属性的角度去设计，我没有找到比较好的方案。\n我的思路 我提出来的解决问题的思路是什么呢，是组件级别的复用。说明白我的设计思路前，需要先谈谈我对组件的理解。我认为组件就是一段交互逻辑，我们没有办法避免产品设计出新的交互逻辑，但是我们需要想办法提高这些交互逻辑的复用性。\n如何提交复用性呢，将数据和逻辑剥离。前端在设计一个表单的时候，是没有任何业务假设的，他只知道自己要什么样的数据，渲染出什么样的结果。比如二级联动的下拉框，在开发这个组件的时候，前端只知道自己需要一个List、一个Map，至于这两个集合来自哪儿，是无所谓的，可能来自服务器，可能是用户提供的固定List。前端拿到这两个集合，他就知道了当用户选择了第一个框的时候，第二个框的预选值就确认了。\n在开发一个组件的时候，是有可能存在对表单中其他字段依赖的，比如开发一个动态渲染某些字段的表单，他会根据用户选择的类目，渲染出不同的表单出来。我们也需要将这些数据剥离出来，前端告诉组件的使用着，你需要提供这个字段，组件的使用者会指定一个表单中已经存在的字段，交给组件使用（我会在我的案例中说明这个问题）。\n目前我就总结出了三种数据源：一是渲染字段的名字，这个需要我们绑定我们的属性；二是表单中的其他字段；三是从服务器获取的值。我认为为一个表单提供这三种数据，就能够实现交互逻辑的复用。\n我设计的案例（Version 1） 我举了一个二级联动组件的案例：这个需求是这样的，用户需要在其他组件中选择一个品牌，我们的组件需要根据这个品牌所属的国家，然后在一个二级组件中选择这个品牌所在地（这个案例是专门设计的，不代表真实存在这个需求）\n于是前端开发了一个二级联动的组件，他将这个组件的描述（这个描述不是最终版，是方便讲解版）：\n 组件ID： COMPONENT_001 组件属性： province city 组件表单上下文输入： brand 组件服务器输入： 服务器输入一： 输入名称：brand_info 请求参数：brand 返回值格式：{ \u0026quot;country\u0026quot;:\u0026quot;CountryName\u0026quot; } 服务器输入二： 输入名称：province_infos 请求参数：country 返回值格式：{ [\u0026quot;AProvince\u0026quot;,\u0026quot;BProvince\u0026quot;,\u0026quot;CProvince\u0026quot;,\u0026quot;DProvince\u0026quot;] } 服务器输入三： 输入名称：city_infos 请求参数：province 返回值格式：{ [ \u0026quot;AProvince\u0026quot;:[], \u0026quot;BProvince\u0026quot;:[], \u0026quot;CProvince\u0026quot;:[], \u0026quot;DProvince\u0026quot;:[] } 前端怎么使用他索取的这些数据呢？他首先会将用拿到的属性渲染出两个文本输入框，然后监听表单中brand值的变化，一旦发生了变化，就使用brand_info配置的请求，去服务器获取当前brand所属的国家（当然，在实现上服务端可以选择当焦点在第一个文本框上时再去获取这些信息），然后再利用返回的值，调用第二个请求获取到省份信息，然后渲染第一个文本框的下拉框。在第二个文本框的值被选定后，前端又会用第一个文本框的值，调用第三个请求，去获取省份信息。\n这种实现需要多次与服务端交互，肯定不是最佳的实现方案，但是这个是完全取决于前端怎么实现自己组件的。\n现在我们在做表单编排的时候，我们又该怎么做呢？我们提供如下一份文件，就能够指导页面渲染出该组件。\n 组件ID： COMPONENT_001 组件属性： province：（绑定到我们属性库中的province属性） city：（绑定到我们属性库中的city属性） 组件表单上下文输入： brand：context.brand（context代表表单上下文） 组件服务器输入： brand_info：anta-material/getBrandInfo province_infos：anta-material/getProvinceInfos city_infos：anta-material/getCityInfoMap 当然，服务端是需要开发自己的Controller的，而且这些Controller接受的参数必须为组件要求的参数。\nOkay，经过上面的工作，我们已经能够指导我们的页面渲染出一个我们想要的组件了，这个组件做逻辑时需要的所有数据我们也提供给他了。这个组件在提交数据时也会根据我们绑定的属性，提交到我们指定字段上（我其实在这块还有一些别的设计，但是不太成熟，所以就不提了）。\n我设计的案例（Version 2） 上面的案例因为命名的原因导致这个组件用在其他场景并不是那么好理解，我们对它进行如下调整：\n 组件ID： COMPONENT_001 组件属性： property1 property2 组件表单上下文输入： in1 组件服务器输入： 服务器输入一： 输入名称：context_info_url 请求参数：context_param 返回值格式：{ \u0026quot;context_return\u0026quot;:\u0026quot;ContextReturn\u0026quot; } 服务器输入二： 输入名称：first_inputbox_url 请求参数：context_info_url_return 返回值格式：{ [\u0026quot;AAA\u0026quot;,\u0026quot;BBB\u0026quot;,\u0026quot;CCC\u0026quot;,\u0026quot;DDD\u0026quot;] } 服务器输入三： 输入名称：second_inputbox_url 请求参数：first_input 返回值格式：{ [ \u0026quot;AAA\u0026quot;:[], \u0026quot;BBB\u0026quot;:[], \u0026quot;CCC\u0026quot;:[], \u0026quot;DDD\u0026quot;:[] } 调整后可能不是太好理解，所以前端需要提供充分的文档说明。类似于后端的YAPI，前端也需要组件库之类的东西，用于展示自己的组件，这个后面会谈到。\n接下来我们演示两种不同场景中使用该组件，第一个还是刚才的案例：\n 组件ID： COMPONENT_001 组件属性： property1：（绑定到我们属性库中的province属性） property2：（绑定到我们属性库中的city属性） 组件表单上下文输入： in1：context.brand（context代表表单上下文） 组件服务器输入： context_info_url：anta-material/getBrandInfo first_inputbox_url：anta-material/getProvinceInfos second_inputbox_url：anta-material/getCityInfoMap 第二个案例的需求为：我们需要一个二级联动组件，这个组件需要根据之前组件选择的性别信息来为当前用户选择居住的楼层及房间（我随便编的，为了套这个组件）。\n 组件ID： COMPONENT_001 组件属性： property1：（绑定到我们属性库中的floor属性） property2：（绑定到我们属性库中的room属性） 组件表单上下文输入： in1：context.sex（context代表表单上下文） 组件服务器输入： context_info_url：（我们不提供这个值，需要组件支持不提供该值） first_inputbox_url：anta-material/getFloorInfo second_inputbox_url：anta-material/getCityInfo 这个需求在使用这个组件的时候，需要充分了解这个组件如果不提供context_info_url时是如何处理的。嗯，我问过开发，开发说如果不传递context_info_url值的话，他会将in1获取的值当做first_inputbox_url请求参数。\n我的期待   如果这个方案可行，我希望我们能有个组件库的东西。在组件库里，前端开发的组件先通过mock接口跑起来，然后配上该组件输入信息的描述，当然还可以带上一些其他功能，比如开发将自己生成的数据放在这块来试下组件能跑起来不。总之组件库是肯定有存在必要性的。\n  如果可行，我们也开发一个表单编排器，拖一拖拽一拽就能搞出一张表单。组件的输入需求，我们可以用数据源、表单上下文的概念呈现给用户，至于属性，就是我们的属性库中的属性。\n  哪些好处   前端将注意力集中于组件的开发、管理，而不是一整个表单的。\n  开发流程上前端开发组件、自己提供mock接口测试，后端开发接口，然后进行测试，当一个组件变得非预期的时候，可能很快的知道问题出现在哪。\n  我暂时就想到这些。\n哪些不足   样式的问题，如果这个方案实施，可能我们需要统一我们表单的页面的样式，这样组件适用性就比较强。如果开发组件的时候，将样式也剥离出来，或许也会有些别的收获。\n  关于属性关系部分，我还没有花功夫去设计。如何与表单编排绑定，我也没去设计这些细节。\n  前端目前的框架可能实现不了目前的这些需求，因为这套方案基本设计了一套自己的数据结构。前端可能需要开发表单渲染框架。\n  后端也是有付出的，之前有针对性开发组件的时候，后端可以找一个现成的结构，直接甩给前端，现在不行了，前端成主导了，我们需要针对前端提出的数据结构需求出数据。\n  还有很多细节需要设计，这些设计关于到前后端开发万能表单的规范。\n  还需要继续收集需求，确保方案能覆盖全部的需求。\n  ","description":"","id":651,"section":"notes","tags":null,"title":"动态表单的设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E6%80%9D%E8%B7%AF%E6%96%87%E6%A1%A3%E6%95%B4%E7%90%86/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"content":" 应用从无到有（开发通用版即演示版功能）   鞋楦男女 鞋楦码数 鞋楦长度   应用用户从无到有（从演示版到用户定制版）\n  添加属性的工作由谁来完成\n  各个不同的企业对同一个属性有不同的约束怎么办\n  安踏：鞋楦男女：值为男、女\n耐克：鞋楦男女：值为男人、女人\n必须要满足这个需求，因为需要和用户的报表一致\n 通用版本身也是一个企业，通用版具备如下特殊性：   属性表中的字段的任何改变，会自动同步到关联表中    属性的约束如何实现 同一个属性在不同的企业有不同的约束如何实现  属性的约束：\n  输入范围\n  输入数字\n  输入格式\n  单位是什么\n  不允许为空（这个应该数据表单的吧）\n  为什么初始化是复制东西。\n  系统属性、业务属性全都是我们公司的，用户主要关注业务属性，系统属性是不会给客户看到的（系统属性高度与组件等绑定，细节处还没有设计）。我们不会主动将A企业的业务属性暴露给B企业，除非我们已经充分评估，认为这个业务属性就是一个大家都可以用的业务属性。但是B企业添加了一个和A企业同特征的业务属性时，我们可能会关联到同一个业务属性（目前特征相同定义为中文、英文名相同）。\n  我们之所以热衷于将一些企业定制的业务属性，变成一个通用的业务属性，是为了让我们的通用版更强大，更符合绝大多数用户的需求。换句话说，就是当一个新的用户需要使用我们的系统时，他可以做更少的工作，就定制出他想要的效果。同样，将一个业务属性通用了，有利用企业间的交流，觉一个例子，A企业的属性，B企业可以呈现出自己字段名称。\n  如果不是出于这个目标的话，我认为业务属性完全是可以各个公司管理各个公司自己的。\n  关联表中特殊的需求：\n 修改自定义中英文 修改属性值的约束    添加数据的流程大概为：\n   属性表中检索是否具备同样特征的属性 存在相同特征的属性性：关联表中进行企业与顺序性的关联，将企业的个性化配置保存在关联表中 不存在相同特征的属性时：在属性表中插入一条记录，在关联表中进行企业与属性的关联，将企业的个性化配置保存在关联表中  属性值的约束有哪些：\n[]\n{\n\u0026ldquo;us\u0026rdquo;:[]\n\u0026ldquo;cn\u0026rdquo;:[]\n}\n{\n}\n","description":"","id":652,"section":"notes","tags":null,"title":"动态表单需求收集（一）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E9%9C%80%E6%B1%82%E6%94%B6%E9%9B%86%E4%B8%80/"},{"content":"当我感觉我有动态调整日志等级的需求时，我发现SpringBoot Actuator天然支持这种功能，进一步研究，我发现了SpringBoot Admin对SpringBoot Actuator进一步包装，提供了更友好的界面。但是SpringBoot Admin的定位不仅仅在于日志等级动态调整，且启用该功能需要每个服务都配置Admin Server，我并不是很满意这一点。\nSpringBoot Admin局限性在于在调整logger等级时比较好用，在其他方面，我还没有发现什么特色。至于监控、查看Bean信息等，这些功能使用的频率并不高。如果只是为了调整logger等级，我比较热衷于开发一个小脚本实现。\n如果SpringBoot Admin可以调整为用户主动添加式的，就是我启动一个Admin Server，然后我将我的一个服务地址给到它，它自动去请求数据，然后渲染服务相关的信息，如果我不需要它帮我监控了，我直接删除这个服务就好了。那么，我还是会选择Spring Boot Admin，并将这个工具作为我的工具箱之一。\n无意间看到了美团团队关于这个问题的讨论，他们是在超高并发场景下讨论动态调整日志等级的重要性，并开发了自己的框架，而且他们还考虑到RestFul服务和纯RPC服务对该功能的需求。我们的产品目前没有超高并发的需求，而且我们也不存在纯RPC服务。我打算收集这些资料，并持续关注着，至于我目前的需求，我还是打算找一款更简单的工具或者直接通过脚本实现。\n资料收集  Spring Boot 2动态修改日志级别 日志级别动态调整——小工具解决大问题 junjie2018/dynamic_adjust_log_level  ","description":"","id":653,"section":"notes","tags":null,"title":"动态调整日志等级","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E6%97%A5%E5%BF%97%E7%AD%89%E7%BA%A7/"},{"content":"公司开新项目，我参考以往的代码起了一个项目，项目启动很成功，但是请求时报如下错误：\n我们开发了相应的拦截器，负责解析请求中传递的token，将token中的信息塞到属性中（当且仅当请求不通过网关直接请求服务时）。但是从如上报错信息中可以看出我们的拦截器并没有起到作用。在我们的拦截器UserInfoInterceptor中打上断点，结果发现请求确实没有进入我们的拦截器。\n观察以往项目，发现我们的新项目结构和以往的包结构是有出入的，以往的项目包结构为com.abc.project，而新项目为com.abc.project.server，新项目想较以往的项目多了一层包结构。然后一些奇奇怪怪的原因，就导致我们的包无法被扫描到，从而无法加载UserInfoInterceptor到SpringBean中。\n后来我将我们的启动类改为如下配置，该问题恢复了。\n我对这个问题做了一些分析，com.sdstc.pdm.server包是肯定会被自动扫描到的，com.sdstc.core包是无法被自动扫描到，实际上com.sdstc.pdm.server也确实被自动扫描到了，而com.sdstc.core没有。想要实现com.sdstc.core包被自动扫描到，我们可以通过开发starter实现这个效果。\n","description":"","id":654,"section":"notes","tags":null,"title":"包扫描位置指定错误，导致无法进入自定义Intercepter","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E5%8C%85%E6%89%AB%E6%8F%8F%E4%BD%8D%E7%BD%AE%E6%8C%87%E5%AE%9A%E9%94%99%E8%AF%AF%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95%E8%BF%9B%E5%85%A5%E8%87%AA%E5%AE%9A%E4%B9%89intercepter/"},{"content":"报错如下（这个报错不是我场景中的报错）：\n Installing GitBook 3.2.3 /home/travis/.nvm/versions/node/v12.18.3/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 if (cb) cb.apply(this, arguments) ^ TypeError: cb.apply is not a function at /home/travis/.nvm/versions/node/v12.18.3/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 at FSReqCallback.oncomplete (fs.js:169:5) The command \u0026quot;gitbook install\u0026quot; failed and exited with 1 during . 我采用的方案：\n cd /usr/lib/node_modules/gitbook-cli npm i graceful-fs@4.1.4 --save cd /usr/lib/node_modules/gitbook-cli/node_modules/npm npm i graceful-fs@4.1.4 --save 我觉得node.js是我一生之敌，各种各样的问题太多了！！！\n参考资料  Gitbook build stopped to work in node 12.18.3  ","description":"","id":655,"section":"notes","tags":null,"title":"升级Node到V14后，gitbook-cli无法正常运行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/%E5%8D%87%E7%BA%A7node%E5%88%B0v14%E5%90%8Egitbook-cli%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C/"},{"content":"因为需要升级内核的原因，将CentOS的软件包也一起升级了一下，升级后发现无法正常的安装K8S集群了。\n执行systemctl status kubelet有如下输出：\n ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /usr/lib/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since Tue 2022-02-15 22:51:17 EST; 6s ago Docs: https://kubernetes.io/docs/ Process: 22267 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE) Main PID: 22267 (code=exited, status=1/FAILURE) Feb 15 22:51:17 node1 systemd[1]: kubelet.service: main process exited, code=exited, status=1/FAILURE Feb 15 22:51:17 node1 systemd[1]: Unit kubelet.service entered failed state. Feb 15 22:51:17 node1 systemd[1]: kubelet.service failed. 执行``有如下输出：\n Feb 15 22:57:10 node1 kubelet[3467]: Flag --network-plugin has been deprecated, will be removed along with dockershim. Feb 15 22:57:10 node1 kubelet[3467]: Flag --network-plugin has been deprecated, will be removed along with dockershim. Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.087929 3467 server.go:446] \u0026quot;Kubelet version\u0026quot; kubeletVersion=\u0026quot;v1.23.3\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.088067 3467 server.go:874] \u0026quot;Client rotation is on, will bootstrap in background\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.089873 3467 certificate_store.go:130] Loading cert/key pair from \u0026quot;/var/lib/kubelet/pki/kubelet-client-current.pem\u0026quot;. Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.090757 3467 dynamic_cafile_content.go:156] \u0026quot;Starting controller\u0026quot; name=\u0026quot;client-ca-bundle::/etc/kubernetes/pki/ca.crt\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.121338 3467 server.go:693] \u0026quot;--cgroups-per-qos enabled, but --cgroup-root was not specified. defaulting to /\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.121801 3467 container_manager_linux.go:281] \u0026quot;Container manager verified user specified cgroup-root exists\u0026quot; cgroupRoot=[] Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122098 3467 container_manager_linux.go:286] \u0026quot;Creating Container Manager object based on Node Config\u0026quot; nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:docker CgroupsPerQOS:tr Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122685 3467 topology_manager.go:133] \u0026quot;Creating topology manager with policy per scope\u0026quot; topologyPolicyName=\u0026quot;none\u0026quot; topologyScopeName=\u0026quot;container\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122700 3467 container_manager_linux.go:321] \u0026quot;Creating device plugin manager\u0026quot; devicePluginEnabled=true Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122724 3467 state_mem.go:36] \u0026quot;Initialized new in-memory state store\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122784 3467 kubelet.go:313] \u0026quot;Using dockershim is deprecated, please consider using a full-fledged CRI implementation\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122806 3467 client.go:80] \u0026quot;Connecting to docker on the dockerEndpoint\u0026quot; endpoint=\u0026quot;unix:///var/run/docker.sock\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.122826 3467 client.go:99] \u0026quot;Start docker client with request timeout\u0026quot; timeout=\u0026quot;2m0s\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.128300 3467 docker_service.go:571] \u0026quot;Hairpin mode is set but kubenet is not enabled, falling back to HairpinVeth\u0026quot; hairpinMode=promiscuous-bridge Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.128489 3467 docker_service.go:243] \u0026quot;Hairpin mode is set\u0026quot; hairpinMode=hairpin-veth Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.135699 3467 docker_service.go:258] \u0026quot;Docker cri networking managed by the network plugin\u0026quot; networkPluginName=\u0026quot;cni\u0026quot; Feb 15 22:57:10 node1 kubelet[3467]: I0215 22:57:10.141221 3467 docker_service.go:264] \u0026quot;Docker Info\u0026quot; dockerInfo=\u0026amp;{ID:7NE4:QRQ2:ICIH:N556:WNAB:MT6E:YOZM:UPVH:45JC:MVQG:47KQ:KG6L Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:7 Driver Feb 15 22:57:10 node1 kubelet[3467]: E0215 22:57:10.141257 3467 server.go:302] \u0026quot;Failed to run kubelet\u0026quot; err=\u0026quot;failed to run Kubelet: misconfiguration: kubelet cgroup driver: \\\u0026quot;systemd\\\u0026quot; is different from docker cgroup driver: \\\u0026quot;cgroupfs\\\u0026quot;\u0026quot; Feb 15 22:57:10 node1 systemd[1]: kubelet.service: main process exited, code=exited, status=1/FAILURE Feb 15 22:57:10 node1 systemd[1]: Unit kubelet.service entered failed state. Feb 15 22:57:10 node1 systemd[1]: kubelet.service failed. 核心信息在于 kubelet cgroup driver: \\\u0026quot;systemd\\\u0026quot; is different from docker cgroup driver: \\\u0026quot;cgroupfs\\\u0026quot;\n执行如下指令（我默认情况下没有/etc/docker/daemon.json文件，所以我可以使用下面的指令，如果已经存在该文件了，则需要将exe-opts添加到daemon.json中）：\n1 2 3 4 5 6 7  sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt; EOF { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } EOF   参考资料  【kubeadm初始化报错】failed to run Kubelet: misconfiguration: kubelet cgroup driver: \u0026ldquo;cgroupfs\u0026rdquo; is different from docker cgroup driver: \u0026ldquo;systemd\u0026rdquo;   ","description":"","id":656,"section":"notes","tags":null,"title":"升级软件包后，无法正常的安装Kubernetes","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%8D%87%E7%BA%A7%E8%BD%AF%E4%BB%B6%E5%8C%85%E5%90%8E%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E7%9A%84%E5%AE%89%E8%A3%85kubernetes/"},{"content":"  writeInbound：将入站消息写到EmbeddedChannel中。如果可以通过readInbound()方法从EmbeddedChnnel中读取数据，则返回true。\n  readInbound：从EmbeddedChannel中读取一个入站消息。任何返回的东西都穿越了整个ChannelPipeline。如果没有任何可供读取的，则返回null。\n  writeOutbound：将出站消息写到EmbeddedChannel中。如果现在可以通过readOutbound()方法从EmbeddedChannel中读取到什么东西，则返回true。\n  readOutbound：从EmbeddedChannel中读取一个出站消息。任何返回的东西都穿越了整个ChannelPipeline。如果没有任何可供读取的，则返回null。\n  finish：将EmbeddedChannel标记为完成，并且如果有可被读取的入站数据或者出站数据，则返回true。这个方法还会调用EmbededChannel上的close方法。\n  我觉得EmbeddedChannel已经有点和我的直觉有点冲突了。我以为EmbeddedChannel是为了他替换底层的Channel，然后我们往其中写入一个数据，从而触发pipeline中的ChannelInboundHandler，进而触发各个业务逻辑，最终业务逻辑会往Channel中写一些数据，然后我们获取这些数据，即可以完成一个单元测试，但是实际情况好像不是这样的。\n","description":"","id":657,"section":"notes","tags":null,"title":"单元测试","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"content":"因为时间不是很充裕，且每天的精力有限，我估计这个开发战线会被拉的非常的长。所以我这儿简单的制定一下计划，每日按部就班的完成各种学习、实验和设计等。\n  实现文件自由拖动和防止\n我不会管我最终的数据结构是怎样的，我就只是单纯的完成这个效果。完成这个目标时，我并不在乎最终的数据结构，我只在乎自己是否掌握了相关的开发方法。\n  实现界面效果，开发出一个界面来。\n  ","description":"","id":658,"section":"notes","tags":null,"title":"博客插件开发计划","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E5%8D%9A%E5%AE%A2%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E8%AE%A1%E5%88%92/"},{"content":"普通的参数，直接使用@param就可以了，如果@param是一个普通类型，但是其含义数据某个枚举，可以使用如下的写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  /** * * * @param typeId {@link com.sdstc.mcl.common.enums.MaterialTypeEnum#value} */ @PassToken @GetMapping(\u0026#34;/selectInfos/getSelectInfos\u0026#34;) public ResponseVo\u0026lt;SelectInfosData\u0026gt; createMaterialType( @RequestParam(\u0026#34;typeId\u0026#34;) String typeId, @RequestParam(value = \u0026#34;language\u0026#34;, required = false) String language) { }   我还没看官方文档有没有什么更优雅的解决方案，哈哈。\n","description":"","id":659,"section":"notes","tags":null,"title":"参数上的注解如何处理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/easyyapi/%E5%8F%82%E6%95%B0%E4%B8%8A%E7%9A%84%E6%B3%A8%E8%A7%A3%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86/"},{"content":"我创建OpenWRT模板时，同时考虑到这个模板作为主路由和作为旁路由，所以，我为其配置了两个网卡。在进行旁路由实验时，我已经按照经验配置了所有的项，结果始终无法正常的测试。最后我猜测了是因为双网卡的原因导致的，删除一个网卡后，能正常实验。\n20220219后续：\n也就是说，配置旁路由时，要确保不能拥有两个网卡。\n","description":"","id":660,"section":"notes","tags":null,"title":"双网卡时配置透明代理，测试不成功","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E5%8F%8C%E7%BD%91%E5%8D%A1%E6%97%B6%E9%85%8D%E7%BD%AE%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%B5%8B%E8%AF%95%E4%B8%8D%E6%88%90%E5%8A%9F/"},{"content":"定位这个问题差不多花了我半个小时，所以有必要将其记录下来，我在开发我的工具包，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @Data public class TableRoot { private String tblName; private String tblDesc; private List\u0026lt;ColumnRoot\u0026gt; columns; public TableRoot(String tblName, String tblDesc) { this.tblName = tblName; this.tblDesc = tblDesc; this.columns = new ArrayList\u0026lt;\u0026gt;(); } @Data @SuppressWarnings(\u0026#34;WeakerAccess\u0026#34;) public static class ColumnRoot { private String colName; private String colDesc; @JSONField(deserializeUsing = JavaTypeCodec.class, serializeUsing = JavaTypeCodec.class) private JavaType javaType; } }   我在反序列化json文件时，返现columns的值始终为空，而tblName和tblDesc的值正常，这种情况以往从未发生过。后来我发现是因为我TableRoot缺少默认的构造函数，这个还是蛮坑的。\n如果去分析fastjson的源码，我可以肯定我能清晰的知道背后的原因，但是现在实在是没有必要这么去做，哈哈。\n","description":"","id":661,"section":"notes","tags":null,"title":"反序列化时缺少默认构造函数导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/fastjson/%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%97%B6%E7%BC%BA%E5%B0%91%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"因为我是PVE内部的一个虚拟机做为主路由，导致我进行主路由实验时尝尝会导致我网路崩坏，最终无法访问到PVE的管理界面，最终导致我实验难以进行。\n所以我就想将每个网口都配置成管理网口，一旦主路由蹦了，我就可以通过点对点访问管理界面。我的配置如下：\n但是在实践中，一旦主路由关闭了或者崩溃了，我是没有办法通过非192.168.31.2接口访问管理界面的。在ping的实验中，显示的也多为超时。\n我是这么分析的，请求应该是到了PVE机器的，但是因为PVE默认网卡用的是192.168.31.2那张，所以响应请求的报文发给了192.168.31.2，导致我在其他网口收不到消息。\n我猜想，如果我不设置成/24网段，而是更近一步，设置到/25/26，或许这个问题是可以解决的。但是我不确定这样会不会影响到我主路由的IP地址分配。\n","description":"","id":662,"section":"notes","tags":null,"title":"同网段的多网卡为何不能实现多网口管理","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E5%90%8C%E7%BD%91%E6%AE%B5%E7%9A%84%E5%A4%9A%E7%BD%91%E5%8D%A1%E4%B8%BA%E4%BD%95%E4%B8%8D%E8%83%BD%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BD%91%E5%8F%A3%E7%AE%A1%E7%90%86/"},{"content":"使用场景是这样的，我们要将本地的数据库导入到阿里的数据库中，如果通过shell执行这个导入工作，可能会因为shell链接中断，导致导入工作失败，所以想到了这个方案。\n我已经忘记了实施效果了。这个是很久前收藏的文档。\n20210615后续：\n现在看一看，我似乎有很多方案实现这种效果。\n参考资料  MySQL后台执行SQL导入  ","description":"","id":663,"section":"notes","tags":null,"title":"后台执行MySQL导入","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/mysql/%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8Cmysql%E5%AF%BC%E5%85%A5/"},{"content":"报错内容如下：\n open /run/flannel/subnet.env: no such file or directory 参考资料  open /run/flannel/subnet.env: no such file or directory  ","description":"","id":664,"section":"notes","tags":null,"title":"启动Pod时因为flannel报错","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%90%AF%E5%8A%A8pod%E6%97%B6%E5%9B%A0%E4%B8%BAflannel%E6%8A%A5%E9%94%99/"},{"content":"类似PostConstructor、PreDestroy等，我一直在代码中使用，但是我从来没有系统的去学习和调节它们，这次看到了，刚好一起整理一下。\n@PostConstructor、@PreDestroy JSR250规定了两个注解：\n @PostContructor：在bean创建完成并且属性赋值完成，来执行初始化方法 @PreDestroy：在容器销毁bean之前通知我们进行清理工作  在@Bean中指定initMethod和destroyMethod 代码如下：\n1 2 3  @Bean(initMethod = \u0026#34;init\u0026#34;, destroyMethod = \u0026#34;destroy\u0026#34;)   Bean实现InitializingBean和DisposableBean InitializingBean：定义初始化逻辑\nDisposableBean：定义销毁逻辑\n开发BeanPostProcesor bean的后置处理器，在bean初始化前后进行一些处理工作。\n这个后置处理器会在每个bean注入到容器时都调用一次，开发者可以通过名称、实例等判断出自己需要进行处理的bean，然后进行处理。\n","description":"","id":665,"section":"notes","tags":null,"title":"四种方式管理Bean的生命周期","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%AE%A1%E7%90%86bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"content":"纯粹整理一下，感觉实战意义不大。\n  包扫描+组件标注注解（@Controller、@Service、@Repository等）\n  @Bean导入第三方包里面的组件\n  @Import快速给容器中导入一个组件\n  @Import(要导入到容器中的组件)：id默认为全类名\n  @Import(ImportSelector的实现类)：返回需要导入的组件的全类名数组\n  @Import(ImportBeanDefinitionRegister的实现类)：手动注册bean到容器中\n    使用Spring提供的FactoryBean\n  后续：\n收集了一段有趣的代码，在SpringBoot中用的可能会比较少，但是有时候想快速测一些东西时，还是可以用到的。\n1 2 3 4 5 6  AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); applicationContext.register(XXXConfiguration.class); applicationContext.refresh();   ","description":"","id":666,"section":"notes","tags":null,"title":"四种方式给Spring容器注入组件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%BB%99spring%E5%AE%B9%E5%99%A8%E6%B3%A8%E5%85%A5%E7%BB%84%E4%BB%B6/"},{"content":"我在CentOS上，通过在github上下载release包的方式安装了hugo，但是安装后无法启动，报如下错误：\n [root@base junjie.com]# hugo server --minify --theme book --bind=\u0026quot;0.0.0.0\u0026quot; hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by hugo) 我解决了一阵子，没有什么优雅、方便、快捷、易于理解的解决方案，遂放弃了，转而在Ubuntu上研究hugo。\n解决这个问题的心得就是，以后新东西的研究还是在Ubuntu上搞吧，在CentOS上往往需要花费大量的时间。\n","description":"","id":667,"section":"notes","tags":null,"title":"因为centos依赖文件太旧，而无法启动hugo","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/%E5%9B%A0%E4%B8%BAcentos%E4%BE%9D%E8%B5%96%E6%96%87%E4%BB%B6%E5%A4%AA%E6%97%A7%E8%80%8C%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8hugo/"},{"content":"其实我之前研究过\u0026lt;relativePath/\u0026gt;，这个标签貌似是说从库中去寻找依赖，但是我当时理解的并不是很深入，知道我今天踩了这个坑。\n我项目结构如下：\n parent: sub pom.xml pom.xml 我在sum目录写了如下的\u0026lt;parent\u0026gt;：\n1 2 3 4 5 6 7 8  \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.sdstc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;srm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt;   结果无法执行mvn clean指令，报如下错误：\n [ERROR] [ERROR] Some problems were encountered while processing the POMs: [FATAL] Non-resolvable parent POM for com.sdstc:srm-common:1.0-SNAPSHOT: Failure to find com.sdstc:srm:pom:1.0-SNAPSHOT in http://192.168.20.9:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of maven-public has elapsed or updates are forced and 'parent.relativePath' points at no local POM @ line 5, column 13 @ [ERROR] The build could not read 1 project -\u0026gt; [Help 1] [ERROR] [ERROR] The project com.sdstc:srm-common:1.0-SNAPSHOT (C:\\Users\\wujj\\Desktop\\projects\\srm\\srm-common\\pom.xml) has 1 error [ERROR] Non-resolvable parent POM for com.sdstc:srm-common:1.0-SNAPSHOT: Failure to find com.sdstc:srm:pom:1.0-SNAPSHOT in http://192.168.20.9:8081/repository/maven-public/ was cached in the local repository, resolution will not be reattempted until the update interval of maven-public has elapsed or updates are forced and 'parent.relativePath' points at no local POM @ line 5, column 13 -\u0026gt; [Help 2] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/UnresolvableModelException Process finished with exit code 1 去掉\u0026lt;relativePath/\u0026gt;后恢复正常。\n","description":"","id":668,"section":"notes","tags":null,"title":"因为relativePath导致项目内依赖失败","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E5%9B%A0%E4%B8%BArelativepath%E5%AF%BC%E8%87%B4%E9%A1%B9%E7%9B%AE%E5%86%85%E4%BE%9D%E8%B5%96%E5%A4%B1%E8%B4%A5/"},{"content":"不知道是什么时候开始的，SNAPSHOT无法deploy到我们的仓库里，我使用如下代码将SNAPSHOT更改为了Release版本：\n mvn versions:set -DnewVersion=1.1.0 20211025后续：\n今天又遇到这个问题了，哈哈\n参考资料   maven批量修改版本号\n  Maven常见报错原因及解决方案\n我从这篇教程中得到了一点解决该问题的思路。\n  ","description":"","id":669,"section":"notes","tags":null,"title":"因为使用了SNAPSHOT，导致无法deploy","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E5%9B%A0%E4%B8%BA%E4%BD%BF%E7%94%A8%E4%BA%86snapshot%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95deploy/"},{"content":"如图，我Idea编辑器中无运行按钮：\n当我注释掉一个类后，运行按钮恢复了：\n很奇怪的现象，之前没有注意到存在这个问题。\n参考资料  关于引入com.sun.org.apache.xpath.internal.operations.String后右键RUN选项消失  ","description":"","id":670,"section":"notes","tags":null,"title":"因为引入了错误的类，导致main方法无运行按钮","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%9B%A0%E4%B8%BA%E5%BC%95%E5%85%A5%E4%BA%86%E9%94%99%E8%AF%AF%E7%9A%84%E7%B1%BB%E5%AF%BC%E8%87%B4main%E6%96%B9%E6%B3%95%E6%97%A0%E8%BF%90%E8%A1%8C%E6%8C%89%E9%92%AE/"},{"content":"现象如下，每次右键reimport后，在右侧的maven选项卡中都看不到相应的依赖：\n这个问题非常的难查，因为Idea没有报任何错误，我最后打开了Idea的日志，发现了spring-security-oauth2-autoconfigure没有写入版本号，导致了这个错误：\n修改该问题后，maven选项卡可以正常的出现Dependencies：\n","description":"","id":671,"section":"notes","tags":null,"title":"因为没有写Version，导致Idea无法正常导入依赖","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E5%9B%A0%E4%B8%BA%E6%B2%A1%E6%9C%89%E5%86%99version%E5%AF%BC%E8%87%B4idea%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96/"},{"content":"因为我的脚本会生成SUMMARY.md和Reademe.md，所以我一致认为gitbook init操作是没有意义的（其实我至今仍然认为这个操作没有任何意义），所以我选择直接使用gitbook build指令，结果发现我的折叠等插件根本没有生效。这个问题对我来说非常严重，如果笔记不能够折叠，看上就会有点乱糟糟的。\n我花费了一个晚上定位修复这个问题，最后定位到了gitbook init操作上。gitbook init操作做了什么，目前我认为它主要生成了SUMMARY.md和README.md文件，而之所以我没有运行gitbook init导致我插件失效的原因就是，我的脚本是在Windows上开发的，我的SUMMARY.md生成的时候使用的是Windows的分割符，而gitbook貌似不支持这种分割符。\n以往之所以能够成功，我觉得这里面更多的是运气吧，可能我运气好执行了gitbook init，又或者我的SUMMARY.md文件和gitbook init生成的几乎一致，所以导致我一直没有意识到这个问题。\n后续：\n这个问题可能没有我想象的这么简单，我又进行了一些尝试，如果我项目里原本没有READEME.md和SUMMARY.md则运行gitbook init后生成的SUMMARY.md也是空的（我需要再次验证这个问题），只有当我的项目里有SUMMARY.md时，gitbook init才会打印一些奇怪的create的日志信息（不是很理解这个日志信息）。\n我是真的很想换掉gitbook了，node.js的版本问题就像魔鬼一样，我永远都不知道该使用哪个版本？现在gitbook暴漏出太多我无法理解的问题，需要靠无数次尝试才能够解决的问题，加之GitBook构建速度实在是太慢了，加之官方已经没有对GitBook Cli工具进行维护了。我现在真的挺想放弃GitBook。\n","description":"","id":672,"section":"notes","tags":null,"title":"因为没有执行git init导致折叠插件不生效","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/%E5%9B%A0%E4%B8%BA%E6%B2%A1%E6%9C%89%E6%89%A7%E8%A1%8Cgit-init%E5%AF%BC%E8%87%B4%E6%8A%98%E5%8F%A0%E6%8F%92%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88/"},{"content":"我们的项目是多租户的，所以同事自定义了MyBatis的拦截器，在该拦截器中获取请求头中传递过来的租户Id，然后注入到所有的SQL中，其具体实现方式我暂时没有研究（我暂时没有计划去系统研究MyBatis-Plus）。\n问题在于使用该方案后，会导致如下的代码无法正常执行：\n1 2 3 4 5 6 7 8 9 10 11  @Mapper public interface ProjectMapper extends BaseMapper\u0026lt;Project\u0026gt; { // @InterceptorIgnore(tenantLine = \u0026#34;true\u0026#34;)  Project getProjectFileOrMaterialDepotCatalogueId( @Param(\u0026#34;tenantId\u0026#34;) String tenantId, @Param(\u0026#34;catalogueId\u0026#34;) String catalogueId); }   1 2 3 4 5 6 7 8 9  \u0026lt;select id=\u0026#34;getProjectFileOrMaterialDepotCatalogueId\u0026#34; resultType=\u0026#34;com.sdstc.pdm.server.entity.Project\u0026#34;\u0026gt; select * from t_project where org_id = #{tenantId} and ((catalogue_info::jsonb -\u0026gt;\u0026gt; \u0026#39;projectFileCatalogueId\u0026#39;) = #{catalogueId} or (catalogue_info::jsonb -\u0026gt;\u0026gt; \u0026#39;materialDepotCatalogueId\u0026#39;) = #{catalogueId}) \u0026lt;/select\u0026gt;   具体报错如下：\n Caused by: net.sf.jsqlparser.parser.ParseException: Encountered unexpected token: \u0026quot;-\u0026gt;\u0026gt;\u0026quot; \u0026quot;-\u0026gt;\u0026gt;\u0026quot; at line 4, column 39. Was expecting one of: \u0026quot;\u0026amp;\u0026quot; \u0026quot;\u0026amp;\u0026amp;\u0026quot; \u0026quot;)\u0026quot; \u0026quot;::\u0026quot; \u0026quot;\u0026lt;\u0026lt;\u0026quot; \u0026quot;\u0026gt;\u0026gt;\u0026quot; \u0026quot;AND\u0026quot; \u0026quot;[\u0026quot; \u0026quot;^\u0026quot; \u0026quot;|\u0026quot; at net.sf.jsqlparser.parser.CCJSqlParser.generateParseException(CCJSqlParser.java:25031) at net.sf.jsqlparser.parser.CCJSqlParser.jj_consume_token(CCJSqlParser.java:24875) at net.sf.jsqlparser.parser.CCJSqlParser.AndExpression(CCJSqlParser.java:8062) at net.sf.jsqlparser.parser.CCJSqlParser.OrExpression(CCJSqlParser.java:8008) at net.sf.jsqlparser.parser.CCJSqlParser.AndExpression(CCJSqlParser.java:8134) at net.sf.jsqlparser.parser.CCJSqlParser.OrExpression(CCJSqlParser.java:8008) at net.sf.jsqlparser.parser.CCJSqlParser.Expression(CCJSqlParser.java:7979) at net.sf.jsqlparser.parser.CCJSqlParser.WhereClause(CCJSqlParser.java:6922) at net.sf.jsqlparser.parser.CCJSqlParser.PlainSelect(CCJSqlParser.java:4075) at net.sf.jsqlparser.parser.CCJSqlParser.SetOperationList(CCJSqlParser.java:4264) at net.sf.jsqlparser.parser.CCJSqlParser.SelectBody(CCJSqlParser.java:3923) at net.sf.jsqlparser.parser.CCJSqlParser.Select(CCJSqlParser.java:3916) at net.sf.jsqlparser.parser.CCJSqlParser.SingleStatement(CCJSqlParser.java:130) at net.sf.jsqlparser.parser.CCJSqlParser.Statement(CCJSqlParser.java:81) at net.sf.jsqlparser.parser.CCJSqlParserUtil.parse(CCJSqlParserUtil.java:63) ... 84 more 该问题其实之前没出现过的这个问题的，该如何处理呢，将ProjectMapper.java改为如下内容：\n1 2 3 4 5 6 7 8 9 10 11  @Mapper public interface ProjectMapper extends BaseMapper\u0026lt;Project\u0026gt; { @InterceptorIgnore(tenantLine = \u0026#34;true\u0026#34;) Project getProjectFileOrMaterialDepotCatalogueId( @Param(\u0026#34;tenantId\u0026#34;) String tenantId, @Param(\u0026#34;catalogueId\u0026#34;) String catalogueId); }   解决这个问题花费了我整整一个上午的时间，实际上我根本不需要花费这么长时间解决这个问题，因为我一开始就尝试了正确的方案，结果因为其他的Bug，导致我认为自己的方案有问题。对解决这个问题的过程进行复盘，有如下问题：\n 项目做如此底层的调整，没有通知到所有的开发人员。 项目做了调整后，开发却忘记提交相关的配置文件，导致我这边无论如何尝试，都是错误的。  因为注入了自定义拦截器，导致pg的-\u0026gt;\u0026gt;无法不可用，同事使用的解决方案是使用${operation}将-\u0026gt;\u0026gt;作为一个参数传入到SQL中，这样就可以避免JSQLParser对此的解析。我觉得这是一种不优雅的写法，所以我还是比较推荐上面的写法。\n解决此问题的过程中，我尝试了如下的方案：\n 升级和降级JSQLParser 使用InterceptorIgnore注解 使用SQLParser注解 使用bind标签 使用参数传递-\u0026gt;\u0026gt;操作  我觉得可能有更优雅的方案，比如在开发注解时下点功夫，但是暂时没有精力研究相关问题。\n","description":"","id":673,"section":"notes","tags":null,"title":"因为自定义拦截器，导致不支持jsonb相关的语法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E5%9B%A0%E4%B8%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8%E5%AF%BC%E8%87%B4%E4%B8%8D%E6%94%AF%E6%8C%81jsonb%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AF%AD%E6%B3%95/"},{"content":"典型的自己挖坑自己填。\n问题是这样的，我的Postman登录我的账号后，进行请求时一直报代理错误，浏览器可以正常访问的URL，在Postman中请求都是代理错误，但是实际上我系统压根就没有开代理。\n我此时已经开始怀疑我测试Python的Request类的代理时，添加的ALL_PROXY、HTTP_PROXY、HTTPS_PROXY环境变量影响到我的Postman了，果断去掉这几个环境变量，然后重启Postman，发现Postman恢复正常了。\n我觉得这种问题很怪异，于是去看了看Postman的配置，结果发现我本机的Postman有如下配置：\n这个是真的巧合的不能再巧合了。\n参考教程  Postman设置网络代理  ","description":"","id":674,"section":"notes","tags":null,"title":"因为设置了All_PROXY导致Postman总是报代理错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postman/%E5%9B%A0%E4%B8%BA%E8%AE%BE%E7%BD%AE%E4%BA%86all_proxy%E5%AF%BC%E8%87%B4postman%E6%80%BB%E6%98%AF%E6%8A%A5%E4%BB%A3%E7%90%86%E9%94%99%E8%AF%AF/"},{"content":"如图，我编写了如下的data.sql，结果在启动SpringApplication时报错误：\n报错如下：\n Caused by: org.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement \u0026quot;INSERT INTO T_USER (ID, USERNAME, PASSWORD, NICKNAME, CREATE_USER, UPDATE_USER)[*]\u0026quot;; expected \u0026quot;DIRECT, SORTED, DEFAULT, VALUES, SET, (, WITH, SELECT, TABLE, VALUES\u0026quot;; SQL statement: INSERT INTO t_user (id, username, password, nickname, create_user, update_user) [42001-200] at org.h2.message.DbException.getJdbcSQLException(DbException.java:453) at org.h2.message.DbException.getJdbcSQLException(DbException.java:429) at org.h2.message.DbException.getSyntaxError(DbException.java:243) at org.h2.command.Parser.getSyntaxError(Parser.java:1053) at org.h2.command.Parser.read(Parser.java:4995) at org.h2.command.Parser.parseQuerySub(Parser.java:2821) at org.h2.command.Parser.parseSelectUnion(Parser.java:2649) at org.h2.command.Parser.parseQuery(Parser.java:2620) at org.h2.command.Parser.parseInsertGivenTable(Parser.java:1832) at org.h2.command.Parser.parseInsert(Parser.java:1749) at org.h2.command.Parser.parsePrepared(Parser.java:954) at org.h2.command.Parser.parse(Parser.java:843) at org.h2.command.Parser.parse(Parser.java:819) at org.h2.command.Parser.prepareCommand(Parser.java:738) at org.h2.engine.Session.prepareLocal(Session.java:657) at org.h2.engine.Session.prepareCommand(Session.java:595) at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1235) at org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:212) at org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:201) at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:94) at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) at org.springframework.jdbc.datasource.init.ScriptUtils.executeSqlScript(ScriptUtils.java:261) ... 94 more 就是说，在values后缺少一些指令，我只好尝试去除了代码中的换行符，该问题修复了。\n在随后的实验中，我发现，其实换行符还是可以保留的，但是insert指令必须以分号结尾，我觉得这种细节，很难被注意到。\n","description":"","id":675,"section":"notes","tags":null,"title":"因为进行了换行，导致data.sql中的脚本无法执行","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/datagrip-h2/%E5%9B%A0%E4%B8%BA%E8%BF%9B%E8%A1%8C%E4%BA%86%E6%8D%A2%E8%A1%8C%E5%AF%BC%E8%87%B4data.sql%E4%B8%AD%E7%9A%84%E8%84%9A%E6%9C%AC%E6%97%A0%E6%B3%95%E6%89%A7%E8%A1%8C/"},{"content":"如图，我在Apollo中配置了该namespace，但是在SpringBoot的配置文件中没有忘记配置该项，结果导致zookeeper的配置项没有起作用：\n这个问题其实并没有花费我太多的时间，因为同事注意到这个问题了，及时告诉我了。\n有点糟心的是，少配置了一项，但是项目还能争吵跑起来，导致我很长时间都没有注意到我的功能没有跑起来。\n","description":"","id":676,"section":"notes","tags":null,"title":"因为配置文件中少些一个namespace，到时配置项不生效","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/apollo/%E5%9B%A0%E4%B8%BA%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%B0%91%E4%BA%9B%E4%B8%80%E4%B8%AAnamespace%E5%88%B0%E6%97%B6%E9%85%8D%E7%BD%AE%E9%A1%B9%E4%B8%8D%E7%94%9F%E6%95%88/"},{"content":"实际上我不知道这个Bug是数据Idea还是Maven的，Bug是这样的：我Idea中的一个模块A依赖了另一个模块B，但是A中B依赖始终报红，说找不到这个依赖，我install了B，结果在本地仓库中找不到B的jar包（能找到这个文件夹）。\n我新开一个项目，该问题不存在。回忆一下我旧项目，我做错了如下几件事：\n 模块命名错误（我选择移除该Module，然后新建一个module） group id忘记设置了（我后来通过groupId文件修改过一次）  后来该问题是如何修复的：同事构建的B Jar包和B Pom文件手动放置到本地仓库中（并将pom文件的前缀改成和jar包一致的），此时A已经不会报依赖找不到。\n为了确保Idea能正确的install这个jar包和pom文件，我删除了这两个文件，然后再进行install，此时B项目的Jar包可以正常的安装。\n我不确实是不是我之前的一些操作失误导致我的Idea和Maven卡Bug了。\n20210809后续：\n我大概率定位这个Bug属于Idea的呢，我使用Idea的源码跳转功能，无法跳转到我B的源码，只能跳转到其字节码。\n我目前已经知道问题出现在哪儿了，但是不知道该如何修复。我的项目相对于另一个正常的项目，server部分缺乏对common模块的依赖：\n我的项目（手动添加无效，刷新后需要重新导入）：\n正常的项目：\n我用如下按钮临时解决了跳转问题，但是我不太满意，因为我认为这个可能在我断点调试时失去同步，且每次重新导入项目时都需要配置一次：\n最后的最后，我终于发现我写了一个什么神奇的Bug！！！\n1 2 3 4 5 6 7  \u0026lt;artifactId\u0026gt;customer-service-center\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;sdstc.com\u0026lt;/groupId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;   如下我将com.sdstc错写成了sdstc.com（root、server、common都写错了），然而在依赖处我又写的是com.sdstc，真糟心：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.sdstc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;csc-common\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":677,"section":"notes","tags":null,"title":"因写错包名，导致的一些奇奇怪怪的错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%9B%A0%E5%86%99%E9%94%99%E5%8C%85%E5%90%8D%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA%E7%9A%84%E9%94%99%E8%AF%AF/"},{"content":"今天我在某个分组下创建了一个项目，向这个项目推送代码时始终报错。我没有在第一时间联想到是权限的问题导致的错误，从而导致我花费了大量的时间来解决这个问题。\n其实奇怪的问题是，我在这组只有developer权限，但是其他项目我都可以正常的推送代码，只有这个我自己新建的项目不能正确的推送。\n先记录一下吧，防止下次在相同的问题上浪费太多的时间。\n","description":"","id":678,"section":"notes","tags":null,"title":"因缺少权限导致无法推送代码","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/%E5%9B%A0%E7%BC%BA%E5%B0%91%E6%9D%83%E9%99%90%E5%AF%BC%E8%87%B4%E6%97%A0%E6%B3%95%E6%8E%A8%E9%80%81%E4%BB%A3%E7%A0%81/"},{"content":"之所以选择卸载Docker，是因为我觉得简单工具的安装使用Docker只是提供了安装便利性，工具运行时并没有直接安装在物理机或虚拟机上那么高性能（直觉，未验证）。\n yum list installed | grep docker # 这种方式貌似会删除较多的东西，还是建议一个一个的删除，安全些 yum -y remove docker* rm -rf /var/lib/docker # 如果不执行这一步的话，docker的适配器不会消失 reboot 参考资料  [https://blog.csdn.net/liujingqiu/article/details/74783780](Centos 7 如何卸载docker)  ","description":"","id":679,"section":"notes","tags":null,"title":"在CentOS 7中卸载docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos-7%E4%B8%AD%E5%8D%B8%E8%BD%BDdocker/"},{"content":"问题描述 我在CenOS 8中搭建了Docker，然后启动了一个busybox，我在busybox中无法ping通任何IP地址。我大概知道是防火墙那块出了问题，我关闭防火墙，重启Docker后，这个问题会消失。我打算等系统学完iptables后再来解决这个问题。\n","description":"","id":680,"section":"notes","tags":null,"title":"在CentOS 8中Docker容器无法访问网络（待完成）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos-8%E4%B8%ADdocker%E5%AE%B9%E5%99%A8%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":" 20210504:\n该方案在CentOS 7和CentOS 8上均可用\n 使用Ubuntu时，一直是直接在网上找一篇教程来使用，这次求稳去官方找了篇文档，进行操作，我将我使用到的指令整理如下：\n 安装yum-utils（yum-utils提供了yun-config-manager工具），并设置文档的仓库（说实话，我对yum和dnf其实还不太熟悉）：  1 2 3 4 5 6  yum install -y yum-utils yum-config-manager \\  --add-repo \\  https://download.docker.com/linux/centos/docker-ce.repo   安装docker   yum install docker-ce docker-ce-cli containerd.io 这个遇到到了一些小插曲，安装的时候报如下错误：\n Last metadata expiration check: 0:02:47 ago on Sat 10 Apr 2021 02:02:50 PM CST. Error: Problem 1: problem with installed package podman-2.0.5-5.module_el8.3.0+512+b3b58dca.x86_64 - package podman-2.0.5-5.module_el8.3.0+512+b3b58dca.x86_64 requires runc \u0026gt;= 1.0.0-57, but none of the providers can be installed - package podman-2.2.1-7.module_el8.3.0+699+d61d9c41.x86_64 requires runc \u0026gt;= 1.0.0-57, but none of the providers can be installed - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - cannot install the best candidate for the job - package runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64 is filtered out by modular filtering Problem 2: problem with installed package buildah-1.15.1-2.module_el8.3.0+475+c50ce30b.x86_64 - package buildah-1.15.1-2.module_el8.3.0+475+c50ce30b.x86_64 requires runc \u0026gt;= 1.0.0-26, but none of the providers can be installed - package buildah-1.16.7-4.module_el8.3.0+699+d61d9c41.x86_64 requires runc \u0026gt;= 1.0.0-26, but none of the providers can be installed - package docker-ce-3:20.10.5-3.el8.x86_64 requires containerd.io \u0026gt;= 1.4.1, but none of the providers can be installed - package containerd.io-1.4.3-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-70.rc92.module_el8.3.0+699+d61d9c41.x86_64 - cannot install the best candidate for the job - package containerd.io-1.4.3-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.3-3.2.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 conflicts with runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package containerd.io-1.4.4-3.1.el8.x86_64 obsoletes runc provided by runc-1.0.0-68.rc92.module_el8.3.0+475+c50ce30b.x86_64 - package runc-1.0.0-56.rc5.dev.git2abd837.module_el8.3.0+569+1bada2e4.x86_64 is filtered out by modular filtering - package runc-1.0.0-64.rc10.module_el8.3.0+479+69e2ae26.x86_64 is filtered out by modular filtering (try to add '--allowerasing' to command line to replace conflicting packages or '--skip-broken' to skip uninstallable packages or '--nobest' to use not only best candidate packages) 经过查询资料了解，podman也是一种类似与Docker的容器服务，CentOS会默认安装podman，结果就导致了冲突，所以这个地方需要先将podman给卸载掉。\n yum -y erase podman buildah 网上对podman的评价还是蛮高的，但是我不清楚我目前研究的Kubernetes技术栈是否有使用podman的计划，如果有的话，我会安排时间研究下这个东西。\n启动并设置开机运行Docker   systemctl start docker systemctl enable docker 配置镜像加速  Docker镜像加速，我目前主要用阿里云的。首次使用阿里云镜像加速时需要注册（具体细节我忘记了，可以百度下）\n sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF' { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://coded9m2.mirror.aliyuncs.com\u0026quot;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 参考文档  Install Docker Engine on CentOS CentOS8卸载podman安装docker 阿里云镜像加速器 Docker 镜像加速教程  ","description":"","id":681,"section":"notes","tags":null,"title":"在CentOS中安装Docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8centos%E4%B8%AD%E5%AE%89%E8%A3%85docker/"},{"content":"安装Protobuf语法高亮插件 插件使用：Protobuf Support，安装重启后即可实现语法高亮。\n配置Maven插件 首先，proto文件需要放置在src.main.proto目录下，其次对Maven进行如下配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  \u0026lt;build\u0026gt; \u0026lt;extensions\u0026gt; \u0026lt;extension\u0026gt; \u0026lt;groupId\u0026gt;kr.motd.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;os-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0\u0026lt;/version\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/extensions\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.xolstice.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.6.1\u0026lt;/version\u0026gt; \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;protocArtifact\u0026gt; com.google.protobuf:protoc:${j.protobuf-java.version}:exe:${os.detected.classifier} \u0026lt;/protocArtifact\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt; \u0026lt;goal\u0026gt;test-compile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   os-maven-plugin插件用于设置各种有用的属性，我对此的理解就是相当于设置了一些properties标签。\n配置完成后就可以在target中找到生成的字节码文件：\n遇到的问题  遇到如下报错：   Failed to execute goal org.xolstice.maven.plugins:protobuf-maven-plugin:0.6.1:compile (default) on project Netty: protoc did not exit cleanly. Review output for more information. 我解决该问题的方式是，检查自己的proto文件，删除语法错误的proto文件（本次实验中是两个文件的java_outer_classname设置成一样的了）\n随着对portobuf较深入的了解，我发现protobuf貌似不允许同一个命名空间存在两个相同的message。\n貌似不会生成相应的源码  我增加了如下的配置（还导致我一些代码丢失，找都找不会了，头疼）：\n1 2 3 4  \u0026lt;outputDirectory\u0026gt;${project.build.sourceDirectory}\u0026lt;/outputDirectory\u0026gt; \u0026lt;clearOutputDirectory\u0026gt;false\u0026lt;/clearOutputDirectory\u0026gt;   我现在很好奇，我该如何查看一个插件支持哪些配置？\n我新一个项目，进行如此配置后，报如下错误，此时我旧项目也会报该错误：   [ERROR] Failed to execute goal org.xolstice.maven.plugins:protobuf-maven-plugin:0.6.1:compile (default) on project Netty: Unable to resolve artifact: Missing: [ERROR] ---------- [ERROR] 1) com.google.protobuf2:protoc:exe:windows-x86_64:3.17.3 [ERROR] [ERROR] Try downloading the file manually from the project website. [ERROR] [ERROR] Then, install it using the command: [ERROR] mvn install:install-file -DgroupId=com.google.protobuf2 -DartifactId=protoc -Dversion=3.17.3 -Dclassifier=windows-x86_64 -Dpackaging=exe -Dfile=/path/to/file [ERROR] [ERROR] Alternatively, if you host your own repository you can deploy the file there: [ERROR] mvn deploy:deploy-file -DgroupId=com.google.protobuf2 -DartifactId=protoc -Dversion=3.17.3 -Dclassifier=windows-x86_64 -Dpackaging=exe -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id] [ERROR] [ERROR] Path to dependency: [ERROR] 1) org.example:Netty:jar:1.0-SNAPSHOT [ERROR] 2) com.google.protobuf2:protoc:exe:windows-x86_64:3.17.3 [ERROR] [ERROR] ---------- [ERROR] 1 required artifact is missing. [ERROR] [ERROR] for artifact: [ERROR] org.example:Netty:jar:1.0-SNAPSHOT [ERROR] [ERROR] from the specified remote repositories: [ERROR] central (https://repo.maven.apache.org/maven2, releases=true, snapshots=false) [ERROR] [ERROR] -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException Process finished with exit code 1 经过我的观察，我发现我配置中的com.google.protobuf:protoc:${j.protobuf-java.version}:exe:${os.detected.classifier}被改为了com.google.protobuf2:protoc:${j.protobuf-java.version}:exe:${os.detected.classifier}。之所以会发生这样的改变，是因为我昨天在调整代码文件时用了Shift + F6快捷键，一个包原本为protobuf，我用快捷键改为了protobuf2。\n这件事给我提了一个醒，我下次修改代码时一定要防止不小心改动了不该改动的东西（最好找找Idea是否存在相关的解决方案）。\n小结 我最终使用的配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  \u0026lt;build\u0026gt; \u0026lt;extensions\u0026gt; \u0026lt;extension\u0026gt; \u0026lt;groupId\u0026gt;kr.motd.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;os-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.0\u0026lt;/version\u0026gt; \u0026lt;/extension\u0026gt; \u0026lt;/extensions\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.xolstice.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.6.1\u0026lt;/version\u0026gt; \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;outputDirectory\u0026gt;${project.build.sourceDirectory}\u0026lt;/outputDirectory\u0026gt; \u0026lt;clearOutputDirectory\u0026gt;false\u0026lt;/clearOutputDirectory\u0026gt; \u0026lt;protocArtifact\u0026gt; com.google.protobuf:protoc:${j.protobuf-java.version}:exe:${os.detected.classifier} \u0026lt;/protocArtifact\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;compile\u0026lt;/goal\u0026gt; \u0026lt;goal\u0026gt;test-compile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;   参考资料  Intellij IDEA中使用Protobuf的正确姿势 os-maven-plugin Maven 插件 使用maven自动编译protocol buffer的配置 protobuf + maven 爬坑记  ","description":"","id":682,"section":"notes","tags":null,"title":"在Idea中打造比较舒服的Protobuf开发环境","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/%E5%9C%A8idea%E4%B8%AD%E6%89%93%E9%80%A0%E6%AF%94%E8%BE%83%E8%88%92%E6%9C%8D%E7%9A%84protobuf%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"content":"核心就两点：\n 搜索json、md等文件中的内容，可以直接搜索 搜索编译后的字节码中的内容，需要先下载源码（参考我Idea分类下另外的笔记）  参考资料  https://blog.csdn.net/w8y56f/article/details/103292300  ","description":"","id":683,"section":"notes","tags":null,"title":"在Idea中搜索jar包中的内容","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%9C%A8idea%E4%B8%AD%E6%90%9C%E7%B4%A2jar%E5%8C%85%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9/"},{"content":"问题描述 在导入项目时，我按下图配置了Maven，同时我的setting.xml文件是从我同事那要的。结果我项目中多处报红。\n解决步骤 修改setting.xml文件中如下标签，该标签需要与在Idea中配置位置对应。\n1 2 3  \u0026lt;localRepository\u0026gt;D:\\MavenRepository\\repository\u0026lt;/localRepository\u0026gt;   ","description":"","id":684,"section":"notes","tags":null,"title":"在Idea中配置Maven时遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E5%9C%A8idea%E4%B8%AD%E9%85%8D%E7%BD%AEmaven%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9  // 选择一个版本号最大的作为最新版本 LambdaQueryWrapper\u0026lt;Style2d\u0026gt; queryWrapperForStyle = new LambdaQueryWrapper\u0026lt;Style2d\u0026gt;() .eq(Style2d::getStyleId, style2d.getStyleId()) .eq(Style2d::getOrgId, tenantId) .eq(Style2d::getIsCurrentVersion, IsCurrentVersion.NOT_CURRENT_VERSION.getValue()) .orderByDesc(Style2d::getVersionNumber) .last(\u0026#34;limit 1\u0026#34;);   参考资料  MyBatis-Plus#last mybatis plus 限制查询个数 Mybatis-Plus3.x如何取单表前10条  ","description":"","id":685,"section":"notes","tags":null,"title":"在LambdaQueryWrapper中使用limit","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E5%9C%A8lambdaquerywrapper%E4%B8%AD%E4%BD%BF%E7%94%A8limit/"},{"content":"自从用了RestTemplate，我已经很少在Java代码中使用HttpClient之类的东西了。RestTemplate的便利性，能够帮助我快速的开发一些小工具。\n我接下来需要研究的RestTemplate的技术是：看能不能脱离SpringBoot项目使用RestTemplate。现阶段使用这个工具时我还需要初始化一个SpringBoot项目，有点麻烦。\nRestTemplate的Get请求，优雅的传递参数的方法如下：\n1 2 3 4 5 6 7 8 9 10 11  UriComponents apiInterfaceListUrl = UriComponentsBuilder.fromUriString(YAPI) .path(YApi.API_INTERFACE_LIST.getPath()) .queryParam(\u0026#34;token\u0026#34;, TOKEN) .queryParam(\u0026#34;limit\u0026#34;, RESPONSE_ITEM_LIMIT) .build(); ApiInterfaceListResponse apiInterfaceListResponse = restTemplate.getForObject( apiInterfaceListUrl.toUriString(), ApiInterfaceListResponse.class);   queryParam方法是允许传递一个Map\u0026lt;String, String\u0026gt;类型的参数的，但是我没有找到一个很好的工具将一个对象转换成Map\u0026lt;String, String\u0026gt;，自己开发这个工具，我暂时又没有足够的动力，所以暂时先直接传递字符串了。\n参考教程  使用RestTemplate发送get请求,获取不到参数的问题  ","description":"","id":686,"section":"notes","tags":null,"title":"在RestTemplate的Get请求中，稍微优雅的传递参数的方式","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/resttemplate/%E5%9C%A8resttemplate%E7%9A%84get%E8%AF%B7%E6%B1%82%E4%B8%AD%E7%A8%8D%E5%BE%AE%E4%BC%98%E9%9B%85%E7%9A%84%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E7%9A%84%E6%96%B9%E5%BC%8F/"},{"content":"今天在调MyBatis-Plus Generator时，遇到一个奇怪的问题：我配置了表信息，断点调试的时候发现获取的tableInfo信息时，长度总为零。我敏锐的感觉到是数据库配置出现了问题。MyBatis-Plus Generator没有报任何错误，我使用PostgreSQL的经验比较少，很难定位到问题的原因，所以我决定用JdbcTemplate调试代码。\npom.xml文件如下，我基本上没怎么动，就是使用SpringBoot初始化器初始出一份代码，然后加上Generator相关的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;fun.junjie\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatisplus-code-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;mybatisplus-code-generator\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;spring-boot.version\u0026gt;2.3.7.RELEASE\u0026lt;/spring-boot.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.postgresql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;postgresql\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;42.2.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-generator\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.freemarker\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;freemarker\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.31\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.8\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.7.RELEASE\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt;fun.junjie.mybatisplus.code.generator.MybatisplusCodeGeneratorApplication\u0026lt;/mainClass\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;repackage\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;   application.properties代码如下\n spring.application.name=mybatisplus-code-generator server.port=8888 spring.datasource.url=jdbc:postgresql://192.168.19.12:5432/dyf?currentSchema=dyf\u0026amp;stringtype=unspecified spring.datasource.username=postgres spring.datasource.password=dev.DB spring.datasource.driver-class-name=org.postgresql.Driver 这份配置文件中有很多地方需要了解一下：我们数据库结构为：dyf库下的dyf模式。如果在配置的时候不加currentSchema=dyf，则无法检索出目标表。\n测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package fun.junjie.mybatisplus.code.generator.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jdbc.core.JdbcTemplate; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.util.Map; /** * @author wujj */ @RestController public class TestController { @Autowired private JdbcTemplate jdbcTemplate; @GetMapping(\u0026#34;test\u0026#34;) public void test() { Map\u0026lt;String, Object\u0026gt; stringObjectMap = jdbcTemplate.queryForMap(\u0026#34;select * from t_dyf_app\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } }   整个实验环境让我花费时间最多的就是，找到currentSchema=dyf配置。在使用该配置前，我尝试了使用spring.datasource.scheme=dyf配置，结果无法正常启动。\n该配置在测试环境能正常运行了，但是在我做MyBatis-Plus Generator时，依旧没有作用。在MyBatis-Plus Generator中，需要在DataSourceConfig配置中通过setSchemaName指定dyf模式。因为我后来决定不使用MyBatis-Plus Generator，而是自己开发一个该工具，所以我暂时放弃了对该技术的研究。\n","description":"","id":687,"section":"notes","tags":null,"title":"在SpringBoot中使用JdbcTemplate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E5%9C%A8springboot%E4%B8%AD%E4%BD%BF%E7%94%A8jdbctemplate/"},{"content":"操作步骤  引入依赖  1 2 3 4 5  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   准备配置文件  1 2 3 4 5 6 7  spring:rabbitmq:host:192.168.30.174port:5672username:adminpassword:123456virtual-host:/  准备配置类  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package cn.watsons.mmp.brand.api.config; import org.springframework.amqp.core.Queue; import org.springframework.amqp.rabbit.config.SimpleRabbitListenerContainerFactory; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.support.converter.SimpleMessageConverter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RabbitConfig { @Bean public Queue Queue() { return new Queue(\u0026#34;hello\u0026#34;); } }   准备测试文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  package cn.watsons.mmp.brand.api.rabbit; import cn.watsons.mmp.brand.api.BrandMemberApiApplication; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.amqp.core.AmqpTemplate; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.Date; @RunWith(SpringRunner.class) @SpringBootTest(classes = {BrandMemberApiApplication.class}) public class RabbitMQTest { @Autowired private AmqpTemplate rabbitTemplate; @Test public void send() { String context = \u0026#34;hello \u0026#34; + new Date(); System.out.println(\u0026#34;Sender : \u0026#34; + context); this.rabbitTemplate.convertAndSend(\u0026#34;hello\u0026#34;, context); } }   相关教程  Spring Boot(八)：RabbitMQ 详解  ","description":"","id":688,"section":"notes","tags":null,"title":"在SpringBoot中配置RabbitMQ","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/rabbitmq/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AErabbitmq/"},{"content":"操作步骤  引入依赖  1 2 3 4 5 6 7 8 9  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   准备配置文件  1 2 3 4 5 6 7 8 9 10 11 12  spring:redis:database:12host:192.168.75.62port:6379timeout:60slettuce:pool:max-active:100max-idle:100min-idle:50max-wait:6000  准备配置类  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  package cn.watsons.mmp.brand.api.config.redis; import com.alibaba.fastjson.support.spring.FastJsonRedisSerializer; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; import org.springframework.cache.annotation.CachingConfigurerSupport; import org.springframework.cache.annotation.EnableCaching; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.*; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.RedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.net.UnknownHostException; /** * redis配置类 * * @program: springbootdemo * @Date: 2019/1/25 15:20 * @Author: Mr.Zheng * @Description: */ @Configuration @EnableCaching //开启注解 public class RedisConfig extends CachingConfigurerSupport { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(LettuceConnectionFactory connectionFactory) { RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new FastJsonRedisSerializer\u0026lt;\u0026gt;(Object.class)); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; } @Bean public StringRedisTemplate stringRedisTemplate(LettuceConnectionFactory connectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(connectionFactory); return template; } @Bean public HashOperations\u0026lt;String, String, Object\u0026gt; hashOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForHash(); } @Bean public ValueOperations\u0026lt;String, Object\u0026gt; valueOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForValue(); } @Bean public ListOperations\u0026lt;String, Object\u0026gt; listOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForList(); } @Bean public SetOperations\u0026lt;String, Object\u0026gt; setOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForSet(); } @Bean public ZSetOperations\u0026lt;String, Object\u0026gt; zSetOperations(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) { return redisTemplate.opsForZSet(); } }   准备测试文件  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package cn.watsons.mmp.brand.api.redis; import cn.watsons.mmp.brand.api.BrandMemberApiApplication; import cn.watsons.mmp.brand.api.utils.RedisUtil; import lombok.RequiredArgsConstructor; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.test.context.junit4.SpringRunner; import org.springframework.web.client.RestTemplate; @RequiredArgsConstructor @RunWith(SpringRunner.class) @SpringBootTest(classes = {BrandMemberApiApplication.class}) public class RedisTest { @Autowired private RedisTemplate redisTemplate = new RedisTemplate(); @Autowired private RedisUtil redisUtil; @Test public void test() { redisUtil.set(\u0026#34;temp\u0026#34;, \u0026#34;you are fun...\u0026#34;); System.out.println(redisUtil.get(\u0026#34;temp\u0026#34;)); } }   ","description":"","id":689,"section":"notes","tags":null,"title":"在SpringBoot中配置Redis","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AEredis/"},{"content":"问题描述  描述如下   java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:123) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:244) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redisUtil': Unsatisfied dependency expressed through field 'redisTemplate'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:893) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:120) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 24 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:797) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 43 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:884) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:788) ... 56 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:650) ... 70 more Caused by: java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration$LettucePoolingClientConfigurationBuilder.\u0026lt;init\u0026gt;(LettucePoolingClientConfiguration.java:94) at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration.builder(LettucePoolingClientConfiguration.java:51) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration$PoolBuilderFactory.createBuilder(LettuceConnectionConfiguration.java:159) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.createBuilder(LettuceConnectionConfiguration.java:107) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.getLettuceClientConfiguration(LettuceConnectionConfiguration.java:92) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.redisConnectionFactory(LettuceConnectionConfiguration.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 71 more Caused by: java.lang.ClassNotFoundException: org.apache.commons.pool2.impl.GenericObjectPoolConfig at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 82 more 解决步骤  引入commons-pool2  1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   ","description":"","id":690,"section":"notes","tags":null,"title":"在SpringBoot中配置了Redis连接池后链接失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%9C%A8springboot%E4%B8%AD%E9%85%8D%E7%BD%AE%E4%BA%86redis%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%90%8E%E9%93%BE%E6%8E%A5%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":" 依赖文件   \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; application.yml文件   spring: datasource: # driver-class-name: org.postgresql.Driver # 原始的 driver-class-name: com.p6spy.engine.spy.P6SpyDriver # 使用p6spy后的 password: HelloWorld # url: jdbc:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 原始的 url: jdbc:p6spy:postgresql://192.168.13.68:5432/postgres?currentSchema=public\u0026amp;stringtype=unspecified # 使用p6spy后的 username: postgres 参考资料  spring boot整合使用JdbcTemplate之详解!!  ","description":"","id":691,"section":"notes","tags":null,"title":"在SpringBoot项目整合JdbcTemplate","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E5%9C%A8springboot%E9%A1%B9%E7%9B%AE%E6%95%B4%E5%90%88jdbctemplate/"},{"content":"操作步骤  指令如下  sudo apt install -y docker-ce ","description":"","id":692,"section":"notes","tags":null,"title":"在Ubuntu 18.04中安装Docker","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8ubuntu-18.04%E4%B8%AD%E5%AE%89%E8%A3%85docker/"},{"content":"操作步骤  指令如下   # 创建docker用户组 sudo groupadd docker # 将当前用户添加到docker组 sudo gpasswd -a ${USER} docker # 重启服务 sudo service docker restart # 切换当前会话到新组 newgrp - docker 相关资料  Ubuntu16.04 添加 Docker用户组  ","description":"","id":693,"section":"notes","tags":null,"title":"在Ubuntu 18.04中添加Docker用户组","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%9C%A8ubuntu-18.04%E4%B8%AD%E6%B7%BB%E5%8A%A0docker%E7%94%A8%E6%88%B7%E7%BB%84/"},{"content":"我本来只是需要一个简简单单的K8S语法提示工具的，但是找到了Visual Studio Code Kubernetes Tools工具，所以就打算配置好试用一下。我没有完全按照教程走，因为我觉得教程配置kubeconfig那一部分有点不优雅，我可能更愿意为某个用户生成一份kubeconfig文件，但是我忘记相关的指令了，所以最终决定将自己管理员的kubeconfig拿来用一用，反正是学习环境，影响不大。\n  VS Code安装Kubernetes插件\n  按照如下步骤，添加kubeconfig文件\n  配置完成之后就可以查看各种资源了  参考资料  安装配置Visual Studio Code Kubernetes Tools  ","description":"","id":694,"section":"notes","tags":null,"title":"在VS Code上配置K8S插件","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%9C%A8vs-code%E4%B8%8A%E9%85%8D%E7%BD%AEk8s%E6%8F%92%E4%BB%B6/"},{"content":"为了测试家里电脑vue-cli好不好使，我在桌面上随便新建了目录，然后在这个目录下初始化一个项目，结果项目初始化后，无法运行起来，报如下错误：\n ERROR Failed to compile with 1 error 00:26:24 error Conflict: Multiple assets emit different content to the same filename index.html ERROR in Conflict: Multiple assets emit different content to the same filename index.html webpack compiled with 1 error Issues checking in progress... No issues found. 查了下资料，发现是中文目录导致的，将项目从中文目录移除后，该问题修复了。\n参考资料  Vue.js - ERROR in Conflict: Multiple assets emit different content to the same filename index.html  ","description":"","id":695,"section":"notes","tags":null,"title":"在一个中文目录下初始项目，无法运行起来","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/vue/%E5%9C%A8%E4%B8%80%E4%B8%AA%E4%B8%AD%E6%96%87%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%88%9D%E5%A7%8B%E9%A1%B9%E7%9B%AE%E6%97%A0%E6%B3%95%E8%BF%90%E8%A1%8C%E8%B5%B7%E6%9D%A5/"},{"content":"我暂时没有该技术的需求，整理处理，方便以后学习：\nHow to easily install multiple instances of the Ingress NGINX controller in the same cluster\n","description":"","id":696,"section":"notes","tags":null,"title":"在同一个集群中安装多个IngressNginx","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E9%9B%86%E7%BE%A4%E4%B8%AD%E5%AE%89%E8%A3%85%E5%A4%9A%E4%B8%AAingressnginx/"},{"content":"我为试验机设置了全新的网络环境，完全不必担心镜像下载速度过慢、镜像无法下载的问题。所以相应的教程也非常的清晰明了。\n另外需要说明的是，我的所有节点都是根据我制作的模板生成的，我在模板中安装了许多的工具。可以参考我模板配置相关的说明。\n基础环境准备： 我这次是失误了，这些工作应该在模板节点上做的。这样生成的所有节点都已经被配置好了。\n 关闭防火墙  1 2 3 4  systemctl disable firewalld systemctl stop firewalld   关闭selinux  1 2 3 4 5 6 7 8  # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config   关闭交换分区  1 2 3 4 5 6 7  # 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab   修改内核参数  1 2 3 4 5 6 7  cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system   重启后检查各台机器的状态   reboot sestatus swapon -s 安装K8S 注意事项：\n 我推荐指定apiserver-advertise-address参数，是因为有些虚拟机是双网卡的，一张是nat，用于虚拟机访问外部网络，一张是private，用于虚拟机内部访问。如果让kubeadm自己选，可能会选错网卡。 我推荐不指定版本号，用最新的，比较香 不需要指定仓库，我这边基础设施上已经做了处理了，可以很快的拉取到各个镜像。  1 2 3 4 5 6 7 8 9 10 11 12  # 可不必执行 kubeadm config images list kubeadm config images pull kubeadm init \\  --pod-network-cidr=10.244.0.0/16 \\  --apiserver-advertise-address=172.20.11.201 # 用于还原kubeadm init对系统进行的任何改变（用于重装） kubeadm reset   添加节点 参考资料  kubeadm reset  ","description":"","id":697,"section":"notes","tags":null,"title":"在实验机上安装Kubernetes","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%9C%A8%E5%AE%9E%E9%AA%8C%E6%9C%BA%E4%B8%8A%E5%AE%89%E8%A3%85kubernetes/"},{"content":"安装插件：Suspicious Site Reporter\n新版可以进行如下配置，不再需要这个插件了：\n","description":"","id":698,"section":"notes","tags":null,"title":"地址栏显示http或者https（废弃）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%9C%B0%E5%9D%80%E6%A0%8F%E6%98%BE%E7%A4%BAhttp%E6%88%96%E8%80%85https%E5%BA%9F%E5%BC%83/"},{"content":"这是我推荐的方式，Anaconda是学习Python的好帮手。\n 创建环境并激活环境   conda create --name ansible python=2.7 conda activate ansible 安装ansible   # 我在学习《奔跑吧Ansible》，该书使用的是这个版本 pip install ansible==1.8.4 安装sshpass（使用密码连接时必须要这个软件）  1 2 3  sudo apt install -y sshpass   进行测试  1 2 3 4 5 6 7 8  tee hosts \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [test] 192.168.23.60 ansible_ssh_user=root ansible_ssh_port=22 ansible_ssh_pass=123456 EOF ansible test -i hosts -m ping   ","description":"","id":699,"section":"notes","tags":null,"title":"基于Anaconda安装Ansible（推荐）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/%E5%9F%BA%E4%BA%8Eanaconda%E5%AE%89%E8%A3%85ansible%E6%8E%A8%E8%8D%90/"},{"content":"安装网络工具包 指令如下：\n1 2 3  dnf -y install net-tools   配置SSH服务 指令如下：\n1 2 3 4 5 6  dnf -y install openssh-server systemctl start sshd systemctl enable sshd   安装常用工作环境 指令如下：\n dnf -y install git 安装学习环境  安装VirtualBox 安装Vagrant 安装Shadowsocks-libev  待完成\n","description":"","id":700,"section":"notes","tags":null,"title":"基于Vagrant的虚拟机环境设计","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/%E5%9F%BA%E4%BA%8Evagrant%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%8E%AF%E5%A2%83%E8%AE%BE%E8%AE%A1/"},{"content":"  ping出现了Destination Host Unreachable，大概率时防火墙的问题：\n  如果你配置了SNAT，结果发现没有任何效果，还是无法ping通另一个网络中的ip，大概率ip服务没有启动。\n  tcpdump -i wg0 icmp只看到request，看不到reply，大概率是因为忘记设置snat了。\n  ","description":"","id":701,"section":"notes","tags":null,"title":"处理WireGuard时积累的一些经验","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/%E5%A4%84%E7%90%86wireguard%E6%97%B6%E7%A7%AF%E7%B4%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C/"},{"content":"（实验失败了，而且找不到相关的资料，很挫败）\n菱形 六边形 ","description":"","id":702,"section":"notes","tags":null,"title":"复杂场景下使用RingBuffer","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/disruptor/%E5%A4%8D%E6%9D%82%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%BD%BF%E7%94%A8ringbuffer/"},{"content":"问题描述 我也是第一次意识到这个问题，我在Chrome上打开了一个无痕窗口，进入项目首页，因为没有登录，直接跳转到登录页面，这是我需要的。然后我再打开一个无痕窗口，进入项目首页，结果直接以登录状态进入了项目首页。额，这个肯定不是我想要的，因为我需要同时测试多个账号的登录。\n解决方案 我目前选择的是绕开这个问题，我新建了一个Chrome用户，每个用户登录一个账号。\n","description":"","id":703,"section":"notes","tags":null,"title":"多个无痕窗口共用一套Cookie","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%A4%9A%E4%B8%AA%E6%97%A0%E7%97%95%E7%AA%97%E5%8F%A3%E5%85%B1%E7%94%A8%E4%B8%80%E5%A5%97cookie/"},{"content":"今天学习使用Helm安装NginxIngress是发现配置清单中有一个有趣的Service，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  # Source: ingress-nginx/templates/controller-service.yamlapiVersion:v1kind:Servicemetadata:annotations:labels:helm.sh/chart:ingress-nginx-4.0.15app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:\u0026#34;1.1.1\u0026#34;app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginx-controllernamespace:ingress-nginxspec:type:LoadBalanceripFamilyPolicy:SingleStackipFamilies:- IPv4ports:- name:httpport:80protocol:TCPtargetPort:httpappProtocol:http- name:httpsport:443protocol:TCPtargetPort:httpsappProtocol:httpsselector:app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/component:controller  这个Service的type为LoadBalancer，这个有点颠覆我之前对LocalBalancer的理解，之前的理解中LocalBalancer需要在云环境中才能使用，而我的环境时我自己搭建的。使用kubectl get service -n ingress-nginx，得到如下输出：\n ingress-nginx-controller LoadBalancer 10.98.152.7 \u0026lt;pending\u0026gt; 80:30062/TCP,443:32440/TCP 160m ingress-nginx-controller-admission ClusterIP 10.102.86.84 \u0026lt;none\u0026gt; 443/TCP 160m 160m 此时请注意，ingress-nginx-controller的EXTERNAL-IP字段的状态始终为pending。我有通过节点IP加端口进行测试，是可以正常访问的。\n我暂时得不到更多的知识点了，\n","description":"","id":704,"section":"notes","tags":null,"title":"奇怪的LoadBalancer","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E5%A5%87%E6%80%AA%E7%9A%84loadbalancer/"},{"content":"配置如下：\n","description":"","id":705,"section":"notes","tags":null,"title":"如何为Idea设置代理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%A6%82%E4%BD%95%E4%B8%BAidea%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/"},{"content":"这个技术存在的意义是可以让我对服务端的数据包管理更严格，避免一些不必要的问题造成我无法正常使用。\n 使用如下指令得到数据包的文件：  1 2 3 4 5  tcpdump -tttt -s0 -X -vv tcp port 8080 -w captcha.cap tcpdump -i eth0 -w captcha.cap tcpdump -i enp34s0 -w captcha.cap   下载capcha.cap文件到开发机，用鲨鱼进行分析（我这块很简单，东西down下来后，直接可以点开）。  ","description":"","id":706,"section":"notes","tags":null,"title":"如何使用tcpdump抓包，并用鲨鱼分析","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8tcpdump%E6%8A%93%E5%8C%85%E5%B9%B6%E7%94%A8%E9%B2%A8%E9%B1%BC%E5%88%86%E6%9E%90/"},{"content":"\u0026lt;? extends T\u0026gt; 表示类型的上界，也就是说，参数化的类型可能是T或者T的子类型。例如下面的写法都是合法的赋值语句： ~~~ java Listlist = new ArrayList(); Listlist = new ArrayList(); Listlist = new ArrayList(); ~~~ ### 读数据分析 1. 不管给list如何赋值，可以保证list里面存放的一定是Number类型或其子类，因此可以从list列表里读取Number类型的值。 2. 不能从list中读取Integer，因为list里面可能存放的是Float值，同理，也不可以从list里面读取Float。 ### 写数据分析 1. 不能向list中写Number，因为list中有可能存放的是Float 1. 不能向list中写Integer，因为list中有可能存放的是Float 2. 不能向list中写Float，因为list中有可能存放的是Integer 从上面的分析可以发现，只能从List读取T，因为无法确认它实际执行列表的类型，从而无法确定列表里面存放的实际的类型，所以无法向列表里面添加元素。 *（个人表示怀疑吧，如果只能读取，那完全不知道这个容器存在的意义）* ## 表示类型下届，也就是说，参数化的类型是此类型的超类型。 ~~~ java Listlist = new ArrayList(); Listlist = new ArrayList(); Listlist = new ArrayList(); ~~~ 被设计为用来写数据的泛型（只能写入T或者T的子类类型），不能用来读，分析如下。 ### 读数据分析 无法保证list里面一定存放的是Float类型或Number类型，因此有可能存放的是Object类型，唯一能确定的是list里面存放的是Object或其他子类，但是无法确定子类的类型。正是由于无法确认list里面存放数据的类型，因此无法从list里面读取数据。 ### 写数据分析 1. 可以向list里面写入Float类型的数据（不管list里面实际存放的是Float、Number或Object，写入Float都是允许的）；同理，也可以向list里面添加Float子类类型的元素。 2. 不可以向list里面添加Number或Object类型的数据，因为list中可能存放的是Float类型的数据。 ## 使用案例 代码如下： ~~~ java public static  void copy(Listdest, Listsrc) { for (int i = 0; i ","description":"","id":707,"section":"notes","tags":null,"title":"如何区分？extends T与？ super T","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%86extends-t%E4%B8%8E-super-t/"},{"content":"需求太少了，古作废该笔记\n之前有被这个问题困惑过，今天看书的时候，遇到了相关的资料，故记载下来。\n可以比较U盘插入计算机前后dmesg命令输出的最后一行内容，也可以用lsblk。\n实践dmesg 实践中使用dmesg后，新增内容如下：\n [ 2650.933707] usb 1-2: new high-speed USB device number 4 using xhci_hcd [ 2651.082193] usb 1-2: New USB device found, idVendor=0781, idProduct=5571, bcdDevice= 1.00 [ 2651.082196] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [ 2651.082198] usb 1-2: Product: Cruzer Fit [ 2651.082199] usb 1-2: Manufacturer: SanDisk [ 2651.082200] usb 1-2: SerialNumber: 4C530001160824101320 [ 2651.094526] usb-storage 1-2:1.0: USB Mass Storage device detected [ 2651.094773] scsi host2: usb-storage 1-2:1.0 [ 2651.094891] usbcore: registered new interface driver usb-storage [ 2651.095645] usbcore: registered new interface driver uas 我并没有看出任何有用的信息，稍后，信息变为如下内容，依旧没有看出任何信息：\n [ 2650.933707] usb 1-2: new high-speed USB device number 4 using xhci_hcd [ 2651.082193] usb 1-2: New USB device found, idVendor=0781, idProduct=5571, bcdDevice= 1.00 [ 2651.082196] usb 1-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [ 2651.082198] usb 1-2: Product: Cruzer Fit [ 2651.082199] usb 1-2: Manufacturer: SanDisk [ 2651.082200] usb 1-2: SerialNumber: 4C530001160824101320 [ 2651.094526] usb-storage 1-2:1.0: USB Mass Storage device detected [ 2651.094773] scsi host2: usb-storage 1-2:1.0 [ 2651.094891] usbcore: registered new interface driver usb-storage [ 2651.095645] usbcore: registered new interface driver uas [ 2652.102859] scsi 2:0:0:0: Direct-Access SanDisk Cruzer Fit 1.00 PQ: 0 ANSI: 6 [ 2652.103259] sd 2:0:0:0: Attached scsi generic sg0 type 0 [ 2652.104008] sd 2:0:0:0: [sda] 30842880 512-byte logical blocks: (15.8 GB/14.7 GiB) [ 2652.105118] sd 2:0:0:0: [sda] Write Protect is off [ 2652.105120] sd 2:0:0:0: [sda] Mode Sense: 43 00 00 00 [ 2652.105338] sd 2:0:0:0: [sda] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA [ 2652.129919] sda: sda1 sda2 [ 2652.131186] sd 2:0:0:0: [sda] Attached SCSI removable disk 额，结合我lsblk的实验，可以看出U盘的设备名为sda1和sda2。\nlsblk实践 U盘插入前后lsblk输出：\n # U盘插入前 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:0 0 465.8G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot/efi ├─nvme0n1p2 259:2 0 464.3G 0 part / └─nvme0n1p3 259:3 0 976M 0 part [SWAP] # U盘插入后 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 1 14.7G 0 disk ├─sda1 8:1 1 14.1G 0 part └─sda2 8:2 1 298M 0 part nvme0n1 259:0 0 465.8G 0 disk ├─nvme0n1p1 259:1 0 512M 0 part /boot/efi ├─nvme0n1p2 259:2 0 464.3G 0 part / └─nvme0n1p3 259:3 0 976M 0 part [SWAP] ","description":"","id":708,"section":"notes","tags":null,"title":"如何找到U盘设备名","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/debian/%E4%BD%9C%E5%BA%9F/%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0u%E7%9B%98%E8%AE%BE%E5%A4%87%E5%90%8D/"},{"content":"这个需求基本操作一次就不会忘记了，哈哈，还是整理一下吧。\n","description":"","id":709,"section":"notes","tags":null,"title":"如何查看Idea日志","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bidea%E6%97%A5%E5%BF%97/"},{"content":"测试 测试非DTO参数 准备如下测试代码：\n1 2 3 4 5 6 7 8 9  @Validated @Service public class TmpService { public void doService(@JNotBlank String inputParam) { // do something  } }   这份代码有两个地方需要注意：\n 类上的注解只能为@Validated，@Valid并不会生效。 方法参数不需要@Validated、@Valid，我看网上有些教程写了，其实是不需要的。  测试DTO参数 准备如下代码：\n1 2 3 4 5 6 7 8 9  @Validated @Service public class TmpService { public void doService(@Valid TestRequest request) { // do something  } }   在我的测试中，类上的@Validated注解和方法上的@Valid注解，缺一不可，我觉得这是一种非常让人迷惑的写法，一不小心就可能翻车。\n小结 message提示的问题 实验中我其实是有其他收获的，我发现当方法校验失败时，得到的返回结果是（基于我小小开发了一下的校验框架）：\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;doService.inputParam 为空或长度为0\u0026#34; }   也就是说basePath会指明方法及方法的参数。这说明了一个问题，我们开发的用于Request的注解，最好只用于Controller层，否则的话会将内部实现的一些细节暴露给用户。当然不仅仅是我们开发的注解，框架的注解也同样需要存在这个问题，甚至因为没有足够的提示信息，框架的提示信息更让人迷惑。\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;不能为空\u0026#34; }   貌似说我们为注解加上message就可以完事了，这样用户就可以得到清晰明了的信息了，但是，我们应该好好思考一下，我们应该将service层参数校验的信息抛给用户么？我决定在下面好好讨论一下。\n1 2 3 4 5 6  { \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;inputParam不能为空\u0026#34; }   关于异常的讨论 异常目前主要分为两种：系统异常和业务异常，数据库无法获取链接，属于系统异常，一个给定的Id无法从数据库中找到数据，属于业务异常。这些异常都能很好的区分。\n但是因为我们开发的Service往往需要提供给第其他人用，我们需要对传入的参数进行非空等校验，校验失败的时候，我们该抛出什么样的异常呢？系统的还是业务的？我目前的想法还是算作业务异常吧，因为我们写的Service本质上就是业务Service，所以这些Service抛出的异常理应为业务异常。\n从这个分析的角度，我们Controller中对Request的校验失败属于业务异常、Service层方法对参数的校验数据也属于业务异常，我们可以用相同的方式处理。\n异常捕获的问题 目前在参数校验方面，我发现了三种不同的异常，但是我目前用到的主要是两种：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @ResponseBody @ExceptionHandler(value = { MethodArgumentNotValidException.class, ConstraintViolationException.class, BindException.class}) public Response exceptionHandler(Exception e) { String message = \u0026#34;参数校验失败\u0026#34;; if (e instanceof BindException) { message = ((BindException) e).getBindingResult().getFieldError().getDefaultMessage(); } else if (e instanceof ConstraintViolationException) { Optional\u0026lt;String\u0026gt; messageOptional = ((ConstraintViolationException) e).getConstraintViolations() .stream() .map(ConstraintViolation::getMessage) .findFirst(); message = messageOptional.get(); } else { message = ((MethodArgumentNotValidException) e).getBindingResult().getFieldError().getDefaultMessage(); } return new Response(0, message); }   Service层校验失败，抛出来的就是ConstraintViolationException异常。\n另外，关于异常处理，我收集了一段非常不错的代码，之所以觉得它用的好，是因为它使用了orElse，这个方法我使用的次数非常的少。\n1 2 3 4 5 6 7  message e.getConstraintViolations() .stream() .findFirst() .map(ConstraintViolation::getMessage) .orElse(\u0026#34;参数校验失败\u0026#34;))   这是我目前收集的信息。\n参考资料  spring boot 参数校验这么做简洁实用  ","description":"","id":710,"section":"notes","tags":null,"title":"如何校验普通的方法参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%A6%82%E4%BD%95%E6%A0%A1%E9%AA%8C%E6%99%AE%E9%80%9A%E7%9A%84%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0/"},{"content":"我昨天一直在思考Maven Profile与SpringBoot配置文件的关系，想知道Maven Profile中的配置是如何传递给SpringBoot配置文件的，是通过环境变量么？\n我最终获取到了一个项目启动时的Idea运行指令（相关笔记在Idea分类下寻找），我发现这条指令平平无奇，并没有传递任何参数到应用程序。\n我又观察target下classes目录中的配置文件，发现该目录下的application.properties中原有的配置已经被替换为如下内容：\n所以我作出了如下分析，Idea启动前会自动的调用Maven的打包功能，从而生产target目录下的classes等文件，这个过程中我们在Maven项目中配置的Maven过滤器会发挥作用，将文件中引用的特定符号转换成指定的值。\n其实我的代码中并没有配置Maven过滤器插件，为什么application.properties中的@spring.profiles.active@会被Maven过滤器插件转换为Profile的值呢，我个人认为是因为我引入了SpringBoot的打包插件，该插件默认配置了Maven打包插件（我没有证据）。\n我看过网上关于如何使用Maven过滤器插件的文章，它们都是针对application*.yml进行处理，我猜想SpringBoot的打包插件也是这样的（实际上我做了实验，非application*.yml文件的确不会被处理）。\n为了验证我的，我设计了如下实验：先准备一份application-tmp.properties，包含@spring.profiles.active@，然后运行package指令，在target目录下观察application-tmp.properties文件，的确发现进行了字符串的替换。\n综上，我可以解释另一篇笔记中提到的疑问：我如何在application.yml中使用该机制，我只需要在编辑了applicaiton.yml文件后，运行一下package指令就好了（也可以不运行，貌似启动指令会根据Maven Profile帮我们生成新的application.yml文件），如下：\n参考资料  在Spring Boot YML配置文件中使用MAVEN变量@var@ Maven Profile 与 SpringBoot Profile 多环境打包指派指定环境  ","description":"","id":711,"section":"notes","tags":null,"title":"如何理解Maven Profile与SpringBoot配置文件的关系","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3maven-profile%E4%B8%8Espringboot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"content":"《奔跑吧，Ansible》有个小小的问题，它在写下载软件的脚本中没有指定下载的软件的版本，所以我们阅读并执行这些脚本时，往往下载的是最新的版本，最后导致现象不一致。\n如下脚本下载并启动一个Nginx，该Nginx支持tls。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  - name:Config Webservers With Nginx And TLShosts:webserverssudo:Truevars:key_file:/etc/nginx/ssl/nginx.keycert_file:/etc/nginx/ssl/nginx.crtconf_file:/etc/nginx/sites-available/default/nginx.confserver_name:localhosttasks:- name:Install Nginxyum:name=nginx- name:Create Directories For TLS Certificatesfile:path=/etc/nginx/ssl state=directory- name:Copy TLS Keycopy:src=files/nginx.key dest={{ key_file }} owner=root mode=0600notify:restart nginx- name:Copyt TLS Certificatecopy:src=files/nginx.crt dest={{ cert_file }}- name:Generate Nginx Config Filetemplate:src=templates/nginx.conf.j2 dest={{ conf_file }}- name:Enable Configurationfile:dest=/etc/nginx/sites-enabled/default src={{ conf_file }} state=linknotify:restart nginx- name:Generate Index.htmltemplate:src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html mode=0644handlers:- name:restart nginxservice:name=nginx state=restarted  该脚本执行后，并不能Nginx并不能如愿的监听在443端口。观察/etc/nginx/nginx.conf文件后发现，我们的nginx.conf不应该放在/etc/nginx/sites-available/default/nginx.conf，而应该放置在conf.d目录下。\n下面为nginx的配置文件，注意查看几个include配置。\n # For more information on configuration, see: # * Official English Documentation: http://nginx.org/en/docs/ # * Official Russian Documentation: http://nginx.org/ru/docs/ user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic. include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 4096; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } # Settings for a TLS enabled server. # # server { # listen 443 ssl http2; # listen [::]:443 ssl http2; # server_name _; # root /usr/share/nginx/html; # # ssl_certificate \u0026quot;/etc/pki/nginx/server.crt\u0026quot;; # ssl_certificate_key \u0026quot;/etc/pki/nginx/private/server.key\u0026quot;; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 10m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # error_page 404 /404.html; # location = /40x.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } # } } 参考资料  nginx 配置根目录不生效问题  ","description":"","id":712,"section":"notes","tags":null,"title":"学习Ansible发现的Nginx配置问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/%E5%AD%A6%E4%B9%A0ansible%E5%8F%91%E7%8E%B0%E7%9A%84nginx%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/"},{"content":"控制节点  用pip安装Ansible   pip install paramiko PyYAML Jinja2 httplib2 six --user ansible python -m pip install --user ansible 我不知道这样调用的是pip还是pip3，但是我看日志，好像是用Python3的目录下找的模块，应该是pip3。\n由于pip不与系统包管理器协调，它可能会更改您的系统，使其处于不一致或无法运行的状态。对于macOS尤其如此。建议使用\u0026ndash;user安装。\n测试安装结果 测试之前，一定要ssh一次，将目标机器的码加入到known_hosts文件中，否则无法正常测试\n 127.0.0.1 | FAILED! =\u0026gt; { \u0026quot;msg\u0026quot;: \u0026quot;Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host's fingerprint to your known_hosts file to manage this host.\u0026quot; } 我看到有教程可以设置环境便令HOST_KEY_CHECKING=False，但实践中没有效果，所以就放弃环境变量的方案，最后使用了ansible.cfg文件的方案：\n1 2 3 4 5 6 7 8 9 10  mkdir -p /etc/ansible \u0026amp;\u0026amp; tee tee /etc/ansible/ansible.cfg \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [defaults] host_key_checking = False EOF ansible all -m ping --ask-pass   方案一 对官方的方案进行改进：\n1 2 3 4 5 6 7  yum install -y sshpass mkdir -p /etc/ansible \u0026amp;\u0026amp; echo \u0026#34;127.0.0.1\u0026#34; \u0026gt; /etc/ansible/hosts ansible all -m ping --ask-pass   方案二 来自网络上的方案：\n1 2 3 4 5 6 7 8 9 10 11 12  yum install -y sshpass mkdir -p /etc/ansible \u0026amp;\u0026amp; tee tee /etc/ansible/hosts \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; [test] 127.0.0.1 ansible_ssh_user=root ansible_ssh_port=22 ansible_ssh_pass=123456 EOF ansible test -m ping   失败的测试方案  这是官网提供的方案，这个方案不可行，我认为是ANSIBLE_HOSTS环境变量不在支持了  1 2 3 4 5 6  echo \u0026#34;127.0.0.1\u0026#34; \u0026gt; ~/ansible_hosts export ANSIBLE_HOSTS=~/ansible_hosts ansible all -m ping --ask-pass   托管节点  安装Python3  参考教程   Ansible 日常使用技巧 - 运维总结\n干货很多，但是目前能接触到的比较少。\n  ansible配置文件解读\n  ansible不配置ssh免密钥,使用密码登录\n  ansible 提示安装sshpass\n  ","description":"","id":713,"section":"notes","tags":null,"title":"安装Ansible","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/%E5%AE%89%E8%A3%85ansible/"},{"content":"我执行了如下指令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  git clone git://github.com/ansible/ansible.git --recursive cd ./ansible # 使用Bash source ./hacking/env-setup # 安装pip（参考python分类下笔记） # 安装Python模块 pip install paramiko PyYAML Jinja2 httplib2 six # 测试 echo \u0026#34;127.0.0.1\u0026#34; \u0026gt; ~/ansible_hosts export ANSIBLE_HOSTS=~/ansible_hosts ansible all -m ping --ask-pass   参考资料   Installation\n这个教程太老了，还在用Python2，现在Ansible都会提示你使用Python3\n ERROR: Ansible requires Python 3.8 or newer on the controller. Current version: 2.7.5 (default, Oct 14 2020, 14:45:30) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]   ","description":"","id":714,"section":"notes","tags":null,"title":"安装Ansible（废弃）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/ansible/%E5%AE%89%E8%A3%85ansible%E5%BA%9F%E5%BC%83/"},{"content":"操作步骤   下载CentOS 8 dvd的镜像文件（可以避免安装时的网络需求）\n  使用Win32DiskImager制作U盘启动盘（目前这是事最少的方案了）\n  在物理机上进行安装，安装时不要忘记如下工作：\n 在Software Selection中将默认的Server With GUI换成Server（可以节省内存资源） 在Time \u0026amp; Date中将时区改为我们常用的时区 在Network \u0026amp; Host Name中将主机名改为我们cpu的型号，但是不建议打开网络（我个人习惯） 在User Creating中创建一个用户，不建议将这个用户设置为管理员（我个人习惯）    遇到的问题 如果安装以上步骤进行安装，遇到的坑可能是最少的，我尝试过的方案及遇到的问题如下：\n  使用dvd镜像，使用Ultraiso制作U盘启动，目前的问题在于找不到引导程序，这个是存在解决方案的，我在我另一篇文章说明了如何解决这个问题。另外，因为这个方案是很久前用的，我并没有关注是否会遇到我下面描述的其他问题。总之，不推荐这种方案。\n  使用dvd镜像，使用rufus-3.13.exe制作U盘启动，问题在于我使用的是dvd镜像，但是安装引导程序中选择软件源的时候我无法进行任何选择我本地的源，只能使用网络源，这和我的目标并不太相符。\n  使用boot镜像，使用rufus-3.13.exe制作U盘启动，问题是：如果不打开网络，则无法配置软件仓库地址，如果打开网络，安装引导程序就会卡死，我觉得可能是我网络访问外网时速度太慢导致的。\n  我还没有尝试使用Win32DiskImager制作Centos 8 boot版的启动U盘进行安装，不确定这个方案会不会在网络源配置时卡死。但是，还是比较推荐使用dvd版的镜像。\n","description":"","id":715,"section":"notes","tags":null,"title":"安装CentOS 8（推荐）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E5%AE%89%E8%A3%85centos-8%E6%8E%A8%E8%8D%90/"},{"content":"已经拥有更优雅的方案解决该问题了，所以作废该笔记\n因为之前使用Ubuntu系统的时候，总是会遇到一些奇奇怪怪的问题，而且这些问题并不是很好查到资料（Ubuntu更新的太快了，网上的教程往往落后于系统发展，而且我有时候遇到的问题都是别人未遇到过的）。\n所以我一直有计划将我工具机的系统更新为CentOS。之前使用工具机时，我会在工具机里再装虚拟机，为了在我开发机上能通过IP直接访问到工具机上的虚拟机，我又在工具机上安装了OpenVPN，这样我的开发机就可以通过挂OpenVPN，访问工具机上的虚拟网络了，很方便一些软件的测试。另外，我还在工具机上装了形形色色的环境和工具软件，时间长了，我也忘记我工具机的具体环境是怎样的了。\n所以我计划乘着这次重装CentOS系统，我将这些教程再整理一遍，方便我未来还原我工具机的环境。\nCentOS系统的安装 操作步骤 核心操作步骤：\n  下载CentOS 7的镜像文件\n  用Ultraiso制作启动盘\n  在物理机上进行安装\n  这一部分比较简单，具体细节不贴出来了，如果有需要的建议自行百度“物理机上装CentOS”，我参考的教程如下：\n 物理机安装linux系统（centos7.6）  遇到的问题 本着学新不学旧方针，我觉得将Centos 7换成Centos 8，结果在装CentOS 8时就遇到了 dracut initqueue timeout 问题。我参考了如下的教程解决该问题：\n Linux（CentOs 7）系统重装笔记(一) dracut-initqueue timeout 安装CentOS7出现dracut-initqueue timeout的解决办法  我解决该问题的步骤为（这些步骤请参考以上教程食用）：\n 在一次完整的失败安装后，安装并不会退出，而会出现一个命令行工具，在命令行中执行如下代码（我估计我的U盘是sda打头的）：  1 2 3 4  cd /dev/ ls | grep sda   执行该代码后，会显示出两个结果（此时我U盘保持插着的状态），拔下U盘，再次执行该指令，该指令执行结果为空。可以确定U盘为sda4（猜的成分更多）\n重启电脑，进入安装界面，先按TAB后按e，将指令改为：  1 2 3  vmlinuz initrd=initrd.img inst.stage2=hd:/dev/sda4 quiet   如此这个问题就解决了。  20210404补充：\n之前用Ultraiso装Centos 8时出现了一些奇奇怪怪的问题，我用了相对复杂的方案解决这个问题了，但是我越想越不对劲，我认为是引导出问题了，所以换成了rufus-3.13做U盘启动，结果成功解决该问题。即上述的问题，在使用rufus-3.13做U盘启动的时候，并不会出现。\n20210410补充：\nUltraiso和rufus-3.13方案都存在不足，我已经更新为Win32DiskImager方案，目前该方案问题最少。\n","description":"","id":716,"section":"notes","tags":null,"title":"安装CentOS 8，使用Ultraiso制作U盘启动（不推荐）","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/%E5%AE%89%E8%A3%85centos-8%E4%BD%BF%E7%94%A8ultraiso%E5%88%B6%E4%BD%9Cu%E7%9B%98%E5%90%AF%E5%8A%A8%E4%B8%8D%E6%8E%A8%E8%8D%90/"},{"content":"指令如下：\n1 2 3 4 5 6  sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.29.1/docker-compose-Linux-x86_64\u0026#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version    mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version 参考资料   Docker Compose\n教程里的版本太旧了，我用了最新版。\n  docker/compose\n  ","description":"","id":717,"section":"notes","tags":null,"title":"安装Docker Compose","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E5%AE%89%E8%A3%85docker-compose/"},{"content":"官网下载并安装，参考官网的教程启动h2。\n这部分比较简单，稍微尝试一下，很快就可以掌握。\n","description":"","id":718,"section":"notes","tags":null,"title":"安装H2 Console工具","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/datagrip-h2/%E5%AE%89%E8%A3%85h2-console%E5%B7%A5%E5%85%B7/"},{"content":" 下载二进制文件，并解压二进制文件   tar -zxvf helm-v3.5.4-linux-amd64.tar.gz 将二进制文件移动$PATH目录下   mv linux-amd64/helm /usr/local/bin/helm Helm常用指令  添加一个chart仓库，并查看charts列表   helm repo add bitnami https://charts.bitnami.com/bitnami helm search repo bitnami 查看chart详细信息，并安装、卸载chart   helm show chart bitnami/mysql helm show all bitnami/mysql helm install bitnami/mysql --generate-name helm uninstall mysql-1612624192 helm uninstall mysql-1612624192 --keep-history 查看哪些chart被发布了   helm ls helm list 获取帮助信息   helm get -h 参考资料  官方教程：安装Helm Helm二进制文件下载地址 快速入门指南  ","description":"","id":719,"section":"notes","tags":null,"title":"安装Helm（废弃）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/%E5%AE%89%E8%A3%85helm%E5%BA%9F%E5%BC%83/"},{"content":"家里需要使用这个NAS，最终决定还是使用OpenMediaVault，主要原因有如下几点：\n 我的NAS主要用于文件存储，我不折腾什么家庭影音中心 虚拟机部分我主要使用PVE，所以也不需要NAS提供虚拟机功能 Docker部分我有自己的Ubuntu系统，完全可以胜任这个工作，也不需要NAS提供 这个系统是基于Debian的，目前，我用的比较多的三个系统Ubuntu、PVE、OpenMediaVault都是基于Debian了，遇到问题，有一定能力解决  遇到的问题：\n 需要配置多个硬盘，第一个硬盘用来装系统，其他的盘用来存储。  20211022后续：\n后续的学习中，我发现我真正需要的并不是Nas，而是一个网盘程序，所以关于OMV的\n20211025后续：\n后续的学习中，我发现相比于NextCloud，我更需要OMV，但是从大道至简的原则来说，我连OMV也不需要\n参考资料  Proxmox VE(PVE) 安装openmediavault详细教程  ","description":"","id":720,"section":"notes","tags":null,"title":"安装OpenMediaVault","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BD%9C%E5%BA%9F/openmediavault/%E5%AE%89%E8%A3%85openmediavault/"},{"content":"安装vue-cli有如下两种指令：\n npm install vue-cli npm install @vue/cli 第一个指令安装的是2.x，第二条指令安装的是5.x。我之前就是错误的安装了2.x，导致我webstorm无法正确的初始化项目。\n其实官方文档有相关的说明：\n Vue CLI的包名称由vue-cli改成了@vue/cli。如果你已经全局安装了旧版本的vue-cli(1.x或2.x)，你需要先通过npm uninstall vue-cli -g或yarn global remove vue-cli卸载它。\n 参考资料  安装  ","description":"","id":721,"section":"notes","tags":null,"title":"安装vue-cli时踩的坑","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/vue/%E5%AE%89%E8%A3%85vue-cli%E6%97%B6%E8%B8%A9%E7%9A%84%E5%9D%91/"},{"content":"问题描述  执行如下VBoxManage \u0026ndash;version，报如下错误：   WARNING: The vboxdrv kernel module is not loaded. Either there is no module available for the current kernel (4.18.0-240.el8.x86_64) or it failed to load. Please recompile the kernel module and install it by sudo /sbin/vboxconfig You will not be able to start VMs until this problem is fixed. 6.1.18r142142 解决步骤  执行sudo /sbin/vboxconfig后，有如下提示（这不是完整的提示，是我修复了一部分问题后的提示，仅做参考）：   This system is currently not set up to build kernel modules. Please install the Linux kernel \u0026quot;header\u0026quot; files matching the current kernel for adding new hardware support to the system. The distribution packages containing the headers are probably: kernel-devel kernel-devel-4.18.0-240.el8.x86_64 This system is currently not set up to build kernel modules. Please install the Linux kernel \u0026quot;header\u0026quot; files matching the current kernel for adding new hardware support to the system. The distribution packages containing the headers are probably: kernel-devel kernel-devel-4.18.0-240.el8.x86_64 There were problems setting up VirtualBox. To re-start the set-up process, run /sbin/vboxconfig as root. If your system is using EFI Secure Boot you may need to sign the kernel modules (vboxdrv, vboxnetflt, vboxnetadp, vboxpci) before you can load them. Please see your Linux system's documentation for more information. 按照提示安装相应的软件包，具体安装的软件包有（建议按照提示做，仔细读提示，会告诉你缺少哪些软件包）：   dnf install -y gcc make perl dnf install -y kernel-devel 完成如上工作后执行sudo /sbin/vboxconfig依旧报如下错误，仍然提示是kernel-devel的错误，我仔细对比后发现，执行dnf install -y kernel-devel后安装的为kernel-devel-4.18.0-240.22.1.el8_3.x86_64，但是这个和我内核的对不上，我实际上需求为：kernel-devel-4.18.0-240.el8.x86_64。   vboxdrv.sh: Stopping VirtualBox services. vboxdrv.sh: Starting VirtualBox services. vboxdrv.sh: Building VirtualBox kernel modules. This system is currently not set up to build kernel modules. Please install the Linux kernel \u0026quot;header\u0026quot; files matching the current kernel for adding new hardware support to the system. The distribution packages containing the headers are probably: kernel-devel kernel-devel-4.18.0-240.el8.x86_64 This system is currently not set up to build kernel modules. Please install the Linux kernel \u0026quot;header\u0026quot; files matching the current kernel for adding new hardware support to the system. The distribution packages containing the headers are probably: kernel-devel kernel-devel-4.18.0-240.el8.x86_64 There were problems setting up VirtualBox. To re-start the set-up process, run /sbin/vboxconfig as root. If your system is using EFI Secure Boot you may need to sign the kernel modules (vboxdrv, vboxnetflt, vboxnetadp, vboxpci) before you can load them. Please see your Linux system's documentation for more information. 如何处理该问题，我选择去官网手动下载该软件包，拖到服务器后，执行如下指令安装：   # 软件包下载地址 http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/ dnf -y install kernel-devel-4.18.0-240.el8.x86_64.rpm 解决该问题后，执行/sbin/vboxconfig有如下报错，并按照报错查看日志文件有，所以按照日志文件中的提示我又安装了一部分软件：   # 报错 vboxdrv.sh: Stopping VirtualBox services. vboxdrv.sh: Starting VirtualBox services. vboxdrv.sh: Building VirtualBox kernel modules. vboxdrv.sh: failed: Look at /var/log/vbox-setup.log to find out what went wrong. There were problems setting up VirtualBox. To re-start the set-up process, run /sbin/vboxconfig as root. If your system is using EFI Secure Boot you may need to sign the kernel modules (vboxdrv, vboxnetflt, vboxnetadp, vboxpci) before you can load them. Please see your Linux system's documentation for more information. [root@3400g KernelDevel]# cat/var/log/vbox-setup.log -bash: cat/var/log/vbox-setup.log: No such file or directory # 日志文件 Building the main VirtualBox module. Error building the module: make V=1 CONFIG_MODULE_SIG= CONFIG_MODULE_SIG_ALL= -C /lib/modules/4.18.0-240.el8.x86_64/build M=/tmp/vbox.0 SRCROOT=/tmp/vbox.0 -j8 modules make[1]: warning: -jN forced in submake: disabling jobserver mode. Makefile:978: *** \u0026quot;Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel\u0026quot;. Stop. make: *** [/tmp/vbox.0/Makefile-footer.gmk:117: vboxdrv] Error 2 # 安装的软件包 dnf -y install elfutils-libelf-devel 完成如上步骤后，再次执行/sbin/vboxconfig，一路顺顺利利的完成任务了。哈哈，终于拨开云雾见日明，可喜可贺。   [root@3400g ~]# VBoxManage --version 6.1.18r142142 个人小结 之前用Ubuntu时，确实在这些方面没有遇到过这么多问题。但是在解决CentOS的问题时，我需要查的资料数量远远小于Ubuntu，查到的很多资料都是可用的，像我解决的这个问题，甚至在日志信息中都给了足够的解决方案。\n这次我CentOS、VirtualBox和Vagrant都使用了最新版，遇到问题在所难免，但是我感觉这样才有意思，哈哈。\n","description":"","id":722,"section":"notes","tags":null,"title":"安装最新版VirtualBox后，无法启动","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%89%88virtualbox%E5%90%8E%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/"},{"content":"问题描述   我们通过切面编程，自动为进入controller的参数进行aes加密，然而这个接口在window上表现正常，在Linux系统上表现异常。\n  最后发现这个问题很常见，我没有参与这个问题的解决，记录该篇博客，是为了便于下次出现这种问题时，能够第一时间联想到是这个问题。\n  20210440补充：\n我记得网上提供的方法是需要下载个什么jar包，但是我们嫌这种方式太麻烦了，直接改了加密的长度，额，我不确定这种方式好不好。\n","description":"","id":723,"section":"notes","tags":null,"title":"定位Java在Linux上AES加密失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%AE%9A%E4%BD%8Djava%E5%9C%A8linux%E4%B8%8Aaes%E5%8A%A0%E5%AF%86%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题的表现：\n 我们数据库中使用了timestamptz类型 我们代码中使用了LocalDateTime类型 我们的代码使用了LocalDateTimeTypeHandler注解  数据能够正常的入库，但是当从数据库中读取数据的时候，会报timestamp转换异常。我断点发现，报异常的时候，代码并没有进入LocalDateTimeTypeHandler，而是走了PGResultSet，我断定是LocalDateTimeTypeHandler无法进入导致的错误。我以该现象为关键字，寻找解决方案，最后有如下解决方案：\n mybatis-plus: type-handlers-package: com.sdstc.core.mybatisplus.type 参考资料   mybatis plus坑之 - @TableField(typeHandler) 查询时不生效为null\n  更新时自定义的TypeHandler不生效\n我没有看这个教程，但是这篇教程似乎讨论的更深入\n  ","description":"","id":724,"section":"notes","tags":null,"title":"定位并修复TypeHandler的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E5%AE%9A%E4%BD%8D%E5%B9%B6%E4%BF%AE%E5%A4%8Dtypehandler%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"1 2 3 4 5 6 7 8 9  @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { UnixTime m = (UnixTime) msg; ByteBuf encode = ctx.alloc().buffer(4); encode.writeInt((int) m.value); ctx.write(encode, promise); }   几点需要注意的地方：\n  调用ctx的write方法时需要将promise传递过去，我分析如果不传递的话，可能上一层的handler永远得不到通知\n  可以不用调用flush方法，因为ChannelOutboundHandlerAdapter中有如下方法（有点不理解，为什么可以不调用了，那谁在调用呢）：\n  1 2 3 4 5 6 7  @Skip @Override public void flush(ChannelHandlerContext ctx) throws Exception { ctx.flush(); }   测试不传递promise会怎样 代码如下，最终结果和我分析的一致：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  BootstrapUtils.runServer(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline() .addLast(new ChannelOutboundHandlerAdapter() { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { ctx.write(msg, promise); System.out.println(promise); } }) .addLast(new ChannelOutboundHandlerAdapter() { @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { ctx.write(msg, promise); System.out.println(promise); } }) .addLast(new ChannelInboundHandlerAdapter() { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ByteBuf buffer = ctx.alloc().buffer(4); buffer.writeInt(100); ChannelFuture channelFuture = ctx.writeAndFlush(buffer).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { System.out.println(\u0026#34;Write Success\u0026#34;); } }); System.out.println(channelFuture); } }); } });   而且在实验的过程中发现，InboundHandlerAdater中调用writeAndFlush得到的ChannelFuture和各个ChannelOutboundHandlerAdapter中的write方法中的promise参数是同一个对象。\n","description":"","id":725,"section":"notes","tags":null,"title":"实现ChannelOutboundHandlerAdapter需要注意的点","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E6%8A%80%E6%9C%AF%E7%82%B9%E7%A0%94%E7%A9%B6/%E8%A7%A3%E7%A0%81%E5%99%A8/%E5%AE%9E%E7%8E%B0channeloutboundhandleradapter%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%82%B9/"},{"content":"使用管道的方法实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  def create_status(conn, uid, message, *date): pipeline = conn.pipeline(True) pipeline.hget(\u0026#39;user:%s\u0026#39; % uid, \u0026#39;login\u0026#39;) pipeline.incr(\u0026#39;status🆔\u0026#39;) # 对这个键不是很理解 login, id = pipeline.execute() if not login: return None data.update({ \u0026#39;message\u0026#39;: message, \u0026#39;posted\u0026#39;: time.time() \u0026#39;id\u0026#39;: id, \u0026#39;uid\u0026#39;: uid, \u0026#39;login\u0026#39;: login }) pipeline.hmset(\u0026#39;status:%s\u0026#39; % id, data) pipeline.hincrby(\u0026#39;user:%s\u0026#39; % uid, \u0026#39;posts\u0026#39;) pipeline.execute() return id   这是《Redis实战》中的一段代码，看这本书的时候我是跳着看的，所以我没有看到这段代码的讲解，我只能以自己的想法理解这段代码：\n 当这个方法被调用的时候，先判断用户是否处于登录状态，如果不是，则返回 如果用户登录了，则创建一个状态信息，存储到status:uid的键上 最后再更新一下用户posts字段  这个方法的作用叫做发送状态消息，所以我猜测是存在一个逻辑，扫描status:uid，然后作为某个用户的状态信息的。\n","description":"","id":726,"section":"notes","tags":null,"title":"实现状态消息的发送功能","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/scripts/%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%91%E9%80%81%E5%8A%9F%E8%83%BD/"},{"content":"20210430：\n目前我已经为试验机装好了CentOS 8系统，并安装了VirutalBox和Vagrant两款虚拟化软件，我安装好了OpenVPN。我进行了一个简单的测试：开发机上挂VPN，然后在实验机中启动一个虚拟机，在我的开发机上ping这个虚拟机，能够成功的ping通。初步的环境搭建是成功的。\n","description":"","id":727,"section":"notes","tags":null,"title":"实验机基础环境","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%AE%9E%E9%AA%8C%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/"},{"content":"我不计划将实验机器放置在内网环境下，因为实验机器会被很多同事使用，我担心会有同事在该机器上装内网穿透、VPN等工具，从而访问到公司内网的资源，我没有技术能力约束这些事情，所以决定实验机不放置在内网环境下。\n但是我觉得应该有同事有在自己工作的机器上连接实验机器的需求，目前我整理了两套方案，方案如下。\n方案一 由运维提供VPN，实现13网段到17网段的访问。\n该方案的需求：\n 不知道运维能够提供从13网段到17网段的VPN。 不知道运维能否提供一个网线位，用于将实验机器接入到公司17网段。  方案二（自助） 实验机器上安装OpenVPN，通过内网穿透工具暴露OpenVPN的1194端口号，及实验机器的SSH的22端口号。该方案的图示为：\n该方案我已经验证过是可行的。我简单介绍下该方案的设计意图：\n frp做内网穿透，是为了工作环境的机器访问到处于公司wifi环境中的实验机，这个理解比较容易 OpenVPN是为了开发更方便的访问实验机器中的虚拟机，通过OpenVPN，开发可以很方便的ping通实验机器上的所有虚拟机，及虚拟机中的K8S集群。  该方案的需求：\n 运维能否提供一台内外网络够可以访问的虚拟机，作为frp服务端（我目前已有的资源是一台广州的腾讯云服务器，但是处于公网环境） 不知道运维能否提供一个网线位，用于将实验机器接入到公司17网段。  方案三 忽略员工的工作机访问实验机器的请求，员工可以通过自己的笔记本电脑访问该机器。理了理，我比较赞成这种方案，最能避免内网资源的泄漏。\n最终选择的方案 我们最终选择的方案：实验机器接入到公司内网环境，主机会进行物理锁定。\n20210616后续：\n这件事后来又有了调整，我们将机器放到了我们的小机房里，然后走23网段，非我们工作的内网。\n","description":"","id":728,"section":"notes","tags":null,"title":"实验机网络设计","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%AE%9E%E9%AA%8C%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1/"},{"content":"动态调整计划。\n待解决的问题  构建OpenWRT纯净版的img（已完成） 在PVE中安装OpenWRT并研究网关直通技术（不研究直通技术了，意义并不大） 配置OpenWRT，使其可以拨号上网（已完成） 确定自己是否拥有公网IP（已完成，有，但是不是固定IP） 研究DDNS技术（已完成） 学习一些Linux Bridge技术（已完成） 学习虚拟网卡技术（已完成） 研究OpenWRT + OpenVPN（已完成） 研究PVE硬盘直通技术 研究Win10优化技术（减少硬件资源的使用） 研究IDM下载器的使用 需要一个低成本的数据备份方案（可以考虑移动硬盘，但是需要手动备份） 需要一个数据备份方案  已解决的问题  拉取最新的OpenWrt代码，构建包含Frp和OpenVPN插件的img  ","description":"","id":729,"section":"notes","tags":null,"title":"家庭网络方案","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/"},{"content":"输入了正确密码，登录有浏览器仍然不跳转 先说明一下现象，我OpenWRT的密码是正确的，已经通过SSH成功登录了，但是在登录管理页面时，输入密码确认后，会又跳转到登录页面。\n该现象在Edge、Chrome匿名浏览器中不存在，仅在日常使用的Chrome中存在，清空Cookie无法解决该问题。\n对比了成功登录时的网络请求和失败时的网路请求，如下：\n","description":"","id":730,"section":"notes","tags":null,"title":"密码正确，无法登录","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E5%AF%86%E7%A0%81%E6%AD%A3%E7%A1%AE%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95/"},{"content":"我目前通过GitBook发布的笔记大约有300多篇，执行gitbook build的时间大约需要5分钟作用，我觉得这个真的是一个让人无法接受的时间！\n我有计划去探索一些新的文档工具，比如VuePress、docsify、HuGo等，我对新工具的要求是对文档编辑零侵入性，编译速度足够块（VuePress、docsify似乎不需要编译）。\n最近时间比较紧张，我可能没有足够的时间去研究，而且这方面的需求貌似没有那么急。\n","description":"","id":731,"section":"notes","tags":null,"title":"对GitBook不满意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/%E5%AF%B9gitbook%E4%B8%8D%E6%BB%A1%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"技术研究后发现不符合我的需求，故作废\n我开始决定研究这个技术是因为我单纯的想将NextCloud作为一个盘挂载到我OpenWRT上。这样，我就可以用NextCloud的手机客户端将OpenWRT下载的内容下载到手机中，方便我使用这些资源。\n之前之所以Pass掉了Nas方案，是因为我发现一些Nas系统，本身也在使用NextCloud，所以我当时决定直接使用PVE的LCX容器安装NextCloud。\n但是我体验后发现NextCloud根本就无法满足我的需求，那就是一个非常单纯的网盘。它似乎没有办法被挂载到其他的系统上，这样的话，我一开始的设想就无法实现，所以我决定放弃对NextCloud的研究。\n另外，研究NextCloud的时候，我再次意识到PVE真的是个非常强大的虚拟机系统，我要分配时间对此进行深入的学习。\n","description":"","id":732,"section":"notes","tags":null,"title":"对NextCloud的一些看法","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E4%BD%9C%E5%BA%9F/%E5%AF%B9nextcloud%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9C%8B%E6%B3%95/"},{"content":"我的代码如下：\nRequest:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  @Data public class ClientCalibrationReportRequest { /** * 上报内容详情 */ @NotNull private Detail detail; @Data public static class Detail { /** * 白平衡校准数据 */ @NotBlank private String wbs; } }   Controller:\n1 2 3 4 5 6 7 8 9 10 11  @PostMapping(\u0026#34;/client/calibration/report\u0026#34;) public ResponseVo\u0026lt;Object\u0026gt; clientCalibrationReport( @RequestHeader(value = \u0026#34;terminal\u0026#34;) Integer terminal, @Valid @RequestBody ClientCalibrationReportRequest request) { clientCalibrationReportService.saveClientCalibrationReport(terminal, request); return ResponseVo.createSuccess(); }   问题是这样的，我在测试时使用了如下的json：\n1 2 3 4 5 6 7  { \u0026#34;detail\u0026#34;: { // \u0026#34;wbs\u0026#34;: \u0026#34;100\u0026#34;, } }   结果校验依旧通过了，这不符合我的设计，后来我在detail字段上加上了@Valid注解后，能够正常的进行校验。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  @Data public class ClientCalibrationReportRequest { /** * 上报内容详情 */ @NotNull @Valid private Detail detail; @Data public static class Detail { /** * 白平衡校准数据 */ @NotBlank private String wbs; } }   后来我尝试将controller方法中的@Valid移动到ClientCalibrationReportRequest类上，我期待实现统一的注解位置配置，但是很失望，这样是不能够达到我的目标的。这次实验中我使用的是javax.validation.Valid，但是我知道Spring有一个org.springframework.validation.annotation.Validated注解，我不确定该注解能否实现我的目标。\n参考资料  javax框架之@Valid对象嵌套的效验  ","description":"","id":733,"section":"notes","tags":null,"title":"对Request的内部对象进行校验","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%AF%B9request%E7%9A%84%E5%86%85%E9%83%A8%E5%AF%B9%E8%B1%A1%E8%BF%9B%E8%A1%8C%E6%A0%A1%E9%AA%8C/"},{"content":"要想应用程序对WebSocket支持，需要将适当的客户端或者服务端WebSocket ChannelHandler添加到ChannelPipeline中，这个类将处理由WebSocket定义的成为帧的特殊消息类型。\n数据帧：\n BinaryWebSocketFrame：二进制数据 TextWebSocketFrame：文本数据 ContinuationWebSocketFrame：属于上一个BinaryWebSocketFrame或者TextWebSocketFrame的文本的或者二进制数据  控制帧：\n CloseWebSocketFrame：一个CLOSE请求，关闭的状态码以及关闭的原因 PingWebSocketFrame：请求一个PongWebSocketFrame PongWebSocketFrame：对PingWebSocketFrame请求的响应  如果需要为WebSocket添加安全性，只需要将SslHandler作为第一个ChannelHandler添加到Channelpipeline中即可。\n","description":"","id":734,"section":"notes","tags":null,"title":"对WebSocket的支持","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E5%AF%B9websocket%E7%9A%84%E6%94%AF%E6%8C%81/"},{"content":"这次需求的特殊性：\n 有几个字段是List类型的，需要转换成AAA,BBB,CCC形式 有几个字段是JSONArray类型的，需要转换成AAA,BBB,CCC形式 有几个字段是Integer类型的，但是其有自己对应的中文值 有几个字段是LocalDateTime类型的，需要转换成相应的时间  代码结构如下：\n工具类还是之前的功能类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package com.sdstc.tmp.common.utils; import com.alibaba.excel.EasyExcel; import com.alibaba.excel.converters.Converter; import com.alibaba.excel.write.builder.ExcelWriterSheetBuilder; import com.alibaba.excel.write.handler.WriteHandler; import com.alibaba.excel.write.metadata.style.WriteCellStyle; import com.alibaba.excel.write.style.HorizontalCellStyleStrategy; import com.alibaba.excel.write.style.column.LongestMatchColumnWidthStyleStrategy; import org.apache.poi.ss.usermodel.BorderStyle; import org.apache.poi.ss.usermodel.IndexedColors; import java.io.OutputStream; import java.util.ArrayList; import java.util.List; public class EasyExcelUtils { public static void writeExcelWithModel(OutputStream outputStream, List\u0026lt;? extends Object\u0026gt; dataList, Class\u0026lt;? extends Object\u0026gt; classT, String sheetName, WriteHandler... writeHandlers) { ExcelWriterSheetBuilder excelWriterSheetBuilder = EasyExcel.write(outputStream, classT).sheet(sheetName); for (WriteHandler writeHandler : getDefaultWriteHandlerList()) { excelWriterSheetBuilder.registerWriteHandler(writeHandler); } if (null != writeHandlers \u0026amp;\u0026amp; writeHandlers.length \u0026gt; 0) { for (WriteHandler writeHandler : writeHandlers) { excelWriterSheetBuilder.registerWriteHandler(writeHandler); } } // 开始导出  excelWriterSheetBuilder.doWrite(dataList); } private static List\u0026lt;WriteHandler\u0026gt; getDefaultWriteHandlerList() { List\u0026lt;WriteHandler\u0026gt; writeHandlerList = new ArrayList\u0026lt;\u0026gt;(); WriteCellStyle headWriteCellStyle = new WriteCellStyle(); headWriteCellStyle.setWrapped(false); setBorderStyle(headWriteCellStyle); List\u0026lt;WriteCellStyle\u0026gt; contentWriteCellStyleList = new ArrayList\u0026lt;\u0026gt;(); WriteCellStyle writeCellStyle = new WriteCellStyle(); setBorderStyle(writeCellStyle); contentWriteCellStyleList.add(writeCellStyle); writeHandlerList.add(new HorizontalCellStyleStrategy(headWriteCellStyle, contentWriteCellStyleList)); writeHandlerList.add(new LongestMatchColumnWidthStyleStrategy()); return writeHandlerList; } private static void setBorderStyle(WriteCellStyle writeCellStyle) { writeCellStyle.setBorderTop(BorderStyle.THIN); writeCellStyle.setBorderRight(BorderStyle.THIN); writeCellStyle.setBorderBottom(BorderStyle.THIN); writeCellStyle.setBorderLeft(BorderStyle.THIN); writeCellStyle.setTopBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setRightBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setBottomBorderColor(IndexedColors.BLACK.getIndex()); writeCellStyle.setLeftBorderColor(IndexedColors.BLACK.getIndex()); } }   开发了如下的Converts：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  package com.sdstc.tmp.common.utils.converters; import com.alibaba.excel.converters.Converter; import com.alibaba.excel.enums.CellDataTypeEnum; import com.alibaba.excel.metadata.CellData; import com.alibaba.excel.metadata.GlobalConfiguration; import com.alibaba.excel.metadata.property.ExcelContentProperty; public class IsRecommendConverter implements Converter\u0026lt;Integer\u0026gt; { @Override public Class supportJavaTypeKey() { return Integer.class; } @Override public CellDataTypeEnum supportExcelTypeKey() { return CellDataTypeEnum.STRING; } @Override public Integer convertToJavaData(CellData cellData, ExcelContentProperty excelContentProperty, GlobalConfiguration globalConfiguration) throws Exception { throw new RuntimeException(\u0026#34;未实现该操作\u0026#34;); } @Override public CellData convertToExcelData(Integer integer, ExcelContentProperty excelContentProperty, GlobalConfiguration globalConfiguration) throws Exception { switch (integer) { case 0: return new CellData(\u0026#34;否\u0026#34;); case 1: return new CellData(\u0026#34;是\u0026#34;); default: return new CellData(\u0026#34;-\u0026#34;); } } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176  package com.sdstc.tmp.common.utils.converters; import com.alibaba.excel.converters.Converter; import com.alibaba.excel.enums.CellDataTypeEnum; import com.alibaba.excel.metadata.CellData; import com.alibaba.excel.metadata.GlobalConfiguration; import com.alibaba.excel.metadata.property.ExcelContentProperty; import java.util.List; public class IsTopConverter implements Converter\u0026lt;Integer\u0026gt; { @Override public Class supportJavaTypeKey() { return Integer.class; } @Override public CellDataTypeEnum supportExcelTypeKey() { return CellDataTypeEnum.STRING; } @Override public Integer convertToJavaData(CellData cellData, ExcelContentProperty excelContentProperty, GlobalConfiguration globalConfiguration) throws Exception { throw new RuntimeException(\u0026#34;未实现该操作\u0026#34;); } @Override public CellData convertToExcelData(Integer integer, ExcelContentProperty excelContentProperty, GlobalConfiguration globalConfiguration) throws Exception { switch (integer) { case 0: return new CellData(\u0026#34;否\u0026#34;); case 1: return new CellData(\u0026#34;是\u0026#34;); default: return new CellData(\u0026#34;-\u0026#34;); } } } 其他Converter的代码我就不粘贴了。 DTO的代码如下： ~~~ java package com.sdstc.tmp.common.dto; import com.alibaba.excel.annotation.ExcelProperty; import com.alibaba.fastjson.JSONArray; import com.sdstc.tmp.common.utils.converters.*; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.time.LocalDateTime; import java.util.List; @Data @NoArgsConstructor @AllArgsConstructor public class TrendModelDataForExportDTO { /** * 型体号 */ @ExcelProperty(value = \u0026#34;型体号\u0026#34;, index = 0) private String modelNumber; /** * 配色名称 */ @ExcelProperty(value = \u0026#34;配色名称\u0026#34;, index = 1) private String placeHolder = \u0026#34;配色名称\u0026#34;; /** * 款式类型 */ @ExcelProperty(value = \u0026#34;款式类型\u0026#34;, index = 2) private String shapeTypeAllName; /** * 适用品牌 */ @ExcelProperty(value = \u0026#34;款式类型\u0026#34;, index = 3, converter = JSONArrayConverter.class) private JSONArray brands; /** * 工艺（Id转Name后） */ @ExcelProperty(value = \u0026#34;工艺类型\u0026#34;, index = 4, converter = ListConverter.class) private List\u0026lt;String\u0026gt; crafts2; /** * 风格（Id转Name后） */ @ExcelProperty(value = \u0026#34;场景风格\u0026#34;, index = 5, converter = ListConverter.class) private List\u0026lt;String\u0026gt; styles2; /** * 趋势主题 */ @ExcelProperty(value = \u0026#34;趋势主题\u0026#34;, index = 6) private String theme; /** * 流行季节 */ @ExcelProperty(value = \u0026#34;流行季节\u0026#34;, index = 7, converter = JSONArrayConverter.class) private JSONArray seasons; /** * 流行地区（Id转Name后） */ @ExcelProperty(value = \u0026#34;流行地区\u0026#34;, index = 8, converter = ListConverter.class) private List\u0026lt;String\u0026gt; regions2; /** * 趋势标签（Id转Name后） */ @ExcelProperty(value = \u0026#34;趋势标签\u0026#34;, index = 9, converter = ListConverter.class) private List\u0026lt;String\u0026gt; trendTags2; /** * 设计师Name */ @ExcelProperty(value = \u0026#34;设计师姓名\u0026#34;, index = 10) private String designerName; /** * 发布状态（1：未发布，2：已发布） */ @ExcelProperty(value = \u0026#34;是否发布\u0026#34;, index = 11, converter = PublishStatusConverter.class) private Integer publishStatus; /** * 是否置顶（0：否，1：是） */ @ExcelProperty(value = \u0026#34;是否置顶首页\u0026#34;, index = 12, converter = IsTopConverter.class) private Integer isTop; /** * 是否推荐（0：否，1：是） */ @ExcelProperty(value = \u0026#34;是否设为推荐\u0026#34;, index = 13, converter = IsRecommendConverter.class) private Integer isRecommend; /** * 预览次数 */ @ExcelProperty(value = \u0026#34;预览次数\u0026#34;, index = 14) private Integer browseCount; /** * 搭配次数 */ @ExcelProperty(value = \u0026#34;选用次数\u0026#34;, index = 15) private Integer usedCount; /** * 发布人员 */ @ExcelProperty(value = \u0026#34;发布人员\u0026#34;, index = 16) private String publisher = \u0026#34;Placeholder\u0026#34;; /** * 发布时间 */ @ExcelProperty(value = \u0026#34;发布时间\u0026#34;, index = 17, converter = LocalDateTimeConverter.class) private LocalDateTime publishTime; }   测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Test void writeExcelWithModel() { try (OutputStream os = new FileOutputStream(\u0026#34;tmp.xlsx\u0026#34;)) { PageTrendModelRequest request = new PageTrendModelRequest(); request.setCurrent(1); request.setLimit(100); Page\u0026lt;TrendModelData\u0026gt; trendModelDataPage = trendModelService.pageTrendModel(\u0026#34;0\u0026#34;, \u0026#34;0\u0026#34;, request); Page\u0026lt;TrendModelDataForExportDTO\u0026gt; trendModelDataForExportDTOPage = entityPageToResponseDataPage(trendModelDataPage, TrendModelDataForExportDTO.class); // 核心在这儿  EasyExcelUtils.writeExcelWithModel(os, trendModelDataForExportDTOPage.getRecords(), TrendModelDataForExportDTO.class, \u0026#34;测试\u0026#34;); } catch (IOException e) { e.printStackTrace(); } }   最后Controller层代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  /** * 导出 */ @PostMapping(\u0026#34;/trendModel/exportTrendModel\u0026#34;) public ResponseVo\u0026lt;Page\u0026lt;TrendModelData\u0026gt;\u0026gt; exportTrendModel( @RequestHeader(APICons.HEADER_TENANT_ID) String tenantId, @RequestAttribute(APICons.REQUEST_USER_ID) String userId, @RequestBody @Valid PageTrendModelRequest request, HttpServletResponse response) throws IOException { response.setContentType(\u0026#34;application/vnd.ms-excel\u0026#34;); response.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); String fileName = URLEncoder.encode(\u0026#34;趋势款式\u0026#34;, \u0026#34;UTF-8\u0026#34;); response.setHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment;filename=\u0026#34; + fileName + \u0026#34;.xlsx\u0026#34;); return ResponseVo.createSuccessByData(trendModelService.exportTrendModel(tenantId, userId, request, response.getOutputStream())); }   参考资料  easyexcel将数据库枚举字段转换成字符串类型（例：1/男，2/女）的解决方法 EasyExcel 自定义LocalDate类型转换器Converter  ","description":"","id":735,"section":"notes","tags":null,"title":"导出功能的开发","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/%E5%AF%BC%E5%87%BA%E5%8A%9F%E8%83%BD%E7%9A%84%E5%BC%80%E5%8F%91/"},{"content":"将CentOS配置成网关，并不是一个常见的需求，所以不在维护该笔记\n之前的实验中，我发现了如下的问题：\n 没有相应的ifcfg，我手动copy的（已解决） 有很多时候执行nmcli c reload并不会让/etc/sysconfig/network-scripts下的配置文件生效（已解决） enp2s0的ifcfg配置文件不知道该如何写（已解决） 四份ifcfg配置文件中的defaultroute都为yes 存在断线的情况，断线后重连也无法ping通8.8.8.8（已解决）   我的网线是六类网线，B450M上显示1000m，J4125上显示100M，同一个网线的两端 全部机器都重启后，笔记本只能ping通192.168.31.1，其他的都显示Ping：传输事故。常见故障（已解决） 很奇怪的一件事，我笔记长时间未动后，无法正常ping，包括不能ping 172.16.100.1/24网段和ping 8.8.8.8。之前与172.16.100.1/24建立的连接不会受到任何印象，但是无法建立新的连接，表现为之前的ssh连接始终是可用的，但是无法创建新的ssh连接。重启笔记本网卡后，这个问题恢复了。而且，我是可以正常与J4125建立连接的。  我目前挨个挨个解决这些问题，有些问题可能还没有解决方案。\n问题一   删除/etc/sysconfig/network-scripts/下所有的配置文件，然后执行下nmcli c reload\n  然后执行如下4条指令：\n   nmcli conn add con-name enp2s0 ifname enp2s0 type ethernet nmcli conn add con-name enp3s0 ifname enp3s0 type ethernet nmcli conn add con-name enp4s0 ifname enp4s0 type ethernet nmcli conn add con-name enp5s0 ifname enp5s0 type ethernet 如此就在/etc/sysconfig/network-scripts/目录下就生成了4份ifcfg配置文件\n还原拨号上网   nmcli conn add con-name pppoe-home type pppoe ifname enp2s0 username 13022052202D396 password 123456 nmcli conn up pppoe-home nmcli conn up pppoe-home # 关闭 这个地方有些小插曲，我执行了ppp-home添加后，又执行up操作，会提示我出错了，让我看日志信息。我注意到这个时候已经可以ping通了8.8.8.8，所以我分析，add后会理解执行拨号（不太确定哦），我再执行up时发生了冲突，所以报错了。\n而且这个时候执行ifconfig，会发现第一次试验时截图中的ppp1变成了ppp0，我觉得这个应该是没有什么印象的。\n还原192.168.31.1，确保能够在笔记本上ssh  我这次用了如下指令，相比直接改配置文件更优雅一点：\n nmcli connection modify enp3s0 ipv4.addresses 192.168.31.1/24 ipv4.method manual connection.autoconnect yes nmcli connection modify enp4s0 ipv4.addresses 192.168.41.1/24 ipv4.method manual connection.autoconnect yes 这个地方也有小插曲，我执行完指令后注意到：192.168.31.1这个ip地址被分配给了enp5s0网卡，这不符合我的意愿，我注意到nmcli生成的配置文件中没有DEVICE，我手动为4份配置文件加上了DEVICE后，执行nmcli c reload，恢复到正常情况。（我简单验证了下，nmcli命令行貌似不支持DEVICE的设置）\n对比配置文件，我发现connection.autoconnect yes等配置项似乎没有映射到我的配置文件。\n 恢复笔记本上网   iptables -t nat -A POSTROUTING -s 192.168.31.0/24 -j MASQUERADE iptables -t nat -A POSTROUTING -s 172.16.100.0/24 -j MASQUERADE 问题二 ~~~该现象发生的时候，使用nmcli connection modify也无法正常的修改ip地址。~~~ 解决这个问题还有一个办法，就是使用nmcli c reload先加载一下，~~~然后使用nmcli c down先关闭网卡，~~~使用SSH的话，使用down然后再执行up会导致SSH断开链接，我发现直接使用up就可以了，然后再重启，我比较喜欢这个方案，更方便一些。 ## 问题三 使用问题的方法，自动生成一份配置文件，不进行任何改写。 ## 问题四 我目前做了如下的分析： 1. 我使用-j MASQUERADE前，一般都是先ssh到J4125上，然后执行这条指令，我认为此时我的笔记本与J4125已经建立了某种连接，所以导致我此时仍然可以正常访问该机器 2. 当192.168.31.1不可ping通的时候，8.8.8.8也不可ping通，之前认为的将所有的数据包转给了ens2s0网卡的分析应该是站不住脚的，因为这个时候8.8.8.8应该是可以ping通的。 3. VirtualBox的nat模式有个特点：就是虚拟机可以访问主机，访问主机所在网络中的其他机器，但是主机和其他机器无法访问主机。我目前的网络拓补和VirbualBox的nat模式很像，从原理来说，J4125上应该是访问不到我的笔记本的（难道这个是核心的原因么）。但是VMWare中的nat模式，主机和虚拟机是可以互相访问的，这个也没有足够的说服力。 我设计了一写实验： 1. 断开ssh连接，使用netstat -an监控tcp连接，直到两台机器之间没有相关的连接信息了，然后再来进行ping实验（实验结果是依然可以ping通） 2. 重启J4125，然后直接在机器上执行nat指令，在笔记本上进行ping实验（实验结果是依然可以ping通） ## 问题七 我发现网上有其他人也遇到类似的的问题了，在[这篇文章](https://askubuntu.com/questions/1287967/cant-get-rtl8125-realtek-driver-working-on-version-20-04)里，原文简单的摘抄如下： \u0026gt; When you write \u0026quot;...Well the 9.003.05-1 version I found on ElRepo turned out to be buggy...\u0026quot; are you talking about the sub-par speed in one direction when connected to a 1 GbE network? Or something else? ## 问题八 需要再提供更多的关于这个问题的资料。3400G装的是Linux，这台机器可以正常的ping通192.168.31.1、192.168.41.1。我windows机器只能ping通192.168.31.1。 我将window机器的以太网断掉一段时间后，再重新连接，此时连192.168.31.1都无法正常的ping通。 我将3400G机器重启一下后，再重新连接，此时连192.168.41.1都无法正常的ping通。 这个时候将J4125重启一下，可以笔记本就可以正常的ping通192.168.31.1、192.168.41.1了。3400G机器也在J4125重启后可以正常的ping通。 如果重启笔记本，还是无法正常的ping通的，我可以确定不是iptables遭横的原因，我在该问题发生后，清除了所有的iptables，依旧无法ping通。 我现在基本把问题定位在J4125上了。 我注意到每次重连后，arp都无法正确的显示： 重连前 XiaoQiang (192.168.80.1) at ec:41:18:9f:60:45 [ether] on enp2s0\n? (192.168.31.154) at 6c:2b:59:75:6b:e8 [ether] on enp3s0\n? (192.168.41.203) at 2c:f0:5d:24:73:f8 [ether] on enp4s0\n重连后 XiaoQiang (192.168.80.1) at ec:41:18:9f:60:45 [ether] on enp2s0\n? (192.168.31.154) at 6c:2b:59:75:6b:e8 [ether] on enp3s0\n? (192.168.41.203) at  on enp4s0\n 同时我注意到，3400G重启后一直在发送ARP报文 ![2021-05-03-14-17-52](https://junjie2018sz.oss-cn-shenzhen.aliyuncs.com/images/2021-05-03-14-17-52.png) 我是这么分析的，J4125的网卡驱动出了问题，没有正确处理设备的重连，导致3400G实际上根本就没有链接到该机器，也就导致ARP无法更新。怎么验证这个问题呢，我计划加上usb网卡，然后看看能够在usb网卡上重现这个问题。 很难受，我现在基本定位是网卡驱动除了问题，但是这样的话，这个问题就变得非常的复杂了。 我尝试了把驱动降为r8125-9.003.05，没有解决问题！！！ 哈哈哈，终于搞定了，我把内核将到了5.4，然后这个问题恢复了，哈哈哈，很开心。 ## 参考资料 1. [VMware-centos7 添加网卡后发现没有ifcfg-ens网卡配置文件 使用nmcli来配置ip地址并生成配置文件](https://blog.csdn.net/weixin_44654329/article/details/106575526) 学习了如何为新网卡增加配置文件，及一些nmcli指令的应用 2. [linux配置网络，nmcli配置法及直接修改配置文件法](https://www.bilibili.com/read/cv4560096/) 学习到了nmcli conn modify的使用 ","description":"","id":736,"section":"notes","tags":null,"title":"将CentOS配置成路由器问题收集","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/%E5%B0%86centos%E9%85%8D%E7%BD%AE%E6%88%90%E8%B7%AF%E7%94%B1%E5%99%A8%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/"},{"content":"我记得我之前用的并不是这个方案，但是我又找不到之前的资料了，先用下这个方案先。代码如下：\n1 2 3 4  List\u0026lt;String\u0026gt; cities = Arrays.asList(\u0026#34;Milan\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;San Francisco\u0026#34;); String citiesCommaSeparated = String.join(\u0026#34;,\u0026#34;, cities);   参考资料  Java8-如何将List转变为逗号分隔的字符串  ","description":"","id":737,"section":"notes","tags":null,"title":"将List转变成逗号分隔符的字符串","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E5%B0%86list%E8%BD%AC%E5%8F%98%E6%88%90%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E7%AC%A6%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"content":"操作步骤  指令如下   sudo yum -y install mysql 不是整个mysql服务，而仅仅只是mysql客户端，非常好的测试工具。\n","description":"","id":738,"section":"notes","tags":null,"title":"将MySQL客户端安装在CentOS上","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/mysql/%E5%B0%86mysql%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E5%9C%A8centos%E4%B8%8A/"},{"content":"我决定使用nvm技术，故作废该笔记\n我测试工具用的，所以细节处没有太讲究：\n1 2 3 4 5 6 7  sudo yum install epel-release sudo yum install nodejs # 我没有执行这行代码 sudo yum install npm   参考教程  如何在 CentOS 安装 node.js  ","description":"","id":739,"section":"notes","tags":null,"title":"将Node.js安装在CentOS上（作废）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/node.js/%E4%BD%9C%E5%BA%9F/%E5%B0%86node.js%E5%AE%89%E8%A3%85%E5%9C%A8centos%E4%B8%8A%E4%BD%9C%E5%BA%9F/"},{"content":"还不错，打包出来后只有6M多一点，哈哈，虽然我只写了几行代码。\n20210628后续：\n该工具还可以将脚本打包成Linux可执行的文件，记录一下步骤：\n 安装工具pip3 install pyinstaller 检查工具版本pyinstaller -v 执行pyinstaller -F launch.py指令 在dist目录下找生成的可执行文件  参考资料  使用pycharm将python项目打包成exe运行文件  ","description":"","id":740,"section":"notes","tags":null,"title":"将Python脚本打包成可执行文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E5%B0%86python%E8%84%9A%E6%9C%AC%E6%89%93%E5%8C%85%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/"},{"content":"操作步骤  从官网下载源码包   yum install -y gcc mkdir -p ~/Software/Redis \u0026amp;\u0026amp; cd ~/Software/Redis wget http://download.redis.io/releases/redis-5.0.8.tar.gz 解压并编译安装  1 2 3 4 5 6 7 8 9 10  # yum install -y gcc tar -zxvf redis-5.0.8.tar.gz cd redis-5.0.8 make # 指定安装目录 make install PREFIX=/usr/local/redis   设置环境变量  1 2 3 4 5 6 7  sudo tee -a /etc/profile \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; REDIS_HOME=/usr/local/redis PATH=${REDIS_HOME}/bin:${PATH} EOF source /etc/profile   常用指令  常用指令如下   redis-cli -h host.com.cn -p auth password select 12 keys C* del xxxx 相关教程  Centos7安装Redis redis使用redis-cli查看所有的keys及清空所有的数据 通过redis-cli批量删除多个指定模式的key(几乎没用到)  ","description":"","id":741,"section":"notes","tags":null,"title":"将Redis安装在CentOS 7上（废弃）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%B0%86redis%E5%AE%89%E8%A3%85%E5%9C%A8centos-7%E4%B8%8A%E5%BA%9F%E5%BC%83/"},{"content":" 拷贝一份配置文件   cp Software/redis-6.2.6/redis.conf ~/redis.conf  设置daemonize no为daemonnize yes（有时间需要研究一下sed指令了）\n  使用该配置文件启动Redis服务，并使用redis-cli工具进行测试\n   redis-server ~/redis.conf redis-cli ","description":"","id":742,"section":"notes","tags":null,"title":"将Redis配置成后台启动","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E5%B0%86redis%E9%85%8D%E7%BD%AE%E6%88%90%E5%90%8E%E5%8F%B0%E5%90%AF%E5%8A%A8/"},{"content":"操作步骤 方案一 步骤一：启用VirtualBox和EPEL仓库  执行如下命令并启用VirtualBox和EPEL包仓库：  1 2 3  dnf config-manager --add-repo=https://download.virtualbox.org/virtualbox/rpm/el/virtualbox.repo   使用一下rpm命令导入Oracle VirtualBox公钥：  1 2 3  rpm --import https://www.virtualbox.org/download/oracle_vbox.asc   使用以下dnf命令启用EPEL仓库：  1 2 3  dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm -y   步骤二：安装VirtualBox构建工具和依赖项  运行一下命令来安装所有VirtualBox构建工具和依赖项：  1 2 3  dnf install binutils kernel-devel kernel-headers libgomp make patch gcc glibc-headers glibc-devel dkms -y   步骤三：在Centos 8上安装VirtualBox 6.0  成功安装上面的依赖项和构建工具后，使用dnf命令继续安装VirtualBox，先使用如下指令列出所有可安装版本，并进行安装：  1 2 3 4 5  dnf search virtualbox dnf install VirtualBox-6.0 -y   方案二（未测试）：  使用如下指令：  1 2 3  dnf install -y VirtualBox-6.1-6.1.18_142142_el8-1.x86_64.rpm   参考资料  如何在 CentOS 8 / RHEL 8 上安装 VirtualBox 6.0  个人小结 我没有系统学习过EPEL，所以整篇教程我云里雾里，但是目前没有必要在这方面下太大的功夫。\n","description":"","id":743,"section":"notes","tags":null,"title":"将VirtualBox安装到CentOS 8上","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/virtualbox/%E5%B0%86virtualbox%E5%AE%89%E8%A3%85%E5%88%B0centos-8%E4%B8%8A/"},{"content":"应用场景是这样的，平时解决问题时会查大量的资料然后解决问题，等解决了问题后需要将这些资料整理成笔记，但是有时候因为忙暂时无法整理。\n我之前的方式是：设置Chrome开启时打开上次未关闭的页面，结果发现多窗口的场景下可能会导致我的页面丢失，结果就是我的知识丢失。\n新的方案为Ctrl + Shift + D，一键将所有页面保存为书签，书签文件夹在设置为一个时间戳，完美解决这个问题。\n","description":"","id":744,"section":"notes","tags":null,"title":"将当前所有打开的Tab保存到书签","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%B0%86%E5%BD%93%E5%89%8D%E6%89%80%E6%9C%89%E6%89%93%E5%BC%80%E7%9A%84tab%E4%BF%9D%E5%AD%98%E5%88%B0%E4%B9%A6%E7%AD%BE/"},{"content":"需求就是要将某个类中的日志输出到某个文件中，配置和代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  \u0026lt;Appenders\u0026gt; \u0026lt;!-- 用于客户端日志上报 --\u0026gt; \u0026lt;RollingRandomAccessFile name=\u0026#34;CLIENT_LOG\u0026#34; fileName=\u0026#34;${LOG_HOME}/${APP_NAME}_${INFO_LOG_FILE_NAME}_Client_Log.log\u0026#34; filePattern=\u0026#34;${LOG_HOME}/${APP_NAME}_${INFO_LOG_FILE_NAME}_Client_Log.log.%d{yyyy-MM-dd}.gz\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;128MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;30\u0026#34;/\u0026gt; \u0026lt;/RollingRandomAccessFile\u0026gt; \u0026lt;!-- 用于硬件信息上报 --\u0026gt; \u0026lt;RollingRandomAccessFile name=\u0026#34;CLIENT_CALIBRATION_REPORT\u0026#34; fileName=\u0026#34;${LOG_HOME}/${APP_NAME}_${INFO_LOG_FILE_NAME}_Client_Calibration_Report.log\u0026#34; filePattern=\u0026#34;${LOG_HOME}/${APP_NAME}_${INFO_LOG_FILE_NAME}_Client_Calibration_Report.log.%d{yyyy-MM-dd}.gz\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;Filters\u0026gt; \u0026lt;ThresholdFilter level=\u0026#34;info\u0026#34; onMatch=\u0026#34;ACCEPT\u0026#34; onMismatch=\u0026#34;DENY\u0026#34;/\u0026gt; \u0026lt;/Filters\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;SizeBasedTriggeringPolicy size=\u0026#34;128MB\u0026#34;/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;DefaultRolloverStrategy max=\u0026#34;30\u0026#34;/\u0026gt; \u0026lt;/RollingRandomAccessFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;AsyncLogger name=\u0026#34;com.sdstc.message.service.impl.ClientLogServiceImpl\u0026#34; level=\u0026#34;debug\u0026#34; includeLocation=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CLIENT_LOG\u0026#34;/\u0026gt; \u0026lt;/AsyncLogger\u0026gt; \u0026lt;AsyncLogger name=\u0026#34;com.sdstc.message.service.impl.ClientCalibrationReportServiceImpl\u0026#34; level=\u0026#34;debug\u0026#34; includeLocation=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CLIENT_CALIBRATION_REPORT\u0026#34;/\u0026gt; \u0026lt;/AsyncLogger\u0026gt; \u0026lt;/Loggers\u0026gt;   代码中就是普通的获取Logger，然后进行日志输出。\n参考资料  【log4j2打印日志】指定日志打印到指定文件  ","description":"","id":745,"section":"notes","tags":null,"title":"将指定日志输出到指定文件","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E5%B0%86%E6%8C%87%E5%AE%9A%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E5%88%B0%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6/"},{"content":"之前没有发现Chrome导出书签的时候默认不支持导出某个文件夹，只能将全部的书签到导出来。解决方案是新创建一个Chrome账户，然后将需要导出的文件夹拖过去，再导出来。\n目前没有发现更好的方案了，难受。\n","description":"","id":746,"section":"notes","tags":null,"title":"将某个文件夹下的书签导出来","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E5%B0%86%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E7%9A%84%E4%B9%A6%E7%AD%BE%E5%AF%BC%E5%87%BA%E6%9D%A5/"},{"content":"20210504：\n我工具机的网络环境设计的比较复杂，但是目前实现的还比较简单，我打算以后慢慢完善。我今天理了理我虚拟机的规划。\n虚拟机规划 我决定将服务分为稳定性和非稳定性，目前有如下设计：\n稳定：\n 数据库程序（PG、MySQL） Rancher Harbor NFS Applo  非稳定：\n K8s集群，及集群中的所有应用  我计划单独开一个虚拟机，划分较大的内存，专门安装这些稳定性的服务。这个过程中，我尽量做好相关数据的保护工作，避免我虚拟机重装后，这些应用的数据都没了（Vagrant支持将主机目录挂载到虚拟机上）。\n稳定应用中可能有部分非常的稳定，比如NFS，我计划直接在主机上安装。\n非稳定的，比如K8s，我基本不会考虑数据安全问题，但凡虚拟机出问题了，我会直接销毁重建所有的虚拟机。所以，这些非稳定的服务的搭建资料，就非常重要，可以用这些资料很快的还原出这些服务。\n网络规划 我工具机使用了172.16.100.0/24网段，之前的192.168网段许多内部网络冲突，我未来的目标是可以在任意场合轻松的通过内网穿透+OpenVPN，访问到我的家庭内部网络。\n我J4125上使用的ip是172.16.0.1，工具机上的ip是172.16.0.2，我计划以后ip的第四段，100以下的都用于物理机，100以上都用于虚拟机。\n","description":"","id":747,"section":"notes","tags":null,"title":"工具机基础环境","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%B7%A5%E5%85%B7%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/"},{"content":"创建虚拟机 我使用了Vagrant + VirtualBox创建和管理虚拟机。我这些Vagrant配置文件和使用的Box，都是高度定制化的，大家环境不一致，是不可以直接使用的。\n我会提供一个github地址，将我用到vagrant脚本放置在里面。\n有以下建议：\n  主机不要安装Docker，安装Docker会增加虚拟网卡，在使用Vagrant时需要手动选择网卡。\n  我发现搞性能CPU真的很重要，我的3400G启动一个虚拟机要很长的时间，很难受。\n  考虑到没个虚拟机都要下载Docker，是很慢的一件事，我这块使用了Vagrant自制Box技术。\n  master机器上装docker-compose master机器上装Harbor ","description":"","id":748,"section":"notes","tags":null,"title":"工具机操作记录","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%B7%A5%E5%85%B7%E6%9C%BA%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95/"},{"content":"这是我工具集的设计思路：\nhttps://blog.csdn.net/qmhball/article/details/86719671\nhttps://hhbbz.github.io/2019/03/31/jdbcTemplate%E9%AB%98%E6%95%88%E7%8E%87%E8%8E%B7%E5%8F%96%E8%A1%A8%E7%BB%93%E6%9E%84%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%83%E6%95%B0%E6%8D%AE%E4%BF%A1%E6%81%AF/\nhttps://blog.csdn.net/weixin_38450840/article/details/80812572\nhttps://blog.csdn.net/fzz19960915/article/details/70948553\nhttps://hellosean1025.github.io/yapi/documents/data.html#postman-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5\nhttps://www.jianshu.com/p/1361f1f43e99\nhttps://blog.csdn.net/wangyijie521/article/details/112844717\nhttps://www.cnblogs.com/hellojesson/p/12109312.html\nhttps://blog.csdn.net/wangxiaotongfan/article/details/93498164\nhttps://blog.csdn.net/huangbaokang/article/details/88862791\n","description":"","id":749,"section":"notes","tags":null,"title":"工具集设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E9%9B%86/%E5%B7%A5%E5%85%B7%E9%9B%86%E8%AE%BE%E8%AE%A1/"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;select id=\u0026#34;pageUserInfoByAccount\u0026#34; resultType=\u0026#34;com.sdstc.authcenter.pojo.UserAndCompany\u0026#34;\u0026gt; SELECT tu.id as id, tu.name as name , tu.company_id as companyId, tu.mobile as mobile, tc.name as companyName FROM t_user tu JOIN t_company tc on tc.id = tu.company_id AND tu.is_delete = \u0026#39;0\u0026#39; \u0026lt;if test=\u0026#34;@org.apache.commons.lang3.StringUtils@isNotBlank(account)\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;account\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + account\u0026#34;/\u0026gt; AND tu.account LIKE #{account} \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt;   收集点：\n bind标签放在了if标签的内部 if标签中使用了lang3的StringUtils.isNotBlank()  参考资料  Mybatis中xml判断字符串不为空和null简单方法  ","description":"","id":750,"section":"notes","tags":null,"title":"常用代码收集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E6%94%B6%E9%9B%86/"},{"content":" 查看CPU和硬盘概要：   pveperf 查看设备信息   lspci ","description":"","id":751,"section":"notes","tags":null,"title":"常用指令","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"content":"需求过少，不在维护\n regedit  打开注册表\nmstsc  打开远程桌面\ncontrol  打开控制面板\nmsconfig  可以用来设置引导，从而进入安全模式。\nservices.msc  打开Windows的服务\n","description":"","id":752,"section":"notes","tags":null,"title":"常用的命令","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4/"},{"content":"常用资源 服务器  kvm.yunserver.com 搬瓦工 Hostwinds Linode  教程  V2RaySSR综合网  多地检测到国外服务器的延迟  打开https://ping.chinaz.com/，输入需要检测的ip地址  检测自己外网IP是否被墙  打开https://www.vps234.com/ipchecker/，输入需要检测的ip地址  参考资料  IPChecker检查IP是否被墙的利器，通过这个工具轻松检查IP是否被封 IP被墙检测网站  ","description":"","id":753,"section":"notes","tags":null,"title":"常用资源整理","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E5%B8%B8%E7%94%A8%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86/"},{"content":"因为kc connect在windows机器上存在太多问题，每个人都有不同的状况，所以我想在linux上开一个kt connect，然后大家将代理设置成这个实例即可。\n代码如下：\n ktctl -n dev -c /root/.kube2/config connect --method socks5 --dump2hosts 实践的过程中有如下问题：\n  我机器上已经在管理一个k8s集群了，所以我需要为ktctl工具指定另一份配置文件。\n  ktctl默认监听在127.0.0.1，而且没有提供参数修改这个地址，所以我选择使用一些特殊的工具完成端口映射。具体的笔记在Linux分类下可以找到，我这儿就不呈现了。\n  ","description":"","id":754,"section":"notes","tags":null,"title":"开一个kt connect服务多台机器","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/%E5%BC%80%E4%B8%80%E4%B8%AAkt-connect%E6%9C%8D%E5%8A%A1%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8/"},{"content":"一个约束注解可以关联多个验证器，根据要验证的属性类型选择合适的验证器，及代码中可能有如下写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE }) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {AgeIntegerValidtor.class, AgeStringValidtor.class}) public @interface Age { } public class AgeIntegerValidtor implements ConstraintValidator\u0026lt;Age, Integer\u0026gt; { @Override public boolean isValid(Integer value, ConstraintValidatorContext context) { } } public class AgeStringValidtor implements ConstraintValidator\u0026lt;Age, Integer\u0026gt; { @Override public boolean isValid(Integer value, ConstraintValidatorContext context) { } }   之所以单独提一下这件事，是因为这件事我之前从未注意到。\n","description":"","id":755,"section":"notes","tags":null,"title":"开发自定义参数校验注解时需要注意的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E5%BC%80%E5%8F%91%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"先直接呈现各种调试后的代码吧\napplication.yml\n1 2 3 4  tmp2:weight:10kg  Weight.java\n1 2 3 4 5 6 7 8  @Data @AllArgsConstructor @NoArgsConstructor public class Weight { private Long weight; }   WeightConvert.java\n1 2 3 4 5 6 7 8 9 10 11  public class WeightConverter implements Converter\u0026lt;String, Weight\u0026gt; { @Override public Weight convert(String source) { if (source.endsWith(\u0026#34;kg\u0026#34;)) { return new Weight(Long.valueOf(source.substring(0, source.length() - 2))); } return null; } }   TmpConfiguration.java\n1 2 3 4 5 6 7 8 9 10  @Configuration public class TmpConfiguration { @Bean @ConfigurationPropertiesBinding public WeightConverter weightConverter() { return new WeightConverter(); } }   Tmp2Properties.java\n1 2 3 4 5 6 7 8  @Data @Component @ConfigurationProperties(prefix = \u0026#34;tmp2\u0026#34;) public class Tmp2Properties { private Weight weight; }   实验总结 本次实验中最核心的一点是要将WeightConverter注入到Spring Context中，并让Spring Context知道这个类是用来做转换的。实验中采用了如下的代码实现：\n1 2 3 4 5 6 7  @Bean @ConfigurationPropertiesBinding public WeightConverter weightConverter() { return new WeightConverter(); }   其中@ConfigurationPropertiesBinding注解就是让Spring Boot知道使用该住户按期做数据绑定。在理解这个实验核心的部分后，我们可以使用如下的方式开发Converter，并移除TmpConfiguration.java。\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Component @ConfigurationPropertiesBinding public class WeightConverter implements Converter\u0026lt;String, Weight\u0026gt; { @Override public Weight convert(String source) { if (source.endsWith(\u0026#34;kg\u0026#34;)) { return new Weight(Long.valueOf(source.substring(0, source.length() - 2))); } return null; } }   参考资料  @ConfigurationProperties 注解使用姿势，这一篇就够了  ","description":"","id":756,"section":"notes","tags":null,"title":"开发自己的Convert，用在application.yml解析中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84convert%E7%94%A8%E5%9C%A8application.yml%E8%A7%A3%E6%9E%90%E4%B8%AD/"},{"content":"这部分我还没有系统研究，所以只能写一个Demo，我之所以注意到这个问题，是因为我们项目中，如果遇到404错误，会返回一个空的请求体，这使我在测试代码时非常的迷惑，所以我决定修改这部分的实现，让404错误也返回我们制定的统一返回框架。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @RestController public class MyErrorController implements ErrorController { @Data @NoArgsConstructor @AllArgsConstructor public static class ResponseVo { private String code; private String msg; } @RequestMapping(\u0026#34;/error\u0026#34;) public ResponseVo error(HttpServletRequest request) { return new ResponseVo(\u0026#34;404\u0026#34;, \u0026#34;NotFound\u0026#34;); } }   参考资料  Spring Boot 实现ErrorController接口处理404、500等错误页面  ","description":"","id":757,"section":"notes","tags":null,"title":"开发自己的ErrorController","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84errorcontroller/"},{"content":"拦截器代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  @Slf4j public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { log.info(\u0026#34;preHandle Running\u0026#34;); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { log.info(\u0026#34;postHandle Running\u0026#34;); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { log.info(\u0026#34;afterCompletion Running\u0026#34;); } }   配置拦截器的代码如下：\n1 2 3 4 5 6 7 8 9 10 11  @Configuration public class WebConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new MyInterceptor()) .addPathPatterns(\u0026#34;/**\u0026#34;) .excludePathPatterns(\u0026#34;/\u0026#34;, \u0026#34;/login\u0026#34;, \u0026#34;/css/**\u0026#34;); } }   遇到的问题：\n WebConfig类上忘记@Configuration，导致配置的拦截器不生效。  拦截器原理  根据当前请求，找到HandlerExecutionChain（可以处理请求的handler以及handler的所有拦截器）   先来顺序执行 所有拦截器的 preHandle方法\n 如果当前拦截器prehandler返回为true。则执行下一个拦截器的preHandle 如果当前拦截器返回为false。直接倒序执行所有已经执行了的拦截器的afterCompletion 如果任何一个拦截器返回false。直接跳出不执行目标方法    所有拦截器都返回true。执行目标方法\n  倒序执行所有拦截器的postHandle方法。\n  前面的步骤有任何异常都会直接倒序触发afterCompletion\n  页面成功渲染完成以后，也会倒序触发afterCompletion\n  拦截器的应用 UserInfoInterceptor 这个拦截器是用于拦截token信息的，我现在逐行研究该拦截器的实现：\n1 2 3 4 5  if (response.getStatus() == HttpServletResponse.SC_NOT_FOUND) { return false; }   这行代码是想处理404错误，目前的实现方案会导致调用接口时如果接口不存在，则返回空请求体。我建议是实现ErrorController解决该问题。\n1 2 3 4 5 6 7 8 9 10 11  // 如果不是映射到方法直接通过 if (!(object instanceof HandlerMethod)) { return true; } if (request.getRequestURI().contains(\u0026#34;/internal/\u0026#34;)) { return true; }   我不知道这两行代码的含义，我不确定在什么情况下不是映射到方法。而且，在我看来，我们应该在拦截器处时，排除掉静态资源的URL。同样的对于/internal资源，我们可以在配置拦截器时排除掉。\n1 2 3 4 5 6 7 8 9 10 11  //检查是否有passtoken注释，有则跳过认证 HandlerMethod handlerMethod = (HandlerMethod) object; Method method = handlerMethod.getMethod(); if (method.isAnnotationPresent(PassToken.class)) { PassToken passToken = method.getAnnotation(PassToken.class); if (passToken.required()) { return true; } }   这一段代码是说，如果我们的方法被@PassToken注解了，则直接放行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  String userJson = request.getHeader(\u0026#34;user\u0026#34;); JSONObject user; if (StringUtils.isEmpty(userJson)) { if (StringUtils.isEmpty(request.getHeader(APICons.TOKEN))) { throw new TokenNotFoundException(\u0026#34;token required\u0026#34;); } else { user = apiUtils.currentUser(); if (user == null) { throw new PermissionException(\u0026#34;not authorized\u0026#34;); } } } else { try { userJson = URLDecoder.decode(userJson, \u0026#34;utf-8\u0026#34;); user = JSONObject.parseObject(userJson); } catch (UnsupportedEncodingException e) { throw new ValidateException(\u0026#34;user info not validate\u0026#34;); } } request.setAttribute(APICons.REQUEST_USER, user); request.setAttribute(APICons.REQUEST_USER_ID, user.getString(\u0026#34;id\u0026#34;)); request.setAttribute(APICons.REQUEST_COMPANY_ID, user.getString(\u0026#34;companyId\u0026#34;));   接下来，我们尝试从Header中获取User信息，如果获取的用户信息为空，我们尝试获取Token信息，如果Token信息也为空，则我们抛出异常。如果Token信息不为框，则我们用Token从Redis中获取用户的信息；如果获取的用户信息不为空，则我们直接解析Token的信息。\n最后将解析的信息塞到Attributes中，完美收工。\n最后，对该拦截器的配置如下，配置的项过于粗糙，导致我们需要在拦截器中进行假设。\n1 2 3  registry.addInterceptor(userInfoInterceptor).addPathPatterns(\u0026#34;/**\u0026#34;).order(3);   RequestInfoForwardInterceptor 该拦截器是为了让我们的所有返回体带上我们的trace code，核心代码如下：\n1 2 3  response.setHeader(APICons.TRACKING_CODE, request.getHeader(APICons.TRACKING_CODE));   ","description":"","id":758,"section":"notes","tags":null,"title":"开发自己的Interceptor","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84interceptor/"},{"content":"引入如下依赖：\n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;   SpringBoot做了如下工作：\n  自动配置好SpringMVC\n 引入SpringMVC全套组件 自动配置SpringMVC常用组件（功能）    自动配置Web常见功能\n SpringBoot帮我们配置好了所有web开发的常见场景    默认的包结构\n 主程序所在包及其下面的所有子包里面的组件都会被默认扫描进来 无需以前的包配置扫描 如果想该表扫描路径  @SpringBootApplication(scanBasePackages=\u0026ldquo;com.atguigu\u0026rdquo;) 或者@ComponentScan 指定扫描路径      各种配置拥有默认值\n 默认配置最终都是映射到某个类上，如：MultipartProperties 配置文件的值最终会绑定每个类上，这个类会在容器中创建对象    按需加载所有自动配置项\n 引入非常多的Starter 引入了哪些场景这个场景的自动配置才会开启 SpringBoot所有的自动配置功能都在spring-boot-autoconfigure包里面    ","description":"","id":759,"section":"notes","tags":null,"title":"引入spring-boot-starter-tomcat时做了什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E5%BC%95%E5%85%A5spring-boot-starter-tomcat%E6%97%B6%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88/"},{"content":"这个稍微有点违背我的使用习惯，但是问题还不太严重，具体问题描述如下：\n 我DataGrip指定了h2的数据库文件，url为：jdbc:h2:file:~/test2;AUTO_SERVER=TRUE; 我Java代码中指令了h2的数据库文件，url为：jdbc:h2:file:~/test2;AUTO_SERVER=TRUE;  结果我Java代码启动的时候会报如下的错误：\n Caused by: java.lang.IllegalStateException: The file is locked: nio:C:/Users/wujj/test2.mv.db [1.4.200/7] at org.h2.mvstore.DataUtils.newIllegalStateException(DataUtils.java:950) at org.h2.mvstore.FileStore.open(FileStore.java:172) at org.h2.mvstore.MVStore.\u0026lt;init\u0026gt;(MVStore.java:381) at org.h2.mvstore.MVStore$Builder.open(MVStore.java:3579) at org.h2.mvstore.db.MVTableEngine$Store.open(MVTableEngine.java:170) ... 117 more 这个现象从原理上很好理解的，两个进程操作同一个文件，会造成很多的问题，所以将这个文件锁住，阻止另一个文件访问时很有必要的。\n","description":"","id":760,"section":"notes","tags":null,"title":"当在url中指定文件路径时，不允许两个客户端同时链接","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/datagrip-h2/%E5%BD%93%E5%9C%A8url%E4%B8%AD%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E6%97%B6%E4%B8%8D%E5%85%81%E8%AE%B8%E4%B8%A4%E4%B8%AA%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%8C%E6%97%B6%E9%93%BE%E6%8E%A5/"},{"content":"现在很少修改输入法了，故作废\n问题描述 系统更新前，在语言选项中删除了微软输入法，但是系统更新后，微软输入法又被系统自动添加进来了。且这个时候去输入法选项中看的时候，是没有微软输入法的，感觉微软输入法貌似成了内置不可修改的选项（我被迷惑了很长时间，直到忍无可忍）。\n这个时候你只需要先添加一下微软输入法，然后再删除掉它就可以了。\n可能很少人遇到类似的问题吧。哈哈\n","description":"","id":761,"section":"notes","tags":null,"title":"微软输入法已禁用但是还是可以切换出来","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E5%BE%AE%E8%BD%AF%E8%BE%93%E5%85%A5%E6%B3%95%E5%B7%B2%E7%A6%81%E7%94%A8%E4%BD%86%E6%98%AF%E8%BF%98%E6%98%AF%E5%8F%AF%E4%BB%A5%E5%88%87%E6%8D%A2%E5%87%BA%E6%9D%A5/"},{"content":"快速使用的指令如下：\n nodeppt new slide.md nodeppt serve slide.md nodeppt build slide.md 有意思的是，使用了nodeppt serve指令后，可以实时的编辑并渲染ppt。\nDemo代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  title: Demo speaker: JJ plugins: - echarts \u0026lt;slide class=\u0026#34;bg-black-blue aligncenter\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; # Demo {.text-landing.text-shadow}  By JJ {.text-intro} [:fa-github: Github](https://github.com/ksky521/nodeppt){.button.ghost} \u0026lt;slide class=\u0026#34;bg-black-blue\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; 第一页 \u0026lt;slide class=\u0026#34;bg-black-blue\u0026#34; image=\u0026#34;https://source.unsplash.com/C1HhAQrbykQ/ .dark\u0026#34;\u0026gt; 第二页   参考资料  nodeppt 2.0  ","description":"","id":762,"section":"notes","tags":null,"title":"快速使用NodePPT的指令","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/nodeppt/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8nodeppt%E7%9A%84%E6%8C%87%E4%BB%A4/"},{"content":"我之前为了避免all_proxy给我实验代理不好的影响，我会直接新起一个shell。新的方案如下：\n unset all_proxy 参考资料  pip install报错：Missing dependencies for SOCKS support解决方法  ","description":"","id":763,"section":"notes","tags":null,"title":"快速取消代理设置","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%BF%AB%E9%80%9F%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"},{"content":"15号博文\n今天到新公司入职，公司电脑的配置不错，所以可能未来很长时间都会使用公司的电脑。\n在搭建自己开发环境时，我遇到了一些问题，需要记录在自己的博客中，所以需要公司电脑上也搭建自己的博客开发平台。上次搭建博客开发平台是很久以前的事了，很多细节都已经忘记了，我正好可以整理下，方便以后还原自己的博客开发环境。\n这篇博客我计划分为两部分，一部分为“快速搭建”，记录仅仅为完成我本次最基本需求所需要的操作。另一部分为“后续补充”，记录我未来为了让自己开发更舒适，而逐渐增加的操作等。\n快速搭建   下载VS Code\n  下载Markdown All In One插件\n  下载Paste Image插件，进行配置 (这部分忘记了，需要回忆下)\n  后续补充   下载Markdown Preview Enhanced插件\n  下载IntellJ IDEA Keybindings插件\n  ","description":"","id":764,"section":"notes","tags":null,"title":"快速搭建博客开发平台","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%BC%80%E5%8F%91%E5%B9%B3%E5%8F%B0/"},{"content":"我之前用VS Code打开一个文件夹，需要先打开这个文件夹，然后右键选择使用VS Code打开，感觉操作步骤还挺多的。所以我开发了下面的小脚本，感觉还不错。\n1 2 3 4 5 6 7  @echo off REM start your program, if the path has space start \u0026#34;\u0026#34; \u0026#34;D:\\Software\\Microsoft VS Code\\Code.exe\u0026#34; \u0026#34;D:\\Blogs\u0026#34; REM exit this cmd exit   因为bat的图标不好看，我又修改了一下文件的图标，具体操作如下：\n 将bat放到D盘中，然后再桌面上创建一个快捷方式 修改快捷方式名称为Blogs 右键快捷方式，选择属性，选择修改图表，然后选择一个新的图标（可以参考其他快捷方式的图标）  幸福度+1，非常满意。\n","description":"","id":765,"section":"notes","tags":null,"title":"快速用VSCode打开一个文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E5%BF%AB%E9%80%9F%E7%94%A8vscode%E6%89%93%E5%BC%80%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"我竟然发现我一直没有整理这个，今天急用，找不到相关的笔记。\npom配置如下：\n1 2 3 4 5 6  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;   application.yml配置如下：\n management: endpoints: web: exposure: include: '*' 观察日志：\n我有几次这样配置了，接口还是无法访问，重启多次后才恢复，我不确定是哪块出问题了，所以建议看到日志文件后再访问接口。\n","description":"","id":766,"section":"notes","tags":null,"title":"快速配置Actuator","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AEactuator/"},{"content":"当客户端加载好后，会想服务端发送一个已加载\n","description":"","id":768,"section":"notes","tags":null,"title":"房间服务的设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E8%BF%9E%E8%BF%9E%E7%9C%8B%E8%81%94%E6%9C%BA%E7%89%88/%E6%88%BF%E9%97%B4%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"content":"打包成tar文件 这条指令需要传递两个参数，我容易忘记另一个参数：\n tar -cvf feeds.tar feeds/ ","description":"","id":769,"section":"notes","tags":null,"title":"打包成tar文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/%E6%89%93%E5%8C%85%E6%88%90tar%E6%96%87%E4%BB%B6/"},{"content":"之前在解决一个技术问题时发现Maven打包时很难实现将空文件夹从Resources目录复制到target下（我尝试过很多插件，都没有效果）。\n因为我打包使用的是SpringBoot的打包插件，所以具体什么原因导致的这个问题我很难定位，所以暂不修复。\n","description":"","id":770,"section":"notes","tags":null,"title":"打包时空文件夹问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E6%89%93%E5%8C%85%E6%97%B6%E7%A9%BA%E6%96%87%E4%BB%B6%E5%A4%B9%E9%97%AE%E9%A2%98/"},{"content":" 美团技术团队  ","description":"","id":771,"section":"notes","tags":null,"title":"技术博客整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E6%95%B4%E7%90%86/"},{"content":"报错如下：\n SyntaxError: Non-ASCII character '\\xe2' in file 我选择的解决方式是从调用python3而不是python，我系统里存在两个版本的python3，经常用错这个东西。其他解决方案有：Python报错：(编码问题)SyntaxError: Non-ASCII character \u0026lsquo;\\xe2\u0026rsquo; in file，但是我并没有实践过。\n","description":"","id":772,"section":"notes","tags":null,"title":"报错Non-ASCII character in file","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E6%8A%A5%E9%94%99non-ascii-character-in-file/"},{"content":"报错如下：\n The connection to the server localhost:8080 was refused - did you specify the right host or port? 是因为我忘记执行如下代码：\n mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 参考资料  The connection to the server localhost:8080 was refused - did you specify the right host or port?  ","description":"","id":773,"section":"notes","tags":null,"title":"报错：connect was refused","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%8A%A5%E9%94%99connect-was-refused/"},{"content":"因为MyBatis的分页插件在处理PG复杂语法时无法拼接排序条件，所以排序项的逻辑需要自己拼接，主要逻辑为收集各个排序项，然后再Mapper中通过foreach进行拼接。\n拼接时需要额外注意一下，不能使用$符号，而要使用#：\n1 2 3 4 5 6 7 8 9  \u0026lt;if test=\u0026#34;@org.apache.commons.collections4.CollectionUtils@isNotEmpty(orderItems)\u0026#34;\u0026gt; order by \u0026lt;foreach collection=\u0026#34;orderItems\u0026#34; item=\u0026#34;orderItem\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; ${orderItem.column} \u0026lt;if test=\u0026#34;not orderItem.asc\u0026#34;\u0026gt;desc\u0026lt;/if\u0026gt; \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt;   另外，在Mapper中使用CollectionUtils等工具，我想有时间改为别名的方式，这样的话代码长度更短。\n","description":"","id":774,"section":"notes","tags":null,"title":"拼排序条件时应该使用$符号而不会#","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E6%8B%BC%E6%8E%92%E5%BA%8F%E6%9D%A1%E4%BB%B6%E6%97%B6%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E7%AC%A6%E5%8F%B7%E8%80%8C%E4%B8%8D%E4%BC%9A#/"},{"content":"Netty之所以说是异步阻塞网络框架时因为通过NioSocketChannel的write系列方法向连接里面写入数据的时候是非阻塞的（这个地方细化就是：通过channel写数据，其实完整的走了整个pipeline），马上就会返回，即使调用写入的线程是我们的业务线程。\n（在应用中，我们可能将channel缓存起来，然后在业务线程中进行调用）\n这是Netty通过在ChannelPipeline中判断调用NioSocketChannel的write的调用线程是不是其对应的NioEventLoop中的线程来实现的，如果发现不是则会把写入请求封装WriteTask投递到其对应的NioEventLoop中的队列里面，然后等其对应的NioEventLoop中的线程轮询链接套接字的读写事件时候捎带从队列里面取出来执行。总结来说就是每个NioSocketChannel对应的读写事件都是在其对应的NioEventloop管理的单线程内执行，对同一个NioSocketChannel不存在并发读写，所以无需加锁处理。\n三点不理解的地方：\n  调用Channel上的write方法为什么由ChannelPipeline判断调用write方法的调用线程是不是NioEventLoop中的线程。\n  投递到其对应的NioEventLoop中的队列里面，这个技术上是如何实现的。\n  NioEventLoop线程伦旭套接字的读写事件，这个又是如何实现的呢？\n  一个高级问题 NioEventLoop中的线程负责监听注册到Selector上的所有连接的读写事件和处理队列里面的消息，那么会不会导致由于处理队列里面任务耗时太长导致来不及处理连接的读写事件？\n（从这个问题可以看出来，我们需要处理连接的读写事件，还需要处理队列中的事件）\nNetty默认是采用时间均分策略来避免某一方处于饥饿状态：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 记录开始处理事件 final long ioStartTime = System.nanoTime(); try{ // 处理连接套接字的读写事件  processSelectedKeys(); } finally { // 计算连接套接字处理耗时，ioRatio默认为50  final long ioTime = System.nanoTime() - ioStartTime; // 运行队列里面任务  runAllTasks(ioTime * (100 - ioRatio) / ioRatio); }   参考资料  谈谈Netty的线程模型  ","description":"","id":775,"section":"notes","tags":null,"title":"换一个角度理解Netty的异步","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E6%8D%A2%E4%B8%80%E4%B8%AA%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3netty%E7%9A%84%E5%BC%82%E6%AD%A5/"},{"content":" 先使用kubectl describe pod \u0026lt;pod-name\u0026gt;查看初始化容器的详情，主要查看initContainerStatuses字段。也可以使用如下指令查看（这条指令我使用的不熟悉）：  1 2 3  kubectl get pod \u0026lt;pod-name\u0026gt; --template \u0026#39;{{.status.initContainerStatuses}}\u0026#39;   使用如下指令查看初始化容器的日志：  1 2 3  kubectl logs \u0026lt;pod-name\u0026gt; -c \u0026lt;init-container-1\u0026gt;   Pod的状态（带初始化容器）  Init:N/M ：Pod中包含M个初始化容器，其中N个初始化容器已经成功执行 Init:Error ：Pod中有一个初始化容器执行失败 Init:CrashLoopBackOff ：Pod中有一个初始化容器反复执行失败 Pending ：Pod还未开始执行初始化容器 PodInitializing or Running ：Pod已经完成初始化容器的执行  ","description":"","id":776,"section":"notes","tags":null,"title":"排查初始化容器的错误","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%8E%92%E6%9F%A5%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AE%B9%E5%99%A8%E7%9A%84%E9%94%99%E8%AF%AF/"},{"content":"问题描述 今天将我的工具机从公司搬到了家里，配置好了网络后，想测试一下openVPN是否能够正常使用。结果开发机登录后，仍然无法访问工具机上的虚拟机。\n这次的现象与之前解决AnyConnection时遇到的现象有一定的出入，它显示为请求超时；且请求工具机上的任意一个bridge都会显示请求超时；在开发机上使用tracert指令，也看不到任何有价值的结果。\n给人的感觉就是，似乎请求的地址并不存在。\n解决方案 我重新查看了openVPN的配置教程，将防火墙配置部分重新操作了一遍，该问题恢复了。\n参考教程：  Ubuntu 搭建 OpenVPN 服务 Ubuntu 16.04搭建OpenVPN服务器以及客户端的使用  ","description":"","id":777,"section":"notes","tags":null,"title":"排查更换网络环境后，无法访问工具机上的虚拟机网络","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/%E6%8E%92%E6%9F%A5%E6%9B%B4%E6%8D%A2%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E5%90%8E%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E5%B7%A5%E5%85%B7%E6%9C%BA%E4%B8%8A%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"content":"对于save 60 10000指令，描述为：60秒内有10000次写入，则Redis会自动触发BGSAVE指令。\n我好奇的是：假如600秒内，我写入的次数累计达到10000次，但每60秒的写入次数都不足10000次，这个时候会触发BGSAVE么？我设计并进行了如下实现。\n实验过程   配置Redis为save 10 5，重新启动Redis\n  下载rdbtools工具\n   pip install rdbtools python-lzf 连接Redis服务器，检测键的变化   rdb -c memory dump.rdb 实验结果 实验发现，累计写入次数达到5次时，也会触发BGSAVE。\n","description":"","id":778,"section":"notes","tags":null,"title":"探索save指令的一些特性","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E6%8E%A2%E7%B4%A2save%E6%8C%87%E4%BB%A4%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7/"},{"content":"指令如下：\n1 2 3 4 5 6 7  npm install gitbook-cli -g # 进入一个新文件夹后 gitbook init gitbook serve   参考教程  如何用gitbook搭建自己的文档整合平台  ","description":"","id":779,"section":"notes","tags":null,"title":"搭建GitBook","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_gitbook/%E6%90%AD%E5%BB%BAgitbook/"},{"content":"考虑到我们的项目需要同时在中美部署，我们需要进行数据同步，我们选择的同步方案是：\n  每一条记录都有一个gmt_create_time、gmt_modify_time，gmt_modify_time用于记录更新时间，我们的同步工具会定时的全量跑库中的所有记录，然后对比gmt_modify_time，从而判断是否需要进行更新。\n  倘若有一条记录需要进行更新，我们只需要在一个库中修改其值，然后利用数据同步机制，在美国的库稍后就可以完成修改了。\n  那么问题在哪了？问题就在于业务复用了这个字段，业务将业务数据的更新时间也用这个字段表示，在一些页面中，我们甚至用这个字段表示记录的更新时间。\n这最终带来了什么结果呢？比如，用户3.18日更新了一条记录，记录的详情页面显示的是3.18更新，这个时间是符合业务的需求的。在3.20的一次发版中，我们修改了某个字段的含义，并用脚本全量更新了这个字段的值及gmt_modify_time，并利用同步机制扩散到其他的库中。于是用户理解的修改时间就和他实际操作的不一致的，最终会认为我们库中得数据是错误的。\n追根揭底，表单的更新时间，本身也属于业务数据，不应该复用gmt_modify_time。\n为什么不多地库同时更新，而不更新gmt_modify_time呢，这肯定是一个可行的办法，但是用这种方案终究不符合数据库设计规范。\n","description":"","id":780,"section":"notes","tags":null,"title":"数据库中创建时间、更新时间的字段设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%97%B6%E9%97%B4%E6%9B%B4%E6%96%B0%E6%97%B6%E9%97%B4%E7%9A%84%E5%AD%97%E6%AE%B5%E8%AE%BE%E8%AE%A1/"},{"content":"考虑再三，我决定前端向数据源发送请求的时候，必须带上datasourceName参数，该参数就是请求当前使用的数据源，为什么需要这个参数了，是为了支持rawData。\n比如如下一个rawData，它几乎是一个非常常规的需求，我们不可能每次为了这样的一个数据结构写出一大堆的代码。\n { \u0026quot;男\u0026quot;: { \u0026quot;EURO\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;UK\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;US\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;CM\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ] }, \u0026quot;女\u0026quot;: { \u0026quot;EURO\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;UK\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;US\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ], \u0026quot;CM\u0026quot;: [ 40.5, 41, 41.5, 42, 42.5, 43, 43.5, 44, 44.5 ] } } 我是如何设计解决这个问题的呢？当用户提供的rawData支持我们默认的jsonScheme，且此时数据源的参数为共用的参数，比如firstLevel、secondLevel、thridLevel，那我们就可以通过datasourceName拿到rawScheme，然后按照固定的处理方法，进行处理（此时rawData的名字，就是我们数据源的名称，数据源是自动生成的。）。\n比如上面的rawData，名称为abcdefg，符合我们预设的jsonScheme，那么我们就会自动生成如下几个数据源及检查源：\n # 数据源 shoeLastGender type:fixed params:null returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize.keys() shoeLastFootType type:fixed params: shoeLastGender JJString returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize[shoeLastGender].keys() shoeLastSize type:fixed params: shoeLastGender JJString shoeLastFootType JJString returnType:JList returnValues:shoeLastGenderAndFootTypeAndSize[shoeLastGender][shoeLastFootType] # 检查源 abcdefg first_level ","description":"","id":782,"section":"notes","tags":null,"title":"数据源的一些其他设计思路","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/%E6%95%B0%E6%8D%AE%E6%BA%90%E5%8F%8A%E6%A3%80%E6%9F%A5%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF/"},{"content":"在我的这套方案里，我们是需要对所有的数据源进行管理的，说的简单粗暴点就是：我们存在一个“数据源的管理系统”。\n从我们的业务场景中来说，数据源应该是支持多租户的，不同的租户有不同的数据源，某些数据源是针对某个企业特定开发的。但是我认为在这个阶段，这些都不是最重要的东西，所以我的设计只考虑了但用户的场景。\n t_datasource id # 自增主键 name # 数据源的名称全局唯一 type # 取值Get、Post，前端按照该值发送http请求（目前主要为Get，Post用于开发高度自定义） # 新增一种Fixed，Fixed代表的是由rawData生成的 params # 前端按照该值提供参数，存储为对象数组：[{\u0026quot;paramName\u0026quot;:\u0026quot;tmp\u0026quot;,\u0026quot;paramType\u0026quot;:\u0026quot;JString\u0026quot;}] requestUrl # 前端将请求发送到该地址 returnType # 表单编排器通过该字段判断该数据源能够绑定到某个组件的某个属性声明（系统定义的类型JList、JBoolean、JMap） t_raw_data id name data 技术需求  需要知道Get支不支持向服务器传递复杂的请求体，如果可以的话，type字段可以不用存在（其实不建议删除）。 params目前也无法描述负载的请求体，实际上，如果params是一个json的话，完全是可以进行描述的，案例如下：  需求的请求体为（即params参数为）：\n { \u0026quot;condition\u0026quot;: { \u0026quot;app\u0026quot;: 1, \u0026quot;timeStart\u0026quot;: 2, \u0026quot;timeEnd\u0026quot;: 3 }, \u0026quot;scope\u0026quot;: { \u0026quot;app\u0026quot;: \u0026quot;auth-center\u0026quot;, \u0026quot;ownder\u0026quot;: \u0026quot;system-admin\u0026quot;, \u0026quot;timeStart\u0026quot;: 2, \u0026quot;timeEnd\u0026quot;: 4 } } 对应的描述可以为：\n { \u0026quot;condition\u0026quot;: { \u0026quot;app\u0026quot;: \u0026quot;JInteger\u0026quot;, \u0026quot;timeStart\u0026quot;: \u0026quot;JInteger\u0026quot;, \u0026quot;timeEnd\u0026quot;: \u0026quot;JInteger\u0026quot; }, \u0026quot;scope\u0026quot;: { \u0026quot;app\u0026quot;: \u0026quot;JString\u0026quot;, \u0026quot;ownder\u0026quot;: \u0026quot;JString\u0026quot;, \u0026quot;timeStart\u0026quot;: \u0026quot;JInteger\u0026quot;, \u0026quot;timeEnd\u0026quot;: \u0026quot;JInteger\u0026quot; } } 当用户为某个组件绑定了了该数据源，所呈现的参数配置为：\n condition.app condition.timeStart condition.timeEnd scope.app scope.ownder scope.timeStart scope.timeEnd 这部分都是临时设计的，我不确定这样的设计能不能囊括需求。这个只能算作抛砖引玉，到时候看看大家有没有更好的需求吧。这部分的需求，在基础组件的设计与实现过程中应该是不需要的，所以暂时不用太着急。\n按照该表结构设计的数据源与实现（针对企业库案例） 数据源管理  增、删、改、查 检查数据源是否可用 查看数据源的数据  组件库 ","description":"","id":783,"section":"notes","tags":null,"title":"数据源的表结构设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E9%98%B6%E6%AE%B5%E4%B8%80%E5%8F%AF%E9%85%8D%E7%BD%AE%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0/%E6%95%B0%E6%8D%AE%E6%BA%90%E5%8F%8A%E6%A3%80%E6%9F%A5%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1/%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E8%A1%A8%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"content":"功能性的需求：\n 多渠道用户可以一起游玩（华为、小米、微信、QQ等） 多平台用户可以一起游玩（手机、电脑、平板等） 游戏的过程中一定要提供语音服务（最基本的）  ","description":"","id":784,"section":"notes","tags":null,"title":"整体目标","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E8%BF%9E%E8%BF%9E%E7%9C%8B%E8%81%94%E6%9C%BA%E7%89%88/%E6%95%B4%E4%BD%93%E7%9B%AE%E6%A0%87/"},{"content":"3.20 博文\n这篇博文记录我对博客管理程序的需求：\n 文件顺序可以任意调整。  我们可以对文件的父级目录进行设置，设置该目录的默认排序方式，按创建时间、修改时间、大小、自定义。当父级目录排序方式为自定义时，我们可以任意对文件进行拖动，而拖动后的结果就是我们的文件顺序。\n这个需求存在的问题是：当从该项目工程导出到发布平台时，该顺序可能被打乱。比如我先创建了博文B，再创建了博文A，我希望博文A在博文B的前面，但是发布到hexo平台时，因为博文A的创建时间最新，它会把博文A放置在博文B的前方。（这个例子举的并不好，总之，我就是想说Hexo平台有一套自己的排序博文的方式）。我将尽我最大的努力实现在发布平台也保持在项目中的自定义排序（当然，前提时我到时候有这个需求），我可能会去调整一下Hexo主题的代码，使它也支持我这种自定义排序，或者利用一些小技巧，比如修改下文档的更新时间什么的，确保发布时能有我自己想要的顺序。不过这个目前不必太上心，我会将发布插件分开，可以根据需求调整发布插件，甚至自行开发发布插件。\n全局检索可以避免部分文件夹  这个需求是这样的，随着后期博文的增加，我会将自己的周报日报等等东西都放进我的博客里。而周报日报技术含量比较低，我平时搜索时很少会搜索这些稳定，所以我希望我全局搜索时可以避免搜索这些文档。\n我这个需求可以结合下一个需求实现，这样的话，对文件夹的设置可以集中在一起。\n设置文件夹默认展开状态  我发现当我的文档非常多的时候，展开时会很长，并不是便于浏览，而像周报日报之类的文档，其实并没有展开的必要。我希望设置他们的默认展开状态，这样我使用编辑器提供的展开所有文件的功能时，仍然可以避免展开这些文档。\n快速格式化  这个需求是这样的，我在写博客时，当我在当前博客进行格式化时，能快速的将所有代码块里的代码都格式化了。这个过程可能需要识别代码块里代码的语言，根据语言进行格式化。这个过程最好有提示。\n添加标签的功能  原创、笔记、转载、整理等，可以为文件夹设置一个标签，然后这个文件夹下的所有文件都默认是这个标签。当然，文件也可以单独设置标签，文件的单独标签优先级是远远高于文件夹的。这样的话，我又产生了一个新的需求，我需要一个界面，去查看我所有博文的标签，并且可以动态调整它们的标签。我还需要一个功能，我搜索的时候能够筛选这些标签。\n需要区分一下这块的标签与文章里的关键字，我目前博文中的tags更多的是关键字，而不是标签。\n一个奇奇怪怪的需求  我决定用管理代码的方式管理博文的时候，我们可能会建非常深的目录结构，但是博客程序的目录结构太深了，并不是非常好的体验，所以，我有计划在这方面做一些计划。\n提供一种目录方案的东西？因为我的博文需要发布多个平台，可能每个平台都有自己方案，比如我现在用和Hexo主题就支持二级的目录结构，但是有些主题是不支持这个的。那我就可以创建两个目录方案，一个是一级的目录方案，一个是二级的目录方案，当然我还需要一个默认的目录方案。编辑文章属性，或者文件夹属性，修改其在各个目录方案下放置的位置。\n举一个例子，我设计例如如下的目录方案：\n { \u0026quot;name\u0026quot;: \u0026quot;一级\u0026quot;, \u0026quot;autoScript\u0026quot;:\u0026quot;\u0026quot; \u0026quot;categories\u0026quot;: [ \u0026quot;新的博文\u0026quot;, \u0026quot;202103\u0026quot;, \u0026quot;202104\u0026quot;, \u0026quot;202105\u0026quot;, \u0026quot;202106\u0026quot;, \u0026quot;202107\u0026quot;, ] }  目录结构需要支持脚本，该脚本会在文档创建和修改时自动执行，自动为文件设置合适目录方案值  举一个例子，我设置了一个脚本，这个脚本会在新增文件时，读取文件的创建时间，根据计算得到年份，如果目录方案中没有该年份，则创建一个该年份，并设置值为该年年份。总之这个脚本的入参将会时这个文件的所有属性，（部分信息是只读的）包括插件配置文件中目录方案部分的配置（部分信息是只读的）。对返回数据将会全部写回到相应的文件中。\n需要解决draw.io和思维导图渲染的问题，这个非常需要。  这个优先级没有那么高。\n","description":"","id":785,"section":"notes","tags":null,"title":"新博客方案需求收集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E6%96%B0%E5%8D%9A%E5%AE%A2%E6%96%B9%E6%A1%88%E9%9C%80%E6%B1%82%E6%94%B6%E9%9B%86/"},{"content":"3.20号博文\n强迫症如我，根本没有办法满足用脚本来管理自己的博文，在每篇博文中还要加上Head信息，感觉非常的不舒适。\n我对自己博客开发系统的畅想是：\n 它是一个项目工程，就像一个Java项目一样，为什么要是一个项目工程，是因为它有一些自己的需求 每一篇博文都会有自己的mata文件，这些mata信息记录了博文的一些独特的信息，比如创建时间、历史修改次数等，发布平台、发布渠道等等 考虑到将Head从每篇博文的头部移动到了meta文件中，而文件名又限制了长度和特殊字符，我计划博文中的一级标题作为博文的title，该信息会被自动读入到meta文件中 在IDE中，单击一篇博文，就可以修改该博文的元信息 在IDE中，我们修改博文的名称等，图片Url等，甚至一些我们自己开发的标签，IDE会实时的把我们的修改渲染成一份md文件，再交给IDE进行渲染，具体怎么实现，还需要研究 我们在开发的过程中，进行任何移动都会导致该项目自动进行调整。 这个项目工程有自己的一系列插件，比如发布到Hexo、发布到GitHub等。  本质上，我的博客项目就是一堆的文件，但是这些文件是博客的本体，而博客本身又有很多自己的需求，如果只是单纯的把它当文件来对待的话，很多博客的需求处理起来都非常的麻烦。\n","description":"","id":786,"section":"notes","tags":null,"title":"新博客调整方案","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E6%96%B0%E5%8D%9A%E5%AE%A2%E8%B0%83%E6%95%B4%E6%96%B9%E6%A1%88/"},{"content":"浪费时间的点在于新版Luci的Lan口设置中没有了物理设置这一项，所以不知道在哪却设置桥接，尝试了直接修改配置文件，结果因为学艺不佳，多次修改都不成功。\n最终找参考资料里找到了在哪设置桥接，喜大泪奔。\n参考资料  Luci missing physical settings tab  ","description":"","id":787,"section":"notes","tags":null,"title":"新版Luci设置桥接","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/openwrt/%E6%96%B0%E7%89%88luci%E8%AE%BE%E7%BD%AE%E6%A1%A5%E6%8E%A5/"},{"content":"我肯定会划分一段时间去解决日志相关的问题，但是现阶段该问题该优先级并没有那么高，我先记录下我遇到的问题，未来系统学习的时候再解决这些问题。\n在做RestTemplate日志输出的时候，我发现如果我日志如果是Debug级别的，系统并不会输出我的日志。当然，我是知道设置日志输出级别的问题的，但是问题的关键点在于：我明明看到日志中有Debug级别的日志输出。\n刚才在解决新框架的问题时又遇到了一个类似的情况，ExceptionHandler在打印异常信息的时候用的是Debug级别，我听同事说，需要在SpringBoot的配置文件中配置路径，然后就可以打印相关的日志了。额，相关的知识我也了解过，只是我的知识还停留在log4j的时代，我记得上logbak和log4j2时一般不会在SpringBoot的配置文件中配置什么东西，都是直接通过一个xml文件进行配置。\n先收集一下这些问题，等系统去学习时再解决吧。\n","description":"","id":788,"section":"notes","tags":null,"title":"日志输出的一些事","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/"},{"content":"有更优雅的方案，我采用了如下方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13  # Master上执行 kubectl delete node OLD_NODE # Worker上执行 kubeadm reset # Master上执行 kubeadm token create --print-join-command --ttl 0 # Worker上执行（上一条指令的返回结果） kubeadm join 192.168.23.60:6443 --token muxmxy.s0vsl4hkaf1twgbr --discovery-token-ca-cert-hash sha256:fefb29735b50038189c07c13c0f8b78b20e7ae93780a741ed04b2432f9ed8cd0   ","description":"","id":790,"section":"notes","tags":null,"title":"暴力修改一个节点的hostname","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9A%B4%E5%8A%9B%E4%BF%AE%E6%94%B9%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84hostname/"},{"content":"可能是我的操作失误了，导致我的两个节点掉线了（我可能重启了节点），稍微在网上搜索了下重新将节点加入回集群的方案，没有找到我满意的，所以我采用了如下指令：\n1 2 3 4 5 6 7 8 9 10  # Worker上执行 kubeadm reset # Master上执行 kubeadm token create --print-join-command --ttl 0 # Worker上执行（上一条指令的返回结果） kubeadm join 192.168.23.60:6443 --token muxmxy.s0vsl4hkaf1twgbr --discovery-token-ca-cert-hash sha256:fefb29735b50038189c07c13c0f8b78b20e7ae93780a741ed04b2432f9ed8cd0   这个方案只是临时处理用的，对集群要求稳定是肯定不能采用这个方案的。\n","description":"","id":791,"section":"notes","tags":null,"title":"暴力的将一个掉线的节点重新加入会集群","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9A%B4%E5%8A%9B%E7%9A%84%E5%B0%86%E4%B8%80%E4%B8%AA%E6%8E%89%E7%BA%BF%E7%9A%84%E8%8A%82%E7%82%B9%E9%87%8D%E6%96%B0%E5%8A%A0%E5%85%A5%E4%BC%9A%E9%9B%86%E7%BE%A4/"},{"content":"如果使用如下方式编写SQL，会在查询的时候报错，报错内容大致是说没有找到参数：\n1 2 3  select * from t_user where account like \u0026#39;%#{account}%\u0026#39;   需要修改成如下sql：\n1 2 3  select * from t_user where account like #{account}%   但是这种修改是不符合我们业务逻辑的，我们要的就是有百分号的查询。我们项目中解决该问题的方式是传入account的值时，在代码中加上百分号，这是一种我绝对无法接受的方案，这样的代码实在是不优雅：\n我在查询资料并实践后，排除了如下方案：\n 使用\u0026quot;%\u0026quot;#{account}\u0026quot;%\u0026quot;，可能因为我们使用的是pg，该方案行不通 使用CONCAT('%', #{account}, '%')，同样的可能因为我们使用的是pg，该方案行不通  最后我确认了使用MyBatis提供的bind标签的方案（该方案已经实践，能够成功的查询到数据）：\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;select id=\u0026#34;pageUserInMaterialByAccount\u0026#34; resultType=\u0026#34;com.sdstc.authcenter.pojo.User\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;account\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + account + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; SELECT tu.* FROM t_user tu JOIN t_auth_group_user_role tagur ON tu.ID = tagur.user_id WHERE tagur.app_id = \u0026#39;200\u0026#39; AND tagur.is_delete = \u0026#39;0\u0026#39; AND tu.is_delete = \u0026#39;0\u0026#39; and tu.account like #{account} \u0026lt;/select\u0026gt;   这个方案最大的问题在于，增加了一个标签，导致Idea的自动排版不好使了。\n参考资料  [MyBatis]模糊查询LIKE的三种方式 MyBatis Like 模糊查询解决策略  ","description":"","id":792,"section":"notes","tags":null,"title":"更优雅的处理Like查询（其实也不太优雅）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E6%9B%B4%E4%BC%98%E9%9B%85%E7%9A%84%E5%A4%84%E7%90%86like%E6%9F%A5%E8%AF%A2%E5%85%B6%E5%AE%9E%E4%B9%9F%E4%B8%8D%E5%A4%AA%E4%BC%98%E9%9B%85/"},{"content":"DipatcherServlet使用默认的Bean处理请求 Spring的DispatcherServlet使用了内置在WebApplicationContext中的特定的Bean来处理请求、渲染视图等，这些Bean是Spring MVC框架的一部分。\n如果你想指定使用哪个特定的Bean，可以在WebApplicationContext中简单地配置它们。当然这只是可选的，Spring MVC维护了一个默认的Bean列表，如果没有进行特别的配置，框架将会使用默认的Bean。DispatcherServlet都依赖的这些Bean如下所示。\nHandlerMapping处理器映射 HandlerMapping处理器映射。它会根据某些规则将进入容器的请求映射到具体的处理器以及一系列前处理器和后处理器（即处理器拦截器）上。\n具体的规则视HandlerMapping类的实现不同而有所不同。其最常用的一个实现支持你在控制器上添加注解，配置请求路径。当然，也存在其他的实现。\n（这里提到了前处理器和后处理器，即处理器拦截器，这部分知识我接触的比较少）\nHandlerAdapter处理器适配器 HandlerAdapter处理器适配器。拿到请求所对应的处理器后，适配器将负责去调用该处理器，这使得DispatcherServlet无需关心具体的调用细节。\n比方说，要调用的是一个基于注解配置的控制器，那么调用前还需要从许多注解中解析出一些相应的信息。因此，HandlerAdapter的主要任务就是对DispatcherServlet屏蔽这些具体的细节。\n（能够理解其需要进行的工作，将请求体转换成Request DTO可能是在这个处理器中做的）\nMultipartResolver解析器 MultipartResolver解析multi-part的传输请求，比如支持通过HTML表单进行的文件上传等。\n其他的Bean HandlerExceptionResolver处理器异常解析器它负责将捕获的异常映射到不同的视图上去，此外还支持更复杂的异常处理代码。\nViewResolver视图解析器。它负责将一个代表逻辑视图名的字符串（String）映射到实际的视图类型View上。\nLocaleResolver \u0026amp; LocaleContextResolver地区解析器 和 地区上下文解析器。它们负责解析客户端所在的地区信息甚至时区信息，为国际化的视图定制提供了支持。\nThemeResolver主题解析器。它负责解析你web应用中可用的主题，比如，提供一些个性化定制的布局等。\nFlashMapManagerFlashMap管理器。它能够存储并取回两次请求之间的FlashMap对象。后者可用于在请求之间传递数据，通常是在请求重定向的情境下使用。\nDispatcherServlet.properties文件 这个Bean列表保存在包org.springframework.web.servlet下的DispatcherServlet.properties文件中。\nDispatcherServlet的处理流程   首先，搜索应用的上下文对象WebApplicationContext并把它作为一个属性（attribute）绑定到该请求上，以便控制器和其他组件能够使用它。属性的键名默认为DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE\n  将地区（locale）解析器绑定到请求上，以便其他组件在处理请求（渲染视图、准备数据等）时可以获取区域相关的信息。如果你的应用不需要解析区域相关的信息，忽略它即可\n  将主题（theme）解析器绑定到请求上，以便其他组件（比如视图等）能够了解要渲染哪个主题文件。同样，如果你不需要使用主题相关的特性，忽略它即可\n  如果你配置了multipart文件处理器，那么框架将查找该文件是不是multipart（分为多个部分连续上传）的。若是，则将该请求包装成一个MultipartHttpServletRequest对象，以便处理链中的其他组件对它做进一步的处理。\n  为该请求查找一个合适的处理器。如果可以找到对应的处理器，则与该处理器关联的整条执行链（前处理器、后处理器、控制器等）都会被执行，以完成相应模型的准备或视图的渲染\n  如果处理器返回的是一个模型（model），那么框架将渲染相应的视图。若没有返回任何模型（可能是因为前后的处理器出于某些原因拦截了请求等，比如，安全问题），则框架不会渲染任何视图，此时认为对请求的处理可能已经由处理链完成了\n  如果在处理请求的过程中抛出了异常，那么上下文WebApplicationContext对象中所定义的异常处理器将会负责捕获这些异常。通过配置你自己的异常处理器，你可以定制自己处理异常的方式。\nSpring的DispatcherServlet也允许处理器返回一个Servlet API规范中定义的最后修改时间戳（last-modification-date） 值。决定请求最后修改时间的方式很直接：DispatcherServlet会先查找合适的处理器映射来找到请求对应的处理器，然后检测它是否实现了LastModified接口。若是，则调用接口的long getLastModified(request)方法，并将该返回值返回给客户端。\nSpringBoot中配置DispatcherServlet时的一些配置类 这是我看视频课程时看到的，记录一下，方便以后查看项目的源码。\nDispatcherServletAutoConfiguration\nHttpEncodingAutoConfiguration\nMultipartAutoConfiguration\nServletWebServerFactoryAutoConfiguration\nWebMvcAutoConfiguration\n参考资料  Spring MVC DispatcherServlet详解  ","description":"","id":793,"section":"notes","tags":null,"title":"更多的了解DispatcherServlet","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E6%9B%B4%E5%A4%9A%E7%9A%84%E4%BA%86%E8%A7%A3dispatcherservlet/"},{"content":"出于如下原因，可能不想激活Service的环境变量发现机制：\n 可能与应用程序的环境变量冲突 太多的环境变量 只想使用DNS等  我目前出于第三个原因。可以采取的方案是将Pod的enableServiceLinks标记设置为false。\n貌似Deployment不支持该配置项，所以目前看来没有研究的意义\n","description":"","id":794,"section":"notes","tags":null,"title":"服务发现不是使用环境变量方案实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%B8%8D%E6%98%AF%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%96%B9%E6%A1%88%E5%AE%9E%E9%AA%8C/"},{"content":"目前已知需求：\n 打马赛克的插件 图片粘贴工具 图片渲染等重要工具  如果做成插件有哪些有意思的事？更好的和ide配合。将我们所许诺的东西百分百的实现。做成小工具呢？\n","description":"","id":795,"section":"notes","tags":null,"title":"本地博客软件的设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E6%9C%AC%E5%9C%B0%E5%8D%9A%E5%AE%A2%E8%BD%AF%E4%BB%B6%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"content":"看IngressNginx的文档时，发现了一种RBAC的权限罗列方式，如下：\n以下权限授予一个名为ingress-nginx的ClusterRole：\n configmaps、endpoints、nodes、pods、secrets：list、watch nodes：get services、ingress：get、list、watch events：create、patch ingress/status：update  以下权限授予一个名为ingress-nginx的Role：\n configmaps、pods、secrets：get endpoints：get configmaps：get、update configmaps：create  其对应的配置清单如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153  apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:labels:helm.sh/chart:ingress-nginx-4.0.15app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:\u0026#34;1.1.1\u0026#34;app.kubernetes.io/managed-by:Helmname:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- endpoints- nodes- pods- secrets- namespacesverbs:- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- nodesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch---apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:labels:helm.sh/chart:ingress-nginx-4.0.15app.kubernetes.io/name:ingress-nginxapp.kubernetes.io/instance:ingress-nginxapp.kubernetes.io/version:\u0026#34;1.1.1\u0026#34;app.kubernetes.io/managed-by:Helmapp.kubernetes.io/component:controllername:ingress-nginxnamespace:ingress-nginxrules:- apiGroups:- \u0026#34;\u0026#34;resources:- namespacesverbs:- get- apiGroups:- \u0026#34;\u0026#34;resources:- configmaps- pods- secrets- endpointsverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- servicesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingressesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- ingresses/statusverbs:- update- apiGroups:- networking.k8s.ioresources:- ingressclassesverbs:- get- list- watch- apiGroups:- \u0026#34;\u0026#34;resources:- configmapsresourceNames:- ingress-controller-leaderverbs:- get- update- apiGroups:- \u0026#34;\u0026#34;resources:- configmapsverbs:- create- apiGroups:- \u0026#34;\u0026#34;resources:- eventsverbs:- create- patch  很有趣，我觉得这样把资源罗列下来，更有利于自己之后的开发工作。当然我先解决不需要如此升入的学习，我们的应用目前甚至不会去获取集群的任何资源，所以即使不为它们设置ServiceAccount，我觉得都是可以的。\n","description":"","id":796,"section":"notes","tags":null,"title":"权限的罗列方法（可以帮助学习RBAC）","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9D%83%E9%99%90%E7%9A%84%E7%BD%97%E5%88%97%E6%96%B9%E6%B3%95%E5%8F%AF%E4%BB%A5%E5%B8%AE%E5%8A%A9%E5%AD%A6%E4%B9%A0rbac/"},{"content":"我们项目管理目前可以是非常的不规范，只做功能层面的管理，并不会关心代码质量、项目结构等片底层的东西。开发人员忙于实现功能，也并不会将精力放在这些东西上面（讲道理，这本来也不属于开发操心）。所以我们并没有很规范的使用Maven，就版本号而言，我们只使用Release版本，且从来不升版本。\n这在构建机上带来了一个问题，构建机会优先使用本地缓存，而本地缓存的Jar其实已经不是最新的了，但是构建机并不会去拉取最新的Jar包。似乎有个-U选项可以使用，但在实验中，该选项并不能强制拉取最新的Release版本的包。\n在我们本机上，我们处理这个问题的方式是删除com.sdstc下得所有jar包（我们公司的group），这样Maven就会自动拉取最新的Jar包，但是该方案在构建机上是不可行的，因为构建机上往往同事构建多个项目，如果删除了Jar包，会导致其他项目构建失败。\n最后我们采用的方案是什么呢？我们选在在执行构建指令时加上-Dmaven.repo.local xxx/xxx，为每个项目单独指定一个本地仓库，然后在使用这个仓库前，删除其com.sdstc下的所有jar包。因为同一时间一个项目只会有一个构建，所以并不会因为删除了jar包就导致构建出现问题。而且，单独构建一个项目所需要的仓库容量大约为200MB~300MB，100个项目也不过30G，完全是可以接受的（我们才20多个Java项目）。\n参考资料    ","description":"","id":797,"section":"notes","tags":null,"title":"构建机如何解决开发使用Release版本不适用SNAPSHOT版本的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E6%9E%84%E5%BB%BA%E6%9C%BA%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%BC%80%E5%8F%91%E4%BD%BF%E7%94%A8release%E7%89%88%E6%9C%AC%E4%B8%8D%E9%80%82%E7%94%A8snapshot%E7%89%88%E6%9C%AC%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"事情是这样的，我们dev环境发现一些接口不可用，这个问题追溯到源码，发现一份源码文件被删除了。我对这种问题非常敏感，因为我常常使用Idea的一些操作，很容易就影响到别的文件，而我自己还不知道（我最近一次发现的问题是我修改实体的delete为isDelete时，xml文件、@Select中的delete也跟着一起被修改了，非常恐怖），所以我计划定位出这个问题来。\n我先使用了git log -- RoleController.java指令查看了该文件的日志信息，找到了我最近作出修改的commitId，然后我用git checkout commitId切换到该分支上，我发现该文件确实消失了，其实基本上已经可以定位是我的操作导致了该文件的消失。\n我又使用git show commitId查看了该提交时做出来的修改，有如下信息：\n这基本上就定位了，就是我的误操作导致了该文件的丢失。\n我有时候操作会过快，会触发一些误操作，这次误删除的是顶级的Controller类，导致这个问题暴露的比较晚。\n参考资料  Git 查看某次commit的内容  ","description":"","id":798,"section":"notes","tags":null,"title":"查文件误删","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_git/%E6%9F%A5%E6%96%87%E4%BB%B6%E8%AF%AF%E5%88%A0/"},{"content":"我记得当时的需求是我的集群中出现了不明白的问题，我判断是etcd出现了问题，我需要查看etcd中的数据。\n这是对以前收藏的整理。\n 查看k8s的etcd pod中的数据  ","description":"","id":799,"section":"notes","tags":null,"title":"查看etcd中的数据","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9F%A5%E7%9C%8Betcd%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE/"},{"content":"我在尝试通过JdbcTeamplate获取数据库中列的元数据，有如下一段代码：\n1 2 3 4 5 6 7 8  ResultSet columns = dbMetaData.getColumns(null, null, \u0026#34;t_dyf_%\u0026#34;, null); while(columns.next()){ String tableName = columns.getString(\u0026#34;COLUMN_NAME\u0026#34;); System.out.println(tableName); }   我并不知道columns.getString(columnTable)方法能够传递哪些参数，我查看了这个方法的源码，也没有说清楚。我懒得找文章，最后我通过断点的方式查看了该方法支持的所有参数：\n这件事情中唯一让我感觉到意外的是，我断点查看columns的实现时，显示的是HikariProxyResultSet，但是在这个类中的断点不会执行到，需要在PgResultSet中进行断点。\n","description":"","id":800,"section":"notes","tags":null,"title":"查看getString方法支持哪些参数","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/jdbctemplate/%E6%9F%A5%E7%9C%8Bgetstring%E6%96%B9%E6%B3%95%E6%94%AF%E6%8C%81%E5%93%AA%E4%BA%9B%E5%8F%82%E6%95%B0/"},{"content":"主要是为了方便抄一份，原本的实现无法满足我们的框架：\norg.hibernate.validator:hibernate-validator:6.0.18.Final\n在org.hibernate.validator.internal.constraintvalidators.bv包下\n","description":"","id":801,"section":"notes","tags":null,"title":"查看hibernate对校验注解的实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E6%9F%A5%E7%9C%8Bhibernate%E5%AF%B9%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"content":"已经忘记需求场景了，故作废该笔记\n开始 \u0026gt; 设置 \u0026gt; 系统 \u0026gt; 关于\n参考资料  我运行的是哪个 Windows 操作系统版本？  ","description":"","id":802,"section":"notes","tags":null,"title":"查看Windows的版本和版本号","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E6%9F%A5%E7%9C%8Bwindows%E7%9A%84%E7%89%88%E6%9C%AC%E5%92%8C%E7%89%88%E6%9C%AC%E5%8F%B7/"},{"content":"需求太少了，故作废\n很久前建的虚拟机，突然要用一下，忘记密码了，但是密码保存在了XShell中，我使用了AsteriskPassword.exe查看密码。\n我用的是免费版的，只能看秘密的前三个字符，不过已经够了。\n参考资料  如何查看xshell保存的密码  ","description":"","id":803,"section":"notes","tags":null,"title":"查看XShell密码","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E6%9F%A5%E7%9C%8Bxshell%E5%AF%86%E7%A0%81/"},{"content":"这个指令用的比较少，记录纯粹是因为好玩：\n # 在名称空间里 kubectl api-resources --namespaced=true # 不在名称空间里 kubectl api-resources --namespaced=false ","description":"","id":804,"section":"notes","tags":null,"title":"查看哪些Kubernetes对象在名称空间里，哪些不在","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9F%A5%E7%9C%8B%E5%93%AA%E4%BA%9Bkubernetes%E5%AF%B9%E8%B1%A1%E5%9C%A8%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4%E9%87%8C%E5%93%AA%E4%BA%9B%E4%B8%8D%E5%9C%A8/"},{"content":"由控制器生成的Pod都有一个metadata.ownerReferences ，该字段用于标识该Pod从属于哪一个ReplicaSet。\n用如下配置生成一个RS资源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  apiVersion:apps/v1kind:ReplicaSetmetadata:name:frontendlabels:app:guestbooktier:frontendspec:replicas:3selector:matchLabels:tier:frontendtemplate:metadata:labels:tier:frontendspec:containers:- name:nginximage:nginx  使用如下指令进行查看（我实际上使用的是VSCode的插件）：\n1 2 3 4  kubectl get pods frontend-ndlm6 -o yaml kubectl get pods frontend-ndlm6 -o yaml | grep ownerReferences   相关输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  metadata:labels:tier:frontendname:frontend-24c4lnamespace:defaultownerReferences:- apiVersion:apps/v1blockOwnerDeletion:truecontroller:truekind:ReplicaSetname:frontenduid:3bdf82b0-7cb0-401f-9294-00d1b969720dresourceVersion:\u0026#34;8089\u0026#34;uid:3e675a1b-2d2c-4a1a-a4d2-ab8daacb6a5c  ","description":"","id":805,"section":"notes","tags":null,"title":"查看容器的metadata.ownerReferences","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E6%9F%A5%E7%9C%8B%E5%AE%B9%E5%99%A8%E7%9A%84metadata.ownerreferences/"},{"content":"代码如下：\n1 2 3  echo $SHELL   ","description":"","id":806,"section":"notes","tags":null,"title":"查看当前使用的Shell","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E4%BD%BF%E7%94%A8%E7%9A%84shell/"},{"content":"如下，我们将模块之间的依赖直接写在根项目中的dependencyManagement标签中：\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cn.tim\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-oauth2-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;   为什么要将这部分移动到根目录的dependencyManagement标签中呢，因为如果将依赖代码分部到整个项目中是一件非常麻烦的事情，非常的不利用维护。从这个角度思考，我们自己开发的starter-parent完全可以在继承springboot的starter-parent后，加上我们的自己的各个client的版本仲裁，并提供变量允许各个项目自行精细化控制各个client的版本（这样真的好么，我不是太确信，没有实践过）。至于各个项目自己的common依赖，则直接写在自己的父项目中。\n","description":"","id":807,"section":"notes","tags":null,"title":"模块之间的依赖，一种很好的写法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E6%A8%A1%E5%9D%97%E4%B9%8B%E9%97%B4%E7%9A%84%E4%BE%9D%E8%B5%96%E4%B8%80%E7%A7%8D%E5%BE%88%E5%A5%BD%E7%9A%84%E5%86%99%E6%B3%95/"},{"content":"账户管理Handers主要完成如下目标：\n 创建账号 修改密码（如果当前账号已经登录了，需要将该账号下线了） 登录游戏（如果当前账号已经登录了，则将这个账号挤下去）  大厅的Handlers主要完成如下目标：\n 创建房间 加入房间 搜索房间 进行匹配 查看房间列表等等  游戏的Handlers主要完成如下目标：\n 退出当前游戏  系统操作的Handlers目前没有相应的分工：\n","description":"","id":808,"section":"notes","tags":null,"title":"模块的设计","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E6%88%BF%E9%97%B4%E6%9C%8D%E5%8A%A1/%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AE%BE%E8%AE%A1/"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115  import re def match(): # match默认情况下会在起始位置匹配 # print(re.match(\u0026#39;www\u0026#39;, \u0026#39;www.runoob.com\u0026#39;).span()) # (0, 3) # print(re.match(\u0026#39;com\u0026#39;, \u0026#39;www.runoob.com\u0026#39;)) # None line = \u0026#39;Cats are smarter than dogs\u0026#39; matchObj = re.match(r\u0026#39;(.*) are (.*?) .*\u0026#39;, line, re.M | re.I) if matchObj: print(\u0026#39;matchObj.group() :\u0026#39;, matchObj.group()) print(\u0026#39;matchObj.group(1):\u0026#39;, matchObj.group(1)) print(\u0026#39;matchObj.group(2):\u0026#39;, matchObj.group(2)) else: print(\u0026#39;No Match!!\u0026#39;) def search(): # search默认情况下会在全部范围内匹配 print(re.search(\u0026#39;www\u0026#39;, \u0026#39;www.runoob.com\u0026#39;).span()) print(re.search(\u0026#39;com\u0026#39;, \u0026#39;www.runoob.com\u0026#39;).span()) line = \u0026#39;Cats are smarter than dogs\u0026#39; searchObj = re.search(r\u0026#39;(.*) are (.*?) .*\u0026#39;, line, re.M | re.I) if searchObj: print(\u0026#39;searchObj.group() :\u0026#39;, searchObj.group()) print(\u0026#39;searchObj.group(1):\u0026#39;, searchObj.group(1)) print(\u0026#39;searchObj.group(2):\u0026#39;, searchObj.group(2)) else: print(\u0026#39;No Match!!\u0026#39;) def sub(): # phone = \u0026#39;2004-959-959 # 这是一个国外的电话号码\u0026#39; # # num = re.sub(r\u0026#39;#.*$\u0026#39;, \u0026#39;\u0026#39;, phone) # print(\u0026#39;phone is: \u0026#39;, num) # # num = re.sub(r\u0026#39;\\D\u0026#39;, \u0026#39;\u0026#39;, phone) # print(\u0026#39;phone is: \u0026#39;, num) def double(matched): value = int(matched.group(\u0026#39;value\u0026#39;)) return str(value * 2) # 这个写法非常的不理解，待会研究一下 s = \u0026#39;A23G4HFD567\u0026#39; print(re.sub(\u0026#39;(?P\u0026lt;value\u0026gt;\\d+)\u0026#39;, double, s)) def compile(): # input = \u0026#39;one12twothree34four\u0026#39; # # pattern = re.compile(r\u0026#39;\\d+\u0026#39;) # # print(pattern.match(input)) # 查找头部，没有匹配 # print(pattern.match(input, 2, 10)) # 从\u0026#39;e\u0026#39;的位置开始匹配，没有匹配 # print(pattern.match(input, 3, 10)) # 从\u0026#39;1\u0026#39;的位置开始匹配，匹配成功 # print(pattern.match(input, 3, 10).group(0)) # print(pattern.match(input, 3, 10).start(0)) # print(pattern.match(input, 3, 10).end(0)) # print(pattern.match(input, 3, 10).span(0)) pattern = re.compile(r\u0026#39;([a-z]+) ([a-z]+)\u0026#39;, re.I) m = pattern.match(\u0026#39;Hello World Wide Web\u0026#39;) print(m) print(m.group(0)) print(m.span(0)) print(m.group(1)) print(m.span(1)) print(m.group(2)) print(m.span(2)) print(m.groups()) # print(m.group(3)) def findall(): # match和search是匹配一次，findall是匹配所有 # pattern = re.compile(r\u0026#39;\\d+\u0026#39;) # print(pattern.findall(\u0026#39;runoob 123 google 456\u0026#39;)) # print(pattern.findall(\u0026#39;run88oob123google456\u0026#39;, 0, 10)) print(re.findall(r\u0026#39;(\\w+)=(\\d+)\u0026#39;, \u0026#39;set width=20 and height=10\u0026#39;)) def finditer(): it = re.finditer(r\u0026#39;\\d+\u0026#39;, \u0026#39;12a32bc43jf3\u0026#39;) for match in it: print(match.group()) def split(): print(re.split(\u0026#39;\\W+\u0026#39;, \u0026#39;runoob, runoob, runoob.\u0026#39;)) print(re.split(\u0026#39;(\\W+)\u0026#39;, \u0026#39; runoob, runoob, runoob.\u0026#39;)) print(re.split(\u0026#39;\\W+\u0026#39;, \u0026#39; runoob, runoob, runoob.\u0026#39;, 1)) print(re.split(\u0026#39;a+\u0026#39;, \u0026#39;hello world\u0026#39;)) if __name__ == \u0026#39;__main__\u0026#39;: # match() # search() # sub() # compile() # findall() # finditer() split()   参考资料  Python 正则表达式  ","description":"","id":809,"section":"notes","tags":null,"title":"正则表达式简单练习","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AE%80%E5%8D%95%E7%BB%83%E4%B9%A0/"},{"content":"我这里只是纯粹记录的，方便我查阅相关注解实现的源码。相应的知识积累多了，也有助于我寻找Spring的设计思路。\n注解：\n @PreDestroy: InitDestroyAnnotationBeanPostProcessor @Autowired: AutowiredAnnotationBeanPostProcessor  Aware：\n ApplicationContextAware: ApplicationContextAwareProcessor  ","description":"","id":810,"section":"notes","tags":null,"title":"注解、Aware及其实现类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E6%B3%A8%E8%A7%A3aware%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E7%B1%BB/"},{"content":"操作步骤  注释如下/etc/apt/sources.list.d/pve-enterprise.list中相关代码（如果你没有该文件，则无需该操作）:  个人小结 因为该文件配置的源为企业版用的，只有你购买了证书后才能够从该源下载软件，如果不注释的话，可能会导致安装软件时报错。\n","description":"","id":811,"section":"notes","tags":null,"title":"注释企业源，防止安装软件时报错","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E6%B3%A8%E9%87%8A%E4%BC%81%E4%B8%9A%E6%BA%90%E9%98%B2%E6%AD%A2%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%97%B6%E6%8A%A5%E9%94%99/"},{"content":"以前用到的，但是忘记使用场景了，想记录下来。\n参考资料  Pipeline Steps Reference  ","description":"","id":812,"section":"notes","tags":null,"title":"流水线相关的资料","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/jenkins/%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%9B%B8%E5%85%B3%E7%9A%84%E8%B5%84%E6%96%99/"},{"content":"如下一张表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  CREATETABLE\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;(\u0026#34;id\u0026#34;varchar(32)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;NOTNULL,\u0026#34;org_id\u0026#34;varchar(32)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;DEFAULT\u0026#39;\u0026#39;::charactervarying,\u0026#34;is_delete\u0026#34;int2DEFAULT0,\u0026#34;gmt_create_time\u0026#34;timestamptz(6)DEFAULTnow(),\u0026#34;field_type\u0026#34;int4DEFAULT1,\u0026#34;data_type\u0026#34;int4DEFAULT1,\u0026#34;default_value\u0026#34;varchar(255)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;DEFAULT\u0026#39;\u0026#39;::charactervarying,\u0026#34;default_json_schema\u0026#34;jsonb,\u0026#34;is_required\u0026#34;int2DEFAULT0,\u0026#34;is_form_index\u0026#34;int2,\u0026#34;alias\u0026#34;varchar(128)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;);COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;id\u0026#34;IS\u0026#39;主键\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;org_id\u0026#34;IS\u0026#39;组织ID（系统表单：-1）\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;is_delete\u0026#34;IS\u0026#39;0-未删除；1-删除\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;gmt_create_time\u0026#34;IS\u0026#39;创建时间\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;field_type\u0026#34;IS\u0026#39;字段类型（1：系统，3：自定义）\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;data_type\u0026#34;IS\u0026#39;数据类型（1：字符串，2：整数，3：浮点数，4：布尔，5：日期，6：时间，7：日期时间，9：文件，10：列表，13：表单）\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;default_value\u0026#34;IS\u0026#39;默认数据值\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;default_json_schema\u0026#34;IS\u0026#39;默认json_schema定义\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;is_required\u0026#34;IS\u0026#39;是否必填（0-否，1-是）\u0026#39;;COMMENTONCOLUMN\u0026#34;dyf\u0026#34;.\u0026#34;t_dyf_field\u0026#34;.\u0026#34;is_form_index\u0026#34;IS\u0026#39;是否为表单查询条件\u0026#39;;  初次解析后能得到如下结果\n id String orgId String is_delete Enum gmt_create_time LocalDateTime field_type Enum data_type Enum default_value String default_json_schema Object is_required Enum is_form_index Enum String、Integer、Long、LocalDate、Object等都相对比较简单，Enum是如何解析到这种类型的呢，是传入某个字段的注释，且这个字段的注释符合预先约定的格式，就可以解析成枚举。\n得到这些数据后，我们接下来该做一些什么呢？这些数据将指导我们生成各种实体类\n","description":"","id":813,"section":"notes","tags":null,"title":"流程说明","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/%E6%B5%81%E7%A8%8B%E8%AF%B4%E6%98%8E/"},{"content":"操作步骤  安装nc工具：   yum install -y nc 服务端监听   nc -l -u 0.0.0.0 80001 客户端发送数据报   nc -u 192.168.31.210 数据报一 数据报二 现象：客户端发送的数据报会显示在服务端  参考资料  测试udp服务的端口是否可用   ","description":"","id":814,"section":"notes","tags":null,"title":"测试udp数据报是否可以正常传递","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E6%B5%8B%E8%AF%95udp%E6%95%B0%E6%8D%AE%E6%8A%A5%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E4%BC%A0%E9%80%92/"},{"content":"需求  需要一键在本地跑起所有服务（或者一整套具有依赖关系的服务） 启动时可以指定使用dev环境的配置还是sit环境的配置 启动时可以指定使用本地已构建的jar包还是拉取最新代码进行构建 启动时如果选择了拉取最新代码进行构建，可以选择分支 工具应该提供在Idea中打开项目的快捷键，在Idea打开项目前需要确保该项目已经关闭了，防止端口占用  额外需求  一键切换所有项目的分支 一键构建所用项目并安装到本地 一键发布所有项目到Dev仓库  实现分析 ","description":"","id":815,"section":"notes","tags":null,"title":"测试工具需求收集","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%B5%8B%E8%AF%95%E7%9B%B8%E5%85%B3/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E9%9C%80%E6%B1%82%E6%94%B6%E9%9B%86/"},{"content":"问题描述  异常如下：   org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records. at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:820) ~[kafka-clients-2.3.1.jar!/:?] at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:692) ~[kafka-clients-2.3.1.jar!/:?] at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1454) ~[kafka-clients-2.3.1.jar!/:?] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:2026) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:1849) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:981) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:927) ~[spring-kafka-2.3.6.RELEASE.jar!/:2.3.6.RELEASE] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_242] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_242] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_242] 探索过程  直接Google查到了是因为消费者没有在Kafka指定的时间内确认消费，直接导致了该异常。我们修改了该指定时间，从默认的300秒改为了500秒，问题依旧。 我尝试使用stack查看jvm运行信息，没有结果（很多东西忘记，加之之前主要学习JProfile，总之基本功不到位） 我尝试配置log4j2让log4j2打印更详细的日志，失败了（log4j2的使用经验比较少，配置没有研究过） 其实我想拥有命令行权限，尝试使用更高级的工具，但是没有获得该权限（所以放弃了） 最后欣哥告诉我们，该问题出现过，是一个已知的问题，于是智敏直接操作了数据库中相关的数据，该问题应该可能被解决了（没有验证，参考下一点） 运维的同事也知道这是一个已知的问题，之前的解决方案为跳过Kafka中的该消息，我们采用该方案，该问题立即得到解决  问题原因  我们在消费消息的时候，会拿到某个消息中的数据，然后去查相关的记录，查到的记录有一千多条，我们会在一个循环中通过同步调用完成我们的功能，最后导致消费该消息的时间非常的长，最终抛出如上异常。 我们在该主题的消费为顺序消费，所以一旦一个消息阻塞就会导致消息积压，而且有个更恐怖的问题，如果消费者总是无法消费确认，最终会导致消费者掉线，最终导致整个job-center都不是正常的（需要再确认细节）  解决问题时的不足  无法看到Kafka中目前阻塞流程的消息是什么？ 对jvm提供的命令行工具使用不熟练，之前有意识到命令行工具才是服务端的利器，但是一直没有下定决心去学习 对Kafka不够了解，基础概念忘了很多（之前学习大数据时有系统学习过，不过都差不多忘记了） 对log4j2不熟悉，不能随心所欲的进行配置，这个必须花时间去学习。  总结  其实我也没有办法，最近的这段时间里，我根本没有搭起自己服务端环境，所以相关技术学习动力不够强。 我可能不想再花太多时间在前端学习上了，我自己想要的编辑器，固然很酷炫，但是工作做的不够好，也不行啊  ","description":"","id":816,"section":"notes","tags":null,"title":"消费确认失败的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/kafka/%E6%B6%88%E8%B4%B9%E7%A1%AE%E8%AE%A4%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"Boostrap为应用程序的网络层配置提供了容器（这个理解角度很新颖），这涉及到将一个进程绑定到某个指定的端口，或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程。\n","description":"","id":817,"section":"notes","tags":null,"title":"理解Bootstrap","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3bootstrap/"},{"content":"Netty的数据处理API通过两个组件暴露ByteBuf、ByteBufHolder。ByteBuf有如下优点：\n 它可以被用户自定义的缓冲区类型扩展 通过内置的复合缓冲区类型实现了透明的零拷贝（不是很理解） 容量可以按需增长 在读和写这两种模式之间切换不需要调用flip()方法 读和写使用了不同的索引 支持方法的链式调用 支持引用计数（不是很理解） 支持池化（不是很理解）  使用模式 堆缓冲区 最常用的ByteBuf模式是将数据存储在JVM的堆空间中。这种模式被称为支撑数据，它能在没有使用池化的情况下提供快速的分配和释放。这种方式如下所示，非常适合有遗留的数据需要处理的情况（有遗留数据需要处理，是怎样的一个场景）：\n1 2 3 4 5 6 7 8 9  ByteBuf heapBuf = ...; if(heapBuf.hasArray()) { byte[] array = heapBuf.array(); int offset = heapBuf.arrayOffset() + heapBuf.readerIndex(); int length = heapBuf.readableBytes(); handlerArray(array, offset, length); }   （对ByteBuf的这种处理方式才是正确的，我在学习尚硅谷的课程时，课程中直接拿到array，然后调用toString方法，最后得到的数据会存在乱码）\n当hasArray()方法返回false时，尝试访问支撑数组将触发一个UnsupporterOperationException。\n直接缓冲区 直接缓冲区的内容驻留在常规的会被垃圾回收的堆之外，这解释了为什么直接缓冲区对于网络数据传输是理想的选择。如果数据包含在一个在堆上分配的缓冲区中，那么事实上，在通过套接字发送数据之前，JVM将会在内部把缓冲区复制到一个直接缓冲区中。\n直接缓冲区的主要缺点是，相对于基于堆的缓冲区，它们的分配和释放都较为昂贵。如果在处理遗留代码，可能因为数据不是在堆上，所以不得不再进行一次复制。\n和支撑数组相比，这涉及的工作更多。因此，如果事先知道容器中的数据将会被作为数组来访问，可能更愿意使用堆内存（不是很理解这个说法）。\n1 2 3 4 5 6 7 8 9  ByteBuf directBuf = ...; if(!directBuf.hasArray()) { int length = directBuf.readableBytes(); byte[] array = new byte[length]; directBuf.getBytes(directBuf.readerIndex(), array); handleArray(array, 0, length); }   符合缓冲区 复合缓冲区为多个ByteBuf提供一个聚合视图，Netty通过CompositeByteBuf实现这个模式，这个类提供了一个将多个缓冲区表示为单个合并缓冲区的虚拟表示。\nCompositeByteBuf中的ByteBuf实例可能同时包含直接内存和非直接内存，如果其中只有一个实例，那么对CompositeByteBuf上的hasArray()方法调用将返回该组件上的hasArray()方法的值，否则它将返回false。\n这个技术的使用场景如下：一个HTTP协议消息由头部和主体组成，这两部分由应用程序的不同模块产生，将会在消息被发送时组装。应用程序可以选择为多个消息重用相同的消息主体。当这种情况发生时，对于每个消息都将会创建一个新的头部。\n1 2 3 4 5 6 7 8 9 10 11 12  CompositeByteBuf messageBuf = Unpooled.compositeBuffer(); ByteBuf headerBuf = ...; ByteBuf bodyBuf = ...; messageBuf.addComponents(headerBuf, bodyBuf); // todo something  messageBuf.removeComponent(0);   CompositeByteBuf可能不支撑访问其支撑数据，因此访问CompositeByteBuf中的数据类似于访问直接缓冲区的模式：\n1 2 3 4 5 6 7 8 9 10  CompositeByteBuf compBuf = Unpooled.compositeBuffer(); int length = compBuf.readableBytes(); byte[] array = new byte[length] compBuf.read(compBuf.readerIndex(), array); handleArray(array, 0, array.length);   Netty使用了CompositeByteBuf来优化套接字的IO操作，尽可能地消除了由JDK的缓冲区实现所导致的性能及内存使用率的惩罚。这种优化发生在Netty的核心代码中，因此不会被暴露出来。（不是很理解在讲什么）\n查找操作 最简单的是使用indexOf()进行查找，较为复杂是通过ByteProcessor作为参数的方法搜索，这个接口只定义了一个方法：\n1 2 3  boolean process(byte value)   使用ByteProcessor的简单案例：\n1 2 3 4  ByteBuf buffer = ...; int index = buffer.forEachByte(ByteProcessof.FIND_CR);   派生缓冲区 派生缓冲区为ByteBuf提供了以专门的方式来呈现内容的视图，这类视图是通过如下方法创建的：\n duplicate() slice() slice(int, int) Unpooled.unmodifiableBuffer() order(ByteOrder) readSlice()  这些方法都将返回一个新的ByteBuf实例，它们具有自己的读、写、标记索引。其内部存储是共享的，这使得派生缓冲区的创建成本很低廉，同时也意味着，如果你修改了它的内容，也同时修改了其对应的源实例。\ncopy()和copy(int, int)方法可以实现缓冲区的复制。这两个调用返回的ByteBuf拥有独立的数据副本。\norder是用于指定使用哪种字节序读取数据。\nduplicate和slice的区别 如下代码，最终输出结果为2，0：\n1 2 3 4 5 6 7 8 9 10 11 12  ByteBuf byteBuf = Unpooled.copiedBuffer(\u0026#34;Hello，World\u0026#34;, StandardCharsets.UTF_8); byteBuf.readByte(); byteBuf.readByte(); ByteBuf duplicate = byteBuf.duplicate(); ByteBuf slice = byteBuf.slice(); System.out.println(duplicate.readerIndex()); System.out.println(slice.readerIndex());   slice和duplicate的区别就在于此，duplicate会将readerIndex和writeIndex都duplicate下来，而slice不会，slice会新建一条readerIndex和writeIndex，具体是如何实现的，我暂时还不想花费精力去研究。\nByteBufHolder 书中简单的提了一下ByteBufHolder，我暂时不研究，等未来有需要再研究。\nByteBuf分配 为了降低分配和释放内存的开销，Netty通过ByteBufAllocator实现了ByteBuf的池化，它可以用来分配任意类型的ByteBuf实例。使用池化是特定于应用程序的决定，并不会以任何方式改变ByteBuf API的含义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  // 返回一个基于堆或者直接内存的ByteBuf buffer(); buffer(int initialCapacity); buffer(int initialCapacity, int maxCapacity); // 返回一个基于堆内存的ByteBuf heapBuffer(); heapBuffer(int initialCapacity) heapBuffer(int initialCapacity, int maxCapacity) // 返回一个基于直接内存的ByteBuf directBuffer(); directBuffer(int initialCapacity); directBuffer(int initialCapacity, int maxCapacity); // 返回一个可以通过添加最大到指定数据的基于堆的或者直接内存存储的缓冲区来扩展的CompositeByteBuf compositeBuffer(); compositeBuffer(int maxNumComponents); compositeDirectBuffer(); compositeDirectBuffer(); compositeHeapBuffer(); compositeHeapBuffer(); // 返回一个用于套接字的IO操作的ByteBuf ioBuffer();   可以通过Channel（每个都可以用一个不同的ByteBufAllocator实例）或者绑定到ChannelHandler的ChannelHandlerContext获取一个到ByteBufAllocator的引用。\n1 2 3 4 5 6 7  Channel channel = ...; ByteBufAllocator allocator = channel.alloc(); ChannelHandlerContext ctx = ...; ByteBufAllocator allocator = ctx.alloc();   Netty提供了两种ByteBufAllocator的实现：PooledByteBufAllocator和UnpooledByteBufAllocator。前者池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片。此实现使用了一种成为jemalloc的已被大量现代操作系统所采用的高效方法来分配内存。后者的实现不池化ByteBuf实例，并且每次它被调用时都会返回一个新的实例。\nNetty默认使用了PooledByteBufAllocator，但是可以很容易地通过ChannelConfig或者引导程序时指定一个不同的分配器来更改。\nUnpooled 这个好东西我已经在使用了。\n引用技术 （我觉得Java可能不需要这个技术，但是池化需要这个技术）（好尴尬，刚理解到这一层就发现书中也是怎么说的）\nNetty为ByteBuf和ByteBufHolder引入了引用技术技术，它们都实现了ReferenceCounted。\n1 2 3 4 5 6 7 8 9 10 11  // 查看引用技术  Channel channel = ...; ByteBuf buffer = channel.alloc().directBuffer(); assert buffer.refCnt() == 1; // 释放引用计数的对象 ByteBuf buffer = ...; boolean released = buffer.release();   其他知识点   可以调用readerIndex(index)、writeIndex(index)来手动设置readerIndex和writeIndex。\n  可以调用discardReadBytes()丢弃已经读取过的字节，从而回收空间。\n  markReaderIndex()、markWriterIndex()、resetWriterIndex()、resetReaderIndex()可以用来标记和重置ByteBuf的readerIndex和writerIndex（我实际上不知道到这些技术的应用场景）。\n  可以调用clear()方法来将readerIndex和writerIndex都设置为0。\n  往ByteBuf中写入数据时，首先确保目标ByteBuf具有足够的可写入空间来容纳当前要写入的数据，如果没有，则将检查当前的写索引以及最大容量是否可以在扩展后容纳该数据，可以则分配并调整容量，否则就会抛出异常（如何体现在代码中）。\n  ByteBufUtils中的hexdump()以十六进制的表达形式打印ByteBuf的内容；equals(ByteBuf, ByteBuf)用于判断两个ByteBuf实例的相等性。\n  验证的问题 如果尝试在缓冲区的可读字数已经耗尽时从中读取数据，那么将引发一个IndexOutOfBoundException。那么source.readBytes(ByteBuf dest);会报错么？\n最后验证的结果为会报错，readBytes会尽量去将dest的空间塞满，如果此时source的数据不够，则直接抛出异常。\n","description":"","id":818,"section":"notes","tags":null,"title":"理解ByteBuf","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3bytebuf/"},{"content":"Channel 基本的IO操作（bind、connect、read、write、accept）依赖于底层网络传输所提供的原语。在基于Java的网络编程中，其基本的构造是Socket。Netty的Channel接口所提供的API，大大降低了使用Socket类的复杂性。\n此外，Channel也是拥有许多预定义的，专门化实现的广泛类层次结构的根，下面时一个简短的部分清单：\n EmbeddedChannel LocalServerChannel NioDatagramChannel NioSctpChannel NioSocketChannel  （这部分内容接触的比较少，还不是很理解）\n每个Channel都将会被分配一个ChannelPipeline和ChannelConfig。ChannelConfig包含了该Channel的所有配置设置，并且支持热更新。由于特定的传输类型可能具有独特的设置，所以它可能会实现一个ChannelConfig的子类型（我是第一次接触ChannelConfig）。\nChannel的其他方法：\n  eventLoop：返回分配给Channel的EventLoop（不知道怎么利用这个）\n  pipeline：返回分配给Channel的ChannelPipeline\n  isActive：如果Channel是活动的，则返回true。活动的意义可能依赖于底层的传输。例如一个Socket传输一旦链接到了远程节点便是活动的，而一个Datagram传输一点被打开便是活动的\n  localAddress：返回本地的SockerAddress\n  remoteAddress：返回远程的SockerAddress\n  write：将数据写到远程节点。这个数据将被传递给ChannelPipeline，并且排队知道它被冲刷\n  flush：将之前已写的数据冲刷到底层传输，如一个Socket\n  writeAndFlush：等同于调用write()并接着调用flush()\n  Netty的Channel实现是线程安全的，因此可以存储一个到Channel的引用，并且每当需要向远程节点写数据时，都可以使用它，即使当时很多线程都在使用它。\nEventLoop Channel、EventLoop、Thread以及EventLoopGroup的关系：\n  一个EventLoopGroup包含一个或者多个EventLoop\n  一个EventLoop在它的生命周期内只有一个Thread绑定\n  所有由EventLoop处理的IO事件都将在它专有的Thread上被处理（不是很理解，是说EventLoop绑定的特定线程池么，还是说EventLoop线程）\n  一个Channel在它的生命周期内只注册于一个EventLoop\n  一个EventLoop可能被分配给一个或多个Channel（这种表述方式容易让人迷惑）\n  在这种设计模式中，一个给定的Channel的IO操作都是由相同的Thread执行的，实际上消除了对同步的需要。\n（我现在迷惑的是EventLoop上发现了IO事件，它是交给自己的线程池处理，还是由EventLoop线程处理，如果由EventLoop线程处理，如果任务阻塞了该怎么办，这时候用taskQueue么，如果不是由EventLoop线程处理，感觉和上面的描述有矛盾）\n","description":"","id":819,"section":"notes","tags":null,"title":"理解Channel、EventLoop的关系","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3channeleventloop%E7%9A%84%E5%85%B3%E7%B3%BB/"},{"content":"Java内置队列 基于数组线程安全的队列，比较典型的是ArrayBlockingQueue，它主要是通过加锁的方式来保证线程安全；基于链表的线程安全队列分为LinkedBlockingQueue和ConcurrentLinkedQueue两大类，前者也是通过锁的方式来实现线程安全，而后者是通过CAS这种不加锁的方式来实现的（LinkedTransferQueue也是通过CAS实现的）。\n通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确切的范围内）；而加锁的方式，可以实现有界队列。在稳定性特别高的系统中，为了防止生产这生产速度过快，导致内存溢出，只能选择有界队列；同时为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。这样筛选下来，符合条件的队列只有ArrayBlockingQueue。\nArrayBlockingQueue伪共享的问题 什么是共享 如下图计算的基本结构，L1、L2、L3分别代表一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。\n当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中（这个比较好理解）。\n另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据（这个比较好理解）。\n缓存行 Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。\nCPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line（当前位置之后的）。\n在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。\n测试利用cache line和不使用cache line特定的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public class Main { static long[][] arr; public static void main(String[] args) { arr = new long[1024 * 1024][]; for (int i = 0; i \u0026lt; 1024 * 1024; i++) { arr[i] = new long[8]; for (int j = 0; j \u0026lt; 8; j++) { arr[i][j] = 0L; } } long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 1024 * 1024; i++) { for (int j = 0; j \u0026lt; 8; j++) { sum += arr[i][j]; } } System.out.println(\u0026#34;Loop times: \u0026#34; + (System.currentTimeMillis() - marked) + \u0026#34;ms\u0026#34;); marked = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 8; i++) { for (int j = 0; j \u0026lt; 1024 * 1024; j++) { sum += arr[j][i]; } } System.out.println(\u0026#34;Loop times: \u0026#34; + (System.currentTimeMillis() - marked) + \u0026#34;ms\u0026#34;); } }   什么是伪共享 ArrayBlockingQueue有三个成员变量： - takeIndex：需要被取走的元素下标 - putIndex：可被元素插入的位置的下标 - count：队列中元素的数量\n这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果（因为一个线程修改后，其他线程需要重新从主存读取）。\n如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取（本来我只需要从主存中只重新获取putIndex、count的，现在好了，我takeIndex也需要重新获取）。\n这种无法充分使用缓存行特性的现象，称为伪共享。\n对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103  public class Main2 { // 用于表明执行次数  public final static long ITERATIONS = 500L * 1000L * 100L; private final int arrayIndex; private static ValuePadding[] longs; private static ValueNoPadding[] longs2; public Main2(final int arrayIndex) { this.arrayIndex = arrayIndex; } public static void main(String[] args) throws Exception { for (int i = 0; i \u0026lt; 10; i++) { System.gc(); long start = System.currentTimeMillis(); runTest2(i); System.out.println(\u0026#34;Thread run \u0026#34; + i + \u0026#34; duration = \u0026#34; + (System.currentTimeMillis() - start)); } for (int i = 0; i \u0026lt; 10; i++) { System.gc(); long start = System.currentTimeMillis(); runTest(i); System.out.println(\u0026#34;Thread run \u0026#34; + i + \u0026#34; duration = \u0026#34; + (System.currentTimeMillis() - start)); } } private static void runTest(int NUM_THREADS) throws InterruptedException { // 创建包含1个到10个ValuePadding的ValuePadding数组  longs = new ValuePadding[NUM_THREADS]; for (int i = 0; i \u0026lt; longs.length; i++) { longs[i] = new ValuePadding(); } // 创建包含1个到10个Thread的Thread数组  Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i \u0026lt; threads.length; i++) { final int idxInLong = i; threads[i] = new Thread(() -\u0026gt; { long idx = ITERATIONS + 1; while (0 != --idx) { longs[idxInLong].value = 0L; } }); } for (Thread thread : threads) { thread.start(); } for (Thread thread : threads) { thread.join(); } } private static void runTest2(int NUM_THREADS) throws InterruptedException { // 创建包含1个到10个ValuePadding的ValuePadding数组  longs2 = new ValueNoPadding[NUM_THREADS]; for (int i = 0; i \u0026lt; longs2.length; i++) { longs2[i] = new ValueNoPadding(); } // 创建包含1个到10个Thread的Thread数组  Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i \u0026lt; threads.length; i++) { final int idxInLong = i; threads[i] = new Thread(() -\u0026gt; { long idx = ITERATIONS + 1; while (0 != --idx) { longs2[idxInLong].value = 0L; } }); } for (Thread thread : threads) { thread.start(); } for (Thread thread : threads) { thread.join(); } } public final static class ValuePadding { protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14, p15; } public final static class ValueNoPadding { // protected long p1, p2, p3, p4, p5, p6, p7;  protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15;  } }   该实验的输出结果如下：\n Thread run 0 duration = 0 Thread run 1 duration = 347 Thread run 2 duration = 1343 Thread run 3 duration = 2503 Thread run 4 duration = 3456 Thread run 5 duration = 2898 Thread run 6 duration = 3359 Thread run 7 duration = 3413 Thread run 8 duration = 3802 Thread run 9 duration = 3943 Thread run 0 duration = 0 Thread run 1 duration = 313 Thread run 2 duration = 322 Thread run 3 duration = 318 Thread run 4 duration = 417 Thread run 5 duration = 419 Thread run 6 duration = 467 Thread run 7 duration = 456 Thread run 8 duration = 513 Thread run 9 duration = 515 分析一下为什么该实验可以验证通过增加元素的间隔使得不同线程存取的元素位于不同的缓存行上，如下代码所示，这行代码是说我第一条线程将第一个longs数组中第一个ValuePadding的value设置成0L。在内存上，这些ValuePadding会位于不同的缓存行，所以对某个线程而言，即使其他线程修改其他的ValuePadding，也不会影响当前的线程的ValuePadding的缓存行。\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 创建包含1个到10个Thread的Thread数组 Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i \u0026lt; threads.length; i++) { final int idxInLong = i; threads[i] = new Thread(() -\u0026gt; { long idx = ITERATIONS + 1; while (0 != --idx) { longs[idxInLong].value = 0L; } }); }   而针对ValueNoPadding，由于没有缓存行，所以可能多个ValueNoPadding位于同一个缓存行中，这样就会导致B线程修改B线程的ValueNoPadding时，一定会导致A线程重新的去主存里加载自己的ValueNoPadding，这个时候就造成了伪缓存。\n备注：在jdk1.8中，有专门的注解@Contended来避免伪共享，更优雅地解决问题。（这个我还没有研究和使用过）\nDisruptor的设计方案 Disruptor采用了以下设计来解决队列速度慢的问题：\n  环形数组结构：为了可以避免垃圾回收，采用数组而非链表。且数组对处理器的缓存机制更加友好。\n  元素位置定位：数组长度2^n，通过位运算，加速定位的速度。下标采用递增的形式，不用担心index溢出的问题。index是long类型，即使100万的QPS的处理速度，也需要30万年才能用完。\n  无锁设计：每个生产者或者消费者线程会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。\n  多个生产者 多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方案时，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。\n（我能这么理解么：就是在Disruptor中申请空间的过程就是上面说的每个线程分配一段空间）\n但是会引入一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与RingBuffer大小相同的buffer：available buffer。当某个位置写入成功的时候，便把available Buffer相应的位置置位，编辑为写入成功。读取的时候，会便利available Buffer，来判断元素是否已经就绪。\n（哈哈，我已经猜到是上面的实现了）\n（我现在产生了新的问题，如果一个线程申请了空间，确迟迟不写入，会不会导致整个队列被阻塞了）\n参考资料  高性能队列——Disruptor  ","description":"","id":820,"section":"notes","tags":null,"title":"理解Distuptor原理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/disruptor/%E7%90%86%E8%A7%A3distuptor%E5%8E%9F%E7%90%86/"},{"content":"今天看Netty源码，遇到如下一个东东：\n1 2 3 4 5 6 7 8 9 10  private static final FastThreadLocal\u0026lt;CodecOutputLists\u0026gt; CODEC_OUTPUT_LISTS_POOL = new FastThreadLocal\u0026lt;CodecOutputLists\u0026gt;() { @Override protected CodecOutputLists initialValue() throws Exception { // 16 CodecOutputList per Thread are cached.  return new CodecOutputLists(16); } };   这使我产生了对FastThreadLocal的兴趣。简单的看了一下FastThreadLocal的JavaDoc文档，说明如下：\n  FastThreadLocal使用数组中的常量索引来查找变量，而不是使用哈希码和哈希表。虽然看起来很微妙，但与使用哈希表相比，它产生了轻微的性能优势，并且在频繁访问时很有用。\n  要利用此线程局部变量，您的线程必须是FastThreadLocalThread或其子类型。 由于这个原因，默认情况下DefaultThreadFactory创建的所有线程都是FastThreadLocalThread。\n  请注意，快速路径仅适用于扩展FastThreadLocalThread的线程，因为它需要一个特殊的字段来存储必要的状态。任何其他类型的线程的访问都会回退到常规的ThreadLocal。\n  得，又引入了一个新的知识点：FastThreadLocalThread。\n对其进行的思考 我暂时对FastThreadLocal底层的东西并不感冒，这个东西真正吸引我的注意的地方是和我平时使用ThreadLocal的方法完全不同，我之前的写法如下：\n1 2 3 4  ThreadLocal\u0026lt;User\u0026gt; cache2 = new ThreadLocal\u0026lt;\u0026gt;(); cache2.set(new User());   我因此去验证了一些ThreadLocal是否支持如上写法，结果发现真的支持：\n1 2 3 4 5 6 7 8  ThreadLocal\u0026lt;User\u0026gt; cache = new ThreadLocal\u0026lt;User\u0026gt;() { @Override protected User initialValue() { return new User(); } };   果真活到老学到老，另外还有另一种写法，非常的优雅帅气：\n1 2 3  ThreadLocal\u0026lt;User\u0026gt; cache = ThreadLocal.withInitial(User::new);   ","description":"","id":821,"section":"notes","tags":null,"title":"理解FastThreadLocal","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E7%90%86%E8%A7%A3fastthreadlocal/"},{"content":"hugo主要有四种布局：single、list、index、404。index就是主页，404就是url找不到时的错误页面，这两个都挺好理解的。\n至于single和list，我目前是这么理解的，如下为content中的内容：\n如果我们的url为localhost:1313/contact，则hugo会使用single布局，因为contact.md在content中是一个文件（叶子），如果我们的url为localhost:1313/blogs，则hugo会使用list布局，因为blogs在content中是一个文件夹（分支）。\n为此我做了一个小小的实验：\n我创建了如下sigle.html和list.html文件（因为我目前正在做内容类型相关的实验，所以我就在此基础上进行我新的实验了）：\n {{/* layouts/acme/sigle.html */}} {{define \u0026quot;body\u0026quot;}} \u0026lt;h1\u0026gt;sigle.html\u0026lt;/h1\u0026gt; {{end}} {{/* layouts/acme/list.html */}} {{define \u0026quot;body\u0026quot;}} \u0026lt;h1\u0026gt;list.html\u0026lt;/h1\u0026gt; {{end}} 此时我重启hugo server是不会看到任何变化的，然后访问markdown和news资源，是不会有任何变化的。我需要怎么做？因为我的sigle和list定义在了acme目录下，所以我需要修改markdow.md文件的type和news文件夹下_index.md的type，将其值改为acme。\n完成上面的步骤后，重启hugo，有如下页面：\n非常棒，和我猜想的一样。\n小结 我学习hugo是为了开发一款我自己的主题，我希望我的主题能呈现gitbook的风格。我掌握了list.html和single.html后，我已经可以完成我想要的效果了（我仅仅只需要开发一个single.html，将css调成gitbook的那种即可）。\n不过，我还是决定再多学习一些，哈哈，感觉hugo真的非常的强大，很喜欢。\n","description":"","id":822,"section":"notes","tags":null,"title":"理解Hugo中的single.html和list.html","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/hugo/%E7%90%86%E8%A7%A3hugo%E4%B8%AD%E7%9A%84single.html%E5%92%8Clist.html/"},{"content":"我一直以为KT Connect命令行工具有一定的玄学因素，参数只是位置放错了，就无法正常的运行，后来才发现是自己理解错了。\n如图：KT Connect的命令行工具是分段的，不同的参数只能位于不同的段：\n图中Global Options参数只能放置在命令行的global options配置项。然后需要写上需要执行的command（可以执行哪些command也在命令行中写了）。\n如何看connect命令支持哪些命令行参数呢，如下执行ktctl connect -help即可。\n按照要求放置各个参数，就不会出现问题了。\n","description":"","id":823,"section":"notes","tags":null,"title":"理解KT Connect命令执行","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/kt-connect/%E7%90%86%E8%A7%A3kt-connect%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"content":"在进行Kubernetes相关的实验时，使用到了该指令，该指令输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  apiVersion:v1clusters:- cluster:certificate-authority-data:DATA+OMITTEDserver:https://192.168.23.60:6443name:kubernetescontexts:- context:cluster:kubernetesuser:kubernetes-adminname:kubernetes-admin@kubernetescurrent-context:kubernetes-admin@kuberneteskind:Configpreferences:{}users:- name:kubernetes-adminuser:client-certificate-data:REDACTEDclient-key-data:REDACTED  clusters：该字段应该说的是集群，我觉得可能在任何情况下都只有一个集群吧。\ncontexts：该字段应该说的是目前具有的上下文，目前只有一个上下文，我待会会尝试创建多个\nusers：该字段应该说的是目前具有的用于，目前也只有一个用户，我待会会尝试常见多个用户\n","description":"","id":824,"section":"notes","tags":null,"title":"理解kubectl config view指令的输出及相关的实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%90%86%E8%A7%A3kubectl-config-view%E6%8C%87%E4%BB%A4%E7%9A%84%E8%BE%93%E5%87%BA%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%9A%84%E5%AE%9E%E9%AA%8C/"},{"content":"Netty使用不同的事件来通知我们状态的改变或者操作的状态，这使得我们能够基于已经发生的事件来触发适当的动作，这些动作可能有：\n 记录日志 数据转换 流控制 应用程序逻辑  Netty是一个网络编程框架，所以事件是按照它们与入站或出站数据流的相关性进行分类的。可能由入站数据或者相关状态更改而触发的事件包括：\n 链接已激活或者链接失活 数据读取 用户事件 错误事件  出站事件是未来将会触发的某个动作的操作结果，这些动作包括：\n 打开或者关闭远程节点的链接 将数据写到或者冲刷到套接字  在ChannelHandler内部，也是用了事件和Future（想看一看源码是如何实现这部分的）。\nNetty的异步编程模型是建立在Future和回调的概念之上的，而将事件派发到ChannelHandler的方法则发生在更深的层次上。\nNetty通过触发事件将Selector从应用程序中抽象出来，消除了所有本来需要手动编写的派发代码。在内部，将会为每个Channel分配一个EventLoop，用于处理所有事件（EventLoop用于处理所有事件），包括：\n 注册感兴趣的事件（这部分代码我怀疑被Bootstrap、ServerBootstrap给隐藏了） 将事件派发给ChannelHandler 安排进一步的动作  EventLoop本身只由一个线程驱动，其处理了一个Channel的所有IO事件，并且在该Eventloop的整个生命周期内都不会改变。\n使得事件流经过ChannelPipeline是ChannelHandler的工作，它们是在应用程序的初始化或者引导阶段被安排的。这些对象接受事件、执行它们所实现的处理逻辑，并将数据传递给链中的下一个ChannelHandler。\n当ChannelHandler被添加到ChannelPipeline时，它将会被分配一个ChannelHandlerContext，其代表了ChannelHandler和ChannelPipeline之间的绑定。虽然这个对象可以被用于获取底层的Channel，但是它主要还是被用于写出数据。\n在Netty中，有两种发送消息的方式。可以直接写到Channel中，也可以写到和ChannelHandler相关联的ChannelHandlerContext对象中。前一种方式会导致消息从ChannelPipeline的尾端开始流动，而后者将导致消息从ChannelPipeline中的下一个ChannelHandler开始流动（擦，我不知道这个下一个该如何理解，如果入站时写，会调用链中的下一个入站ChannelHandler么）。\nChannelHandler的典型用途包括：\n 将数据从一种格式转换成另一种格式（好理解） 提供异常的通知（好理解） 提供Channel变为活动或者非活动的通知（通知到开发人员） 提供当Cahnnel注册到EventLoop或者从EventLoop注销时的通知（通知到开发人员） 提供有关用户自定义事件的通知（目前未接触）  可以根据需要通过添加或者移除ChannelHandler实例来修改ChannelPipeline。通过利用Netty的这项能力可以构建出高度灵活的应用程序。例如，每当STARTTLS协议被请求时，你可以简单地通过想ChannelPipeline添加一个适当的ChannelHandler来按需支持STARTTLS。\n（我在想该技术另一个层面的应用：我们在应用程序和服务端协商后再初始化ChannelPipeline，这样就可以按需加载ChannelHandler，我觉得这个想法非常非常的棒）\nNetty提供了一种额外的传输，可以将一组ChannelHandler作为帮助器类嵌入到其他的ChannelHandler内部，通过这种方式，可以扩展一个ChannelHandler的功能（不是很理解这个在讲什么）。Embedded传输的关键是一个被称为EmbeddedChannel的具体的Channel实现。\n","description":"","id":825,"section":"notes","tags":null,"title":"理解Netty中的事件与ChannelHandler","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3netty%E4%B8%AD%E7%9A%84%E4%BA%8B%E4%BB%B6%E4%B8%8Echannelhandler/"},{"content":"回调 回调理解起来很简单，在Netty中，如下即是回调：\n1 2 3 4 5 6 7 8  public class ConnectHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;Client \u0026#34; + ctx.channel().remoteAddress() + \u0026#34; connected.\u0026#34;); } }   Netty在内部使用了回调来处理事件，当一个回调被触发时，相关的事件可以被ChannelHandler的实现处理。\nFuture Future提供了另一种在操作完成时通知应用程序的方式。这个对象可以看做是一个异步操作的结果的占位符，它将在未来的某个时刻完成，并提供对其结果的访问。\nJDK内置的Future接口只允许手动检查对应的操作是否已经完成，或者一直阻塞直到它完成。这样很繁琐，所以Netty提供了自己的实现ChannelFuture，用于在执行异步操作的时候使用。\n每个Netty的出站IO操作都将返回一个ChannelFuture。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  Channel channel = ...; channel.connect(ADDRESS, PORT).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (future.isSuccess()) { ByteBuf buf = Unpooled.copiedBuffer(\u0026#34;Hello\u0026#34;, StandardCharsets.UTF_8); // writeAndFlush这个IO操作又产生了一个ChannelFuture  ChannelFuture channelFuture1 = future.channel().writeAndFlush(buf); } else { Throwable cause = future.cause(); cause.printStackTrace(); } } });   （这块代码有两点需要注意：1.不是用Bootstrap进行Connect，而是用Channel，这种写法我从来没用过；2.我第一次在ChannelFutureListener中处理异常）\n","description":"","id":826,"section":"notes","tags":null,"title":"理解Netty中的回调与Future","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3netty%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%B0%83%E4%B8%8Efuture/"},{"content":"选择器背后的基本概念是充当一个注册表，在那里可以请求在Channel的状态发生变化时得到通知。可能的状态变化有：\n 新的Channel已被接受并且就绪 Channel链接已经完成 Channel有已经就绪的可供读取的数据 Channel可用于写数据  选择器运行在一个检查状态变化并对其作出响应的线程上，在应用程序对状态的改变作出响应之后，选择器将会被重置，并将重复这个过程（具体的细节不是很理解，我以为是一个While死循环）。\n如下代表了有SelectionKey定义的位模式：\n  OP_ACCEPT：请求在接受新连接并创建Channel时获得通知\n  OP_CONNECT：请求在建立一个连接时获得通知\n  OP_READ：请求当数据已经就绪，可以从Channel中读取时获得通知\n  OP_WRITE：请求当可以向Channel中写更多的数据时获得通知。这处理了套接字缓冲区被完全填满时的情况，这种情况通常发生在数据的发送速度比远程节点可处理的速度更快的时候\n  ","description":"","id":827,"section":"notes","tags":null,"title":"理解SelectionKey","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%90%86%E8%A7%A3selectionkey/"},{"content":"消息字段可以是一下之一：\n singular：消息类型中只能拥有零个或一个此字段，这是proto3语法默认的字段规则 repeated：消息类型中可以重复使用该字段，重复值的顺序将被保留  上面的解释是官方文档中的解释，经过我的实验，我觉得可以这么解释：\n singular：单纯的一个字段 repeated：类似于数组  实验如下：\n1 2 3 4 5 6 7  message SearchRequest2 { string query = 1; repeated int32 page_number = 2; repeated int32 result_per_page = 3;}  生成的entity使用方式如下：\n1 2 3 4 5 6 7 8 9 10  SearchRequest2OuterClass.SearchRequest2.newBuilder() .setQuery(\u0026#34;query\u0026#34;) .setPageNumber(0, 10) .setPageNumber(1, 10) .setPageNumber(2, 10) .setResultPerPage(0, 10) .setResultPerPage(1, 10) .setResultPerPage(2, 10);   ","description":"","id":828,"section":"notes","tags":null,"title":"理解Singular和repeated","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/%E7%90%86%E8%A7%A3singular%E5%92%8Crepeated/"},{"content":"JOSE是一种旨在在各方质检传递声明（Claims）的方法的规范集。我们常用的JWT就是包含了允许客户端访问特定资源的声明。JOSE制定了一系列的规范来达到此目的，目前包含以下几个RFC：\n  JWS：JSON Web签名，描述生成和处理签名消息\n  JWE：JSON Web加密，描述了保护和处理加密消息\n  JWK：JSON Web密钥，描述Javascript对象签名和加密中加密密钥的格式和处理\n  JWA：JSON Web算法，描述了Javascript对象签名和加密中使用的加密算法\n  JWT：JSON Web令牌，描述以JSON编码并由JWS或JWE保护的声明的表示形式\n  JWT JWT实际上是一个对声明进行JOSE处理方式的统称。目前绝大多数教程中提到的JWT实际上应该是JWS——是JWT的一种实现。除了JWS，JWT还有另一种时间JWE。三者的关系如下：\nJWE JWS仅仅对声明（Claims）做了签名（我可以把声明理解成用户要传递的信息么），保证了其不被篡改，但是其payload中的信息是暴露的。也就是说，JWS仅仅保证数据的完整性而不保证数据不被泄漏。也就是说JWS仅仅能保证数据的完整性而不能保证数据不被泄漏。JWE的存在就是为了解决这个问题。\n（我暂时不想研究JWE，因为我目前没有相关的需求）\n参考资料  你知道你对 JSON Web Token 的认识存在误解吗  ","description":"","id":829,"section":"notes","tags":null,"title":"理解什么是JOSE","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/oauth/%E7%90%86%E8%A7%A3%E4%BB%80%E4%B9%88%E6%98%AFjose/"},{"content":"如果考虑使用阿里云Redis的话，哨兵是没有深入研究的价值的，因为阿里云Redis提供了自己的HA组件，来实现备份节点到主节点的转换。但是出于系统学习Redis知识的目的，我还是需要花点时间了解一下哨兵机制底层原理。\n这篇笔记更多的是进行整理。\n配置文件 我没有自己去配哨兵（我用的Helm，可以通过修改values.yaml文件实现哨兵机制）\n 两台Redis服务器的配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # 第一台 port 6379 masterauth admin requirepass admin protected-mode yes bind 192.168.2.110 # 第二台 port 6380 masterauth admin requirepass admin protected-mode yes bind 192.168.2.110 slaveof 192.168.2.110 6379   三个哨兵的配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # 第一个哨兵 port 26379 sentinel monitor mymaster 192.168.2.110 6379 2 sentinel auth-pass mymaster admin sentinel down-after-milliseconds mymaster 15000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 80000 bind 192.168.2.110 protected-mode yes # 第二个哨兵 port 26380 sentinel monitor mymaster 192.168.2.110 6379 2 sentinel auth-pass mymaster admin sentinel down-after-milliseconds mymaster 15000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 80000 bind 192.168.2.110 protected-mode yes # 第三个哨兵 port 26381 sentinel monitor mymaster 192.168.2.110 6379 2 sentinel auth-pass mymaster admin sentinel down-after-milliseconds mymaster 15000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 80000 bind 192.168.2.110 protected-mode yes   工作原理 Sentinel与Sentinel之间、Sentinel与Redis之间的感知   Sentinel与Redis节点：在Sentinel进程启动时，会与Master节点建立连接，然后Sentinel从Master节点获取所有节点信息，之后Sentinel会定时想Master节点和Slave节点发送info命令获取其拓步结构和状态信息。\n  Sentinel与Sentinel节点：基于Redis的Pub/Sub功能，每个Sentinel会向sentinel:hello频道上发送该Sentinel对于主节点的判断以及当前Sentinel节点的信息；同时每个Sentinel也会订阅该频道，来获取其他Sentinel节点的信息已经它们对主节点的判断（主节点如果挂了，这个判断信息有个毛用啊）。\n  通过以上两步，所有的Sentinel节点以及它们与所有的Redis节点之间都已经彼此感知到，之后每个Sentinel节点会向主节点、从节点、以及其余Sentinel节点定时发送ping命令作为心跳检测，来确认这些节点是否可达。\n判断Master节点是否可达   每个sentinel哨兵节点每隔1s向所有的master、slave以及其他sentinel节点发送一个PING命令，作用是通过心跳检测，检测主从服务器的网络连接状态\n  如果master节点回复PING命令的时间超过down-after-milliseconds设定的阈值（默认30s），则这个master会被sentinel标记为主观下线，修改其flags状态为SRI_S_DOWN\n  当sentinel哨兵节点将master标记为主观下线后，会向其余所有的sentinel发送sentinel is-master-down-by-addr消息，询问其他sentinel是否同意该master下线\n  每个sentinel收到命令之后，会根据发送过来的ip和port检查自己判断的结果，回复自己是否认为该master节点已经下线了\n  sentinel收到回复之后，如果同意master节点进入主观下线的sentinel数量大于等于quorum，则master会被标记为客观下线，即认为该节点已经不可用。\n  在一般情况下，每个Sentinel每隔10s向所有的Master，Slave发送INFO命令。当Master被Sentinel标记为客观下线时，Sentinel向下线的Master的所有Slave发送INFO命令的频率会从10秒一次改为每秒一次。作用：发现最新的集群拓扑结构\n  基于Raft算法选举负责故障转移的Sentinel   判断客观下线的sentinel节点向其他sentinel节点发送SENTINEL is-master-down-by-addr ip port current_epoch runid\n  目标sentinel回复是否同意master下线并选举领头sentinel，选择领头sentinel的过程符合先到先得的原则。举例：sentinel1判断了客观下线，向sentinel2发送了第一步中的命令，sentinel2回复了sentinel1，说选你为领头，这时候sentinel3也向sentinel2发送第一步的命令，sentinel2会直接拒绝回复。\n  当sentinel发现选自己的节点个数超过majority的个数的时候，自己就是领头节点\n  如果没有一个sentinel达到了majority的数量，等一段时间，重新选举\n  故障转移   在进行选择之前需要先剔除掉一些不满足条件的slaver，这些slaver不会作为变成master的备选\n 剔除列表中已经下线的从服务 剔除有5s没有回复sentinel的info命令的slave 剔除与已经下线的主服务连接断开时间超过down-after-milliseconds * 10 + master宕机时长的slaver    选主过程\n 选择优先级最高的节点，通过sentinel配置文件中的replica-priority配置项，这个参数越小，表示优先级越高 如果第一步中的优先级相同，选择offset最大的，offset表示主节点向从节点同步数据的偏移量，越大表示同步的数据越多 如果第二步offset也相同，选择run id较小的    修改被选举出来的主节点的配置  领头sentinel会对选出来的从节点执行slaveof no one 命令让其成为主节点 领头sentinel向别的slave发送slaveof命令，告诉他们新的master是谁谁谁，你们向这个master复制数据 如果之前的master重新上线时，领头sentinel同样会给起发送slaveof命令，将其变成从节点  参考资料  Redis哨兵机制原理详解 SpringBoot2.0整合Redis高可用之Sentinel哨兵  ","description":"","id":830,"section":"notes","tags":null,"title":"理解哨兵机制原理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/sentinel/%E7%90%86%E8%A7%A3%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/"},{"content":"如下代码，期待匹配的数字1234567，实际匹配的是数字7\n1 2 3 4  # 输出：7 print(re.match(r\u0026#39;^He.*(\\d+).*Demo$\u0026#39;, \u0026#39;Hello 1234567 World_This is Regex Demo\u0026#39;).group(1))   在贪婪匹配下，.*或匹配尽可能多的字符。正则表达式中.*后面是\\d+，也就是至少一个数字，并没有指定具体多少个数字，因此.*就尽可能匹配多的字符。\n在做匹配时，字符串中间尽量使用非贪婪匹配，也就是用.*?来代替.*以免出现匹配结果缺失的情况：\n1 2 3 4  # 输出：1234567 print(re.match(r\u0026#39;^He.*?(\\d+).*Demo$\u0026#39;, \u0026#39;Hello 1234567 World_This is Regex Demo\u0026#39;).group(1))   .*?如果在字符串结尾，就可能匹配不到任何内容了，因为他会匹配尽可能少的字符。\n1 2 3 4 5 6  content = \u0026#39;https://weibo.com/comment/kEraCN\u0026#39; print(\u0026#39;result1\u0026#39;, re.match(\u0026#39;https.*?comment/(.*)\u0026#39;, content).group(1)) print(\u0026#39;result2\u0026#39;, re.match(\u0026#39;https.*?comment/(.*?)\u0026#39;, content).group(1))   ","description":"","id":831,"section":"notes","tags":null,"title":"理解贪婪与非贪婪","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E7%90%86%E8%A7%A3%E8%B4%AA%E5%A9%AA%E4%B8%8E%E9%9D%9E%E8%B4%AA%E5%A9%AA/"},{"content":"需求产生于我们有两张表，一张表A中的数据为量一张表B中数据的复制品，结果B表结构增加了一些字段，A表未增加这些字段，最后导致接口数据不一致，目标是为A表添加这些字段，并用B表的数据更新A表以后数据。我开发的SQL如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ALTERTABLE\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;ADDCOLUMNapplicable_product_lineVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNcategoryVARCHAR(32)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNdesign_contentVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNmaterials_technologyVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;,ADDCOLUMNsurface_technicsVARCHAR(256)COLLATE\u0026#34;pg_catalog\u0026#34;.\u0026#34;default\u0026#34;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;applicable_product_line\u0026#34;IS\u0026#39;适用产品线\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;category\u0026#34;IS\u0026#39;类目\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;design_content\u0026#34;IS\u0026#39;图案内容\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;materials_technology\u0026#34;IS\u0026#39;材料工艺\u0026#39;;COMMENTONCOLUMN\u0026#34;mall\u0026#34;.\u0026#34;t_mat_mall_favorites_info\u0026#34;.\u0026#34;surface_technics\u0026#34;IS\u0026#39;表面工艺\u0026#39;;UPDATEt_mat_mall_favorites_infoSETapplicable_product_line=t_mat_mall_material.applicable_product_line,category=t_mat_mall_material.category,design_content=t_mat_mall_material.design_content,materials_technology=t_mat_mall_material.materials_technology,surface_technics=t_mat_mall_material.surface_technics,gmt_modify_time=now()FROMt_mat_mall_materialWHEREt_mat_mall_favorites_info.ID=t_mat_mall_material.ID  20210508后续：\n这件事情有后续的，上面开发的SQL无法在DMS中使用，我开发了下面的SQL：\n UPDATE t_mat_mall_favorites_info SET applicable_product_line = ( SELECT applicable_product_line FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), category = ( SELECT category FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), design_content = ( SELECT design_content FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), materials_technology = ( SELECT materials_technology FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ), surface_technics = ( SELECT surface_technics FROM t_mat_mall_material WHERE t_mat_mall_favorites_info.ID = t_mat_mall_material.ID ) 但是非常奇怪的是，之前版本开发的SQL只修改了\n","description":"","id":832,"section":"notes","tags":null,"title":"用一张表中的数据去更新另一张表","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E7%94%A8%E4%B8%80%E5%BC%A0%E8%A1%A8%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%BB%E6%9B%B4%E6%96%B0%E5%8F%A6%E4%B8%80%E5%BC%A0%E8%A1%A8/"},{"content":"对模板的配置 我在模板上执行了如下指令（凭记忆回忆的）：\n 配置下网络环境（我在配置模板机时，网络环境还没有搭起来，所以只能走全局代理的方式了）   # 公司 export all_proxy=http://192.168.13.113:1080 # 家（通过OpenWrt代理的） nmcli connection modify eth0 \\ ipv4.addresses 172.20.11.200/24 \\ ipv4.dns 172.20.11.210 \\ ipv4.method manual \\ ipv4.gateway 172.20.11.210 \\ connection.autoconnect yes nmcli c up eth0  安装docker（相关内容，我有更完整的文档说明，可以参考下）。   yum install -y yum-utils yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io systemctl start docker systemctl enable docker 安装lrzsz   yum install -y lrzsz 关闭firewalld、selinux、swap，配置内核参数（应该做而忘记做了的）   # 关闭防火墙 systemctl disable firewalld systemctl stop firewalld # 临时禁用selinux setenforce 0 sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux sed -i \u0026quot;s/SELINUX=enforcing/SELINUX=disabled/g\u0026quot; /etc/selinux/config # 禁用交换分区 swapoff -a sed -i 's/.*swap.*/#\u0026amp;/' /etc/fstab # 修改内核参数 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system # 重启后检查配置是否生效 reboot systemctl status firewalld sestatus swapon -s 我目前就记起了这四步，之后想起来了再整理。\n安装K8S的工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubectl kubeadm kubelet # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet   对虚拟机的配置  修改hostname   hostnamectl set-hostname base hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 hostnamectl set-hostname node4 hostnamectl set-hostname node5 编辑/etc/hosts文件（不编辑这个文件，Kubernetes集群初始化时会出现问题）   tee /etc/hosts \u0026lt;\u0026lt;-'EOF' 127.0.0.1 localhost 192.168.13.68 base 192.168.13.195 node1 192.168.13.83 node2 192.168.13.32 node3 192.168.13.105 node4 192.168.13.236 node5 EOF tee /etc/hosts \u0026lt;\u0026lt;-'EOF' 127.0.0.1 localhost 172.20.11.201 base 172.20.11.202 node1 172.20.11.203 node2 172.20.11.204 node3 172.20.11.205 node4 172.20.11.206 node5 EOF  配置网络环境：   nmcli connection modify eth0 \\ ipv4.addresses 192.168.13.195/24 \\ ipv4.dns 192.168.13.77 \\ ipv4.method manual \\ ipv4.gateway 192.168.13.77 \\ connection.autoconnect yes nmcli c up eth0 完成以上工作，就完成了一个集群的基本配置了。\n","description":"","id":833,"section":"notes","tags":null,"title":"用于K8S集群的模板配置及对生成的虚拟机的调整","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E7%94%A8%E4%BA%8Ek8s%E9%9B%86%E7%BE%A4%E7%9A%84%E6%A8%A1%E6%9D%BF%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%AF%B9%E7%94%9F%E6%88%90%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E8%B0%83%E6%95%B4/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  package com.sdstc.pdm.common.codec; import com.alibaba.fastjson.parser.DefaultJSONParser; import com.alibaba.fastjson.parser.deserializer.ObjectDeserializer; import com.alibaba.fastjson.serializer.JSONSerializer; import com.alibaba.fastjson.serializer.ObjectSerializer; import java.io.IOException; import java.lang.reflect.Type; import java.time.LocalDateTime; import java.time.ZoneOffset; public class LocalDateTimeCodec implements ObjectSerializer, ObjectDeserializer { @Override public \u0026lt;T\u0026gt; T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { if (type != LocalDateTime.class) { throw new RuntimeException(\u0026#34;Wrong Type\u0026#34;); } Long timestamp = Long.valueOf((String) parser.parse()); //noinspection unchecked  return (T) LocalDateTime.ofEpochSecond( timestamp / 1000, 0, ZoneOffset.ofHours(8)); } @Override public int getFastMatchToken() { return 0; } @Override public void write(JSONSerializer serializer, Object object, Object fieldName, Type fieldType, int features) throws IOException { if (!(object instanceof LocalDateTime)) { throw new RuntimeException(\u0026#34;Wrong Type\u0026#34;); } LocalDateTime time = (LocalDateTime) object; serializer.write(time.toInstant(ZoneOffset.of(\u0026#34;+8\u0026#34;)).toEpochMilli()); } }   目前还是临时方案，我会持续迭代这个Codec。\n参考资料  localdatetime实现时间戳(相互转换)  ","description":"","id":834,"section":"notes","tags":null,"title":"用于LocalDateTime的Codec","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/localdatetime/%E7%94%A8%E4%BA%8Elocaldatetime%E7%9A%84codec/"},{"content":"Autowired 虽然我们现在开发的时候基本用不上这个注解（我们基本用构造函数注入），但是有些东西还是需要了解一下的。\n @Autowired默认按照类型去容器中找对应的组件，如果找到了多个相同的组件，将再按照属性的名称作为组件的id去容器中查找。在实验中，如果在容器中按照类型寻找到了多个组件，且此时这些组件的id和属性名不相等，则会报如下错误（这个时候Idea也会报红，注意下就好）：   org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.example.jj.demo.configuration.TempTmpConfiguration': Unsatisfied dependency expressed through field 'user'; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.example.jj.demo.damain.User' available: expected single matching bean but found 2: user01,user02 可以通过@Qualifier注解，该注解会让@Autowire所有的默认行为都失效，而直接通过该注解给定的组件Id从容器中寻找。  1 2 3 4 5  @Autowired @Qualifier(\u0026#34;bookDao2\u0026#34;) private BookDao bookDao    使用了@Autowired注解，则容器中一定要有符合条件的组件进行装配，否则会报错。当然可以指定@Autowired的required参数为false。\n  @Autowired是可以结合@Primary注解使用的，当我们注入Bean的时候，如果某个Bean上使用了@Primary注解，则@Autowired会有限注入该Bean（想一想，感觉这些注解的实现逻辑会错综复杂，也不知道Spring的开发团队是如何清晰的管理这些框架逻辑的）。在实验中，如果你同时为多个Bean标注了该注解，且注入的时候仅使用了@Autowired注解（我以为会回归到@Autowired的默认行为，看样子不行），则会抛如下的错误，此时如果使用@Qualifier，则不会抛出任何错误。\n   org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.example.jj.demo.configuration.TestTmpConfiguration': Unsatisfied dependency expressed through field 'user01'; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.example.jj.demo.damain.User' available: more than one 'primary' bean found among candidates: [user01, user02] @Autowired可以注解在构造器、参数、方法上。    标注在方法上时，如果该方法同时也被@Bean注解，则可以省略@Autowired注解（额，我大概能猜到原理）\n  标注在构造器上时，如果组件只有一个有参构造器，则这个有参构造器上可以省略@Autowired（这个的原理不好猜）。\n  @Resource和@Inject 如下两个注解皆为Java规范，而@Autowired为Spring定义的：\n  @Resource默认是按照组件名称进行装配的，不支持@Primary功能，不支持required=false参数。\n  @Inject需要导入javax.inject包，和@Autowired的功能一样\n  自定义组件需要使用ApplicationContext、BeanFactory等 自定义组件实现xxxAware，在创建对象的时候，会调用接口规范的方法注入相关的组件。该方案主要用于将Spring底层的一些组件注入到自定义的Bean中。在实现层面，每个xxxAware基本都对应一个xxxAwareProcessor，例如ApplicationContextAware对应ApplicationContextAwareProcessor。\n","description":"","id":835,"section":"notes","tags":null,"title":"用于注入Bean的一些注解","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring/%E7%94%A8%E4%BA%8E%E6%B3%A8%E5%85%A5bean%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B3%A8%E8%A7%A3/"},{"content":"其实别名这个技术挺鸡肋的，如果你使用了别名，Idea的代码跳转就无法实现。但是如果为一些常用的工具类设置别名，可以让mapper.xml文件看上去更优雅一点。\n我们项目保留了一份MyBatis的配置文件，所以正好可以用来配置工具类的别名：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 全局映射器启用缓存 --\u0026gt; \u0026lt;setting name=\u0026#34;useGeneratedKeys\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- 允许 JDBC 支持自动生成主键 --\u0026gt; \u0026lt;setting name=\u0026#34;defaultExecutorType\u0026#34; value=\u0026#34;REUSE\u0026#34;/\u0026gt; \u0026lt;!-- 配置默认的执行器 --\u0026gt; \u0026lt;setting name=\u0026#34;logImpl\u0026#34; value=\u0026#34;SLF4J\u0026#34;/\u0026gt; \u0026lt;!-- 指定 MyBatis 所用日志的具体实现 --\u0026gt; \u0026lt;!-- \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; 驼峰式命名 --\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias type=\u0026#34;org.apache.commons.collections4.CollectionUtils\u0026#34; alias=\u0026#34;CollectionUtils\u0026#34;/\u0026gt; \u0026lt;typeAlias type=\u0026#34;org.apache.commons.lang3.StringUtils\u0026#34; alias=\u0026#34;StringUtils\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;/configuration\u0026gt;   在Mapper中的用法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218  \u0026lt;mapper namespace=\u0026#34;com.sdstc.tmp.server.mapper.TrendModelMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;selectForUpdateById\u0026#34; resultType=\u0026#34;com.sdstc.tmp.server.entity.TrendModel\u0026#34;\u0026gt; select id, favorites_count, browse_count from t_trend_model where is_delete = \u0026#39;0\u0026#39; and id = #{id} for update \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;pageTrendModel\u0026#34; resultType=\u0026#34;com.sdstc.tmp.server.entity.TrendModel\u0026#34;\u0026gt; select * from t_trend_model trm \u0026lt;!-- 登录状态，且搜索条件中包含收藏 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.collect == 1\u0026#34;\u0026gt; join t_favorite tf on trm.id = tf.trend_model_id \u0026lt;/if\u0026gt; \u0026lt;!-- 登录状态，且搜索条件中包含浏览 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.viewed == 1\u0026#34;\u0026gt; join t_viewed tv on trm.id = tv.trend_model_id \u0026lt;/if\u0026gt; where trm.is_delete = 0 \u0026lt;!-- 登录状态，且搜索条件中包含收藏 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.collect == 1\u0026#34;\u0026gt; and tf.is_delete = 0 and tf.creator = #{userId} \u0026lt;/if\u0026gt; \u0026lt;!-- 登录状态，且搜索条件中包含浏览 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.viewed == 1\u0026#34;\u0026gt; and tv.is_delete = 0 and tv.creator = #{userId} and tv.org_id = #{tenantId} \u0026lt;/if\u0026gt; \u0026lt;!-- 关键字 --\u0026gt; \u0026lt;if test=\u0026#34;@StringUtils@isNotBlank(condition.keyword)\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;keyword\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + condition.keyword + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; and (trm.theme like #{keyword} or trm.design_points like #{keyword}) \u0026lt;/if\u0026gt; \u0026lt;!-- 趋势主题（in查询） --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.themes)\u0026#34;\u0026gt; AND trm.theme in \u0026lt;foreach collection=\u0026#34;condition.themes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;themes\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{theme} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 趋势主题（like查询） --\u0026gt; \u0026lt;if test=\u0026#34;@StringUtils@isNotBlank(condition.theme)\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;theme\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + condition.theme + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; AND trm.theme like #{theme} \u0026lt;/if\u0026gt; \u0026lt;!-- 适用品牌 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.brands)\u0026#34;\u0026gt; AND trm.brand in \u0026lt;foreach collection=\u0026#34;condition.brands\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;brand\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{brand} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 允许预览，个人身份登录 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.allowView == 1 and personalLogin\u0026#34;\u0026gt; AND (trm.personal_allow_view = 1 or trm.personal_allow_used = 1) \u0026lt;/if\u0026gt; \u0026lt;!-- 允许预览，企业身份登录 --\u0026gt; \u0026lt;if test=\u0026#34;loginFlag == 1 and condition.allowView == 1 and !personalLogin\u0026#34;\u0026gt; AND (trm.company_allow_view::jsonb ??| array[#{tenantId}] or trm.company_allow_used::jsonb ??| array[#{tenantId}]) \u0026lt;/if\u0026gt; \u0026lt;!-- 发布状态 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.publishStatus)\u0026#34;\u0026gt; AND trm.publish_status in \u0026lt;foreach collection=\u0026#34;condition.publishStatus\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;publishStatusItem\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{publishStatusItem} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 型体号（in查询） --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.modelNumbers)\u0026#34;\u0026gt; AND trm.model_number in \u0026lt;foreach collection=\u0026#34;condition.modelNumbers\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;modelNumber\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{modelNumber} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 型体号（like查询） --\u0026gt; \u0026lt;if test=\u0026#34;@StringUtils@isNotBlank(condition.modelNumber)\u0026#34;\u0026gt; \u0026lt;bind name=\u0026#34;modelNumber\u0026#34; value=\u0026#34;\u0026#39;%\u0026#39; + condition.modelNumber + \u0026#39;%\u0026#39;\u0026#34;/\u0026gt; AND trm.model_number like #{modelNumber} \u0026lt;/if\u0026gt; \u0026lt;!-- 鞋底 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.soles)\u0026#34;\u0026gt; AND trm.sole in \u0026lt;foreach collection=\u0026#34;condition.soles\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;sole\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{sole} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 跟型 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.heelTypes)\u0026#34;\u0026gt; AND trm.heel_type in \u0026lt;foreach collection=\u0026#34;condition.heelTypes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;heelType\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{heelType} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 跟高 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.heelHeights)\u0026#34;\u0026gt; AND trm.heel_height in \u0026lt;foreach collection=\u0026#34;condition.heelHeights\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;heelHeight\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{heelHeight} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 款式类型 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.shapeTypes)\u0026#34;\u0026gt; AND trm.shape_type in \u0026lt;foreach collection=\u0026#34;condition.shapeTypes\u0026#34; open=\u0026#34;(\u0026#34; close=\u0026#34;)\u0026#34; item=\u0026#34;shapeType\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{shapeType} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 流行趋势 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.trendTags)\u0026#34;\u0026gt; AND trm.trend_tags::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.trendTags\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;trendTag\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{trendTag} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 流行地区 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.regions)\u0026#34;\u0026gt; AND trm.regions::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.regions\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;region\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{region} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 场景风格 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.styles)\u0026#34;\u0026gt; AND trm.styles::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.styles\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;style\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{style} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 面料元素 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.materialElements)\u0026#34;\u0026gt; AND trm.material_elements::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.materialElements\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;materialElement\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{materialElement} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 装饰元素 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.decorativeElements)\u0026#34;\u0026gt; AND trm.decorative_elements::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.decorativeElements\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;decorativeElement\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{decorativeElement} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 工艺 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.crafts)\u0026#34;\u0026gt; AND trm.crafts::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.crafts\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;craft\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{craft} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 适用季节 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.seasons)\u0026#34;\u0026gt; AND trm.seasons::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.seasons\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;season\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{season} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 色系 --\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(condition.colors)\u0026#34;\u0026gt; AND trm.colors::jsonb ??| \u0026lt;foreach collection=\u0026#34;condition.colors\u0026#34; open=\u0026#34;array[\u0026#34; close=\u0026#34;]\u0026#34; item=\u0026#34;color\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; #{color} \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;!-- 是否推荐 --\u0026gt; \u0026lt;if test=\u0026#34;condition.isRecommend != null\u0026#34;\u0026gt; AND trm.is_recommend = #{condition.isRecommend} \u0026lt;/if\u0026gt; \u0026lt;!-- 设计师Id --\u0026gt; \u0026lt;if test=\u0026#34;@StringUtils@isNotBlank(condition.designerId)\u0026#34;\u0026gt; AND trm.designer_id = #{condition.designerId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;@CollectionUtils@isNotEmpty(orderItems)\u0026#34;\u0026gt; order by \u0026lt;foreach collection=\u0026#34;orderItems\u0026#34; item=\u0026#34;orderItem\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; ${orderItem.column} \u0026lt;if test=\u0026#34;not orderItem.asc\u0026#34;\u0026gt;desc\u0026lt;/if\u0026gt; \u0026lt;/foreach\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   ","description":"","id":836,"section":"notes","tags":null,"title":"用别名来简化工具类","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E7%94%A8%E5%88%AB%E5%90%8D%E6%9D%A5%E7%AE%80%E5%8C%96%E5%B7%A5%E5%85%B7%E7%B1%BB/"},{"content":"565行代码，感觉是一个大工程呀~\n首先是MERGE_CUMULATOR和COMPOSITE_CUMULATOR两个成员变量，按照JavaDoc上的说明如下：\n  MERGE_CUMULATOR：通过使用内存副本将 ByteBuf 合并为一个 ByteBuf 来累积 ByteBuf。\n  COMPOSITE_CUMULATOR：通过将 ByteBuf 添加到 CompositeByteBuf 来累积 ByteBuf，因此尽可能不要进行内存复制。 请注意， CompositeByteBuf 使用更复杂的索引实现，因此根据您的用例和解码器实现，这可能会比使用 MERGE_CUMULATOR 慢。\n  我只看了一丢丢，但是我有个大胆的想法，能不能使用Disruptor代替掉CodecOutputList，那这样的话就意味着我们可能需要自行管理我们的消费者线程了。\n（最后放弃这个想法了，因为很多东西还没有吃透，不想瞎搞）\nByteToMessageDecoder有点复杂，但是现阶段没有必要将他们全部吃透，如果我真的要用的化，我觉得我可能大概率是会重写这个东东的。\n","description":"","id":837,"section":"notes","tags":null,"title":"研究ByteToMessageDecoder实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E6%8A%80%E6%9C%AF%E7%82%B9%E7%A0%94%E7%A9%B6/%E8%A7%A3%E7%A0%81%E5%99%A8/%E7%A0%94%E7%A9%B6bytetomessagedecoder%E5%AE%9E%E7%8E%B0/"},{"content":"这是Pipeline的第一个ChannelHandler，有一定的研究价值。ChannelHandler继承了ChannelInboundHandlerAdapter，ChannelInboundHandlerAdapter中并没有什么有价值的东东，它存在的唯一目的是可以避免让你实现那些你不关注的东西，且它的实现并不会被Pipeline调用到。\nChannelInitializer实现了exceptionCaught、handlerAdded、channelRegistered方法，其中exceptionCaught比较简单，没有什么研究价值。\nchannelRegistered在channel注册到NioEventLoop时调用，额，有点难受，那此时调用这个方法的究竟是哪个线程呢，是bossLoop还是workerLoop呢？我认为是workerLoop。\nhandlerAdded在handler被添加到channel的pipeline时调用。我现在真的不知道channelRegistered和handlerAdded谁会先被调用。网上找了一篇博文说是handlerAdded先于channelRegistered调用。\n我简单的研究了一下handlerAdded属于ChannelHandler的方法，ChannelHandler仅有如下的方法，这些方法都很基础，可以想象这些方法应该是先于其他方法的调用。\n1 2 3 4 5 6 7 8  void handlerAdded(ChannelHandlerContext ctx) throws Exception; void handlerRemoved(ChannelHandlerContext ctx) throws Exception; @Deprecated void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;   为了进一步验证，我进行了如下实验：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  BootstrapUtils.runServer(new ChannelInboundHandler() { @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelRegistered: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelUnregistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelUnregistered: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelActive: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelInactive: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;channelRead: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelReadComplete: \u0026#34; + Thread.currentThread().getName()); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { System.out.println(\u0026#34;userEventTriggered: \u0026#34; + Thread.currentThread().getName()); } @Override public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelWritabilityChanged: \u0026#34; + Thread.currentThread().getName()); } @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;handlerAdded: \u0026#34; + Thread.currentThread().getName()); } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;handlerRemoved: \u0026#34; + Thread.currentThread().getName()); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\u0026#34;exceptionCaught: \u0026#34; + Thread.currentThread().getName()); } });   其输出如下：\n handlerAdded: nioEventLoopGroup-3-1 channelRegistered: nioEventLoopGroup-3-1 channelActive: nioEventLoopGroup-3-1 channelRead: nioEventLoopGroup-3-1 channelReadComplete: nioEventLoopGroup-3-1 channelRead: nioEventLoopGroup-3-1 channelReadComplete: nioEventLoopGroup-3-1 channelRead: nioEventLoopGroup-3-1 channelReadComplete: nioEventLoopGroup-3-1 channelRegistered和handlerAdded方法实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  public final void channelRegistered(ChannelHandlerContext ctx) throws Exception { // Normally this method will never be called as handlerAdded(...) should call initChannel(...) and remove  // the handler.  if (initChannel(ctx)) { // we called initChannel(...) so we need to call now pipeline.fireChannelRegistered() to ensure we not  // miss an event.  ctx.pipeline().fireChannelRegistered(); // We are done with init the Channel, removing all the state for the Channel now.  removeState(ctx); } else { // Called initChannel(...) before which is the expected behavior, so just forward the event.  ctx.fireChannelRegistered(); } } @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { if (ctx.channel().isRegistered()) { // This should always be true with our current DefaultChannelPipeline implementation.  // The good thing about calling initChannel(...) in handlerAdded(...) is that there will be no ordering  // surprises if a ChannelInitializer will add another ChannelInitializer. This is as all handlers  // will be added in the expected order.  if (initChannel(ctx)) { // We are done with init the Channel, removing the initializer now.  removeState(ctx); } } }   其中用到的辅助方法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.add(ctx)) { // Guard against re-entrance.  try { initChannel((C) ctx.channel()); } catch (Throwable cause) { // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...).  // We do so to prevent multiple calls to initChannel(...).  exceptionCaught(ctx, cause); } finally { ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } return true; } return false; } private void removeState(final ChannelHandlerContext ctx) { // The removal may happen in an async fashion if the EventExecutor we use does something funky.  if (ctx.isRemoved()) { initMap.remove(ctx); } else { // The context is not removed yet which is most likely the case because a custom EventExecutor is used.  // Let\u0026#39;s schedule it on the EventExecutor to give it some more time to be completed in case it is offloaded.  ctx.executor().execute(new Runnable() { @Override public void run() { initMap.remove(ctx); } }); } }   在断点调试中发现其实只有handlerAdded运行了。因为运行handlerAdded的线程已经为workerLoop中的线程，所以此时ctx.channel().isRegistered()的值应该为true。\n小结（错误） （这个小结是我在研究了很多东西后总结的）\nChannelInitializer上是标注了@Sharable的，也就是说这个类某种程度上是一个单例，理论上我们的实现也应该是支持@Sharable的。\n为什么建议我们的实现也是@Sharable呢，因为在ChannelInitializer中有一个Set\u0026lt;ChannelHandlerContext\u0026gt; initMap = Collections.newSetFromMap(new ConcurrentHashMap\u0026lt;ChannelHandlerContext, Boolean\u0026gt;())，我对initMap的理解是：当每个channel的某个ChannelInitializer首次被调用时，会经其ctx放入到initMap中，如果该channel再次调用该ChannelInitializer，因为initMap.add(ctx)返回的值为false，就可以防止多次运行同一个ChannelInitializer，也就防止了多次用同一个ChannelInitializer对Pipeline进行了支持。\n如果我们的ChannelInitializer不是@Sharable，也就以为这我们会使用addLast(new xxxChannelInitializer)的方式添加ChannelInitializer，这样很有可能同一个ChannelInitializer被多次添加，然后引发了一些不不要的问题。测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  private static class InnerChannelInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { System.out.println(\u0026#34;Running\u0026#34;); } } public static void main(String[] args) { BootstrapUtils.runServer(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new InnerChannelInitializer()); ch.pipeline().addLast(new InnerChannelInitializer()); ch.pipeline().addLast(new InnerChannelInitializer()); } }); }   小结2 上面的理解是错误的，我用如下代码发现Running运行了三次：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  public class Server2 { @ChannelHandler.Sharable private static class InnerChannelInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; { @Override protected void initChannel(SocketChannel ch) throws Exception { System.out.println(\u0026#34;Running\u0026#34;); } } public static void main(String[] args) { InnerChannelInitializer innerChannelInitializer = new InnerChannelInitializer(); BootstrapUtils.runServer(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(innerChannelInitializer); ch.pipeline().addLast(innerChannelInitializer); ch.pipeline().addLast(innerChannelInitializer); } }); } }   我忽视了ChannelInitializer在初始化Pipeline后会进行移除，我现在是完全不知道initMap有什么存在的价值了。\n我为什么认为initMap没有价值呢，因为我的实现思路是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  public void handlerAdded(ChannelHandlerContext ctx) throws Exception { if(ctx.channel().isRegistered()) { initChannel((C) ctx.channel()); ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { pipeline.remove(this); } } }   可能理解initMap还是有点难度，因为我了解的应用场景有限，所以暂时不花费精力用来理解这些知识了。\n","description":"","id":838,"section":"notes","tags":null,"title":"研究ChannelInitializer实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E7%A0%94%E7%A9%B6channelinitializer%E5%AE%9E%E7%8E%B0/"},{"content":"先是一个什么都不做的CodecOutputListRecycler，代码如下：\n1 2 3 4 5 6 7 8  private static final CodecOutputListRecycler NOOP_RECYCLER = new CodecOutputListRecycler() { @Override public void recycle(CodecOutputList object) { // drop on the floor and let the GC handle it.  } };   接下来是一个FastThreadLocal\u0026lt;CodecOutputLists\u0026gt;，代码如下：\n1 2 3 4 5 6 7 8 9 10  private static final FastThreadLocal\u0026lt;CodecOutputLists\u0026gt; CODEC_OUTPUT_LISTS_POOL = new FastThreadLocal\u0026lt;CodecOutputLists\u0026gt;() { @Override protected CodecOutputLists initialValue() throws Exception { // 16 CodecOutputList per Thread are cached.  return new CodecOutputLists(16); } };   值得注意的是，这块使用的是CodecOutputLists，而并不是CodecOutputList，而在我们ByteToMessageDecoder中使用的是：CodecOutputList out = CodecOutputList.newInstance();\n简单看了一下CodecOutputLists的构造函数，它只是初始了一个CodecOutputList数组，然后在里面塞了16个CodecOutputList。\n而在在ByteToMessageDecoder中的CodecOutputList.newInstance()，实现上最终调用的是CodecOutputLists的getOrCreate方法。这个方法会先从上面缓存的16个CodecOutputList中拿一个，如果已经被拿完了，则创建一些。\n这个过程中有些数字挺迷惑人的，比如创建CodecOutputLists时的16，初始化CodecOutputList数组时的，传递到每个CodecOutputList的16，和最后临时创建的CodecOutputList时传入给构造函数的4。它们都是有不同的含义的，这个晚点我会整理到。\n如下代码，我简单测了一下长度带来的影响：\n","description":"","id":839,"section":"notes","tags":null,"title":"研究CodecOutputList实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E6%8A%80%E6%9C%AF%E7%82%B9%E7%A0%94%E7%A9%B6/%E8%A7%A3%E7%A0%81%E5%99%A8/%E7%A0%94%E7%A9%B6codecoutputlist%E5%AE%9E%E7%8E%B0/"},{"content":"执行如下指令，下载下IngressNginx的配置文件：\n1 2 3  kubectl exec -it ingress-nginx-controller-54d8b558d4-vm4wq -n ingress-nginx -- cat /etc/nginx/nginx.conf \u0026gt; nginx.conf   查看该配置文件，发现如下配置：\n # PEM sha: 6d61bf891c964552ba11d97bc3a2e5b571458602 ssl_certificate /etc/ingress-controller/ssl/default-fake-certificate.pem; ssl_certificate_key /etc/ingress-controller/ssl/default-fake-certificate.pem; 所以我分析，https的支持是在IngressNginx实现的。\n","description":"","id":840,"section":"notes","tags":null,"title":"研究IngressNginx的https是如何被支持的","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E7%A0%94%E7%A9%B6ingressnginx%E7%9A%84https%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E6%94%AF%E6%8C%81%E7%9A%84/"},{"content":"我目前分析是我在生成秘钥时操作失误了，我还不能确定具体原因，先观察一段时间吧。\n20220218后续 不是因为密钥的问题，是因为我电脑所处的网络环境的问题，大概率是运营商丢弃了我的UDP包，我是如何知道的呢？\n 同样的密钥，使用不同运营商的网络，能正常ping通 我在内网环境中搭建了另一个wg服务端，然后建立连接，能正常ping通  ","description":"","id":843,"section":"notes","tags":null,"title":"秘钥生成错误，会导致全链路无法ping通","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/%E7%A7%98%E9%92%A5%E7%94%9F%E6%88%90%E9%94%99%E8%AF%AF%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%85%A8%E9%93%BE%E8%B7%AF%E6%97%A0%E6%B3%95ping%E9%80%9A/"},{"content":"检测空闲链接及超时对于及时释放资源来说是至关重要的。\n  IdleStateHandler：当链接空闲时间太长时，将会触发一个IdleStateEvent事件。然后可以通过在ChannelInboundHandler中重写userEventTrigger方法来处理该IdleStateEvent事件。\n  ReadTimeoutHandler：如果在指定时间内没有收到任何的入站数据，则抛出一个ReadTimeoutException，可以通过重写exceptionCaught方法来检测该ReadTimeoutException。\n  WriteTimeoutHandler：如果在指定时间内没有收到任何的出站数据，则抛出一个WriteTimeoutException，可以通过重写exceptionCaught方法来检测该WriteTimeoutException。\n  IdleStateHandler在实践中使用的频率最高。\n","description":"","id":844,"section":"notes","tags":null,"title":"空闲的连接和超时","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%A9%BA%E9%97%B2%E7%9A%84%E8%BF%9E%E6%8E%A5%E5%92%8C%E8%B6%85%E6%97%B6/"},{"content":"如下为实验目录及文件：\n其中gihub-actions-demo.yml内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  name:GitHub Actions Demoon:[push]jobs:Explore-GitHub-Actions:runs-on:ubuntu-lateststeps:- run:echo \u0026#34;🎉 The job was automatically triggered by a ${{ github.event_name }} event.\u0026#34;- run:echo \u0026#34;🐧 This job is now running on a ${{ runner.os }} server hosted by GitHub!\u0026#34;- run:echo \u0026#34;🔎 The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\u0026#34;- name:Check out repository codeuses:actions/checkout@v2- run:echo \u0026#34;💡 The ${{ github.repository }} repository has been cloned to the runner.\u0026#34;- run:echo \u0026#34;🖥️ The workflow is now ready to test your code on the runner.\u0026#34;- name:List files in the repositoryrun:|ls ${{ github.workspace }}- run:echo \u0026#34;🍏 This job\u0026#39;s status is ${{ job.status }}.\u0026#34;  当push到仓库时，可以Actions选项卡中看到如下内容（实验中我共Push了三次，触发了Actions三次）：\n左侧为我们在yml中定义的所有工作流，右侧为该工作流执行结果。可以点击执行结果查看执行详情：\n此时右侧为我们定义的Job，点击Job查看Job执行详情：\n本次实验到此结束，这是我第一次接触Github Actions，感觉还是挺有趣的。\n参考资料  GitHub Actions 快速入门  ","description":"","id":845,"section":"notes","tags":null,"title":"简单使用GitHub Actions","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8github-actions/"},{"content":"如下，我准备的协议文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13  // 协议的版本 syntax = \u0026#34;proto3\u0026#34;;// 生成的外部类名，同时也是文件名 option java_outer_classname = \u0026#34;StudentPOJO\u0026#34;;// 会在StudentPOJO外部类生成一个内部类Student，他是真正发送的POJO对象 message Student { int32 id = 1; string name = 2;}  我用如下的指令生成Java文件（我已经为protobuf配置了环境变量）：\n1 2 3  protoc --java_out . student.proto   遇到的问题 生成的java代码中如下处会报红，报红的原因是找不到UnusedPrivateParameter类：\n1 2 3 4 5 6 7  @java.lang.Override @SuppressWarnings({\u0026#34;unused\u0026#34;}) protected java.lang.Object newInstance(UnusedPrivateParameter unused) { return new DeleteRequest(); }   我解决这个问题的方法是，修改protobuf的依赖为3.17.3，和我的编译工具一致。\n但是我没有简单的放下这个问题，我很好奇，为什么我的代码中并不存在UnusedPrivateParameter类的定义，而且生成的代码中也没有任何包的引入，为什么就可以使用这个类呢（因为我一度怀疑是我的工具配置错了，所以出现了这个类）。\n我在检查生成的字节码时，发现导入该包的代码又出现了，我是不是可以理解有个什么类似Lombok的工具，可以在编译期自动帮我编译一些代码：\n后续：\n额，UnusedPrivateParameter其实是其父类的一个静态内部类~\n","description":"","id":846,"section":"notes","tags":null,"title":"简单的使用protobuf及使用过程中遇到的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/protobuf/%E7%AE%80%E5%8D%95%E7%9A%84%E4%BD%BF%E7%94%A8protobuf%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"服务端使用内存对结果排序 当客户端使用流水线发送命令时，服务器将被迫使用内存对回复进行排队。因此，如果您需要使用流水线发送大量命令，最好将它们分批发送，每个包含合理数量的命令，例如10k个命令，读取回复，然后再次发送另外10k个命令，依此类推。速度将几乎相同，但使用的额外内存将最大为对这10k命令的回复进行排队所需的数量。\n","description":"","id":847,"section":"notes","tags":null,"title":"管道","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E7%AE%A1%E9%81%93/"},{"content":"代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Max(150) @Min(0) @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE}) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {}) public @interface JAge { @OverridesAttribute(constraint = Max.class, name = \u0026#34;message\u0026#34;) @OverridesAttribute(constraint = Min.class, name = \u0026#34;message\u0026#34;) String message() default \u0026#34;年龄超出范围\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; }   需要注意的两个地方：\n 类上的@Max(150)，@Min(0)这两个注解是真正的实现校验的注解。 message上的@OverridesAttribute，如果不存在这个，则提示信息将会为@Max和@Min的提示信息。@OverridesAttribute注解可以覆盖组合约束的一些属性  参考资料  spring boot 参数校验这么做简洁实用  ","description":"","id":848,"section":"notes","tags":null,"title":"组合约束","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/validation/%E7%BB%84%E5%90%88%E7%BA%A6%E6%9D%9F/"},{"content":"已经对结构进行了修改的Lua脚本将无法被中断\n在使用EVAL或者EVALSHA执行Lua脚本的时候，用户可能会写出永远也不返回的脚本，导致其他客户端无法正常地执行命令，为了解决这一问题，Redis提供了两种方法来停止正在运行的脚本，选择使用哪种方法取决于脚本是否执行了Redis的写命令。\n对于不执行任何写命令的只读脚本来说，用户可以在脚本的运行时间超过lua-time-limit选项指定的时间之后，执行SCRIPT KILL命令杀死正在运行的脚本（lua-time-limit的详细信息可以通过Redis的配置文件查看）。\n另一方面，如果脚本已经对Redis存储的数据进行了写入，那么杀死脚本将导致Redis存储的数据进入一种不一致的状态，在这种情况下，用户唯一能够使用的恢复（recover）手段就是使用SHUTDOWN NOSAVE命令杀死Redis服务器，这将导致Redis丢失最近一次创建快照之后或者最近一次将命令写入AOF文件之后数据发生的所有变化。\n因为以上这些限制，我们必须在将脚本放到生产环境里面运行之前，先对脚本进行测试\n","description":"","id":849,"section":"notes","tags":null,"title":"终止正在执行的脚本","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/scripts/%E7%BB%88%E6%AD%A2%E6%AD%A3%E5%9C%A8%E6%89%A7%E8%A1%8C%E7%9A%84%E8%84%9A%E6%9C%AC/"},{"content":"我搞了一个picture_3d的字段，结果在插入数据的时候报错，报的错误是picture3d字段不存在，我使用TableField注解暂时解决了这个问题。以后需要注意在设计字段的时候尽量不要融入数字：\n1 2 3 4 5 6 7  /** * 3D图 */ @TableField(\u0026#34;picture_3d\u0026#34;) private String picture3d;   ","description":"","id":850,"section":"notes","tags":null,"title":"给字段取名时需要注意的一些细节","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E7%BB%99%E5%AD%97%E6%AE%B5%E5%8F%96%E5%90%8D%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/"},{"content":"需求过少，不在维护\n公司电脑锁屏后，重登时都会出现与工作站失去信任关系的问题，解决该问题必须重启机器。运维同事帮我解决了很多次，都没有效果，非常绝望。更绝望的是我有随手按Win + L的习惯。\n与其指望自己不按Win + L键，不如把这个键给禁了。\n操作步骤   打开注册表（Win + R，输入regedit进入）\n  进入如下目录：\n   计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies  在左侧：鼠标右键Policies，新建项，命名为System\n  点开System，在右侧，新建DWORD (32-bit) ，命名为DisableLockWorkstation\n  右键点击新建的DisableLockWorkstation，点击修改，将值改为1\n  参考资料  How to Disable the Lock Screen Shortcut Key (Win + L) in Windows  个人小结 本想截图把过程说清晰，但是我打开注册表时，Snapaste就无法使用。参考资料里有清楚的图片，如果不是太理解可以参考那些图片。参考资料可能会无法访问，可以直接谷歌“how to disable lock screen hotkey in win10”。\n这个需求要的人应该非常的少，我百度了很长时间都没有找到解决方案。\n3.20号，运维大大帮我解决这个问题了，非常开心~\n","description":"","id":851,"section":"notes","tags":null,"title":"绝望的Win10锁屏与解决方案","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/win/%E4%BD%9C%E5%BA%9F/%E7%BB%9D%E6%9C%9B%E7%9A%84win10%E9%94%81%E5%B1%8F%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"content":"decode和decodeLast 由于不可能知道远程节点是否会一次性地发送一个完整的消息，所以ByteToMessageDecoder会对入站数据进行缓冲，直到它准备好处理。\n decode：decode方法被调用时将会传入一个包含了传入数据的ByteBuf，以及一个用来添加解码消息的List。对这个方法的调用将会重复进行，直到确定没有新的元素被添加到该List，或者该ByteBuf中没有更多可读取的字节时为止。然后，如果该List不为空，那么它的内容将会被传递给ChannelPipeline中的下一个ChannelInboundHandler。  我对ByteToMessageDecoder的实现有一些自己的想法：ByteToMessageDecoder实现了ChannelInboundHandler，在read方法中，调用decode方法（此时方法是抽象的），调用完成后，可能需要将ByteBuf中已经读取的数据给清理一下（我自己猜的，我认为这个ByteBuf可能需要复用），然后判断out的长度，如果大于零，则通过ctx调用下一个handler的读取方法。（简单看了下源码，大致思路是一致的）\n上面的分析的问题是，我不知道如何在ChannelInboundHandler的read方法中实现多次复用一个ByteBuf，可以实现这个效果么。我意识到一个问题，在decode方法中，不一定能将所有的字节给处理了，那么没有被处理的字节应该被放在哪呢。\n decodeLast：默认实现只是简单地调用了decode方法。当Channel变成非活动时，这个方法会被调用一次。可以重写该方法以提供特殊的处理。  编解码中的引用计数 对于编码器和解码器来说，其过程是相当的简单：一旦消息被编码或者解码，它就会被ReferenceCountUtil.release(message)调用自动释放，如果需要保留引用以便稍后使用，可以调用ReferenchCountUtil.retain(message)方法，这将会增加引用技术，从而防止该消息被释放。\nReplayingDecoder ReplayingDecoder扩展了ByteToMessageDecoder类，可以不必调用readableBytes方法。它通过使用一个自定义的ByteBuf实现——ReplayingDecoderByteBuf，包装传入的ByteBuf实现了这一点，其将在内部执行该调用。\n额，如果是封装在ByteBuf里，那发现长度不足该怎么处理了，直接返回的话是返回到调用方法啊，不能退出Decoder，我看了源码，有点可怕：\n1 2 3 4 5 6 7 8 9 10 11 12 13  @Override public int readInt() { checkReadableBytes(4); return buffer.readInt(); } private void checkReadableBytes(int readableBytes) { if (buffer.readableBytes() \u0026lt; readableBytes) { throw REPLAY; } }   利用异常控制程序的流转，这个性能损失还是蛮大的，我还是不要使用这个类了。\nReplayingDecoderByteBuf注意事项：\n 并不是所有的ByteBuf操作都被支持，如果调用了不被支持的方法， 将会抛出异常 ReplayingDecoder稍慢于ByteToMessageDecoder  CombinedChannelDuplexHandler CombinedChannelDuplexHandler充当了ChannelInboundHandler和ChannelOutboundHandler的容器。通过提供分别继承了解码器类和编码器类的类型，我们可以实现一个编解码器，而又不必直接扩展抽象的编解码器类。\n1 2 3  public class   ","description":"","id":852,"section":"notes","tags":null,"title":"编解码器","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty-in-action/%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8/"},{"content":"具体报Redis的错误我忘记整理了，但是该错误我曾经遇到过，如下（日志来自另一篇笔记）：\n java.lang.IllegalStateException: Failed to load ApplicationContext at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:132) at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:123) at org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:190) at org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:132) at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:244) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.createTest(SpringJUnit4ClassRunner.java:227) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner$1.runReflectiveCall(SpringJUnit4ClassRunner.java:289) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.methodBlock(SpringJUnit4ClassRunner.java:291) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:246) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:97) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61) at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:70) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:190) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70) Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redisUtil': Unsatisfied dependency expressed through field 'redisTemplate'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:643) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:130) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1422) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:594) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:893) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:879) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:551) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758) at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750) at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397) at org.springframework.boot.SpringApplication.run(SpringApplication.java:315) at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:120) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:99) at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124) ... 24 more Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'stringRedisTemplate' defined in class path resource [cn/watsons/mmp/brand/api/config/redis/RedisConfig.class]: Unsatisfied dependency expressed through method 'stringRedisTemplate' parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:797) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:538) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640) ... 43 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [org/springframework/boot/autoconfigure/data/redis/LettuceConnectionConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:655) at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:635) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1338) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1177) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:557) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:517) at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:323) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:226) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:321) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1304) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1224) at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:884) at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:788) ... 56 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory]: Factory method 'redisConnectionFactory' threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185) at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:650) ... 70 more Caused by: java.lang.NoClassDefFoundError: org/apache/commons/pool2/impl/GenericObjectPoolConfig at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration$LettucePoolingClientConfigurationBuilder.\u0026lt;init\u0026gt;(LettucePoolingClientConfiguration.java:94) at org.springframework.data.redis.connection.lettuce.LettucePoolingClientConfiguration.builder(LettucePoolingClientConfiguration.java:51) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration$PoolBuilderFactory.createBuilder(LettuceConnectionConfiguration.java:159) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.createBuilder(LettuceConnectionConfiguration.java:107) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.getLettuceClientConfiguration(LettuceConnectionConfiguration.java:92) at org.springframework.boot.autoconfigure.data.redis.LettuceConnectionConfiguration.redisConnectionFactory(LettuceConnectionConfiguration.java:74) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) ... 71 more Caused by: java.lang.ClassNotFoundException: org.apache.commons.pool2.impl.GenericObjectPoolConfig at java.net.URLClassLoader.findClass(URLClassLoader.java:382) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 82 more 这个错误的原因是没有引入连接池，我们这次报错也是同样的错误原因，但是导致我们没有成功引入连接池的原因确实我们忘记设置项目的parent了。在sdstc-core项目中，我们定义了连接池依赖，在ststc-spring-boot-parent-start中，我们定义了变量，值为依赖的版本，由于我们设置parent标签，导致这些变量不可用，最终导致我们依赖引入失败。\n","description":"","id":853,"section":"notes","tags":null,"title":"缺乏父依赖，导致项目报Redis链接错误","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E7%BC%BA%E4%B9%8F%E7%88%B6%E4%BE%9D%E8%B5%96%E5%AF%BC%E8%87%B4%E9%A1%B9%E7%9B%AE%E6%8A%A5redis%E9%93%BE%E6%8E%A5%E9%94%99%E8%AF%AF/"},{"content":"纠结在三，我还是决定使用PVE做为我的虚拟化方案，我之前一直坚持的CentOS + Virtual + Vagrant方案，原因无非有以下亮点：\n  CentOS上可以配置透明代理，从而实现所有虚拟机直接访问外网，从而避免的设置各种代理，且因为软件源原因导致的下载速度过慢。\n  Vagrant方案非常的灵活，并且我积累的大量的脚本，可以迅速的启动我想要的实验环境。而且使用Vagrant是比较符合我的个人情况的，我不需要稳定的虚拟机，我只需要在我需要的时候能够快速启动我想要的环境。\n  那么我决定放弃这个方案的原因有哪些呢？\n  CentOS搭建透明代理的方案并不理想，下载速度仍然比较低，而且在拉取gcr.io镜像时，经常在部分层需要卡很久。而且每当出现下载缓慢的时候，我还需要去检查我的透明代理是否正常工作。我认为是因为我CentOS的内核相较于OpenWRT等系统是没有经过优化的，它并不是服务于路由场景，所以即使配置了透明代理，速度依然很慢。\n  我目前技术已经定型了，我的学习节奏相比以前更慢更稳，我不用再去尝试一些新的东西，比如Hadoop、Hbase等，所以我不需要频繁的销毁并创建新的虚拟机环境。相反我需要更稳定的虚拟机环境，我需要去搭建自己的稳定的Kubernetes集群、Istio集群，并在上面做应用技术的研究。\n  方案设计 使用PVE后，整体呈现如下：\n细节设计如下，我先从J4125开始：\nJ4125 J4125是我的家里的软路由，因为CPU型号是J4125，所以我简称为J4125。该机器目前采用了物理机安装OpenWRT系统方案，我未来会调整为使用PVE虚拟化技术，实现OpenWRT、Windows双系统。OpenWRT系统作为路由系统，Windows系统目前的计划是安装一些下载器。\nJ4125上有4个2.5g网卡，我计划将我家庭内部升级到2.5g网络，方便我试验的时候往各台机器上传送文件（现在的100M实在是太慢了）。\nOpenWRT上将会安装的插件有：\n frpc：用于实现内网穿透 wol：用于唤醒内网里3400G 透明代理：我计划安装多个版本的透明代理，以适用不同的场景（相关技术还需要结合节点，进行实验研究） openvpn：frpc暴露openvpn接口，通过挂openvpn，可以在家庭直接ping通内网设置（实验环境非常有需要）  基于此，我关于家庭网络最初的设想全部都实现了。我砍去了哪些内容？内外网分离，我曾经想做内外网分离，以确保来我这玩的朋友不会因为连接了我的路由器，而访问到外网。后来想了想，似乎没有这个必要。\n3400G i7 接下来的目标  深入学习PVE 继续深入研究OpenWRT  我将这两种技术当做我的基础技术\n","description":"","id":854,"section":"notes","tags":null,"title":"网络方案（废弃）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%BA%9F%E5%BC%83/"},{"content":"最近接触到一些新的东西，先说说我这边的现象吧：我用npm拉包的时候，报了证书错误；我用yum更新软件的时候，包了证书的错误；今天我用Maven从默认仓库和阿里云拉包的时候，还是报了证书的错误，我开始意识到可能是因为网络管制的问题。\n我询问运维后得知，我们确实有相应的管制，有些网站因为有上传之类的服务，所以被屏蔽了。如果我们的流量是https的，则我们的“小防火墙”就无法了解知道我们流量的内容，所以就无法做策略，所以我们需要怎么做，我们需在我们的计算机中安装证书，这样“小防火墙”就可以知道我们的流量，从而屏蔽（其实我后来分析，可能不完全是这些原因）。\n我是怎么处理这个问题的，我选择了通过我自己的代理服务器，绕开了“小防火墙”。如果不能正常的访问一些技术网站，将非常影响工作效率，这个是难以接受的。\n","description":"","id":855,"section":"notes","tags":null,"title":"网络管制的一些事情","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88/%E7%BD%91%E7%BB%9C%E7%AE%A1%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%E6%83%85/"},{"content":"第一版 代码如下，非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public class TimeClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf m = (ByteBuf) msg; // (1)  try { long currentTimeMillis = (m.readUnsignedInt() - 2208988800L) * 1000L; System.out.println(new Date(currentTimeMillis)); ctx.close(); } finally { m.release(); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); } }   第二版 代码如下，还没有写过这种类型的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  public class TimeClientHandler2 extends ChannelInboundHandlerAdapter { private ByteBuf buf; @Override public void handlerAdded(ChannelHandlerContext ctx) { buf = ctx.alloc().buffer(4); } @Override public void handlerRemoved(ChannelHandlerContext ctx) { buf.release(); buf = null; } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ByteBuf m = (ByteBuf) msg; buf.writeBytes(m); m.release(); if (buf.readableBytes() \u0026gt;= 4) { long currentTimeMillis = (buf.readUnsignedInt() - 2208988800L) * 1000L; System.out.println(new Date(currentTimeMillis)); ctx.close(); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); } }   在handlerRemove中清理掉创建的缓存是一个非常棒的写法。\n参考资料  Writing a Time Client 写个时间客户端 Dealing with a Stream-based Transport 处理一个基于流的传输  ","description":"","id":856,"section":"notes","tags":null,"title":"自动动手实现一个不可分享的ChannelHandler","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/netty%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C/%E8%87%AA%E5%8A%A8%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%B8%8D%E5%8F%AF%E5%88%86%E4%BA%AB%E7%9A%84channelhandler/"},{"content":"我花了很长时间思考这个问题，但是答案确实非常搞笑。因为我在容器启动后运行了wg-quick up wg0，但这不是一条阻塞指令，所以容器在运行完成后直接退出了。\n然后第二次在运行该指令的时候，就开始提示wg0已经存在了。\n","description":"","id":857,"section":"notes","tags":null,"title":"自建wireguard镜像，在k8s中运行时一直提示`wg0' already exists","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E8%87%AA%E5%BB%BAwireguard%E9%95%9C%E5%83%8F%E5%9C%A8k8s%E4%B8%AD%E8%BF%90%E8%A1%8C%E6%97%B6%E4%B8%80%E7%9B%B4%E6%8F%90%E7%A4%BAwg0-already-exists/"},{"content":"这个指令使用的频率太高了，所以专门记一篇笔记：\n1 2 3 4  helm inspect values ingress-nginx/ingress-nginx \u0026gt; values.yaml helm inspect values k8s-at-home/wireguard \u0026gt; values.yaml   ","description":"","id":858,"section":"notes","tags":null,"title":"获取chart的values.yaml","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/helm/%E8%8E%B7%E5%8F%96chart%E7%9A%84values.yaml/"},{"content":"忘记了node添加到master时的指令，可以通过如下指令获取\n1 2 3  kubeadm token create --print-join-command --ttl 0   20211228后续：\n这个指令本来记录在某一篇笔记中，今天需要用了，找了好半天，所以将它单独拉出来写一篇笔记。\n","description":"","id":859,"section":"notes","tags":null,"title":"获取将Node加入到集群中的指令","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E8%8E%B7%E5%8F%96%E5%B0%86node%E5%8A%A0%E5%85%A5%E5%88%B0%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E6%8C%87%E4%BB%A4/"},{"content":"问题描述   因为需要在家访问公司里的工具机上的虚拟机的网络，所以我需要挂访问公司的vpn，然后挂工具机的vpn。\n  但是今天我挂好了这两个vpn后，发现始终无法访问虚拟机上的网络。最后发现是AnyConnect阻止了路由信息的添加，导致网络无法访问\n  定位步骤  重启电脑，使用如下指令删除之前的路由（避免干扰观察），并查看删除结果   route delete 172.17.0.0 route print | findstr \u0026quot;172\u0026quot;   打开AnyConnect连接公司内网，执行如上指令查看路由信息，发现此时有一条路由信息，该配置应该为登录公司VPN后推送的\n  打开OpenVPN登录工具机上的VPN，执行如上指令查看路由信息，发现此时有一条路由信息，不符合实际情况，这个就应该是虚拟机内网无法访问的原因，请求没有被正确路由\n  断开AnyConnect的连接，执行如上指令查看路由信息，期待的路由信息出现。最后定位是AnyConnect的VPN阻止了OpenVPN修改路由信息\n  在OpenVPN成功添加路由信息后，恢复AnyConnect连接，又可以愉快的访问工具机上的虚拟机了\n  相关资料 我在定位解决这个问题后，想知道这是不是AnyConnection的bug时，又发现了如下的资料：\n 解决Cisco AnyConnect 客户端不让改路由表的问题  ","description":"","id":862,"section":"notes","tags":null,"title":"解决AnyConnection与OpenVPN冲突导致的无法直接访问工具机上的虚拟机","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/%E8%A7%A3%E5%86%B3anyconnection%E4%B8%8Eopenvpn%E5%86%B2%E7%AA%81%E5%AF%BC%E8%87%B4%E7%9A%84%E6%97%A0%E6%B3%95%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE%E5%B7%A5%E5%85%B7%E6%9C%BA%E4%B8%8A%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"content":"解决步骤  修改插件源为：  https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json  修改updates/default.json文件：\n updates.jenkins-ci.org/download修改为：mirrors.tuna.tsinghua.edu.cn/jenkins www.google.com修改为：www.baidu.com    重启Jenkins\n  相关教程  【Jenkins】插件更改国内源  ","description":"","id":863,"section":"notes","tags":null,"title":"解决Jenkins下载插件慢","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/jenkins/%E8%A7%A3%E5%86%B3jenkins%E4%B8%8B%E8%BD%BD%E6%8F%92%E4%BB%B6%E6%85%A2/"},{"content":"解决步骤  拿到原镜像地址：  1 2 3  kubectl describe po xxx -n xxx # quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   替换为国内的站点  1 2 3  sudo docker pull quay.mirrors.ustc.edu.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   推送到harbor，方便其他虚拟机进行下载  1 2 3 4  sudo docker tag quay.mirrors.ustc.edu.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 sudo docker push 192.168.30.174:80/test/nginx-ingress-controller:0.30.0   其他虚拟机拉下代码，重新打回原tag  1 2 3 4  sudo docker pull 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 sudo docker tag 192.168.30.174:80/test/nginx-ingress-controller:0.30.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0   相关资料   在国内如何拉取 quay.io 的镜像\n  烂泥：docker.io、gcr.io、quay.io镜像加速(20200413更新)(未实践)\n  【docker 镜像源】解决quay.io和gcr.io国内无法访问的问题(未实践)\n  ","description":"","id":864,"section":"notes","tags":null,"title":"解决Kubernetes从国外站点下载镜像慢的问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E8%A7%A3%E5%86%B3kubernetes%E4%BB%8E%E5%9B%BD%E5%A4%96%E7%AB%99%E7%82%B9%E4%B8%8B%E8%BD%BD%E9%95%9C%E5%83%8F%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题描述  console下会不显示任何东西），在最上面会有一个提示，说客户端事件和服务器实践不一致  解决步骤  调整客户端时间，与服务器一致（分钟级别的），该问题修复  问题小记  我原本想调整服务器事件为世界时间，结果花了很长时间没有解决这个问题，这也激发我以后自己搭ntpd的想法  ","description":"","id":865,"section":"notes","tags":null,"title":"解决Prometheus管理页面的Console下没有任何东西显示","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/prometheus/%E8%A7%A3%E5%86%B3prometheus%E7%AE%A1%E7%90%86%E9%A1%B5%E9%9D%A2%E7%9A%84console%E4%B8%8B%E6%B2%A1%E6%9C%89%E4%BB%BB%E4%BD%95%E4%B8%9C%E8%A5%BF%E6%98%BE%E7%A4%BA/"},{"content":"为了更深刻的学习WireGuard，我开始自己搭建服务端和客户端进行测试。WireGuard本身是不区分服务端和客户端的，但是在我的拓补结构中是可以区分出服务端和客户端的：\n目前遇到的问题就是Windows1和Windows2之间无法ping通。\n解决该问题的方案是，在ECS中开启IP地址转发：\n1 2 3 4 5 6  echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf # 这一行配置可以不用（很多教程都没有这个配置） echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p /etc/sysctl.conf   需要注意的是执行完上面的指令后需要将wg0网口重启一下，即执行：\n1 2 3 4  wg-quick down wg0 wg-quick up wg0   开启IP转发还有别的方法，比如如下指令：\n sysctl -w net.ipv4.ip_forward=1 sysctl -w net.ipv6.conf.all.forwarding=1 如果上面配置需要重启后生效，需要将配置保存在/etc/sysctl.conf中。\n参考资料   \n  轻松几步搭建 WireGuard （快速安全的下一代 VPN）\n学习另一种ip转发的配置方式。\n  ","description":"","id":866,"section":"notes","tags":null,"title":"解决两个Wireguard客户端之间无法Ping通","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/%E8%A7%A3%E5%86%B3%E4%B8%A4%E4%B8%AAwireguard%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B9%8B%E9%97%B4%E6%97%A0%E6%B3%95ping%E9%80%9A/"},{"content":"在装kubernetes时，因为部分镜像下载太慢，我强行终止了下载。待我通过别的网速较快的机器将该镜像拉取并上传到内部的镜像服务器后，然后再次前往这个网速较慢的机器拉取镜像时，即使我已经换了镜像源，镜像始终从断点处拉取。\n解决步骤  查看docker的root目录：  1 2 3  sudo docker info    切换到root用户，进入该目录，删除tmp文件，重docker  1 2 3 4 5 6 7  su root \\  \u0026amp;\u0026amp; cd /var/lib/docker \u0026amp;\u0026amp; rm -r tmp sudo systemctl restart docker   20210504后续：\n没想到今天竟然还有相关的需求。\n参考资料  docker踩坑记  ","description":"","id":867,"section":"notes","tags":null,"title":"解决从不同源拉取同一个镜像多次，始终从断点处执行","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E8%A7%A3%E5%86%B3%E4%BB%8E%E4%B8%8D%E5%90%8C%E6%BA%90%E6%8B%89%E5%8F%96%E5%90%8C%E4%B8%80%E4%B8%AA%E9%95%9C%E5%83%8F%E5%A4%9A%E6%AC%A1%E5%A7%8B%E7%BB%88%E4%BB%8E%E6%96%AD%E7%82%B9%E5%A4%84%E6%89%A7%E8%A1%8C/"},{"content":"说明： 其实这个不是导致问题的核心原因，核心原因是AnyConnection导致的，该问题我已定位并解决，有相关的笔记说明了具体的原因和解决方法，请在相关资料部分中寻找。\n问题描述  ping目标地址172.17.30.101不通 客户端路由信息正确 服务端iptables信息正确 ping 192.168.30.174 通 ping 172.17.0.1 通 ping 172.17.30.1 通  解决方法  指令如下  1  ufw disable   问题小结  首先需要说明的是ufw disable这条指令我一开始就运行过，但是可能是没有控制变量，最终实验效果没有出来 因为之前解决这个问题时，没有详细的观察并记录，导致我一开始就被172.17.30.1可以ping通给误导了，我内心中认定两个问题不是同一个问题  相关资料  解决AnyConnection与OpenVPN冲突导致的无法访问工具机上的虚拟机  ","description":"","id":868,"section":"notes","tags":null,"title":"解决无法访问我工具机上的虚拟机网络的问题（作废）","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/openvpn/%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE%E6%88%91%E5%B7%A5%E5%85%B7%E6%9C%BA%E4%B8%8A%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E9%97%AE%E9%A2%98%E4%BD%9C%E5%BA%9F/"},{"content":"1 2 3  tar -xvf filename.tar   还有一些指令没有消化，先将参考资料罗列下来。\n参考资料  tar文件是什么？怎么解压？  ","description":"","id":869,"section":"notes","tags":null,"title":"解压.tar格式的文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/%E8%A7%A3%E5%8E%8B.tar%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%96%87%E4%BB%B6/"},{"content":"解压tar.xz 1 2 3  tar -xvJf node-v8.11.1-linux-x64.tar.xz   ","description":"","id":870,"section":"notes","tags":null,"title":"解压tar.xz文件","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/%E8%A7%A3%E5%8E%8Btar.xz%E6%96%87%E4%BB%B6/"},{"content":"解压时去掉最外层文件夹 主要是使用--strip-components 1\n1 2 3  tar -xvJf node-v8.11.1-linux-x64.tar.xz --strip-components 1   ","description":"","id":871,"section":"notes","tags":null,"title":"解压是去掉最外层文件夹","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/targzip/%E8%A7%A3%E5%8E%8B%E6%98%AF%E5%8E%BB%E6%8E%89%E6%9C%80%E5%A4%96%E5%B1%82%E6%96%87%E4%BB%B6%E5%A4%B9/"},{"content":"之前开发一个功能时需要用到yaml文件记录配置信息，刚开始使用snakeyml，但是snakeyml有个小小的问题，就是它解析后得到的map的key的顺序与文件中的并不一致。这种情况在很多需求下都是无所谓的，但是因为我们的功能恰巧很重视这个顺序，故只能放弃使用yml。（不知道snakeyml有没有办法通过配置保证key的顺序与文件中的一致）\n后来偶尔发现SpringBoot提供了一些工具，可以简单的处理yaml文件，且能够保证key的顺序，记录如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import org.springframework.beans.factory.config.YamlPropertiesFactoryBean; import org.springframework.core.io.ClassPathResource; @SpringBootTest class YAMLTest{ @SuppressWarnings(\u0026#34;Duplicates\u0026#34;) public void execute() { YamlPropertiesFactoryBean factoryBean = new YamlPropertiesFactoryBean(); factoryBean.setResources(new ClassPathResource(\u0026#34;config/auto-create-tables-schedule.yml\u0026#34;)); Properties properties = factoryBean.getObject(); if (properties != null) { properties.forEach((table, tableCreateSql) -\u0026gt; { }); } } }   这个功能是很久前写的，但是最近因为又遇到了这个问题，故记录之，可能刚好记反了这两个yaml解析工具的特点，见谅，我下次遇到该问题时会及时更新该博客。\n","description":"","id":872,"section":"notes","tags":null,"title":"解析yaml文件的时候维持文件中字段的顺序","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E8%A7%A3%E6%9E%90yaml%E6%96%87%E4%BB%B6%E7%9A%84%E6%97%B6%E5%80%99%E7%BB%B4%E6%8C%81%E6%96%87%E4%BB%B6%E4%B8%AD%E5%AD%97%E6%AE%B5%E7%9A%84%E9%A1%BA%E5%BA%8F/"},{"content":"我没有系统学习相关知识，以后如果有机会，会系统研究下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static String md5_32Encrypt(byte[] bytes) { MessageDigest md5 = null; try { md5 = MessageDigest.getInstance(\u0026#34;MD5\u0026#34;); } catch (Exception e) { e.printStackTrace(); throw new BusinessException(PICTURE_UPLOAD_WRONG); } byte[] md5Bytes = md5.digest(bytes); StringBuilder sb = new StringBuilder(); for (byte md5Byte : md5Bytes) { int val = ((int) md5Byte) \u0026amp; 0xff; if (val \u0026lt; 16) { sb.append(\u0026#34;0\u0026#34;); } sb.append(Integer.toHexString(val)); } return sb.toString(); }   参考资料  java MD5加密(32位MD5加密,16位MD5加密后base64后URL编码,16位MD5base64编码)  ","description":"","id":873,"section":"notes","tags":null,"title":"计算md5值，并转换成32位","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E8%AE%A1%E7%AE%97md5%E5%80%BC%E5%B9%B6%E8%BD%AC%E6%8D%A2%E6%88%9032%E4%BD%8D/"},{"content":"md5 指令如下：\n md5sum 文件名 参考资料  Linux下对文件进行md5校验命令 Shell 变量 Shell —— 变量的声明和使用   ","description":"","id":874,"section":"notes","tags":null,"title":"计算md5值，检测下载内容是否正确","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E8%AE%A1%E7%AE%97md5%E5%80%BC%E6%A3%80%E6%B5%8B%E4%B8%8B%E8%BD%BD%E5%86%85%E5%AE%B9%E6%98%AF%E5%90%A6%E6%AD%A3%E7%A1%AE/"},{"content":"代码如下，单位为秒：\n1 2 3  sleep 50   这个指令其实很强大，但是我没有深入研究。\n","description":"","id":875,"section":"notes","tags":null,"title":"让Shell阻塞一会","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E8%AE%A9shell%E9%98%BB%E5%A1%9E%E4%B8%80%E4%BC%9A/"},{"content":"笔记过于久远，且该场景并不常见，所以不在维护该笔记\nCentOS拨号上网时导致的无法通过192.168.31.217进行ssh的问题。我的解决方案非常的暴力，我拆掉了J4125上的USB网卡，然后将我的笔记本和J4125的enp3s0网卡直连。我对enp3s0网卡进行了如下配置：\n# /etc/sysconfig/network-scripts/ifcfg-enp3s0 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp3s0 UUID=2a6cd38f-6405-4c45-9bd0-2648e1f26a15 DEVICE=enp3s0 ONBOOT=yes IPADDR=192.168.31.1 NETMASK=255.255.255.0 GATEWAY=192.168.31.1 ifcfg-enp3s0这份文件原本是不存在的，我是从系统为我的USB网卡生成的文件中copy出来的，然后改了改。\n接下来配置Windows，Windows配置很简单，就是给一个静态的IP地址就好了。只是我在配置的时候遇到了一些怪异的现象，我填好了ip地址后，退出来后。然后在终端执行ipconfig，会发现我配置的ip地址并没有生效，会变成169.254.69.105，奇奇怪怪，我完全不知道这个ip地址是怎么产生的。\n我多次尝试后，地址依然会变成这个，我只好一一禁用我的网卡，貌似知道我禁用了无线网卡后，该问题才恢复，我其实一开始就断开了我无线的连接，没想到无线网卡还会影响到这个ip的配置，不过我之前无线分配的ip和我这次想设置的ip确实是一样的，可能是发生了什么冲突。\n我好奇的是从网络拓补上来讲，目前的网络拓补和使用USB网卡时的网络拓补基本一样的，这次却可以成功的SSH到J4125上。\n","description":"","id":876,"section":"notes","tags":null,"title":"记录CentOS拨号上网时的一个奇怪的问题","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E4%BD%9C%E5%BA%9F/%E8%AE%B0%E5%BD%95centos%E6%8B%A8%E5%8F%B7%E4%B8%8A%E7%BD%91%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%A5%87%E6%80%AA%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"Digoal.Zhou\u0026rsquo;s Blog\n我暂时没有条件研究这个技术，环境还没有搭好，最近时间也安排的比较满。\n","description":"","id":877,"section":"notes","tags":null,"title":"记录一个大佬的Blog","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/postgresql/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E5%A4%A7%E4%BD%AC%E7%9A%84blog/"},{"content":"我想通过SpringBoot Actuator查看正在运行的应用的一些配置信息，当我引入如下依赖后，启动引用报如下错误：\n \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/D:/MavenRepository/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.13.3/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/D:/MavenRepository/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory] Exception in thread \u0026quot;main\u0026quot; java.lang.ExceptionInInitializerError at com.sdstc.dyf.provider.StartDyfProviderTest.main(StartDyfProviderTest.java:26) Caused by: org.apache.logging.log4j.LoggingException: log4j-slf4j-impl cannot be present with log4j-to-slf4j at org.apache.logging.slf4j.Log4jLoggerFactory.validateContext(Log4jLoggerFactory.java:49) at org.apache.logging.slf4j.Log4jLoggerFactory.newLogger(Log4jLoggerFactory.java:39) at org.apache.logging.slf4j.Log4jLoggerFactory.newLogger(Log4jLoggerFactory.java:30) at org.apache.logging.log4j.spi.AbstractLoggerAdapter.getLogger(AbstractLoggerAdapter.java:54) at org.apache.logging.slf4j.Log4jLoggerFactory.getLogger(Log4jLoggerFactory.java:30) at org.slf4j.LoggerFactory.getLogger(LoggerFactory.java:363) at org.apache.commons.logging.LogAdapter$Slf4jAdapter.createLocationAwareLog(LogAdapter.java:130) at org.apache.commons.logging.LogAdapter.createLog(LogAdapter.java:91) at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:67) at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:59) at org.springframework.boot.SpringApplication.\u0026lt;clinit\u0026gt;(SpringApplication.java:196) ... 1 more 因为我们的项目使用了Maven的SnapShot版本机制，在确定该问题不是同事造成的后，我认为该报错可能是因为jar包冲突。跟架构师了解到，我们的框架默认开启了spring-boot-starter-actuator，所以不需要在引入依赖，我暂时先放置这个问题吧。\n","description":"","id":878,"section":"notes","tags":null,"title":"记录一些解决jar冲突（待完成）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E8%A7%A3%E5%86%B3jar%E5%86%B2%E7%AA%81%E5%BE%85%E5%AE%8C%E6%88%90/"},{"content":"问题简单的描述是这样的：我发现网线两端的网速并不匹配，一边显示100M，一边显示1000M，显示100M的是我的R8125网卡，我就很不开心，想手动速度调整为1000，于是我使用了如下指令:\n ethtool -s enp4s0 speed 1000 autoneg off 发现该操作无效后，我又对着网线的另一端做了类似的操作，最终导致两端的自动协商都被关闭了。于是两个系统就无法正常的通信了，且网口的灯都不闪烁了。\n我刚开始并没有意识到是关闭自动协商导致的问题。\n后来经过实验发现：该操作是可以实现将高速变为低速的，无法将低速变成高速，可能是因为自动协商的结果已经是最高速了。\n","description":"","id":879,"section":"notes","tags":null,"title":"记录一次关闭链路自动协商带来的问题","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/rtl8125/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%85%B3%E9%97%AD%E9%93%BE%E8%B7%AF%E8%87%AA%E5%8A%A8%E5%8D%8F%E5%95%86%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"我们系统架构现在真的拉，一个独立的子系统，有自己独立的数据库数据表，但是最后看上去只是将一部分的Controller以项目为单位分出来了；需求上，还是很多需要连表查询，所以不得不将主项目中的数据冗余一份到这个独立项目中来。\n解决循环依赖问题 冗余的时机是什么？冗余哪些数据？考虑到这个系统使用的人会比较少，没有必要将大量用户的数据导入到自己的库中，我决定在用户首次访问时拉取这些用户的信息。\n如何确保用户的首次访问？我们的系统目前没有办法实现这一点，所以我决定拦截所有的请求，然后判断发起这个请求的用户是否是首次访问。\n拦截请求我使用了Spring MVC相关的拦截器：\n1 2 3 4 5 6 7 8 9 10 11  @Configuration @RequiredArgsConstructor public class CompanyInitInterceptorConfig implements WebMvcConfigurer { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new CompanyInitInterceptor()).order(10); } }   1 2 3 4 5 6 7 8 9 10 11  @Slf4j public class CompanyInitInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { } }   核心代码在CompanyInitInterceptor中，由于在CompanyInitInterceptor中需要调用FeignClient拉取一些数据，而FeignClient又依赖于Web配置，导致这块我们一定会形成循环依赖。\n如何解决循环依赖？我决定让CompanyInitInterceptor脱离IOC容器的管理，由我们自己进行初始化，而在CompanyInitInterceptor中用到的FeignClient在我们在运行的时候从从容器中获取。考虑到并发问题，这儿使用了一个double check。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { private volatile CompanyClientManager companyClientManager; if (companyClientManager == null) { synchronized (CompanyInitInterceptor.class) { if (companyClientManager == null) { companyClientManager = BeanUtils.getBean(CompanyClientManager.class); } } } // do something else }   BeanUtils是如何开发的，其代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class BeanUtils { private static ConfigurableApplicationContext configurableApplicationContext; public static void init(ConfigurableApplicationContext configurableApplicationContext) { if (BeanUtils.configurableApplicationContext != null) { return; } BeanUtils.configurableApplicationContext = configurableApplicationContext; } public static \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; clazz) { if (configurableApplicationContext == null) { return null; } return configurableApplicationContext.getBean(clazz); } }   其初始则是在启动类中：\n1 2 3 4 5 6 7 8 9 10  @EnableFeignClients @SpringBootApplication public class SRMApplication { public static void main(String[] args) { ConfigurableApplicationContext configurableApplicationContext = SpringApplication.run(SRMApplication.class, args); BeanUtils.init(configurableApplicationContext); } }   解决并发问题 由于需要进行一次请求，这个地方的并发问题很突出，很容易就发生了并发问题。如果将整个初始化操作都加上锁，则又会影响用户的体验，所以我决定根据用户的companyId进行上锁。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  private static final ConcurrentHashMap\u0026lt;String, Lock\u0026gt; COMPANY_ID_TO_LOCK = new ConcurrentHashMap\u0026lt;\u0026gt;(); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // do something else  Lock lock = COMPANY_ID_TO_LOCK.computeIfAbsent(companyId, tmp -\u0026gt; new ReentrantLock()); lock.lock(); try { // 查库，判断是否已初始化  try { // 方案一：调用第三方数据进行初始化  return true; } catch (Exception e) { try { // 方案二：直接插入记录进行初始化（稍后等待定时任务进行同步）  return true; } catch (Exception e2) { // 初始化失败了，放行该请求，等待下次请求中初始化  return true; } } } finally { lock.unlock(); } }   我的思路就是用建立companyId到Lock的映射，这样初始化时，只会阻塞某个用户的请求，不会影响到其他的用户。不必担心COMPANY_ID_TO_LOCK会占用太多的内存，因为这个服务的用户量会非常的少，所有的手段都是为了数据安全合法。\n其他 一些其他的东西，比如建立本地缓存，对已查询的、已初始化的进行缓存，加快下次请求的响应时间，这些都是必不可少的，哈哈。\n","description":"","id":880,"section":"notes","tags":null,"title":"记录一次解决并发、循环依赖的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E8%A7%A3%E5%86%B3%E5%B9%B6%E5%8F%91%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"问题是这样的，我们的项目需要使用到GRpc的9090端口，所以申请运维帮我们暴露一下该端口，等我们自己测试该端口时，发现该端口无法正常使用（原80端口是正常的），检查了POD、Service后，可以确认该端口应该处于开启状态的。我后来注意到，运维帮我们配置的Service如下：\n spec: clusterIP: 10.254.73.68 ports: - name: http-tcp port: 80 protocol: TCP targetPort: 8080 - name: http-tcp-9090 port: 9090 protocol: TCP targetPort: 9090 selector: app: dyf-provider sessionAffinity: None type: ClusterIP 我记得我学习Istio时了解到，Istio会根据你Service暴露端口时取的名字，做一些什么操作，我觉得是http-tcp-9090前的http影响到我们了，所以我去掉了http，测试该端口服务正常。我们最后尝试将tpc换成grpc，该端口也是正常使用的。\n最后的最后，为了确认不是巧合，我们又换成了http，该端口服务果然不可以访问了，哈哈，可以肯定就是这个http前缀影响了这个端口的正常使用。\n","description":"","id":881,"section":"notes","tags":null,"title":"记录一次超高速解决Istio问题","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E8%B6%85%E9%AB%98%E9%80%9F%E8%A7%A3%E5%86%B3istio%E9%97%AE%E9%A2%98/"},{"content":"Maven配置代理及常用setting.xml文件 阿里源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;localRepository\u0026gt;F:\\repository\u0026lt;/localRepository\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;proxy\u0026gt; \u0026lt;id\u0026gt;my-proxy\u0026lt;/id\u0026gt; \u0026lt;active\u0026gt;true\u0026lt;/active\u0026gt; \u0026lt;protocol\u0026gt;http\u0026lt;/protocol\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;1080\u0026lt;/port\u0026gt; \u0026lt;/proxy\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt;\u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;aliyunmaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;ali public\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt;\u0026lt;/profiles\u0026gt; \u0026lt;activeProfiles\u0026gt;\u0026lt;/activeProfiles\u0026gt; \u0026lt;/settings\u0026gt;   默认源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;pluginGroups\u0026gt;\u0026lt;/pluginGroups\u0026gt; \u0026lt;localRepository\u0026gt;F:\\repository\u0026lt;/localRepository\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;proxy\u0026gt; \u0026lt;id\u0026gt;my-proxy\u0026lt;/id\u0026gt; \u0026lt;active\u0026gt;true\u0026lt;/active\u0026gt; \u0026lt;protocol\u0026gt;http\u0026lt;/protocol\u0026gt; \u0026lt;host\u0026gt;127.0.0.1\u0026lt;/host\u0026gt; \u0026lt;port\u0026gt;1080\u0026lt;/port\u0026gt; \u0026lt;/proxy\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt;\u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt;\u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt;\u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt;   ","description":"","id":882,"section":"notes","tags":null,"title":"记录两份配置文件，可用于网络限制的场景中","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E4%B8%A4%E4%BB%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%AF%E7%94%A8%E4%BA%8E%E7%BD%91%E7%BB%9C%E9%99%90%E5%88%B6%E7%9A%84%E5%9C%BA%E6%99%AF%E4%B8%AD/"},{"content":"还原命案现场，deploy的时候出现了如下错误：\n [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for thirdplatformcenter 1.0.0: [INFO] [INFO] thirdplatformcenter ................................ FAILURE [ 0.667 s] [INFO] thirdplatform-common ............................... SKIPPED [INFO] thirdplatform-client ............................... SKIPPED [INFO] thirdplatform-server ............................... SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 1.074 s [INFO] Finished at: 2021-04-26T18:25:18+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy (default-deploy) on project thirdplatformcenter: Failed to deploy artifacts: Could not find artifact com.sdstc:thirdplatformcenter:pom:1.0.0 in project-repo (http://192.168.20.9:8081/repository/projectrepo/) -\u0026gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 很熟悉是吧，我在两个不同的场景遇到了相同的报错，而且它们核心的原因都是一样的：仓库的地址找不到。\n我先说说这次发生错误的起因后果，我们的项目依赖了一个内部的框架项目：\n \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.sdstc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sdstc-spring-boot-parent-start\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;/parent\u0026gt; 框架项目的maven中配置了仓库信息：\n \u0026lt;!-- 本地快照 和release 发布 的配置 --\u0026gt; \u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!-- ID要和MAVEN中conif/setting.xml 中的server保持一致 --\u0026gt; \u0026lt;id\u0026gt;project-repo\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;project-repo\u0026lt;/name\u0026gt; \u0026lt;!-- project-repo的url地址 --\u0026gt; \u0026lt;url\u0026gt;${REMOTE_REPO}\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;central\u0026lt;/name\u0026gt; \u0026lt;!-- 配置仓库的地址 --\u0026gt; \u0026lt;url\u0026gt;${REMOTE_PUBLIC}\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 这些仓库信息的具体值是在我们的setting.xml文件中配置的：\n \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;remote-repo\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;REMOTE_REPO\u0026gt;http://192.168.20.9:8081/repository/projectrepo/\u0026lt;/REMOTE_REPO\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;remote-public\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;REMOTE_PUBLIC\u0026gt;http://192.168.20.9:8081/repository/mavenpublic\u0026lt;/REMOTE_PUBLIC\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; 问题在于哪？在于我们的remote-repo在传承的过程中，将http://192.168.20.9:8081/repository/project-repo/地址改为了http://192.168.20.9:8081/repository/projectrepo/，而后者是一个不可访问的地址。\n解决这个问题的方法有哪些了？第一将地址改为正确的，第二在项目的pom.xml文件中加如下配置（后者用在我定位问题和测试我的思路，前者是我最终的采用的方案）：\n \u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;!-- ID要和MAVEN中conif/setting.xml 中的server保持一致 --\u0026gt; \u0026lt;id\u0026gt;project-repo\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;project-repo\u0026lt;/name\u0026gt; \u0026lt;!-- project-repo的url地址 --\u0026gt; \u0026lt;url\u0026gt;http://192.168.20.9:8081/repository/project-repo/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/distributionManagement\u0026gt; 问题解决了，我其实产生了很多新的问题，我之前想尽办法为Maven配置代理的目的是什么？其实上我们的maven-public仓库是配置了阿里云的（感谢小勇，教会我看这个），我使用公司的setting.xml文件时应该是可以拉取到我想要的jar包的。但是当时问题确实太巧合了，我无论如何都拉不到我想要的包，我降了好几个版本都不行，所以我认为是因为仓库原因。\n另外，我本地不能使用中央仓库不能使用阿里云仓库，这本来就不符合我的开发习惯，就像透明代理一样，是一种我必须解决的技术问题。\n后续：\n这个问题更有趣的一点是：我们的pom.xml文件是从pdf文件中复制下来，而pdf中这两个仓库地址刚好处于换行的地方，所以在复制的时候被视为单词的换行符，给自动合并了，这是一个什么鬼？？？后面是Adobe PDF中复制出来的结果（貌似Adobe PDF中所有的横线都会变成空格）。\n \u0026lt;REMOTE_REPO\u0026gt;http://192.168.20.9:8081/repository/project repo/\u0026lt;/REMOTE_REPO\u0026gt; \u0026lt;/prop erties\u0026gt; \u0026lt;/ \u0026lt; \u0026lt;id\u0026gt;remote public\u0026lt;/id\u0026gt; \u0026lt; \u0026lt;REMOTE_PUBLIC\u0026gt;http://192.168.20.9:8081/repository/maven public\u0026lt;/REMOTE_PUBLIC\u0026gt; \u0026lt;/ \u0026lt;/ \u0026lt;/ ","description":"","id":883,"section":"notes","tags":null,"title":"记录解决Maven问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/%E8%AE%B0%E5%BD%95%E8%A7%A3%E5%86%B3maven%E9%97%AE%E9%A2%98/"},{"content":"操作步骤  指令如下  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://cr58lvy7.mirror.aliyuncs.com\u0026#34;], \u0026#34;insecure-registries\u0026#34;:[\u0026#34;192.168.30.174:80\u0026#34;] } EOF sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;insecure-registries\u0026#34;:[\u0026#34;172.16.100.100:80\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker   相关教程  Docker 镜像加速 镜像加速器  ","description":"","id":884,"section":"notes","tags":null,"title":"设置Docker容器加速及允许通过http协议拉取镜像","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/docker/%E8%AE%BE%E7%BD%AEdocker%E5%AE%B9%E5%99%A8%E5%8A%A0%E9%80%9F%E5%8F%8A%E5%85%81%E8%AE%B8%E9%80%9A%E8%BF%87http%E5%8D%8F%E8%AE%AE%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F/"},{"content":"实验的目标是将Pod的名称放在环境变量POD_NAME中，这样就可以在代码中、数据卷挂载时使用该环境变量。\n第一个Deployment：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deployment1labels:app:nginxspec:replicas:1selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80  第二个Deployment：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deployment2labels:app:nginxspec:replicas:1selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80env:- name:POD_NAMEvalueFrom:fieldRef:apiVersion:v1fieldPath:metadata.name  分别查看两个Pod的POD_NAME环境变量：\n1 2 3 4 5 6 7  # 无输出 kubectl exec -it nginx-deployment1-5d59d67564-w22m7 -- bash -c \u0026#39;echo $POD_NAME\u0026#39; # 输出：nginx-deployment2-77996f47cb-hpmd2 kubectl exec nginx-deployment2-77996f47cb-hpmd2 -- bash -c \u0026#39;echo $POD_NAME\u0026#39;   使用kubectl exec pod_name -- bash -c 'echo $POD_NAME'时需要注意，必须使用单引号，我目前还不知道为什么。\n参考资料  kubernetes之如何在POD外执行复杂shell命令  ","description":"","id":885,"section":"notes","tags":null,"title":"设置PodName到环境变量实验","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E5%AE%9E%E9%AA%8C/%E8%AE%BE%E7%BD%AEpodname%E5%88%B0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%AE%9E%E9%AA%8C/"},{"content":"配置如下：\n1 2 3 4 5 6 7  spring:servlet:multipart:max-file-size:100MBmax-request-size:100MB  参考资料  SpringBoot设置文件上传大小限制\u0026ndash;默认为1M  ","description":"","id":886,"section":"notes","tags":null,"title":"设置SpringBoot上传时文件大小限制","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E8%AE%BE%E7%BD%AEspringboot%E4%B8%8A%E4%BC%A0%E6%97%B6%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E9%99%90%E5%88%B6/"},{"content":" 拷贝配置文件到家目录：  1 2 3 4 5 6 7  # ubuntu cp /etc/vim/vimrc ~/.vimrc # centos cp /etc/vimrc ~/.vimrc   编辑该配置文件，增加如下内容   set tabstop=4 参考资料  Linux下设置vim的缩进为4个空格  ","description":"","id":887,"section":"notes","tags":null,"title":"设置VIM缩进为4个空格","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E8%AE%BE%E7%BD%AEvim%E7%BC%A9%E8%BF%9B%E4%B8%BA4%E4%B8%AA%E7%A9%BA%E6%A0%BC/"},{"content":"我配置了5个虚拟机，用于Kubernetes实验，结果进行ssh链接只有两台虚拟机能进行正常链接，其他三台一直卡在如下界面（偶尔一两次会链接成功）：\n我对比了这五台机器的ifconfig数据，发现无法正常链接的机器的broadcast都配置错误了：\n我分析是我在使用nmcli指令设置ip地址时写错成如下导致的：\n1 2 3 4  nmcli c m ipv4.addresses 192.168.31.151/24 # 正确 nmcli c m ipv4.addresses 192.168.31.151 # 错误   配置错broadcast还带来了一些怪异的现象，比如我在PVE的web管理界面打开的是node1虚拟机，显示的确实node5虚拟机的控制台（出现过一次）。\n","description":"","id":888,"section":"notes","tags":null,"title":"设置错broadcast，导致ssh链接时一直卡着","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/centos/%E8%AE%BE%E7%BD%AE%E9%94%99broadcast%E5%AF%BC%E8%87%B4ssh%E9%93%BE%E6%8E%A5%E6%97%B6%E4%B8%80%E7%9B%B4%E5%8D%A1%E7%9D%80/"},{"content":"首先说明下我为什么要开发自己的代码生成工具，因为现有的代码生成工具不是很满足我的需求。我有如下的需求：\n  我想自动帮我生成数据库中的枚举（需要字段的描述信息给到足够的信息）\n  我想针对某些jsonb类型自动生成对象和TypeHandler\n  我可能会调整自动为我生成的枚举（我可能会增加一些备注信息），但是我希望我第二次生成的时候不要覆盖我的变化\n  我可能会修改自动为jsonb类型生成的类的名称，字段、描述信息，但是我不想我第二次生成的时候覆盖掉这些变化\n  我一定会进行二次生成，但数据库中发生了变化，我希望通过二次生成将这些变化体现到我的代码中，而不是通过自己手动填写，这样会让我的代码和数据库中的代码失去同步\n  经过技术评估，我发现3、4、5点实现难度非常高，有两种方案可选：一是解析java文件，解析java文件的方案要求用户高度遵守规则，这个有点难以实现；二是使用动态编译和动态加载的方案，但是这个方案存在诸多技术上的问题，而且研究这些技术的成本实在是太高，而且应用面狭窄。我最终放弃了这两个方案。\n我最终的方案是开发一个Web应用，全面接管代码生成工作，确保Entity、Enum的生成过程完全是由我自己控制的。如果需要进行修改，也需要通过Web应用完成，从而实现代码永远都是支持二次生成的。\n这个Web应用会记录用户的所有修改，当数据库中的数据发生变化时，会进行数据的对比，确保用户的修改能在二次生成中保留。这个应用不会保留任何用户在源码上进行的修改，它会直接覆盖掉这些源码（运行在本地）。\n这么Web设计支持的功能如下：\n 解析数据库中的表，收集枚举需求、对象需求 支持用户对枚举的配置，配置项包括：枚举名称、枚举备注、枚举项（支持添加数据库中不存在的项） 支持用户对对象的配置，配置项包括：对象名称、对象备注、对象字段、对象字段备注 支持将生成的java类直接写到目标文件夹（仅本地运行支持） 支持下载所有生成的java类（优先级非常低，暂时不实现）  ","description":"","id":889,"section":"notes","tags":null,"title":"设计说明","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/%E8%AE%BE%E8%AE%A1%E8%AF%B4%E6%98%8E/"},{"content":"完成往我OSS推送图片的脚本后，我发现了一个问题，我的本地的图片打不开了。检查代理时发现最有可能导致该问题的就是如下代码：\n本应该是读的代码，我写成了写。我将所有本地图片全部改为正确的图片后，清掉OSS，将wb改成了rb，又重新跑了一遍脚本，发现.images里的图片都可以正常的访问。为了确认就是wb造成的问题，我又清掉了OSS里所有正确的图片，用wb重新上传了一次，发现果然图片都不可访问了。已经很明确就是wb造成的问题。\n额，很奇怪的，之前如果wb写rb写错了，程序会立即报错，这次竟然没有报错，还导致我原件损坏。\n","description":"","id":890,"section":"notes","tags":null,"title":"读写文件时wb和rb写错导致的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%E6%97%B6wb%E5%92%8Crb%E5%86%99%E9%94%99%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"添加依赖：\n1 2 3 4 5 6 7  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;   开发application.yml:\n1 2 3 4 5 6 7 8 9  project-config:template-dir:\u0026#39;D:\\Download\\spring-demo-master\\spring-demo-master\\cn\\AutoTools\\src\\main\\resources\\templates\u0026#39;temp-dir:\u0026#39;C:\\Users\\wujj\\Desktop\\Temp\u0026#39;default-primary-key-name:\u0026#39;id\u0026#39;table-info-dir:\u0026#39;D:\\Download\\spring-demo-master\\spring-demo-master\\cn\\AutoTools\\src\\main\\resources\\tables\u0026#39;enum-comment-pattern:\u0026#39;^([\\\\u4e00-\\\\u9fa5]{1,})（(([A-Za-z0-9-]+：[\\\\u4e00-\\\\u9fa5]{1,}，?)+)）$\u0026#39;number-pattern:\u0026#39;^[0-9]*$\u0026#39;  开发配置Bean：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  @Data @Component @ConfigurationProperties(prefix = \u0026#34;project-config\u0026#34;) public class ProjectConfig { /** * 模板文件根目录 */ private String templateDir; /** * 临时文件夹 */ private String tempDir; /** * 默认的主键字段名 */ private String defaultPrimaryKeyName; /** * 储存表信息Yaml文件的文件夹 */ private String tableInfoDir; /** * 枚举的模式 */ private String enumCommentPattern; /** * 数字的模式 */ private String numberPattern; }   @Value与@ConfigurationProperties的对比 之前没有关注到这个层面的问题，之后的使用中需要注意一下这个问题。\n参考资料  SpringBoot 获取yml配置文件信息  ","description":"","id":891,"section":"notes","tags":null,"title":"读取application.yml的配置信息到Bean","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E8%AF%BB%E5%8F%96application.yml%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%88%B0bean/"},{"content":"我有点强迫症（其实是为了开发工具时配置文件更加美观），我有如下的写法：\n配置文件\n1 2 3 4 5 6 7 8 9  tables:- logic-name:t_orderentity-name:订单- logic-name:t_taskentity-name:任务- logic-name:t_color_atlaentity-name:色卡  解析类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  @Data @Component public class TableProperties implements ApplicationContextAware { private List\u0026lt;Table\u0026gt; tables; @Data public static class Table { /** * 表逻辑名称 */ private String logicName; /** * 对应的实体名称 */ private String entityName; /** * 不需要生成的模板 */ private List\u0026lt;String\u0026gt; templatesExclude; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //noinspection unchecked  tables = (List\u0026lt;Table\u0026gt;) applicationContext.getBean(\u0026#34;tables\u0026#34;); System.out.println(\u0026#34;\u0026#34;); } @Configuration public static class TablePropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;tables\u0026#34;) public List\u0026lt;Table\u0026gt; tables() { return new ArrayList\u0026lt;\u0026gt;(0); } } }   比常规的写法有点复杂，如果使用常规的写法，我的配置文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12  # 解析类上@ConfigurationProperties中的参数PERFIX:# 解析类中字段的名称tables:- logic-name:t_orderentity-name:订单- logic-name:t_taskentity-name:任务- logic-name:t_color_atlaentity-name:色卡  这种写法会增加我一层配置，我非常的不喜欢，所以我自己开发了上面的非常规的写法。\n今天我再使用该方法时，遇到了一些问题，记录如下：\n多段名称 我的配置如下：\n1 2 3 4 5 6 7 8 9  development-season-config:- index:1name:季节- index:2name:品牌- index:3name:类别  我的正确的解析类如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  package com.sdstc.pdm.server.config; import com.sdstc.pdm.common.dto.DevelopmentSeasonConfigDTO; import lombok.Data; import org.springframework.beans.BeansException; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.util.ArrayList; import java.util.Collections; import java.util.List; @Data @Component public class DevelopmentSeasonConfigProperties implements ApplicationContextAware { public List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt; developmentSeasonConfig; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { //noinspection unchecked  developmentSeasonConfig = (List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt;) applicationContext.getBean(\u0026#34;developmentSeasonConfig\u0026#34;); } @Configuration public static class DevelopmentSeasonConfigPropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;development-season-config\u0026#34;) public List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt; developmentSeasonConfig() { return new ArrayList\u0026lt;\u0026gt;(); // return Collections.emptyList();  } } }   我犯了哪些错误：\n ConfigurationProperties注解的方法名写错了，用了copy时的tables，最终导致我在容器里找不到相应的Bean。 忘记了这套方案的逻辑：是通过Configuration创造出一个Bean，然后再在setApplicationContext中将这个Bean赋值给对应的字段。  Configuration中返回值 如下代码：\n1 2 3 4 5 6 7 8 9 10 11  @Configuration public static class DevelopmentSeasonConfigPropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;development-season-config\u0026#34;) public List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt; developmentSeasonConfig() { return new ArrayList\u0026lt;\u0026gt;(); // return Collections.emptyList();  } }   如果我注释return new ArrayList\u0026lt;\u0026gt;()，取消注释return Collections.emptyList();，那么最终的表现结果和我预期的是不一样的，根本无法成功的获取到配置文件中得配置，而是得到了一个空列表。所以，我还是建议自己使用如下写法，这种写法是学习尚硅谷课程时学到的：\n1 2 3 4 5 6 7 8 9 10  @Configuration public static class DevelopmentSeasonConfigPropertiesConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;development-season-config\u0026#34;) public List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt; developmentSeasonConfig(List\u0026lt;DevelopmentSeasonConfigDTO\u0026gt; developmentSeasonConfigDTOs) { return developmentSeasonConfigDTOs; } }   ","description":"","id":892,"section":"notes","tags":null,"title":"读取内容到List中的一些细节","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E8%AF%BB%E5%8F%96%E5%86%85%E5%AE%B9%E5%88%B0list%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/"},{"content":"用这种方案目前没有翻过车，使用浏览器地址栏的翻译按钮，可能会翻车（翻译的时候，需要关闭代理）：\n之前用过Edge的翻译功能，翻译效果并不是太好。\n","description":"","id":893,"section":"notes","tags":null,"title":"谷歌翻译当前的网页","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/chrome/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E5%BD%93%E5%89%8D%E7%9A%84%E7%BD%91%E9%A1%B5/"},{"content":"https://kubernetes.github.io/ingress-nginx/\n","description":"","id":894,"section":"notes","tags":null,"title":"资料地址","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/ingressnginx/%E8%B5%84%E6%96%99%E5%9C%B0%E5%9D%80/"},{"content":"因为短时间可能不会研究这方面的东西了，所以将之前收集的资料整理一下：\n EasyExcel为单个Cell设置样式 JAVA操作Excel表格部分不可编辑部分可编辑 easyexcel 文档加密或设置单元格不可编辑 如何才能到达冻结表头的效果  ","description":"","id":895,"section":"notes","tags":null,"title":"资料整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/easyexcel/%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"好久没有用Python写脚本了，感觉API都不太熟悉了，完成脚本后，舍不得关闭网页，整理一份看看自己都查了哪些资料（我罗列的都是我用到的）：\n  Python统计字符串里某个字符出现的次数\n  Python os.path() 模块\n查了os.path.relpath API\n  Python format 格式化函数\n查了格式化输出字符串\n  Python3 字典\n忘记了字典是怎么操作的\n  Python中os.sep的用法\n查看分隔符的问题，其实我想在Window平台也使用Linux平台的路径分隔符。但是没有还找到方案\n  python字典遍历的几种方法\n  感觉写脚本还是用Python舒服些。\n","description":"","id":896,"section":"notes","tags":null,"title":"资料整理","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/python/%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86/"},{"content":"由于Lua的数据传入和传出的限制，由于Lua的数据传入和传出限制，Lua里面的某些数据类型是不允许进行传出的，而另外一些数据类型则需要在传出之前进行相应的修改。\n因为脚本在返回各种不同类型的数据时可能会产生含糊不清的结果，所以我们应该尽量显式地返回字符串，然后手动地进行分析操作。\n（先整理，以后再慢慢消化）\n","description":"","id":897,"section":"notes","tags":null,"title":"返回值需要注意的地方","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/scripts/%E8%BF%94%E5%9B%9E%E5%80%BC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/"},{"content":"OpenWRT上存在一个现成的DNS服务，我可以直接使用它，故作废该笔记\n参考资料如下，我已经成功配置出来了，但是我其实不需要这个服务：\n centos7快速安装coreDns  ","description":"","id":898,"section":"notes","tags":null,"title":"通过CoreDNS配置一个DNS服务器","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E4%BD%9C%E5%BA%9F/%E9%80%9A%E8%BF%87coredns%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AAdns%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"content":"我核心想实现的是：自动的完成笔记源文件到Gitbook源文件到Gitbook编译后文件推送到github仓库的工作。\n该工作如果手动完成，有如下步骤：\n 调整md文件中的图片引用，防止更改过md文件的层级关系，无法找到图片的位置 将图片上传到OSS，然后记录图片对应的OSS的位置，这个值在生成Gitbook源文件时要用到 调整md文件中图片引用为OSS中的位置，生成Gitbook源文件 生成GitBook需要的Summary文件 下载GitBook所需要的插件 得到静态的GitBook编译后文件，将编译后的文件推送到github仓库  为了更充分使用这次Github Actions学习机会，我计划开发自己的Github Actions，我的Github Actions设计如下：\n  Adjust Pictures In MD Files\n这个Actions的目标是调整md文件中图片引用，确保修改了笔记文件的目录层级，不会找不到相应的图片。\n  Push Pictures To OSS\n这个Actions的目标是将md文件中用到图片资源推送到阿里云OSS上\n  Generate Summary.md Book.json And Readme.md\n这个Actions如其名所述，用于生成book.json、Summary.md、Readme.md文件用的\n  Build Static Htmls\n这个Actions调用Gitbook相关的方法，生成所需要的静态文件。\n  Push Static Htmls To Github\n将编译后的静态文件推送到Github中。\n  在实践中，因为不想倒腾中间产物，为了我将3、4、5步合并成了一个Actions。\n方案小结 本次实验结果已经完全满足了我最开始的设想，我可以通过我自己开发的Actions完成我博客的自动化部署。但是由于对GitHub Actions知识积累不足，导致我在如下方面做的并不是太好：\n  没有利用官方提供的action，我现在并不知道官方提供了哪些action，所以我全部都是靠“蛮力”解决的（即自己控制Action的每一步）\n  冗余数据太多了。我并不是以官方提供的文件夹为工作目录，而是以所使用的Docker镜像的根文件夹为目录，也就是说我开发的每个Action都会首先将源码拉取到当前镜像的Docker根目录中，整个构建工作，该拉取任务供执行了3次。\n  目录位置混乱，因为GitHub Action在启动我的Action时会指定一个工作目录，导致我不得不在我的脚本中使用觉得路径，所以最终导致我的脚本可读性非常化，目录使用有点混乱。\n  没有利用Action之间的文件的流转，和第二点一样，我没有研究到这些技术，所以目前选择的是直接在工作区准备一份全量的数据。\n  脚本没有介个GitHub Action的错误码，我发现有时我的脚本错误，可能不会导致GitHub Action退出，这个问题非常的严重，我后面一定需要花时间优化一下。\n  密码等重要数据硬编码在Action中，因为目前blogs为私有项目，将密码存在该仓库里分享并不是很大，所以我并没有花时间去研究GitHub相关的技术。\n  Action运行不稳定。因为Action中依赖了许多其他的插件和工具等，这些插件我并没有指定版本，这导致我的Action在运行的时候，有一定的概率发生错误。\n  我将持续关注这些技术，然后优化我的方案，知道我的方案足够优雅。\n","description":"","id":899,"section":"notes","tags":null,"title":"通过GitHub Actions实现博客自动化部署的方案","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git_github/%E9%80%9A%E8%BF%87github-actions%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E7%9A%84%E6%96%B9%E6%A1%88/"},{"content":"在Redis里搭Redis感觉只适合搭Standalone模式。如果搭主从模式，则多个从节点通过一个Service暴露服务，那么在SpringBoot配置中，就没有办法感受到配置多个从节点的快感了；如果搭建哨兵模式，主节点Master挂了，以Kubernetes的机制，这个服务本身就能够很快的启动起来，再使用哨兵模式保证它的高可用性，感觉有点多此一举；至于集群模式，我还没有积累相关的知识。\n我最终决定开发自己的Chart，这个Chart定义如下资源：\n 启动3个Redis Pod 启动3个Sentinel Pod 为3个Redis创建3个Service，其类型为NodePort 为3个Sentinel创建3个Service，其类型为NodePort 创建一个ConfigMap用来配置这些Redis和Sentinel  我这儿不用Deployment的原因是避免自动拉起新的Pod，干扰我实验。\n开发自己的StatefulSet 开发自己的Chart ","description":"","id":900,"section":"notes","tags":null,"title":"通过Helm安装哨兵机制的Redis（废弃）","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/sentinel/%E9%80%9A%E8%BF%87helm%E5%AE%89%E8%A3%85%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E7%9A%84redis%E5%BA%9F%E5%BC%83/"},{"content":"  编译固件，并将固件放到PVE宿主机中\n  PVE图形化界面：创建虚拟机，注意需要选择存储介质为无，记录下虚拟机编号\n  PVE图形化界面：删除创建的虚拟机的硬盘、光驱\n  执行如下指令解压固件，并将固件转换成PVE虚拟机的硬盘\n   gzip xxx.img.gz qm importdisk 102 xxx.img local-lvm  PVE图形化界面：编辑新导入的硬盘，修改引导顺序，开机\n  完成安装\n  ","description":"","id":901,"section":"notes","tags":null,"title":"通过PVE安装OpenWrt","uri":"http://junjie2018.github.io/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/proxmox-ve/%E9%80%9A%E8%BF%87pve%E5%AE%89%E8%A3%85openwrt/"},{"content":"我代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  if (companyClientManager == null) { // 返回错误消息  response.setCharacterEncoding(\u0026#34;utf-8\u0026#34;); response.setContentType(\u0026#34;application/json; charset=utf-8\u0026#34;); response.getOutputStream() .write(JSON.toJSONBytes(ResponseVo.createErrorByCodeMessage( INIT_COMPANY_INFO_WRONG.getCode(), INIT_COMPANY_INFO_WRONG.getMessage()))); return false; }   参考资料  Response返回JSON数据  ","description":"","id":902,"section":"notes","tags":null,"title":"通过Response返回JSON数据","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%80%9A%E8%BF%87response%E8%BF%94%E5%9B%9Ejson%E6%95%B0%E6%8D%AE/"},{"content":"我之前有使用过WireGuard连接家庭内部网络，但是当时目的单一，所以研究的并不深入。最近在学习Redis等中间件的高级知识，所以我需要搭建一个Redis集群，然后连接到各个实例进行测试。\n我的Redis集群建立在K8S集群中，使用K8S默认的资源暴露各个Redis实例是工作量巨大，如果不暴露各个实例，则会因为内部负载均衡的原因，导致实验效果不佳。\n我曾考虑过使用OpenVPN让我的开发机连接到K8S的内部网络，但是之前的使用体验非常的不好，繁琐的配置，某些场景下无法安装Windows客户端，所以我决定研究新的VPN工具。WireGuard在原理、配置方面都非常容易理解，而且我已经再使用它了，只需要再深入研究一下，就可以胜任我连接K8S集群内部网络的需求。\n为什么不考虑代理或其他成熟的工具呢？KTConnect之类的工具我也有使用经验，且在公司积累了足够的使用经验。但是我的开发机是Windows系统的，KTConnect对其支持并不是太好，只能走Socks模式。而走Socks模式，很多headless服务是无法暴露出来的，这会给我造成困扰。\n使用WireGuard方案，将DNS配置成容器内部的CoreDNS，则可以通过集群内部的DNS服务，轻松访问到各个Pod、Service、Headless Service，这使得我的配置可以在不进行任何修改的情况下，从开发机迁移到集群内部。\n我的网络拓补结构及对WireGuard方案的设计 如图，为我的网络拓补结构：\nWorkPC1和WorkPC2其实就是我在两种不同环境中连接这个网络的某类代表。在家庭内部时，家庭内部的网段不需要进行路由，及AllowIPs不需要配置家庭内部网段；而在外网环境下，我需要路由这个网段，即AllowIPs需要设置这个网段。\n创建服务端和客户端的秘钥文件  rm ~/WireGuard -rf mkdir -p ~/WireGuard/Server cd ~/WireGuard/Server wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/OpenWRT cd ~/WireGuard/OpenWRT wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/KubernetesWork cd ~/WireGuard/KubernetesWork wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/WindowsHome cd ~/WireGuard/WindowsHome wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/WindowsWork cd ~/WireGuard/WindowsWork wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/Matepad11 cd ~/WireGuard/Matepad11 wg genkey | tee privatekey | wg pubkey \u0026gt; publickey mkdir -p ~/WireGuard/HonorX10 cd ~/WireGuard/HonorX10 wg genkey | tee privatekey | wg pubkey \u0026gt; publickey ~\n创建服务端和客户端配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136  # XieFieyan [Peer] PublicKey = aMlUpXen7Z8qDeRnHhn51CeCQYFlbsBNOtVZu/jkP2U= AllowedIps = 10.10.25.20/32 tee /etc/wireguard/wg0.conf \u0026lt;\u0026lt;-EOF # Server [Interface] ListenPort = 12000 Address = 10.10.10.1/24 PrivateKey = $(cat ~/WireGuard/Server/privatekey) # OpenWRT [Peer] PublicKey = $(cat ~/WireGuard/OpenWRT/publickey) AllowedIPs = 10.10.10.10/32,192.168.23.0/24 # KubernetesWork [Peer] PublicKey = $(cat ~/WireGuard/KubernetesWork/publickey) AllowedIPs = 10.10.10.20/32,10.244.0.0/16,10.96.0.0/12 # WindowsHome [Peer] PublicKey = $(cat ~/WireGuard/WindowsHome/publickey) AllowedIPs = 10.10.10.30/32 # WindowsWork [Peer] PublicKey = $(cat ~/WireGuard/WindowsWork/publickey) AllowedIPs = 10.10.10.31/32 # Matepad11 [Peer] PublicKey = $(cat ~/WireGuard/Matepad11/publickey) AllowedIPs = 10.10.10.32/32 # HonorX10 [Peer] PublicKey = $(cat ~/WireGuard/HonorX10/publickey) AllowedIPs = 10.10.10.33/32 EOF tee ~/WireGuard/OpenWRT/wg0.conf \u0026lt;\u0026lt;-EOF # OpenWRT [Interface] Address = 10.10.10.10/24 PrivateKey = $(cat ~/WireGuard/OpenWRT/privatekey) # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24 PersistentKeepalive = 25 EOF tee ~/WireGuard/KubernetesWork/wg0.conf \u0026lt;\u0026lt;-EOF # KubernetesWork [Interface] Address = 10.10.10.20/24 PrivateKey = $(cat ~/WireGuard/KubernetesWork/privatekey) PostUp = iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24 PersistentKeepalive = 25 EOF tee ~/WireGuard/WindowsHome/wg0.conf \u0026lt;\u0026lt;-EOF # WindowsHome [Interface] Address = 10.10.10.30/24 DNS = 10.96.0.10 PrivateKey = $(cat ~/WireGuard/WindowsHome/privatekey) # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24,192.168.23.0/24,10.244.0.0/16,10.96.0.0/12 PersistentKeepalive = 25 EOF tee ~/WireGuard/WindowsWork/wg0.conf \u0026lt;\u0026lt;-EOF # WindowsWork [Interface] DNS = 10.96.0.10 Address = 10.10.10.31/24 PrivateKey = $(cat ~/WireGuard/WindowsWork/privatekey) # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24,10.244.0.0/16,10.96.0.0/12 PersistentKeepalive = 25 EOF tee ~/WireGuard/Matepad11/wg0.conf \u0026lt;\u0026lt;-EOF # Matepad11 [Interface] DNS = 10.96.0.10 Address = 10.10.10.32/24 PrivateKey = $(cat ~/WireGuard/Matepad11/privatekey) # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24,192.168.23.0/24,10.244.0.0/16,10.96.0.0/12 PersistentKeepalive = 25 EOF tee ~/WireGuard/HonorX10/wg0.conf \u0026lt;\u0026lt;-EOF # HonorX10 [Interface] DNS = 10.96.0.10 Address = 10.10.10.33/24 PrivateKey = $(cat ~/WireGuard/HonorX10/privatekey) # Server [Peer] PublicKey =$(cat ~/WireGuard/Server/publickey) Endpoint = ${SERVER_IP}:12000 AllowedIPs = 10.10.10.0/24,192.168.23.0/24,10.244.0.0/16,10.96.0.0/12 PersistentKeepalive = 25 EOF   配置服务端  下载wireguard-tools（针对内核版本大于5.6的Linux系统）（我使用的是Debain 11）  1 2 3 4  apt update apt install wireguard   配置IP地址转发  1 2 3 4 5  echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf echo \u0026#34;net.ipv4.conf.all.proxy_arp = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p /etc/sysctl.conf   启动wg服务   wg-quick up wg0 配置OpenWRT旁路由 OpenWRT配置相对比较简单，步骤如下：\n 安装必要软件  重启一下添加wg0接口，注意协议类型  配置wg0接口，因为我的OpenWRT上的WireGuard是做客户端，所以不需要配置监听端口  配置wg0接口，增加peer：  配置wg0接口，修改防火墙类型为lan  因为我的OpenWRT上的Wireguard有暴露192.168.23.0/24网段的任务，所以还需要配置防火墙，另外我防火墙默认是丢弃任何数据包的，所以还需要Accept来自10.10.10.0/24的数据包  在配置OpenWRT上的WireGuard时遇到的问题：\n 如果把wg0接口的防火墙设置成wan口，导致WireGuard不起作用，具体表现是接受的数据包不增加。我在OpenWRT上配置WireGuard服务端的经验，我大概猜到什么原因了，我将WireGuard的防火墙配置成了Wan口，但是我没有在Traffic Rules增加规则，使放行所有UDP流量。  配置KubernetesWork 参考资料 ","description":"","id":903,"section":"notes","tags":null,"title":"通过Wireguard暴露家庭内部网络及K8S集群内部网络","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/wireguard/%E6%96%B9%E6%A1%88/%E9%80%9A%E8%BF%87wireguard%E6%9A%B4%E9%9C%B2%E5%AE%B6%E5%BA%AD%E5%86%85%E9%83%A8%E7%BD%91%E7%BB%9C%E5%8F%8Ak8s%E9%9B%86%E7%BE%A4%E5%86%85%E9%83%A8%E7%BD%91%E7%BB%9C/"},{"content":"通过云效发布一个简单的Demo 将一个崭新的项目发布到云上，有如下几个关键步骤。我将根据各个步骤提供相应的文档，文档导航可以通过Confluence的左侧导航栏看到。\n在云效上创建一个项目  访问云效后台：https://rdc.console.aliyun.com/，进入如下页面，并点击【进入】  进入如些页面，选择顶部的【项目 \u0026gt; 项目列表】  进入如下页面，选择【新建项目】  进入如下页面，填写项目名称，点击【确定】完成创建  进入如下页面  项目创建完成，项目创建完成后，你随时可以通过项目列表进入该项目  在项目中创建流水线  进入项目，点击左侧【流水线】，进入如下页面，点击【创建流水线】  进入如下页面，选择【Java 测试、构建、部署到k8s】，点击【下一步】  进入如下页面，选择【git】，代码仓库填写【git@120.78.168.136:wujunjie/rdc-demo.git】分支填写【master】，别名任意填写，我使用的是【cloud-flow】，点击【下一步】  进入如下页面，直接点击【创建】  进入如下页面。  流水线创建完毕  编辑流水线中的构建步骤  点击图中绿色框中的【构建】，然后从右侧滑出的框框中点击【Java构建Docker镜像并推送镜像仓库】  在弹出在的框框中往下滑动，选择区域为【深圳】，标签任意填写，我用的是【cloud-flow】,点击仓库选择最下方的创建新仓库  弹出来的新建镜像仓库页面，可做如下填写，点击【确认】完成仓库创建  保存仓库后，页面发生如下变化，编辑流水线构建步骤完成  编辑流水线中的部署步骤  点击图中的绿色框框，从右侧弹出如下选项：  点击任务列表中的【部署到阿里云k8s】，在弹出来的框框中，做如下选择：  点击【应用】，选择最下方的【新建应用】  选择【环境】，选择最想法的【新建环境】  滚动向下，选择【点击创建新服务】，此处建的服务未k8s服务  #########################################################################################################\n 一定不要选择【负载均衡器】，会产生费用的  #########################################################################################################\n进入如下页面，我们选择【内部服务】，点击【确认】，完成服务创建  #########################################################################################################\n 一定不要选择【负载均衡器】，会产生费用的  #########################################################################################################\n点击确认，完成环境创建  页面会发生如下变化，编辑流水线部署步骤完成，不要忘记点击一下【保存】按钮  保存流水线并验证流水线部署情况  点击流水线页面的【运行】按钮，会进入如下页面  稍等一会，等待我们的应用完成构建和部署  现在我们进入容器服务控制台：https://cs.console.aliyun.com/，来验证我们的发布  在左侧点击【无状态】应用，出现如下页面  命名空间选择【kube-pconline】，并找到我们发布的应用，点击【详情】，并往下滚动  记录下Pod Ip后，我们点击【更多 \u0026gt; 终端】  进入如下页面，我们curl下Pod的8080端口，可以看到我们的项目成功的发布了  验证发布工作完毕，恭喜你，哈哈  ","description":"","id":904,"section":"notes","tags":null,"title":"通过云效发布一个简单的demo","uri":"http://junjie2018.github.io/notes/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/%E4%BD%9C%E5%BA%9F/%E4%BA%91%E6%95%88/%E9%80%9A%E8%BF%87%E4%BA%91%E6%95%88%E5%8F%91%E5%B8%83%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84demo/"},{"content":"我添加了如下配置后，SpringBoot无法正常启动（只针对我们的项目框架）：\n management: endpoints: web: exposure: include: * 架构师说我们项目已经开启了相关的功能，而且*的用法不对。额，我在我自己的实验项目中，这个配置是完全没有问题的，奇奇怪怪，暂时先不研究了。\n","description":"","id":905,"section":"notes","tags":null,"title":"配置Actuator导致项目无法启动","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/actuator/%E9%85%8D%E7%BD%AEactuator%E5%AF%BC%E8%87%B4%E9%A1%B9%E7%9B%AE%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/"},{"content":"Idea初始化项目时使用阿里的源：\nhttps://start.aliyun.com/\n该怎么用，懂得都懂，:)\n默认的是：\nhttps://start.spring.io\n","description":"","id":906,"section":"notes","tags":null,"title":"配置Idea初始化SpringBoot项目时使用阿里的源","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%85%8D%E7%BD%AEidea%E5%88%9D%E5%A7%8B%E5%8C%96springboot%E9%A1%B9%E7%9B%AE%E6%97%B6%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E7%9A%84%E6%BA%90/"},{"content":"在加入SpringBoot的Web的starter后，自动配置类做了如下工作：\n 内容协商解析器和BeanName视图解析器 静态资料（包括webjars） 自动注册Convert、GenericConvert、Formatter 自动注册HttpMessageConverts 自动注册MessageCodesResolver（用于国际化，目前已经很少使用这个方案了） 静态index.html支持 自定义Favicon 自动使用ConfigurableWebBindingInitializer（DataBinder负责将请求数据绑定到JavaBean上）  静态资源访问 只要静态资源防止在/static、/public、/resources、/META-INF/resources目录下，可以通过当前项目根路径 / 静态资源名访问\n原理是静态映射/**。请求进来后，先去找Controller看能不能处理。不能处理的所有请求又都交给静态资源处理器。静态资源处理器也找不到则相应404页面。\n可进行如下配置：\n1 2 3 4 5 6 7 8  spring:mvc:static-path-pattern:/res/**resources:static-locations:[classpath:/haha/]  配置了前缀后，访问项目根路径 / static-path-pattern / 静态资源名后，会自动在各个静态目录下查找。配置了static-locations后，则需要将静态文件放置在该目录中。一般来说，我们会配置static-path-pattern，方便进行权限管理（前后端分离项目中，基本用不到这个东西）。\nwebjars是一个非常有意思的技术，就是将一些js文件通过jar包的方式进行管理，这些js文件会被自动放置在webjars目录下。可用该地址访问：http://localhost:8080/webjars/jquery/3.5.1/jquery.js \n1 2 3 4 5 6 7 8  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.webjars\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jquery\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   静态资源路径下的index.html将会被作为欢迎页。这个地方有个Bug，可以配置静态资源路径，但是不可以配置静态资源的访问前缀，否则导致index.html不能被默认访问。\n1 2 3 4 5 6 7 8  spring:# mvc:# static-path-pattern: /res/** 这个会导致welcome page功能失效resources:static-locations:[classpath:/haha/]  将favicon放在静态资源目录下即可被浏览器自动访问到。\n静态资源配置原理 如何进行配置的，首先WebMvcAutoConfiguration配置生效：\n1 2 3 4 5 6 7 8 9 10 11 12  @Configuration(proxyBeanMethods = false) @ConditionalOnWebApplication(type = Type.SERVLET) @ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class }) @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10) @AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class }) public class WebMvcAutoConfiguration { }   这个类并没有配置太核心的东西，但是这个类里面的静态内部类WebMvcAutoConfigurationAdapter集成了WebMVCConfigurer，才是配置的核心：\n1 2 3 4 5 6 7 8 9  @Configuration(proxyBeanMethods = false) @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties({ WebMvcProperties.class, ResourceProperties.class }) @Order(0) public static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer { }   WebMvcAutoConfigurationAdapter构造函数接受的参数如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  /* resourceProperties：获取和spring.resources绑定的所有的值的对象 mvcProperties：获取和spring.mvc绑定的所有的值的对象 beanFactory：Spring的beanFactory messageConvertersProvider：找到所有的HttpMessageConverters resourceHandlerRegistrationCustomizerProvider：找到资源处理器的自定义器 dispatcherServletPath： servletRegistrations：给应用注册Servlet、Filter等 */ public WebMvcAutoConfigurationAdapter( ResourceProperties resourceProperties, WebMvcProperties mvcProperties, ListableBeanFactory beanFactory, ObjectProvider\u0026lt;HttpMessageConverters\u0026gt; messageConvertersProvider, ObjectProvider\u0026lt;ResourceHandlerRegistrationCustomizer\u0026gt; resourceHandlerRegistrationCustomizerProvider, ObjectProvider\u0026lt;DispatcherServletPath\u0026gt; dispatcherServletPath, ObjectProvider\u0026lt;ServletRegistrationBean\u0026lt;?\u0026gt;\u0026gt; servletRegistrations) { this.resourceProperties = resourceProperties; this.mvcProperties = mvcProperties; this.beanFactory = beanFactory; this.messageConvertersProvider = messageConvertersProvider; this.resourceHandlerRegistrationCustomizer = resourceHandlerRegistrationCustomizerProvider.getIfAvailable(); this.dispatcherServletPath = dispatcherServletPath; this.servletRegistrations = servletRegistrations; }   WebMvcAutoConfigurationAdapter配置资源处理的默认规则：\n 针对webjars进行了配置 针对静态资源进行了配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { if (!this.resourceProperties.isAddMappings()) { logger.debug(\u0026#34;Default resource handling disabled\u0026#34;); return; } Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); if (!registry.hasMappingForPattern(\u0026#34;/webjars/**\u0026#34;)) { customizeResourceHandlerRegistration(registry.addResourceHandler(\u0026#34;/webjars/**\u0026#34;) .addResourceLocations(\u0026#34;classpath:/META-INF/resources/webjars/\u0026#34;) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } }   WebMvcAutoConfigurationAdapter配置欢迎页处理规则：\n1 2 3 4 5 6 7 8 9 10 11 12  @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) { WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider)); welcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations()); return welcomePageHandlerMapping; }   ","description":"","id":907,"section":"notes","tags":null,"title":"配置MVC时SpringBoot为我们配置了什么","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/spring-mvc/%E9%85%8D%E7%BD%AEmvc%E6%97%B6springboot%E4%B8%BA%E6%88%91%E4%BB%AC%E9%85%8D%E7%BD%AE%E4%BA%86%E4%BB%80%E4%B9%88/"},{"content":"之前使用SpringBoot，都是自动帮我配置好的，难得有机会自己配置一下，资料整理如下：\n添加依赖如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.32\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-slf4j-impl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.14.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;   添加配置文件log4j2.xml如下，配置文件我是从官网拷贝过来的，我将error修改为info了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration status=\u0026#34;WARN\u0026#34;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt;   配置过程中遇到的问题 我从Maven中央仓库拷贝log4j-slf4j-impl依赖时，中央仓库默认的scope为test，导致我启动的时候报没有找到实现类，只需要删除scope配置即可。\n参考资料  Log4j 2 + Slf4j 的配置和使用 Automatic Configuration  ","description":"","id":908,"section":"notes","tags":null,"title":"配置slf4j+log4j2","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/logging/%E9%85%8D%E7%BD%AEslf4j+log4j2/"},{"content":"配置如下：\n","description":"","id":909,"section":"notes","tags":null,"title":"配置Webstorm启动vue项目","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/vue/%E9%85%8D%E7%BD%AEwebstorm%E5%90%AF%E5%8A%A8vue%E9%A1%B9%E7%9B%AE/"},{"content":"我注意到MyBatis-Plus的配置文件中有如下配置：\n1 2 3 4  mybatis-plus:mapper-locations:classpath:mapper/*Mapper.xml  我觉得在配置文件中使用classpath:表示当前项目的资源文件是一件非常优雅的编码方式，我也想在我自己的配置项中使用这种写法。但是当我发现将classpath:应用到自己的配置项时发现，根本就没有自动将classpath:转换成资源目录，断点如下：\n针对这个问题，我其实开发了自己的解决方案，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  public String getTemplateDir() { return templateDir.startsWith(\u0026#34;classpath:\u0026#34;) ? classpathLabelToAbsolute(templateDir) : templateDir; } public String getTableDataDir() { return tableDataDir.startsWith(\u0026#34;classpath:\u0026#34;) ? classpathLabelToAbsolute(tableDataDir) : tableDataDir; } private String classpathLabelToAbsolute(String path) { try { return ResourceUtils.getFile(templateDir).getAbsolutePath(); // 以后验证一下这个方法  // return this.getClass().getClassLoader().getResource(templateDir).getFile().toString()  } catch (IOException e) { throw new RuntimeException(\u0026#34;TemplateDir Config Wrong\u0026#34;); } }   但是我觉得代码并不是很优雅，所以我决定参考一下MyBatis-Plus对此的实现。\nMyBatis-Plus 寻找MyBatis-Plus的配置类： 我这次寻找配置类，完全是靠运气，一下子就找到了，我想规则大概就是配置类都放放在starter中的吧。\nMyBatis-Plus的实现 MyBatis-Plus的处理代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  private static final ResourcePatternResolver resourceResolver = new PathMatchingResourcePatternResolver(); public Resource[] resolveMapperLocations() { return Stream.of(Optional.ofNullable(this.mapperLocations).orElse(new String[0])) .flatMap(location -\u0026gt; Stream.of(getResources(location))) .toArray(Resource[]::new); } private Resource[] getResources(String location) { try { return resourceResolver.getResources(location); } catch (IOException e) { return new Resource[0]; } }   我们的代码除列使用的工具类不一样，其他的思路基本是一致的。我看过MyBatis-Plus使用的工具类源码，挺复杂的，暂时不想深入研究。\nSpring Datasource 我注意到Spring Datasource也是支持classpath:配置的，我就好奇它是怎么实现对该配置的支持。\n1 2 3 4 5 6  spring:datasource:schema:classpath:h2/schema.sqldata:classpath:h2/data.sql  找到Spring Datasource配置类 我这次鸟枪换泡，用更高级更强大的方法找到了配置类（实际上是因为我一个一个文件翻找，找了半天都找不到），思路如下：\n 先在Idea中下载下载所有Maven依赖的源码 使用全局搜索spirng.datasource  Spring DataSource中的写法 代码如下，我没有深度分析，直接贴过来了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  boolean createSchema() { List\u0026lt;Resource\u0026gt; scripts = getScripts(\u0026#34;spring.datasource.schema\u0026#34;, this.properties.getSchema(), \u0026#34;schema\u0026#34;); if (!scripts.isEmpty()) { if (!isEnabled()) { logger.debug(\u0026#34;Initialization disabled (not running DDL scripts)\u0026#34;); return false; } String username = this.properties.getSchemaUsername(); String password = this.properties.getSchemaPassword(); runScripts(scripts, username, password); } return !scripts.isEmpty(); } private List\u0026lt;Resource\u0026gt; getScripts(String propertyName, List\u0026lt;String\u0026gt; resources, String fallback) { if (resources != null) { return getResources(propertyName, resources, true); } String platform = this.properties.getPlatform(); List\u0026lt;String\u0026gt; fallbackResources = new ArrayList\u0026lt;\u0026gt;(); fallbackResources.add(\u0026#34;classpath*:\u0026#34; + fallback + \u0026#34;-\u0026#34; + platform + \u0026#34;.sql\u0026#34;); fallbackResources.add(\u0026#34;classpath*:\u0026#34; + fallback + \u0026#34;.sql\u0026#34;); return getResources(propertyName, fallbackResources, false); } private List\u0026lt;Resource\u0026gt; getResources(String propertyName, List\u0026lt;String\u0026gt; locations, boolean validate) { List\u0026lt;Resource\u0026gt; resources = new ArrayList\u0026lt;\u0026gt;(); for (String location : locations) { for (Resource resource : doGetResources(location)) { if (resource.exists()) { resources.add(resource); } else if (validate) { throw new InvalidConfigurationPropertyValueException(propertyName, resource, \u0026#34;The specified resource does not exist.\u0026#34;); } } } return resources; } private Resource[] doGetResources(String location) { try { SortedResourcesFactoryBean factory = new SortedResourcesFactoryBean(this.resourceLoader, Collections.singletonList(location)); factory.afterPropertiesSet(); return factory.getObject(); } catch (Exception ex) { throw new IllegalStateException(\u0026#34;Unable to load resources from \u0026#34; + location, ex); } }   小结 我最终肯定还是选择我自己的方案，因为我主要用于工具包的开发，使用我这种方案更易读（其实我觉得MyBatis-Plus也挺好的）。另外使用ResourceUtils貌似打包成Jar包后无法正确的读取路径，我并没验证这个问题。\n我决定当我在生产环境中需要使用相关技术时我再继续探索这个解决方案。\n参考资料  SpringBoot读取resources目录下的文件 springboot获取资源文件、编译文件路径（打包后） Spring 应用访问Classpath路径下的文件  ","description":"","id":910,"section":"notes","tags":null,"title":"配置文件中的classpath配置","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/application.yml/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84classpath%E9%85%8D%E7%BD%AE/"},{"content":"我从源码导入了一个Maven项目，因为我默认的Maven配置中使用的是setting.xml文件，但是我没有这份配置文件（我的文件为setting-default.xml），但是我忽视了这个问题。\n当我配置了Maven Profile，然后启动项目的一个测试用例时，项目正常启动了，但是并没有获取到Maven Profile的值。这个现象其实很奇怪：\n Maven都没有进行导入，为什么测试方法能正常启动 为什么正常启动后，不能获取到Maven Profile的值呢  ","description":"","id":911,"section":"notes","tags":null,"title":"配置错误setting.xml文件，导致的一个奇怪的现象","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/idea/%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AFsetting.xml%E6%96%87%E4%BB%B6%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E4%B8%AA%E5%A5%87%E6%80%AA%E7%9A%84%E7%8E%B0%E8%B1%A1/"},{"content":"实际上我已经有技术实现针对List的TypeHandler了，之所以还开发这个TypeHandler是因为我们的旧代码使用了JSONArray、JSONObject，旧代码之前的使用方案是先将数据检索成字符串，然后再用fastjson转成JSONObject或者JSONArray，为了兼顾这部分需求，所以我开发了这个TypeHandler。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  @Slf4j @MappedTypes({JSONObject.class, JSONArray.class}) public class FastJsonTypHandler extends BaseTypeHandler\u0026lt;Object\u0026gt; { @Override public void setNonNullParameter(PreparedStatement preparedStatement, int i, Object parameter, JdbcType jdbcType) throws SQLException { PGobject insertObj = new PGobject(); insertObj.setType(\u0026#34;jsonb\u0026#34;); insertObj.setValue(JSON.toJSONString(parameter)); preparedStatement.setObject(i, insertObj); } @Override public Object getNullableResult(ResultSet resultSet, String columnName) throws SQLException { final String jsonInDb = resultSet.getString(columnName); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } @Override public Object getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException { final String jsonInDb = resultSet.getString(columnIndex); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } @Override public Object getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException { final String jsonInDb = callableStatement.getString(columnIndex); return StringUtils.isEmpty(jsonInDb) ? null : JSON.parse(jsonInDb); } }   这里踩了一个坑，我之间将@MappedTypes设置成@MappedTypes({Object.class})，结果MyBatis-Plus生成出来的SQL都包含一个双引号，估计是每个字段都走了这个TypeHandler。\n框架中原来的TypeHandler生成的jsonb字段的值，双引号前会加反斜线，不是太方便使用。\n","description":"","id":912,"section":"notes","tags":null,"title":"针对JSONObject、JSONArray的typeHandler","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%92%88%E5%AF%B9jsonobjectjsonarray%E7%9A%84typehandler/"},{"content":"问题就如标题描述的一样，错误的将@RequestParam写成了@Param，最终导致Controller拿不到相应的参数，最终导致接口返回数据不符合业务逻辑。\n","description":"","id":913,"section":"notes","tags":null,"title":"错将@RequestParam写成@Param导致Feign无法正常返回数据","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%94%99%E5%B0%86requestparam%E5%86%99%E6%88%90param%E5%AF%BC%E8%87%B4feign%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E8%BF%94%E5%9B%9E%E6%95%B0%E6%8D%AE/"},{"content":"是这样的，我参考之前的写法，在Request对象中用JSONObject去接受了前端请求传递了一个对象（我并不关心这个对象的结构）。结果接口有如下返回值：\n1 2 3 4 5 6 7 8  { \u0026#34;code\u0026#34;: 100101, \u0026#34;data\u0026#34;: null, \u0026#34;message\u0026#34;: \u0026#34;params invalidate: JSON mapping problem: com.sdstc.show.controller.external.DynamicFormController$PostDataRequest[\\\u0026#34;extraData\\\u0026#34;]-\u0026gt;com.google.gson.JsonObject[\\\u0026#34;asString\\\u0026#34;]; nested exception is com.fasterxml.jackson.databind.JsonMappingException: JsonObject (through reference chain: com.sdstc.show.controller.external.DynamicFormController$PostDataRequest[\\\u0026#34;extraData\\\u0026#34;]-\u0026gt;com.google.gson.JsonObject[\\\u0026#34;asString\\\u0026#34;])\u0026#34;, \u0026#34;success\u0026#34;: false }   抱着试试看的心态，我去掉了@Data注解，该问题消失了。额，但是我是@Data的忠实用户，所以我最后用如下方式改写：\n1 2 3 4 5 6  @Data private static class PutDataRequest { private Map\u0026lt;?, ?\u0026gt; extraData; }   关于@Data，从细节上讲，我有很多想不明白的地方，当我们从Controller接受对象的时候，我们可以不要这个注解，接受没有任何问题；但是，当我们从RestTemplate接受的时候，如果没有这个注解，接受到的所有字段都为null。更奇怪的时，本次开发时，Controller和RestTemplate的HttpMessageConvert都是FastJsonHttpMessageConverter。\n现在唯一能让我信服的理由就是，Controller可能用了字段名反射，而RestTemplate走的是Getter和Setter。\n20210607后续：\n其实这个问题的原因在于JsonObject和JSONObject根本不是同一个东西\n","description":"","id":914,"section":"notes","tags":null,"title":"错将JSONObject写成JsonObject了","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/springboot/%E9%94%99%E5%B0%86jsonobject%E5%86%99%E6%88%90jsonobject%E4%BA%86/"},{"content":"一码一条消息 我之前在做中台项目，我们的错误码方案为一码一个消息，具体实现中我们有一个错误消息枚举类，里面包含了我们所有的错误码消息。如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13  public enum CodeAndMsg{ // 会员  MEMEBER_NOT_FOUND(\u0026#34;1000\u0026#34;, \u0026#34;会员不存在\u0026#34;), MEMBER_STATUS_WRONG(\u0026#34;1001\u0026#34;, \u0026#34;会员状态错误\u0026#34;), // 会员卡  MEMBER_CARD_NOT_FOUND(\u0026#34;2000\u0026#34;, \u0026#34;会员卡不存在\u0026#34;), MEMBER_CARD_STATUS_WRONG(\u0026#34;2001\u0026#34;, \u0026#34;会员卡状态错误\u0026#34;), MEMEBER_CARD_NO_COIN(\u0026#34;2002\u0026#34;, \u0026#34;会员积分不足\u0026#34;), ; }   实践的过程中，为了方便管理，我们又将各个模块的错误消息定义在自己的枚举类中，然后在CodeAndMsg中引用这些枚举：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // 会员 public enum MemberCodeAndMsg{ MEMEBER_NOT_FOUND(\u0026#34;1000\u0026#34;, \u0026#34;会员不存在\u0026#34;), MEMBER_STATUS_WRONG(\u0026#34;1001\u0026#34;, \u0026#34;会员状态错误\u0026#34;), } // 会员卡 public enum MemberCardCodeAndMsg{ MEMBER_CARD_NOT_FOUND(\u0026#34;2000\u0026#34;, \u0026#34;会员卡不存在\u0026#34;), MEMBER_CARD_STATUS_WRONG(\u0026#34;2001\u0026#34;, \u0026#34;会员卡状态错误\u0026#34;), MEMEBER_CARD_NO_COIN(\u0026#34;2002\u0026#34;, \u0026#34;会员积分不足\u0026#34;), } public enum CodeAndMsg{ // 会员  MEMEBER_NOT_FOUND(MemberCodeAndMsg.MEMEBER_NOT_FOUND), MEMBER_STATUS_WRONG(MemberCodeAndMsg.MEMBER_STATUS_WRONG), // 会员卡  MEMBER_CARD_NOT_FOUND(MemberCardCodeAndMsg.MEMBER_CARD_NOT_FOUND), MEMBER_CARD_STATUS_WRONG(MemberCardCodeAndMsg.MEMBER_CARD_STATUS_WRONG), MEMEBER_CARD_NO_COIN(MemberCardCodeAndMsg.MEMEBER_CARD_NO_COIN), ; }   CodeAndMsg中有个main方法，调用后会读取各个枚举的信息，然后自动生成CodeAndMsg的代码。我们之所以如此热衷于将所有的错误信息定义在同一个枚举中，是因为我们还有一套用于参数校验的注解，该套注解支持传入一个CodeAndMsg参数，当我们的参数校验失败了，会自动返回这个CodeAndMsg定义的错误码和错误消息（客户要求我们，不同的字段错误需要返回不同的错误）。\n需要提到的是，我们之前使用的是单体仓库，错误码被放到了common项目下，这样全局都可以使用到这些错误码。\n我个人是比较喜欢这种错误码方案的，原因有下：\n  定位问题快速，我们可以通过错误码，快速检索到代码行\n  定义错误码时不需要费脑，我们定义错误码时，只需要在之前的码值上进行递增，不需要思考哪个码可以用于我们现在的场景。但是，修改已经定义的码的含义，是不被允许的（除非可以确保这个码值只有自己在使用）。\n  非常便利生成文档，我们需要将错误码写到文档中，提交给下游的用户，所有的错误码写在CodeAndMsg中，我们可以很轻松的生成文档。\n  和参数校验注解结合，用起来比较舒服，在参数校验的时候，我们不需要写message，只用提供一个CodeAndMsg，这样可以避免让一些硬编码的Message充斥在代码中。\n  一码多条消息 但是，最近接触到了新的错误码方案，要求我们一码多条消息，也就是说，让我们尽量复用已有的错误码。我本人比排斥这个方案，这意味着我们定义错误码的成本更高了，我们需要去思考，我们当前的场景下应该适用于哪个错误码。当然这其实也意味着足够的便利，因为不在要求我们为每个message定义枚举了。我们可以在任何我们需要的地方，传递一个Code值，加一个Msg值即可。\n但是我肯定还是不愿意将Msg值充斥在代码中，所以在实践中我趋于按如下方式进行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class CodeConstant { public static int DATA_NOT_FOUND = 1000; public static int PARAM_WRONG = 1001; } public enum Code { USER_NOT_EXIST(CodeConstant.DATA_NOT_FOUND, \u0026#34;项目不存在\u0026#34;), PROJECT_NOT_EXIST(CodeConstant.DATA_NOT_FOUND, \u0026#34;项目不存在\u0026#34;), EMAIL_FORMAT_WRONG(CodeConstant.PARAM_WRONG, \u0026#34;邮箱格式错误\u0026#34;), PHONE_FORMAT_WRONG(CodeConstant.PARAM_WRONG, \u0026#34;手机号格式错误\u0026#34;), ; }   两种方案的比较 实际上，到底使用哪种方案，我觉得要考虑如下的问题：\n 接口的消费者需不需要根据不同的码值进行逻辑处理。 接口的消费者是直接将我们接口中的msg暴露给用户，还是说需要拦截下错误码，然后返回统一的错误消息。  第一个问题 如何理解第一个问题？假如我们有一个接口需要先判断用户是否存在，再判断项目是否存在，然后再进行逻辑处理，如果用户不存在，需要进行A操作，如果项目不存在，需要进行B操作（A操作和B操作不仅仅是将错误消息提示给用户），所以这个时候针对用户不存在和项目不存在我们就需要返回不同的错误码。其实两种错误码方案都可以处理这个问题，在一码一条消息中，我们只需要返回不同的码即可；在一码多条消息中，我们需要拆分接口，需要提供判断用户存在的接口、判断项目存在的接口、真正处理业务逻辑的接口，但是即使是这样，考虑并发问题，我们在真正处理业务逻辑的接口中还是需要判断用户信息是否存在、项目信息是否存在，所以说这个接口在并发的场景下还是有可能返回代表多个含义错误码。\n再来思考下，我们的项目中可不可能存在这种需求？我觉得可能性非常大，我们的web端和客户端本质上都是编辑器，都是极度重视用户体验的，我们有很大的可能性针对一个接口的不同错误码进行不同的交互逻辑，从而提高我们产品的体验。\n第二个问题 这个问题同样两个方案都能处理，针对一码一条消息，接口的消费者通过前缀进行拦截；针对一码多条消息，接口的消费者直接针对不同的码值进行处理。我们需要考虑如下两个问题：\n 我们的消费者究竟在怎样的使用我们的错误码及错误消息 究竟如何使用我们的错误码和错误消息才是合理的  我们项目中目前是这样在处理的：针对一些特定的错误码，前端会写function进行处理（比如未登录：用户被挤下去了，需要重新跳转到登录页面），而绝大多数业务上的错误码，前端不会进行任何处理，直接将msg告知给用户。\n前端该不该拦截错误码，返回统一的消息 先讨论下，前端该不该拦截我们的错误码，然后返回统一的msg：\n服务端给出的msg其实是最能体现当前业务的问题出现在哪的，将这些错误消息直接提示给用户并非不可以（仅针对业务上的错误码），而且我们在使用互联网产品的时候，我们发现就大多数的情况下，web应用也的确是给你更描述问题存在的错误消息，而非给你一个笼统的错误消息，甚至有些应用会直接告诉你错误的码值。\n如果我们拦截某一类的错误码，然后统一返回错误消息，我觉得这样很让人迷惑，举一个表单填写的案例，假如我们拦截参数校验的错误，然后提示用户表单数据有误，而不告知用户究竟是哪个字段有错误，我觉得用户应该会非常的迷惑吧。如果用户将这个问题反馈给我们，我们也很难定位这个问题，我们需要查日志，爬下用户填写的表单，然后再本地复现这个问题。为了更好的定位问题，我们还需要知道用户到底在表单里填写了什么东西，才导致前端竟然没有校验出错误。再举一个数据不存在的案例，如果说前端不能将服务端的返回消息直接返回给用户，我们拦截下了这个消息，提示用户数据不存在，那用户如何知道究竟是什么数据不存在呢？\n我们直接将后端返回的错误消息完整的告知给用户，或许不能够帮助到用户定位问题，但是用户将问题反馈给我们的时候，我们可以更快的定位问题。如果提示错误的消息中包含错误码信息，我们甚至可以快速定位到代码行（两种错误码方案都可以，但是一码一消息更快）。\n错误消息的国际化 从上面的讨论，我们可以看出我们的的确确是有需求的将服务端的错误消息直接提示给用户，而不需要进行任何包装。在这种需求场景下，我们还需要对错误消息进行国际化，我们需要的是一个错误码可以获取多个语言不同的msg，在这种场景下我们还是得使用一码一消息，如果使用一码多条消息，我们根本没有办法找到这个错误在不同语言中的表述。\n一码一消息的实践 综上所述，我认为一码一消息更有研究价值，且code的类型应该为String（更灵活，更容易进行处理）。但是考虑到我们目前的项目已经使用了int，所以各个消费者为了处理方便，可以在消费前将int类型的code转换成String，如果是全新类型的项目的话，我还是比较建议适用String类型的，字符串在扩展性、处理灵活性方面是碾压int类型的。\n我们之前的项目使用的是单体仓库，而我们现在的项目中各个服务会独立的成为一个服务，这带来了一些小小的问题，这在使用的时候会带来一些问题，比如我们没有办法再通过修改CodeAndMsg的源码，来增加不同的枚举类型了，从而导致我们没有办法开发一套结合我们错误码系统的注解。\n我有一个大胆的想法，我想将错误码单独成一个项目，采用Git子模块的方案集成到项目中，公司的所有项目都需要依赖这个错误码项目，从而实现整个公司的错误码统一管理的。这个错误码项目中可以进行自动构建，并生成Java语言、Go语言、JavaScript语言所需要的源码文件。在开发上，我希望这个这个项目能给我们单体项目的开发感觉，也就是我们可以迅速的定义并使用这个错误码，而不需要等待。这个方案会引入更高级的知识，我觉得接受成本有点高，但是这个方案肯定是非常方便的。\n（我打算放一放，等我git技术提升了在研究这些东西）\n","description":"","id":915,"section":"notes","tags":null,"title":"错误码方案及考虑的问题","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E6%96%B9%E6%A1%88/errorcode/%E9%94%99%E8%AF%AF%E7%A0%81%E6%96%B9%E6%A1%88%E5%8F%8A%E8%80%83%E8%99%91%E7%9A%84%E9%97%AE%E9%A2%98/"},{"content":"错误码方案 今天在开发时，用到了目前项目中的错误码方案，感觉用起来并不是很顺手，同时在用的时候意识到了我之前设计的方案中的一些不足，比如说，之前的设计的方案，没有考虑到将一些参数通过异常，传递出来（我记得我好像考虑了这个问题，只是说我需要自定义异常，有点麻烦，如果我只使用BusinessException的话，会比较简单）；另外，我没有考虑日志和异常的整合（我考虑了吧，我记得我是在ExceptionHandler中处理的）。总之之前设计时，没有形成文档，导致很多细节出我也忘记了自己是怎么处理的，我现在需要重新整理一些这部分内容，整理过程中进行一些优化。\n先说说我的方案解决了哪些问题：\n","description":"","id":916,"section":"notes","tags":null,"title":"错误码方案设计于实现","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E9%94%99%E8%AF%AF%E7%A0%81%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E4%BA%8E%E5%AE%9E%E7%8E%B0/"},{"content":"我在进行kubectl的上下文相关的实验，在我将当前的上下文切换成我自己创建的上下文时，我执行kubectl get pdos时，会报如下错误：\n The connection to the server localhost:8080 was refused - did you specify the right host or port? 我将kubectl上下文切换成默认的，则此问题修复。我目前不知道其中的原因，先记录下。这个问题在网上找到的资料，都不是解决我这个场景的。\n当然，这个问题没有这么简单的技术，我后来检查了创建上下文的代码，我发现我干错了两件事：\n kubectl config set-context production \\ --namespace=production \\ --cluster kubernetes \\ --user=kubernetes-admin  我将namespace写成了一个我目前尚未创建的命名空间 我将cluster写成了其他值  我更认为是因为cluster写错，导致了如上的报错。\n","description":"","id":917,"section":"notes","tags":null,"title":"错误设置kubectl的上下文，导致kubectl工具无法正常使用","uri":"http://junjie2018.github.io/notes/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubernetes/%E9%94%99%E8%AF%AF%E8%AE%BE%E7%BD%AEkubectl%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AF%BC%E8%87%B4kubectl%E5%B7%A5%E5%85%B7%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E4%BD%BF%E7%94%A8/"},{"content":"简单的阅读了一下阿里云Redis的文档，发现阿里云Redis和原生Redis有一定的出入，简单整理如下：\n 阿里云Redis提供了代理节点，代理节点隐藏了一定的复杂性，会影响到代码的配置方式。 原生的哨兵模式在阿里云中是没有意义的，阿里Redis提供了自己的高可用方案 阿里云Redis支持的Redis指令只是原生Redis指令集的一个子集  我现在面临一个决策：是继续深入研究原生Redis还是研究阿里云Redis。我本人是比较拥抱云计算的，我也期待自己能够基于云计算有一些作为。但是我发现2B的业务中，基础设施的选择很多时候由不得我们，而是被客户限制的死死地，这会导致我们学习的东西没有起到任何作用。如果是2C的话，我们倒是拥有更多的自主权，可以根据我们的需求选择合适技术。其实这个矛盾的问题很好解决，就是未来选择一份2C的工作。\n我比较钟爱小而美的公司，喜欢内聚的团队。在这样的团队中，拥抱云技术是必然的选择。如果使用原生的Redis，需要大量的人力物力运维Redis，才可以达到生产水平。从这个层面来说，我还是应该选择云计算技术，选择阿里云Redis。我也期待自己能拥有足够的云计算技术知识，未来在这样的团队中贡献自己的力量。\n眼下有几个问题阻碍了我去深入研究云计算技术：一是学习成本太高了，如果学习原生的Redis，我可以自己搭建一个环境就可以了。如果学习云计算技术，我得花钱去购买环境，肉痛。二是，各家云服务提供商的产品都有一定的出入，会增加学习成本，不过好在大的就那么几家，我可以先选择一家进行专精，然后再学习其他家的。\n总之，我学习方向还是偏向于云计算方面，对原生技术的学习更多的是偏向于了解基础知识。\n","description":"","id":918,"section":"notes","tags":null,"title":"阅读了阿里云Redis后的想法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/redis/%E9%98%85%E8%AF%BB%E4%BA%86%E9%98%BF%E9%87%8C%E4%BA%91redis%E5%90%8E%E7%9A%84%E6%83%B3%E6%B3%95/"},{"content":"我们生产中用的雪花算法代码如下：\n1 2 3 4 5 6 7 8 9 10 11  @Bean public MybatisPlusPropertiesCustomizer plusPropertiesCustomizer() { //从docker启动参数中获取应用实例WID环境变量  Long workId = (long) Math.random() * 31; Long dataCenterId = (long) Math.random() * 31; log.info(\u0026#34;workId={},dataCenterId={}\u0026#34;, workId, dataCenterId); IdentifierGenerator identifierGenerator = new DefaultIdentifierGenerator(workId, dataCenterId); return plusProperties -\u0026gt; plusProperties.getGlobalConfig().setIdentifierGenerator(identifierGenerator); }   最近总是发现主键重复的问题，就很奇怪，我们目前就两个实例，为什么会发生重复了，后来同事调试后发现是我们的写法出问题了，如下写法最后生成的workId和dataCenterId永远为零：\n1 2 3 4  Long workId = (long) Math.random() * 31; Long dataCenterId = (long) Math.random() * 31;   正确的写法应该如下：\n1 2 3 4  Long workId = (long) (Math.random() * 31); Long dataCenterId = (long) (Math.random() * 31);   其实我目前还接受不了用随机数生成workId和dataCenterId，我觉得风险还是存在的，而且概率是未知的，有点浮沙筑高台的感觉，容易让人心慌。\n","description":"","id":919,"section":"notes","tags":null,"title":"雪花算法配置出问题了，导致主键重复","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/mybatis-mybatis-plus/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95%E9%85%8D%E7%BD%AE%E5%87%BA%E9%97%AE%E9%A2%98%E4%BA%86%E5%AF%BC%E8%87%B4%E4%B8%BB%E9%94%AE%E9%87%8D%E5%A4%8D/"},{"content":"我的分析主要针对二次生成时，用户在二次生成的时候，用户可能会进行哪些改动：\n 增加、删除表，修改表名称、表描述信息 增加、删除列，修改列名称、列数据类型、列描述信息  修改表名称，如果不对该操作进行支持，那么用户看到的就是全新的实体配置信息，而且信息都是默认的，这样体验非常的差。\n提出了资源的概念，初始化后，会根据数据库中的数据生成以下资源：\n 实体资源  静态内部内资源 枚举资源   Request资源（支持多个） Response资源（支持多个） Controller资源（默认不支持覆盖） Service资源（默认不支持覆盖） Mapper资源（默认不支持覆盖）  当用户二次生成的时候，无法发现已有资源未被使用，则会呈现资源绑定页面，用于将已有的表与相应的实体进行绑定。将一组资源绑定到新的表，则这些资源的名称等都会发生变化。\n","description":"","id":920,"section":"notes","tags":null,"title":"需求分析","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/"},{"content":"好久不写泛型代码，突然会想不起来怎么写了，所以记录一下。最近开发了一个工具方法，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public class PageUtils { public static \u0026lt;T, R\u0026gt; Page\u0026lt;R\u0026gt; entityPageToResponseDataPage(Page\u0026lt;T\u0026gt; entityPage, Class\u0026lt;R\u0026gt; clazz) { return entityPageToResponseDataPage(entityPage, clazz, null); } public static \u0026lt;T, R\u0026gt; Page\u0026lt;R\u0026gt; entityPageToResponseDataPage(Page\u0026lt;T\u0026gt; entityPage, Class\u0026lt;R\u0026gt; clazz, BiConsumer\u0026lt;T, R\u0026gt; disposer) { List\u0026lt;R\u0026gt; pageRecords = new ArrayList\u0026lt;\u0026gt;(); for (T record : entityPage.getRecords()) { R pateRecordItem = BeanUtil.copyProperties(record, clazz); if (disposer != null) { disposer.accept(record, pateRecordItem); } pageRecords.add(pateRecordItem); } Page\u0026lt;R\u0026gt; result = new Page\u0026lt;\u0026gt;(); BeanUtils.copyProperties(entityPage, result); result.setRecords(pageRecords); return result; } }   应用场景是这样的，我们分页查询时用的是实体，但是返回给前端时用的是DTO，所以需要进行一些转换工作，这个类就是帮忙快速转换的。\n参考资料  JAVA——泛型类和泛型方法（静态方法泛型）  ","description":"","id":921,"section":"notes","tags":null,"title":"静态泛型方法","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/java/%E9%9D%99%E6%80%81%E6%B3%9B%E5%9E%8B%E6%96%B9%E6%B3%95/"},{"content":"Room可以是非线程安全的，只要将它相关的所有Channel都注册到同一个EventLoop即可。因为在一个EventLoop中永远是单线程运行的，所以就不必担心并发问题。\n如果Netty不支持切换EventLoop（我目前还不知道可不可以切换），那么这个工作移动到协商的过程中。协商好了，大家链接到同一个逻辑服的时候，并且这些Channel注册到同一个EventLoop中（这个应该可以通过开发针对ServerChannel的ChannelHandler实现）。\n这样的技术方案是没有考虑Disruptor的，因为Disruptor会带来新的线程组。如果一个Room中的事件需要在disruptorThreadGroup中进行处理，则其又需要考虑线程安全的问题。\nDisruptor的引入到底有没有必要，取决是Room中操作的逻辑会不会很复杂，如果复杂的话，则运行时间就会比较长，可能在Disruptor中运行会更好一点，否则的话，可以考虑不使用Disruptor。\n（如果是我，我前期可能不会引入Disruptor，而是通过Netty原生的东西实现一些功能，这样会更简单一些。）\n","description":"","id":922,"section":"notes","tags":null,"title":"非线程安全的Room在什么情况下可以存在","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/netty/%E9%9D%9E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84room%E5%9C%A8%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8B%E5%8F%AF%E4%BB%A5%E5%AD%98%E5%9C%A8/"},{"content":"数据源：\nJList\ntype: fixed、get、post\n下拉框组件设计 数据源：\ndropDownValues: JList\n属性绑定：\noutput: JString\n组件说明：\n从该组件拖动到表单编排器的编辑区域时，需要在右侧配置dropDownValues，该值必须为JList类型。该组件会将值写到output所绑定的属性中，然后通过请求发送给后端。\n这一部分是为了进一步阐述我在动态表单设计中提到的组件面向数据源编程。数据源这个概念的提出，是考虑了这么一个场景：有些时候一个组件中会写死一些内容，而有时候这些数据是从服务器动态获取的，前端需要提高一个组件的复用性，那他就不应该假设这个数据是写死的或者是从服务器获取的，他面向的始终是一个叫做数据源的数据结构。\n先举一个例子，说明下数据源是怎样的一个存在吧。在不使用数据源的情况下，我们做一个下拉菜单的伪代码可能是这样的：\n # 写死的数据 组件被点击时： 使用一个数组渲染下拉框 # 从服务器获取数据 组件被点击时： 从服务器获取数据： 回调中渲染下拉框 这个功能的具体实现可能是页面在加载组件的时候，就通过写死的方式，或者通过链接获取到了一个数组，然后都走的是当组件被点击时，通过数组渲染下拉框。我之所以要将案例设计成在组件被点击时，再发送服务器请求获取数组，是因为在我们生产场景中，我们是存在用户往下滚动，然后加载更多数据的设计。\n如果使用数据源，相应的代码又是怎样的呢：\n # 写死的数据 组件被点击时： 数组 = 数据源.getAll() 使用一个数组渲染下拉框 # 从服务器获取数据 组件被点击时： 数组 = 数据源.getAll() 使用一个数组渲染下拉框 有没有发现两种写法是完全一致的，这就是我想达到的目标。数据源本身就是一种数据结构，它是我们表单框架里重要的一部分（具体实现，我有些自己的想法，这个稍后再谈）。我们用数据源来描述下稍微复杂点的需求如何实现，这个需求大概是这样的，用户点开下拉框后，先显示20条数据，用户往下拖动到底部的时候，会继续加载10条数据。\n # 写死的数据 组件被点击时： 渲染数组 = 数据源.get(20) 使用一个数组渲染下拉框 当组件滚动时： 新的数组 = 数据源.next(10) 渲染数组.append(新的数组) 使用渲染数组渲染下拉框 # 从服务器获取数据 组件被点击时： 渲染数组 = 数据源.get(20) 使用一个数组渲染下拉框 当组件滚动时： 新的数组 = 数据源.next(10) 渲染数组.append(新的数组) 使用渲染数组渲染下拉框 实际上我没有系统的学习过前端组件的开发，我并不知道我的设计是否正确。\n我对数据源的设计是，将数据源包装成我们JavaScript中常用的容器类型，比如包装成一个map，如果数据是写死的，那么这个map中的数据也是固定的，如果数据是需要从服务端获取的，那么这个map的get操作会自动拼接出请求，从而从服务端获取数据。如何实现异步效果呢？我不知道js中的原生容器是否支持异步，如果支持，会使用相同的包装方法，如果不支持，则可能会设计新的方法。\n当前，参考以前的表单实现，我们也能够得到一些数据结构。并对这些数据结构进行整理，从而总结出我们自己需要的数据结构。\n","description":"","id":923,"section":"notes","tags":null,"title":"面向数据源的编程","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E6%8A%80%E6%9C%AF/%E4%BD%9C%E5%BA%9F/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95/%E6%80%9D%E8%B7%AF%E6%96%87%E6%A1%A3%E6%95%B4%E7%90%86/%E9%9D%A2%E5%90%91%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84%E7%BC%96%E7%A8%8B/"},{"content":"我注意到我们的starter-parent配置中有如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources/\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;!--先排除所有的配置文件--\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;application*.yml\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;!--引入所需环境的配置文件--\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;application.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;application-${spring.profiles.active}.yml\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;   这段配置是说，当我们打包处理资源文件时我们先不包含所有的application*.yml文件。然后application.yml文件，及application-${spring.profiles.active}.yml文件。\n这段配置完全没有存在的必要，主要有一下的原因：\n SpringBoot打包插件默认开启过滤器，会对进行@@字符串过滤的处理。 我们项目中使用的是bootstrap.properties和bootstrap-xxx.yml，所以这个配置完全起不到任何作用  ","description":"","id":924,"section":"notes","tags":null,"title":"项目中starter-parent中可以优化的点","uri":"http://junjie2018.github.io/notes/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/maven/profile/%E9%A1%B9%E7%9B%AE%E4%B8%ADstarter-parent%E4%B8%AD%E5%8F%AF%E4%BB%A5%E4%BC%98%E5%8C%96%E7%9A%84%E7%82%B9/"}]